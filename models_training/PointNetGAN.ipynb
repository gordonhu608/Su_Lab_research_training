{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d4444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os \n",
    "from tqdm.notebook import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c6e27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirt = 'shape_net_core_uniform_samples_2048/'\n",
    "folders = os.listdir(dirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb735a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for fold in folders:\n",
    "    direc = dirt + fold\n",
    "    for file in os.listdir(direc):\n",
    "        files.append(direc + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251ac00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57449"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "119ccc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shape_net_core_uniform_samples_2048/02691156/10155655850468db78d106ce0a280f87.ply'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b7aba444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .ply file\n",
    "input_file = files[10]\n",
    "pcd = o3d.io.read_point_cloud(input_file) # Read the point cloud\n",
    "\n",
    "# Visualize the point cloud within open3d\n",
    "o3d.visualization.draw_geometries([pcd]) \n",
    "\n",
    "# Convert open3d format to numpy array\n",
    "# Here, you have the point cloud in numpy format. \n",
    "point_cloud_in_numpy = np.asarray(pcd.points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd1661be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10635921,  0.06259143, -0.11650325],\n",
       "       [-0.10808733,  0.05918296, -0.11650223],\n",
       "       [-0.10937055,  0.07403795, -0.11650145],\n",
       "       ...,\n",
       "       [-0.44566393, -0.17004111,  0.11348417],\n",
       "       [-0.4493975 , -0.17151845,  0.11460905],\n",
       "       [-0.45363909,  0.17140326,  0.11650325]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_cloud_in_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb9f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pts = []\n",
    "        for input_file in tqdm(files):\n",
    "            pcd = o3d.io.read_point_cloud(input_file)\n",
    "            point_cloud_in_numpy = np.asarray(pcd.points) \n",
    "            pts.append(point_cloud_in_numpy)\n",
    "            \n",
    "        #maxlen = max([len(x) for x in pts])\n",
    "        #pad_pts = np.zeros((len(pts), maxlen, 3))\n",
    "            \n",
    "        self.pts = pts\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pts)\n",
    "    def __getitem__(self, idx):\n",
    "        pts = self.pts[idx]\n",
    "        pts = torch.tensor(pts.T).float().contiguous()\n",
    "        return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb813b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from PointNetGAN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39c02ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de52166bcc164dda8edf806cb4048c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = TrainDataset()\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a21b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d9ad34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2048])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf61da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e305d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_chamfer(xyz1, xyz2):\n",
    "    xyz1 = xyz1.permute(0, 2, 1)\n",
    "    xyz2 = xyz2.permute(0, 2, 1)\n",
    "    distance = torch.cdist(xyz1, xyz2)\n",
    "    dist1, idx1 = distance.min(2)\n",
    "    dist2, idx2 = distance.min(1)\n",
    "    loss = (dist1 ** 2).mean() + (dist2 ** 2).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0867a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1, idx1, dist2, idx2 = chamfer_distance(src.unsqueeze(0), tgt.unsqueeze(0))\n",
    "# loss = dist1.mean() + dist2.mean()\n",
    "loss = (dist1 ** 2).mean() + (dist2 ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efc865b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.034281112253665924,\n",
       " 0.040341414511203766,\n",
       " 0.0397404208779335,\n",
       " 0.04547237232327461,\n",
       " 0.046153292059898376]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b3957b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12878865141727674"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_metric[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68edd340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.562645170889525,\n",
       " 0.900783295252861,\n",
       " 0.7179492243817258,\n",
       " 0.6486176861693932,\n",
       " 0.6220264026381511,\n",
       " 0.5778169152962465,\n",
       " 0.527606252093169,\n",
       " 0.4604400806855358,\n",
       " 0.4179270237186161,\n",
       " 0.3877804005378468,\n",
       " 0.3956445123076771,\n",
       " 0.3519543801592585,\n",
       " 0.3246562622233312,\n",
       " 0.2685956906055134,\n",
       " 0.16303758530340529,\n",
       " 0.22369547342767415,\n",
       " -0.06466052273267615,\n",
       " -0.5278507889453373,\n",
       " -0.7749239769543737,\n",
       " 0.44411890549081945]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80f82310",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = gen\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (imgs) in enumerate(train_loader):\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (32, 128))))\n",
    "        fake_imgs = generator(z)\n",
    "        break\n",
    "    metric = evaluate_chamfer(real_imgs, fake_imgs)\n",
    "    generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b59dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz1 = real_imgs\n",
    "xyz2 =fake_imgs\n",
    "distance = torch.cdist(xyz1, xyz2)\n",
    "dist1, idx1 = distance.min(2)\n",
    "dist2, idx2 = distance.min(1)\n",
    "loss = (dist1 ** 2).mean() + (dist2 ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f0dd57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(212.6685, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71f3322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0347, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "599676f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04104997590184212"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec4dd6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.49000755100407534,\n",
       " -0.009468605200850612,\n",
       " -0.02194154486318843,\n",
       " -0.048104785403443706,\n",
       " -0.04740284590257539,\n",
       " -0.03603882079737054,\n",
       " -0.040245410880177385,\n",
       " -0.043948019673633903,\n",
       " 0.0008668985683470964,\n",
       " -0.05628052438971483,\n",
       " -0.7757951567570368,\n",
       " -1.6108279943466186,\n",
       " -3.017255633407169,\n",
       " -3.6930554681354097,\n",
       " -3.7768773555755617,\n",
       " -6.686784185303582,\n",
       " -12.235858350329929,\n",
       " -15.29523401260376,\n",
       " -15.274354320102267,\n",
       " -10.244890133539835,\n",
       " -5.836242448786894,\n",
       " -2.4515038874414232,\n",
       " 0.2048629093501303,\n",
       " 6.968668101231257,\n",
       " 15.522910300890604,\n",
       " 16.41706007056766,\n",
       " 16.052669774161444,\n",
       " 15.656219658586714,\n",
       " 13.768474777539572,\n",
       " 9.874130595723788,\n",
       " 2.1358176979753707,\n",
       " 0.8243151863416036,\n",
       " -1.0084337830543517,\n",
       " -2.157898447248671,\n",
       " -0.4445760687192281,\n",
       " 4.463985275559955,\n",
       " 6.225847208499909,\n",
       " 16.68866632911894,\n",
       " 22.19987750980589,\n",
       " 29.300741457939147,\n",
       " 31.208191294140285,\n",
       " 30.182671615812513,\n",
       " 33.536974843343096,\n",
       " 38.190496905644736,\n",
       " 50.38305331336127,\n",
       " 43.08859338760376,\n",
       " 41.41893367767334,\n",
       " 34.98719613817003,\n",
       " 27.702551595369975,\n",
       " 10.631710537274678]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06a985ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(Tensor(np.random.normal(0, 1, (32, 128))))\n",
    "generated_pcd = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5533ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = generated_pcd[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f41a0473",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = generated_pcd[10]\n",
    "points = pcd.permute(1,0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7d76eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f93ac7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd  = o3d.geometry.PointCloud()\n",
    "points = o3d.utility.Vector3dVector(points) \n",
    "pcd.points = points\n",
    "# Visualize the point cloud within open3d\n",
    "o3d.visualization.draw_geometries([pcd]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9076bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8755f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636a4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2efdeb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99817ab84fe4ce1b97afe5cee0dc2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0: 0/1795] train lossD: 3.371928 lossG: 0.491549\n",
      "[0: 5/1795] train lossD: -0.340641 lossG: 0.484702\n",
      "[0: 10/1795] train lossD: -0.170919 lossG: 1.148336\n",
      "[0: 15/1795] train lossD: -0.220001 lossG: 1.490112\n",
      "[0: 20/1795] train lossD: -0.384851 lossG: 0.939465\n",
      "[0: 25/1795] train lossD: -0.458481 lossG: 1.281631\n",
      "[0: 30/1795] train lossD: -0.529572 lossG: 1.424161\n",
      "[0: 35/1795] train lossD: -0.533533 lossG: 1.509425\n",
      "[0: 40/1795] train lossD: 0.128809 lossG: 0.169563\n",
      "[0: 45/1795] train lossD: 0.021605 lossG: 1.456745\n",
      "[0: 50/1795] train lossD: -0.638828 lossG: 2.023964\n",
      "[0: 55/1795] train lossD: -0.794438 lossG: 2.552546\n",
      "[0: 60/1795] train lossD: -0.840939 lossG: 1.806798\n",
      "[0: 65/1795] train lossD: -0.870644 lossG: 2.019814\n",
      "[0: 70/1795] train lossD: -0.257118 lossG: 0.519526\n",
      "[0: 75/1795] train lossD: -0.070141 lossG: 0.905566\n",
      "[0: 80/1795] train lossD: -0.524901 lossG: 1.840304\n",
      "[0: 85/1795] train lossD: 0.334472 lossG: 0.657134\n",
      "[0: 90/1795] train lossD: -0.708794 lossG: 1.968932\n",
      "[0: 95/1795] train lossD: -0.868862 lossG: 2.037119\n",
      "[0: 100/1795] train lossD: -0.905040 lossG: 2.455938\n",
      "[0: 105/1795] train lossD: -0.950023 lossG: 2.506513\n",
      "[0: 110/1795] train lossD: -0.672333 lossG: 2.800550\n",
      "[0: 115/1795] train lossD: -0.764155 lossG: 2.421867\n",
      "[0: 120/1795] train lossD: -0.607934 lossG: 1.283014\n",
      "[0: 125/1795] train lossD: -0.672660 lossG: 1.775547\n",
      "[0: 130/1795] train lossD: -0.936681 lossG: 2.008229\n",
      "[0: 135/1795] train lossD: -0.844601 lossG: 2.203375\n",
      "[0: 140/1795] train lossD: -0.661602 lossG: 1.807258\n",
      "[0: 145/1795] train lossD: -0.814441 lossG: 2.328045\n",
      "[0: 150/1795] train lossD: -0.752702 lossG: 3.009949\n",
      "[0: 155/1795] train lossD: -0.945701 lossG: 3.209782\n",
      "[0: 160/1795] train lossD: -0.674505 lossG: 3.145906\n",
      "[0: 165/1795] train lossD: -0.954708 lossG: 3.171134\n",
      "[0: 170/1795] train lossD: -1.157226 lossG: 3.298277\n",
      "[0: 175/1795] train lossD: -1.028252 lossG: 3.298079\n",
      "[0: 180/1795] train lossD: -0.920630 lossG: 2.722600\n",
      "[0: 185/1795] train lossD: -1.151594 lossG: 3.113168\n",
      "[0: 190/1795] train lossD: -0.107782 lossG: 3.222191\n",
      "[0: 195/1795] train lossD: -0.464656 lossG: 3.397302\n",
      "[0: 200/1795] train lossD: -1.107239 lossG: 3.203096\n",
      "[0: 205/1795] train lossD: -0.591402 lossG: 2.524504\n",
      "[0: 210/1795] train lossD: -1.069598 lossG: 3.218012\n",
      "[0: 215/1795] train lossD: -1.079284 lossG: 3.240725\n",
      "[0: 220/1795] train lossD: -1.286640 lossG: 3.687769\n",
      "[0: 225/1795] train lossD: -0.651286 lossG: 3.939473\n",
      "[0: 230/1795] train lossD: -0.972044 lossG: 2.863544\n",
      "[0: 235/1795] train lossD: -1.047714 lossG: 3.297146\n",
      "[0: 240/1795] train lossD: -1.315206 lossG: 4.058301\n",
      "[0: 245/1795] train lossD: -0.862358 lossG: 2.759151\n",
      "[0: 250/1795] train lossD: -0.726758 lossG: 3.013341\n",
      "[0: 255/1795] train lossD: -0.955816 lossG: 3.064315\n",
      "[0: 260/1795] train lossD: -0.782441 lossG: 2.491573\n",
      "[0: 265/1795] train lossD: -1.035485 lossG: 3.075939\n",
      "[0: 270/1795] train lossD: -0.748740 lossG: 2.246806\n",
      "[0: 275/1795] train lossD: -0.825452 lossG: 2.457978\n",
      "[0: 280/1795] train lossD: -0.901621 lossG: 2.481035\n",
      "[0: 285/1795] train lossD: -0.782222 lossG: 2.821615\n",
      "[0: 290/1795] train lossD: -0.783187 lossG: 2.043127\n",
      "[0: 295/1795] train lossD: -0.715761 lossG: 2.631742\n",
      "[0: 300/1795] train lossD: -0.811015 lossG: 2.046110\n",
      "[0: 305/1795] train lossD: -0.636615 lossG: 1.625453\n",
      "[0: 310/1795] train lossD: -0.509528 lossG: 1.360939\n",
      "[0: 315/1795] train lossD: -0.638426 lossG: 1.658812\n",
      "[0: 320/1795] train lossD: -0.537679 lossG: 1.343789\n",
      "[0: 325/1795] train lossD: -0.564238 lossG: 1.600194\n",
      "[0: 330/1795] train lossD: -0.634199 lossG: 1.822287\n",
      "[0: 335/1795] train lossD: 0.072719 lossG: 0.887221\n",
      "[0: 340/1795] train lossD: 0.015258 lossG: 0.977539\n",
      "[0: 345/1795] train lossD: -0.519656 lossG: 1.313952\n",
      "[0: 350/1795] train lossD: -0.500232 lossG: 0.963233\n",
      "[0: 355/1795] train lossD: -0.568816 lossG: 1.313824\n",
      "[0: 360/1795] train lossD: -0.286380 lossG: 0.760177\n",
      "[0: 365/1795] train lossD: 0.060227 lossG: 0.491715\n",
      "[0: 370/1795] train lossD: -0.558384 lossG: 1.045038\n",
      "[0: 375/1795] train lossD: -0.532307 lossG: 1.146177\n",
      "[0: 380/1795] train lossD: -0.478999 lossG: 0.585133\n",
      "[0: 385/1795] train lossD: -0.451962 lossG: 0.792044\n",
      "[0: 390/1795] train lossD: -0.626911 lossG: 1.053521\n",
      "[0: 395/1795] train lossD: -0.784382 lossG: 1.384560\n",
      "[0: 400/1795] train lossD: -0.842431 lossG: 1.615961\n",
      "[0: 405/1795] train lossD: 0.252185 lossG: 0.628406\n",
      "[0: 410/1795] train lossD: -0.784735 lossG: 1.120127\n",
      "[0: 415/1795] train lossD: -0.610759 lossG: 1.643784\n",
      "[0: 420/1795] train lossD: -1.018793 lossG: 1.863213\n",
      "[0: 425/1795] train lossD: -0.576165 lossG: 1.963584\n",
      "[0: 430/1795] train lossD: -1.259107 lossG: 2.556636\n",
      "[0: 435/1795] train lossD: 0.204154 lossG: 1.238680\n",
      "[0: 440/1795] train lossD: -0.489348 lossG: 1.453948\n",
      "[0: 445/1795] train lossD: -0.617584 lossG: 1.925967\n",
      "[0: 450/1795] train lossD: -1.140572 lossG: 2.023932\n",
      "[0: 455/1795] train lossD: -1.081058 lossG: 2.150269\n",
      "[0: 460/1795] train lossD: -1.165363 lossG: 2.287116\n",
      "[0: 465/1795] train lossD: -1.137742 lossG: 2.628260\n",
      "[0: 470/1795] train lossD: -1.384002 lossG: 2.305669\n",
      "[0: 475/1795] train lossD: -0.364758 lossG: 1.217743\n",
      "[0: 480/1795] train lossD: -0.770412 lossG: 1.518728\n",
      "[0: 485/1795] train lossD: -0.652588 lossG: 2.426148\n",
      "[0: 490/1795] train lossD: -1.085463 lossG: 2.116028\n",
      "[0: 495/1795] train lossD: -0.859052 lossG: 1.240344\n",
      "[0: 500/1795] train lossD: -0.872165 lossG: 1.217541\n",
      "[0: 505/1795] train lossD: -0.713480 lossG: 2.069348\n",
      "[0: 510/1795] train lossD: -0.758300 lossG: 1.345550\n",
      "[0: 515/1795] train lossD: -0.844587 lossG: 1.299153\n",
      "[0: 520/1795] train lossD: -0.695342 lossG: 1.040385\n",
      "[0: 525/1795] train lossD: -0.842247 lossG: 1.453619\n",
      "[0: 530/1795] train lossD: -0.696601 lossG: 1.315235\n",
      "[0: 535/1795] train lossD: -0.908984 lossG: 1.203555\n",
      "[0: 540/1795] train lossD: -0.739523 lossG: 0.795852\n",
      "[0: 545/1795] train lossD: -0.314568 lossG: 0.160709\n",
      "[0: 550/1795] train lossD: -0.892489 lossG: 1.623216\n",
      "[0: 555/1795] train lossD: -0.827329 lossG: 1.148287\n",
      "[0: 560/1795] train lossD: -0.862465 lossG: 1.553081\n",
      "[0: 565/1795] train lossD: -1.098717 lossG: 1.829238\n",
      "[0: 570/1795] train lossD: -1.088295 lossG: 2.129004\n",
      "[0: 575/1795] train lossD: -0.420510 lossG: 1.533938\n",
      "[0: 580/1795] train lossD: -1.269855 lossG: 1.996059\n",
      "[0: 585/1795] train lossD: -0.204557 lossG: 1.344242\n",
      "[0: 590/1795] train lossD: -1.455641 lossG: 2.281986\n",
      "[0: 595/1795] train lossD: -0.954754 lossG: 1.529972\n",
      "[0: 600/1795] train lossD: -1.231384 lossG: 1.923002\n",
      "[0: 605/1795] train lossD: -1.344113 lossG: 1.695776\n",
      "[0: 610/1795] train lossD: -0.742279 lossG: 1.491576\n",
      "[0: 615/1795] train lossD: -1.048226 lossG: 1.496296\n",
      "[0: 620/1795] train lossD: -1.001371 lossG: 1.754680\n",
      "[0: 625/1795] train lossD: -0.751000 lossG: 1.299909\n",
      "[0: 630/1795] train lossD: -1.128916 lossG: 1.670854\n",
      "[0: 635/1795] train lossD: -1.069812 lossG: 1.483807\n",
      "[0: 640/1795] train lossD: -0.317136 lossG: 1.744220\n",
      "[0: 645/1795] train lossD: -0.458633 lossG: 2.119984\n",
      "[0: 650/1795] train lossD: -0.684031 lossG: 0.806816\n",
      "[0: 655/1795] train lossD: -0.899697 lossG: 1.341998\n",
      "[0: 660/1795] train lossD: -0.611143 lossG: 1.094032\n",
      "[0: 665/1795] train lossD: -0.840332 lossG: 1.107943\n",
      "[0: 670/1795] train lossD: -0.381889 lossG: 0.609565\n",
      "[0: 675/1795] train lossD: -0.739385 lossG: 0.773215\n",
      "[0: 680/1795] train lossD: -0.790590 lossG: 0.808776\n",
      "[0: 685/1795] train lossD: -0.835737 lossG: 1.210884\n",
      "[0: 690/1795] train lossD: -0.810943 lossG: 1.095937\n",
      "[0: 695/1795] train lossD: -0.765527 lossG: 0.915489\n",
      "[0: 700/1795] train lossD: -0.711818 lossG: 1.321602\n",
      "[0: 705/1795] train lossD: -0.811022 lossG: 0.918707\n",
      "[0: 710/1795] train lossD: -0.853080 lossG: 1.227403\n",
      "[0: 715/1795] train lossD: -0.777211 lossG: 1.325617\n",
      "[0: 720/1795] train lossD: -0.830548 lossG: 1.861418\n",
      "[0: 725/1795] train lossD: -0.465078 lossG: 1.027764\n",
      "[0: 730/1795] train lossD: -0.825552 lossG: 1.370926\n",
      "[0: 735/1795] train lossD: -0.735632 lossG: 1.444818\n",
      "[0: 740/1795] train lossD: -0.860517 lossG: 1.097989\n",
      "[0: 745/1795] train lossD: -0.630550 lossG: 0.904179\n",
      "[0: 750/1795] train lossD: -0.842861 lossG: 1.104596\n",
      "[0: 755/1795] train lossD: -0.560573 lossG: 1.359216\n",
      "[0: 760/1795] train lossD: -0.854033 lossG: 1.223107\n",
      "[0: 765/1795] train lossD: -0.454537 lossG: 1.549050\n",
      "[0: 770/1795] train lossD: -0.633841 lossG: 1.143336\n",
      "[0: 775/1795] train lossD: -0.593968 lossG: 0.781774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0: 780/1795] train lossD: -0.430038 lossG: 1.325595\n",
      "[0: 785/1795] train lossD: -0.743533 lossG: 1.246795\n",
      "[0: 790/1795] train lossD: 0.229032 lossG: 0.872548\n",
      "[0: 795/1795] train lossD: -0.686428 lossG: 0.929610\n",
      "[0: 800/1795] train lossD: 0.001197 lossG: 0.628793\n",
      "[0: 805/1795] train lossD: -0.526242 lossG: 1.311770\n",
      "[0: 810/1795] train lossD: -0.612677 lossG: 1.296131\n",
      "[0: 815/1795] train lossD: -0.408852 lossG: 1.379410\n",
      "[0: 820/1795] train lossD: -0.552614 lossG: 1.379232\n",
      "[0: 825/1795] train lossD: -0.297291 lossG: 1.501062\n",
      "[0: 830/1795] train lossD: -0.602518 lossG: 0.882540\n",
      "[0: 835/1795] train lossD: -0.642057 lossG: 0.868655\n",
      "[0: 840/1795] train lossD: -0.279704 lossG: 0.757612\n",
      "[0: 845/1795] train lossD: -0.566835 lossG: 1.010291\n",
      "[0: 850/1795] train lossD: -0.281643 lossG: 1.161015\n",
      "[0: 855/1795] train lossD: -0.372771 lossG: 1.092130\n",
      "[0: 860/1795] train lossD: -0.451295 lossG: 1.403988\n",
      "[0: 865/1795] train lossD: -0.124796 lossG: 0.931784\n",
      "[0: 870/1795] train lossD: -0.522037 lossG: 1.075560\n",
      "[0: 875/1795] train lossD: -0.453808 lossG: 1.118850\n",
      "[0: 880/1795] train lossD: -0.272904 lossG: 0.661474\n",
      "[0: 885/1795] train lossD: -0.050602 lossG: 0.769707\n",
      "[0: 890/1795] train lossD: -0.421482 lossG: 1.196969\n",
      "[0: 895/1795] train lossD: -0.220316 lossG: 1.016225\n",
      "[0: 900/1795] train lossD: -0.291441 lossG: 1.077234\n",
      "[0: 905/1795] train lossD: -0.651583 lossG: 1.543566\n",
      "[0: 910/1795] train lossD: -0.314990 lossG: 0.938895\n",
      "[0: 915/1795] train lossD: -0.395788 lossG: 1.070751\n",
      "[0: 920/1795] train lossD: -0.160165 lossG: 1.151087\n",
      "[0: 925/1795] train lossD: -0.603566 lossG: 1.607665\n",
      "[0: 930/1795] train lossD: -0.421554 lossG: 1.521939\n",
      "[0: 935/1795] train lossD: -0.334302 lossG: 0.922120\n",
      "[0: 940/1795] train lossD: -0.413115 lossG: 1.424213\n",
      "[0: 945/1795] train lossD: -0.164038 lossG: 0.997385\n",
      "[0: 950/1795] train lossD: -0.334506 lossG: 1.274071\n",
      "[0: 955/1795] train lossD: -0.477411 lossG: 1.205259\n",
      "[0: 960/1795] train lossD: -0.065987 lossG: 0.902276\n",
      "[0: 965/1795] train lossD: -0.404080 lossG: 1.598053\n",
      "[0: 970/1795] train lossD: -0.157917 lossG: 1.104931\n",
      "[0: 975/1795] train lossD: -0.228481 lossG: 0.909933\n",
      "[0: 980/1795] train lossD: -0.329906 lossG: 1.165983\n",
      "[0: 985/1795] train lossD: -0.393750 lossG: 0.988813\n",
      "[0: 990/1795] train lossD: -0.413287 lossG: 0.785979\n",
      "[0: 995/1795] train lossD: -0.261011 lossG: 1.331634\n",
      "[0: 1000/1795] train lossD: -0.243544 lossG: 1.021634\n",
      "[0: 1005/1795] train lossD: -0.353855 lossG: 0.874778\n",
      "[0: 1010/1795] train lossD: -0.412398 lossG: 1.100784\n",
      "[0: 1015/1795] train lossD: -0.491931 lossG: 1.205530\n",
      "[0: 1020/1795] train lossD: -0.354643 lossG: 1.217054\n",
      "[0: 1025/1795] train lossD: -0.354495 lossG: 1.281859\n",
      "[0: 1030/1795] train lossD: -0.410602 lossG: 1.354162\n",
      "[0: 1035/1795] train lossD: -0.329163 lossG: 1.125887\n",
      "[0: 1040/1795] train lossD: -0.360800 lossG: 1.081322\n",
      "[0: 1045/1795] train lossD: -0.322844 lossG: 1.339599\n",
      "[0: 1050/1795] train lossD: -0.382751 lossG: 0.927927\n",
      "[0: 1055/1795] train lossD: -0.451154 lossG: 1.194367\n",
      "[0: 1060/1795] train lossD: 0.031929 lossG: 0.777816\n",
      "[0: 1065/1795] train lossD: -0.417163 lossG: 1.482713\n",
      "[0: 1070/1795] train lossD: -0.300111 lossG: 1.515109\n",
      "[0: 1075/1795] train lossD: -0.319958 lossG: 1.606639\n",
      "[0: 1080/1795] train lossD: -0.385463 lossG: 1.160259\n",
      "[0: 1085/1795] train lossD: -0.358622 lossG: 1.644862\n",
      "[0: 1090/1795] train lossD: -0.491885 lossG: 1.396275\n",
      "[0: 1095/1795] train lossD: -0.484676 lossG: 1.171912\n",
      "[0: 1100/1795] train lossD: -0.455517 lossG: 1.240329\n",
      "[0: 1105/1795] train lossD: -0.505566 lossG: 1.083760\n",
      "[0: 1110/1795] train lossD: -0.329852 lossG: 1.113146\n",
      "[0: 1115/1795] train lossD: 0.049656 lossG: 1.139840\n",
      "[0: 1120/1795] train lossD: -0.444324 lossG: 1.575977\n",
      "[0: 1125/1795] train lossD: -0.141100 lossG: 1.382667\n",
      "[0: 1130/1795] train lossD: -0.475036 lossG: 1.126444\n",
      "[0: 1135/1795] train lossD: -0.279928 lossG: 1.155070\n",
      "[0: 1140/1795] train lossD: -0.548854 lossG: 1.185210\n",
      "[0: 1145/1795] train lossD: -0.414647 lossG: 1.113528\n",
      "[0: 1150/1795] train lossD: -0.287492 lossG: 1.038286\n",
      "[0: 1155/1795] train lossD: -0.476799 lossG: 1.051748\n",
      "[0: 1160/1795] train lossD: -0.517265 lossG: 1.365484\n",
      "[0: 1165/1795] train lossD: -0.409489 lossG: 1.285705\n",
      "[0: 1170/1795] train lossD: -0.494858 lossG: 1.114477\n",
      "[0: 1175/1795] train lossD: -0.387908 lossG: 1.089793\n",
      "[0: 1180/1795] train lossD: -0.367130 lossG: 1.127136\n",
      "[0: 1185/1795] train lossD: -0.202212 lossG: 1.394820\n",
      "[0: 1190/1795] train lossD: -0.487135 lossG: 1.325010\n",
      "[0: 1195/1795] train lossD: -0.446532 lossG: 1.454815\n",
      "[0: 1200/1795] train lossD: -0.426369 lossG: 1.821302\n",
      "[0: 1205/1795] train lossD: -0.530342 lossG: 1.616434\n",
      "[0: 1210/1795] train lossD: -0.314236 lossG: 1.650544\n",
      "[0: 1215/1795] train lossD: -0.438581 lossG: 1.353257\n",
      "[0: 1220/1795] train lossD: -0.420947 lossG: 1.340156\n",
      "[0: 1225/1795] train lossD: -0.336703 lossG: 1.301349\n",
      "[0: 1230/1795] train lossD: -0.411274 lossG: 1.079757\n",
      "[0: 1235/1795] train lossD: -0.210264 lossG: 1.403890\n",
      "[0: 1240/1795] train lossD: -0.445449 lossG: 1.631595\n",
      "[0: 1245/1795] train lossD: -0.548878 lossG: 1.374849\n",
      "[0: 1250/1795] train lossD: -0.462998 lossG: 1.316046\n",
      "[0: 1255/1795] train lossD: -0.322818 lossG: 1.114359\n",
      "[0: 1260/1795] train lossD: -0.457496 lossG: 1.306591\n",
      "[0: 1265/1795] train lossD: -0.350879 lossG: 1.253428\n",
      "[0: 1270/1795] train lossD: -0.249860 lossG: 1.646264\n",
      "[0: 1275/1795] train lossD: -0.448771 lossG: 1.173125\n",
      "[0: 1280/1795] train lossD: -0.632131 lossG: 1.434825\n",
      "[0: 1285/1795] train lossD: -0.036664 lossG: 1.262771\n",
      "[0: 1290/1795] train lossD: -0.561429 lossG: 1.704493\n",
      "[0: 1295/1795] train lossD: -0.416055 lossG: 1.366843\n",
      "[0: 1300/1795] train lossD: -0.550432 lossG: 1.275498\n",
      "[0: 1305/1795] train lossD: -0.443348 lossG: 1.274763\n",
      "[0: 1310/1795] train lossD: -0.431588 lossG: 1.462819\n",
      "[0: 1315/1795] train lossD: -0.396823 lossG: 1.610796\n",
      "[0: 1320/1795] train lossD: -0.468423 lossG: 1.191860\n",
      "[0: 1325/1795] train lossD: -0.204670 lossG: 1.219554\n",
      "[0: 1330/1795] train lossD: -0.433781 lossG: 1.359888\n",
      "[0: 1335/1795] train lossD: -0.219257 lossG: 1.021709\n",
      "[0: 1340/1795] train lossD: -0.422343 lossG: 1.190153\n",
      "[0: 1345/1795] train lossD: -0.322012 lossG: 1.219506\n",
      "[0: 1350/1795] train lossD: -0.288439 lossG: 1.214106\n",
      "[0: 1355/1795] train lossD: -0.540823 lossG: 1.494187\n",
      "[0: 1360/1795] train lossD: -0.343057 lossG: 1.353912\n",
      "[0: 1365/1795] train lossD: -0.328804 lossG: 1.628357\n",
      "[0: 1370/1795] train lossD: -0.489008 lossG: 1.336774\n",
      "[0: 1375/1795] train lossD: -0.577605 lossG: 1.313671\n",
      "[0: 1380/1795] train lossD: -0.462656 lossG: 1.587207\n",
      "[0: 1385/1795] train lossD: -0.342949 lossG: 1.317953\n",
      "[0: 1390/1795] train lossD: -0.769321 lossG: 1.605382\n",
      "[0: 1395/1795] train lossD: -0.520263 lossG: 1.349072\n",
      "[0: 1400/1795] train lossD: -0.348336 lossG: 1.573305\n",
      "[0: 1405/1795] train lossD: -0.222746 lossG: 1.853766\n",
      "[0: 1410/1795] train lossD: -0.349090 lossG: 1.417540\n",
      "[0: 1415/1795] train lossD: -0.227822 lossG: 0.804123\n",
      "[0: 1420/1795] train lossD: -0.513990 lossG: 1.199967\n",
      "[0: 1425/1795] train lossD: -0.387247 lossG: 1.428798\n",
      "[0: 1430/1795] train lossD: -0.590875 lossG: 1.134822\n",
      "[0: 1435/1795] train lossD: -0.255642 lossG: 1.042453\n",
      "[0: 1440/1795] train lossD: -0.290961 lossG: 1.190547\n",
      "[0: 1445/1795] train lossD: -0.466760 lossG: 1.332344\n",
      "[0: 1450/1795] train lossD: -0.372766 lossG: 1.047687\n",
      "[0: 1455/1795] train lossD: -0.430293 lossG: 1.409065\n",
      "[0: 1460/1795] train lossD: -0.299692 lossG: 1.000229\n",
      "[0: 1465/1795] train lossD: -0.394903 lossG: 1.290257\n",
      "[0: 1470/1795] train lossD: -0.303382 lossG: 0.945473\n",
      "[0: 1475/1795] train lossD: -0.481803 lossG: 1.177000\n",
      "[0: 1480/1795] train lossD: -0.474737 lossG: 1.199686\n",
      "[0: 1485/1795] train lossD: -0.338139 lossG: 1.154581\n",
      "[0: 1490/1795] train lossD: -0.343459 lossG: 0.990854\n",
      "[0: 1495/1795] train lossD: -0.367357 lossG: 1.147027\n",
      "[0: 1500/1795] train lossD: -0.344586 lossG: 1.168053\n",
      "[0: 1505/1795] train lossD: -0.378078 lossG: 1.319122\n",
      "[0: 1510/1795] train lossD: -0.500004 lossG: 1.013626\n",
      "[0: 1515/1795] train lossD: -0.131119 lossG: 0.882296\n",
      "[0: 1520/1795] train lossD: -0.413615 lossG: 0.925428\n",
      "[0: 1525/1795] train lossD: -0.325718 lossG: 1.023266\n",
      "[0: 1530/1795] train lossD: -0.128577 lossG: 0.873303\n",
      "[0: 1535/1795] train lossD: -0.388798 lossG: 1.192287\n",
      "[0: 1540/1795] train lossD: -0.573881 lossG: 1.336848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0: 1545/1795] train lossD: -0.354695 lossG: 1.172195\n",
      "[0: 1550/1795] train lossD: -0.084464 lossG: 1.152655\n",
      "[0: 1555/1795] train lossD: -0.507558 lossG: 1.297679\n",
      "[0: 1560/1795] train lossD: -0.122080 lossG: 0.884212\n",
      "[0: 1565/1795] train lossD: -0.423525 lossG: 1.215957\n",
      "[0: 1570/1795] train lossD: -0.355561 lossG: 1.356374\n",
      "[0: 1575/1795] train lossD: -0.343442 lossG: 1.515525\n",
      "[0: 1580/1795] train lossD: -0.543878 lossG: 1.276631\n",
      "[0: 1585/1795] train lossD: -0.488059 lossG: 1.340485\n",
      "[0: 1590/1795] train lossD: -0.501343 lossG: 1.550645\n",
      "[0: 1595/1795] train lossD: -0.354919 lossG: 1.060756\n",
      "[0: 1600/1795] train lossD: -0.358170 lossG: 1.238329\n",
      "[0: 1605/1795] train lossD: -0.480648 lossG: 0.988510\n",
      "[0: 1610/1795] train lossD: -0.487187 lossG: 1.213575\n",
      "[0: 1615/1795] train lossD: -0.433031 lossG: 0.906981\n",
      "[0: 1620/1795] train lossD: -0.324433 lossG: 0.716878\n",
      "[0: 1625/1795] train lossD: -0.299406 lossG: 0.825016\n",
      "[0: 1630/1795] train lossD: 0.103159 lossG: 0.649324\n",
      "[0: 1635/1795] train lossD: -0.420360 lossG: 1.054322\n",
      "[0: 1640/1795] train lossD: -0.449319 lossG: 1.188786\n",
      "[0: 1645/1795] train lossD: -0.359225 lossG: 1.144811\n",
      "[0: 1650/1795] train lossD: -0.466725 lossG: 1.041543\n",
      "[0: 1655/1795] train lossD: -0.415833 lossG: 1.116733\n",
      "[0: 1660/1795] train lossD: -0.411522 lossG: 0.916663\n",
      "[0: 1665/1795] train lossD: -0.339640 lossG: 1.287133\n",
      "[0: 1670/1795] train lossD: -0.254925 lossG: 1.231086\n",
      "[0: 1675/1795] train lossD: -0.318477 lossG: 0.881702\n",
      "[0: 1680/1795] train lossD: -0.339160 lossG: 0.915967\n",
      "[0: 1685/1795] train lossD: -0.439518 lossG: 0.890457\n",
      "[0: 1690/1795] train lossD: -0.423576 lossG: 0.813633\n",
      "[0: 1695/1795] train lossD: -0.426430 lossG: 0.907768\n",
      "[0: 1700/1795] train lossD: -0.159046 lossG: 0.719581\n",
      "[0: 1705/1795] train lossD: -0.288043 lossG: 0.732956\n",
      "[0: 1710/1795] train lossD: -0.391623 lossG: 0.925633\n",
      "[0: 1715/1795] train lossD: -0.144725 lossG: 0.942722\n",
      "[0: 1720/1795] train lossD: -0.331466 lossG: 0.912175\n",
      "[0: 1725/1795] train lossD: -0.329752 lossG: 1.071653\n",
      "[0: 1730/1795] train lossD: -0.346909 lossG: 1.267915\n",
      "[0: 1735/1795] train lossD: -0.383178 lossG: 1.050349\n",
      "[0: 1740/1795] train lossD: -0.449982 lossG: 1.118406\n",
      "[0: 1745/1795] train lossD: -0.360777 lossG: 1.156912\n",
      "[0: 1750/1795] train lossD: -0.440917 lossG: 0.925831\n",
      "[0: 1755/1795] train lossD: -0.511263 lossG: 1.112851\n",
      "[0: 1760/1795] train lossD: -0.240645 lossG: 0.905420\n",
      "[0: 1765/1795] train lossD: -0.540473 lossG: 1.215292\n",
      "[0: 1770/1795] train lossD: -0.447732 lossG: 1.202461\n",
      "[0: 1775/1795] train lossD: -0.188429 lossG: 0.814194\n",
      "[0: 1780/1795] train lossD: -0.461976 lossG: 0.929962\n",
      "[0: 1785/1795] train lossD: -0.282379 lossG: 0.885751\n",
      "[0: 1790/1795] train lossD: -0.445482 lossG: 1.021241\n",
      "0.04706810414791107\n",
      "[1: 0/1795] train lossD: -0.334671 lossG: 0.884023\n",
      "[1: 5/1795] train lossD: -0.390436 lossG: 0.762255\n",
      "[1: 10/1795] train lossD: -0.197361 lossG: 0.872573\n",
      "[1: 15/1795] train lossD: -0.356635 lossG: 0.780470\n",
      "[1: 20/1795] train lossD: -0.400410 lossG: 0.657732\n",
      "[1: 25/1795] train lossD: -0.504562 lossG: 0.811722\n",
      "[1: 30/1795] train lossD: -0.316320 lossG: 0.661791\n",
      "[1: 35/1795] train lossD: -0.213037 lossG: 0.948337\n",
      "[1: 40/1795] train lossD: -0.369006 lossG: 1.007524\n",
      "[1: 45/1795] train lossD: -0.359423 lossG: 1.204200\n",
      "[1: 50/1795] train lossD: -0.460509 lossG: 1.085034\n",
      "[1: 55/1795] train lossD: -0.279507 lossG: 1.036697\n",
      "[1: 60/1795] train lossD: -0.360637 lossG: 1.091724\n",
      "[1: 65/1795] train lossD: -0.485120 lossG: 1.182892\n",
      "[1: 70/1795] train lossD: -0.371138 lossG: 1.009083\n",
      "[1: 75/1795] train lossD: -0.440282 lossG: 0.827970\n",
      "[1: 80/1795] train lossD: -0.347637 lossG: 0.850853\n",
      "[1: 85/1795] train lossD: -0.303034 lossG: 0.795610\n",
      "[1: 90/1795] train lossD: -0.474189 lossG: 0.949425\n",
      "[1: 95/1795] train lossD: -0.387247 lossG: 0.854402\n",
      "[1: 100/1795] train lossD: -0.138651 lossG: 0.785574\n",
      "[1: 105/1795] train lossD: -0.220859 lossG: 0.704063\n",
      "[1: 110/1795] train lossD: -0.371893 lossG: 0.892461\n",
      "[1: 115/1795] train lossD: -0.359078 lossG: 0.933092\n",
      "[1: 120/1795] train lossD: -0.144838 lossG: 1.180700\n",
      "[1: 125/1795] train lossD: -0.388650 lossG: 0.780199\n",
      "[1: 130/1795] train lossD: -0.317430 lossG: 0.847452\n",
      "[1: 135/1795] train lossD: -0.427800 lossG: 0.934193\n",
      "[1: 140/1795] train lossD: -0.338511 lossG: 0.734259\n",
      "[1: 145/1795] train lossD: -0.416818 lossG: 1.036601\n",
      "[1: 150/1795] train lossD: -0.265445 lossG: 0.660843\n",
      "[1: 155/1795] train lossD: -0.401226 lossG: 0.922590\n",
      "[1: 160/1795] train lossD: -0.275312 lossG: 0.946106\n",
      "[1: 165/1795] train lossD: -0.313907 lossG: 0.680308\n",
      "[1: 170/1795] train lossD: -0.305547 lossG: 1.190563\n",
      "[1: 175/1795] train lossD: -0.428373 lossG: 1.206875\n",
      "[1: 180/1795] train lossD: -0.386799 lossG: 1.145873\n",
      "[1: 185/1795] train lossD: -0.449648 lossG: 1.083942\n",
      "[1: 190/1795] train lossD: -0.257539 lossG: 0.852607\n",
      "[1: 195/1795] train lossD: -0.362103 lossG: 1.029193\n",
      "[1: 200/1795] train lossD: -0.482370 lossG: 1.329547\n",
      "[1: 205/1795] train lossD: -0.277853 lossG: 0.998638\n",
      "[1: 210/1795] train lossD: -0.297614 lossG: 0.743983\n",
      "[1: 215/1795] train lossD: -0.396955 lossG: 1.143001\n",
      "[1: 220/1795] train lossD: -0.307190 lossG: 0.967545\n",
      "[1: 225/1795] train lossD: -0.437614 lossG: 1.077559\n",
      "[1: 230/1795] train lossD: -0.221911 lossG: 0.956833\n",
      "[1: 235/1795] train lossD: -0.397385 lossG: 1.096928\n",
      "[1: 240/1795] train lossD: -0.439621 lossG: 1.158235\n",
      "[1: 245/1795] train lossD: -0.261215 lossG: 0.825425\n",
      "[1: 250/1795] train lossD: -0.187726 lossG: 0.852648\n",
      "[1: 255/1795] train lossD: -0.368515 lossG: 0.731478\n",
      "[1: 260/1795] train lossD: -0.272767 lossG: 0.864321\n",
      "[1: 265/1795] train lossD: -0.371126 lossG: 1.196559\n",
      "[1: 270/1795] train lossD: -0.445801 lossG: 1.004501\n",
      "[1: 275/1795] train lossD: -0.460744 lossG: 1.193606\n",
      "[1: 280/1795] train lossD: -0.387459 lossG: 0.736241\n",
      "[1: 285/1795] train lossD: -0.388254 lossG: 0.912701\n",
      "[1: 290/1795] train lossD: -0.337926 lossG: 0.659381\n",
      "[1: 295/1795] train lossD: -0.306997 lossG: 0.827032\n",
      "[1: 300/1795] train lossD: -0.244146 lossG: 0.624040\n",
      "[1: 305/1795] train lossD: -0.227028 lossG: 1.168442\n",
      "[1: 310/1795] train lossD: -0.431880 lossG: 1.074937\n",
      "[1: 315/1795] train lossD: -0.322407 lossG: 1.083934\n",
      "[1: 320/1795] train lossD: -0.337586 lossG: 1.083097\n",
      "[1: 325/1795] train lossD: 0.124037 lossG: 0.536606\n",
      "[1: 330/1795] train lossD: -0.383849 lossG: 1.041300\n",
      "[1: 335/1795] train lossD: -0.224391 lossG: 0.924993\n",
      "[1: 340/1795] train lossD: -0.139766 lossG: 0.855959\n",
      "[1: 345/1795] train lossD: -0.318706 lossG: 0.779358\n",
      "[1: 350/1795] train lossD: -0.432485 lossG: 1.178807\n",
      "[1: 355/1795] train lossD: -0.450107 lossG: 1.310158\n",
      "[1: 360/1795] train lossD: -0.404014 lossG: 1.009421\n",
      "[1: 365/1795] train lossD: -0.384894 lossG: 0.866510\n",
      "[1: 370/1795] train lossD: -0.436860 lossG: 0.954848\n",
      "[1: 375/1795] train lossD: -0.432454 lossG: 0.955910\n",
      "[1: 380/1795] train lossD: -0.342452 lossG: 1.020394\n",
      "[1: 385/1795] train lossD: -0.355446 lossG: 0.766825\n",
      "[1: 390/1795] train lossD: -0.404135 lossG: 0.860743\n",
      "[1: 395/1795] train lossD: -0.329875 lossG: 0.886412\n",
      "[1: 400/1795] train lossD: -0.387313 lossG: 1.001416\n",
      "[1: 405/1795] train lossD: -0.335244 lossG: 0.798169\n",
      "[1: 410/1795] train lossD: -0.279067 lossG: 0.686742\n",
      "[1: 415/1795] train lossD: -0.363274 lossG: 1.148299\n",
      "[1: 420/1795] train lossD: -0.402666 lossG: 1.230539\n",
      "[1: 425/1795] train lossD: -0.231795 lossG: 1.127382\n",
      "[1: 430/1795] train lossD: -0.434612 lossG: 1.011712\n",
      "[1: 435/1795] train lossD: -0.394895 lossG: 1.020464\n",
      "[1: 440/1795] train lossD: -0.332275 lossG: 0.799480\n",
      "[1: 445/1795] train lossD: -0.404977 lossG: 1.145905\n",
      "[1: 450/1795] train lossD: -0.367912 lossG: 0.744155\n",
      "[1: 455/1795] train lossD: -0.395295 lossG: 0.864071\n",
      "[1: 460/1795] train lossD: -0.373860 lossG: 1.023418\n",
      "[1: 465/1795] train lossD: -0.380232 lossG: 0.836144\n",
      "[1: 470/1795] train lossD: -0.340152 lossG: 0.864184\n",
      "[1: 475/1795] train lossD: -0.235556 lossG: 0.841072\n",
      "[1: 480/1795] train lossD: -0.381581 lossG: 1.089113\n",
      "[1: 485/1795] train lossD: -0.369032 lossG: 1.140363\n",
      "[1: 490/1795] train lossD: -0.222094 lossG: 1.011589\n",
      "[1: 495/1795] train lossD: -0.338813 lossG: 1.034731\n",
      "[1: 500/1795] train lossD: -0.341544 lossG: 1.178186\n",
      "[1: 505/1795] train lossD: 0.213863 lossG: 0.819386\n",
      "[1: 510/1795] train lossD: -0.436161 lossG: 1.083767\n",
      "[1: 515/1795] train lossD: -0.347007 lossG: 0.742021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1: 520/1795] train lossD: -0.371787 lossG: 0.810476\n",
      "[1: 525/1795] train lossD: -0.464386 lossG: 0.930957\n",
      "[1: 530/1795] train lossD: -0.258727 lossG: 1.009196\n",
      "[1: 535/1795] train lossD: -0.104440 lossG: 0.608269\n",
      "[1: 540/1795] train lossD: -0.434098 lossG: 0.926489\n",
      "[1: 545/1795] train lossD: -0.336961 lossG: 0.806462\n",
      "[1: 550/1795] train lossD: -0.479607 lossG: 1.123375\n",
      "[1: 555/1795] train lossD: -0.255199 lossG: 0.733951\n",
      "[1: 560/1795] train lossD: -0.306852 lossG: 0.922632\n",
      "[1: 565/1795] train lossD: -0.366436 lossG: 1.078295\n",
      "[1: 570/1795] train lossD: -0.371630 lossG: 1.040999\n",
      "[1: 575/1795] train lossD: -0.399586 lossG: 0.938664\n",
      "[1: 580/1795] train lossD: -0.411580 lossG: 1.020504\n",
      "[1: 585/1795] train lossD: -0.154236 lossG: 0.803470\n",
      "[1: 590/1795] train lossD: -0.356792 lossG: 0.860609\n",
      "[1: 595/1795] train lossD: -0.473601 lossG: 1.062231\n",
      "[1: 600/1795] train lossD: -0.319587 lossG: 0.902887\n",
      "[1: 605/1795] train lossD: -0.413036 lossG: 0.977973\n",
      "[1: 610/1795] train lossD: -0.328424 lossG: 1.027769\n",
      "[1: 615/1795] train lossD: -0.336408 lossG: 0.761564\n",
      "[1: 620/1795] train lossD: -0.245629 lossG: 0.901502\n",
      "[1: 625/1795] train lossD: -0.394206 lossG: 1.029426\n",
      "[1: 630/1795] train lossD: -0.470467 lossG: 1.076751\n",
      "[1: 635/1795] train lossD: -0.262876 lossG: 1.139992\n",
      "[1: 640/1795] train lossD: -0.294318 lossG: 0.948988\n",
      "[1: 645/1795] train lossD: -0.252359 lossG: 0.862709\n",
      "[1: 650/1795] train lossD: -0.425971 lossG: 1.021363\n",
      "[1: 655/1795] train lossD: -0.375072 lossG: 1.128228\n",
      "[1: 660/1795] train lossD: -0.263492 lossG: 1.131366\n",
      "[1: 665/1795] train lossD: -0.120662 lossG: 1.036009\n",
      "[1: 670/1795] train lossD: -0.289494 lossG: 0.965917\n",
      "[1: 675/1795] train lossD: -0.319100 lossG: 0.887894\n",
      "[1: 680/1795] train lossD: -0.368213 lossG: 0.921708\n",
      "[1: 685/1795] train lossD: -0.159774 lossG: 0.994287\n",
      "[1: 690/1795] train lossD: -0.406337 lossG: 1.102948\n",
      "[1: 695/1795] train lossD: -0.318898 lossG: 1.032502\n",
      "[1: 700/1795] train lossD: -0.359765 lossG: 1.104954\n",
      "[1: 705/1795] train lossD: -0.338512 lossG: 1.132074\n",
      "[1: 710/1795] train lossD: -0.122875 lossG: 0.970433\n",
      "[1: 715/1795] train lossD: -0.324154 lossG: 0.866116\n",
      "[1: 720/1795] train lossD: -0.408095 lossG: 1.163901\n",
      "[1: 725/1795] train lossD: -0.361834 lossG: 1.020257\n",
      "[1: 730/1795] train lossD: -0.402013 lossG: 0.945894\n",
      "[1: 735/1795] train lossD: -0.446977 lossG: 1.358952\n",
      "[1: 740/1795] train lossD: -0.354461 lossG: 1.361683\n",
      "[1: 745/1795] train lossD: -0.389676 lossG: 1.166116\n",
      "[1: 750/1795] train lossD: -0.300722 lossG: 1.150341\n",
      "[1: 755/1795] train lossD: -0.317760 lossG: 0.985393\n",
      "[1: 760/1795] train lossD: -0.332125 lossG: 0.807413\n",
      "[1: 765/1795] train lossD: -0.314822 lossG: 0.840567\n",
      "[1: 770/1795] train lossD: -0.076967 lossG: 1.049989\n",
      "[1: 775/1795] train lossD: -0.195866 lossG: 0.865942\n",
      "[1: 780/1795] train lossD: -0.320730 lossG: 0.894495\n",
      "[1: 785/1795] train lossD: -0.182521 lossG: 0.815561\n",
      "[1: 790/1795] train lossD: -0.297368 lossG: 0.859019\n",
      "[1: 795/1795] train lossD: -0.257451 lossG: 0.849775\n",
      "[1: 800/1795] train lossD: -0.355982 lossG: 1.014422\n",
      "[1: 805/1795] train lossD: -0.263415 lossG: 0.904407\n",
      "[1: 810/1795] train lossD: -0.360786 lossG: 1.139285\n",
      "[1: 815/1795] train lossD: -0.029268 lossG: 0.995120\n",
      "[1: 820/1795] train lossD: -0.264690 lossG: 0.968220\n",
      "[1: 825/1795] train lossD: -0.334384 lossG: 0.900459\n",
      "[1: 830/1795] train lossD: -0.358331 lossG: 1.082061\n",
      "[1: 835/1795] train lossD: -0.239950 lossG: 0.909863\n",
      "[1: 840/1795] train lossD: -0.386158 lossG: 0.965226\n",
      "[1: 845/1795] train lossD: -0.299480 lossG: 1.156040\n",
      "[1: 850/1795] train lossD: -0.392634 lossG: 1.189835\n",
      "[1: 855/1795] train lossD: -0.392909 lossG: 1.217500\n",
      "[1: 860/1795] train lossD: -0.278727 lossG: 1.101060\n",
      "[1: 865/1795] train lossD: -0.338205 lossG: 1.106091\n",
      "[1: 870/1795] train lossD: -0.315976 lossG: 1.107524\n",
      "[1: 875/1795] train lossD: -0.317727 lossG: 1.133346\n",
      "[1: 880/1795] train lossD: -0.259431 lossG: 1.049904\n",
      "[1: 885/1795] train lossD: -0.177250 lossG: 0.949890\n",
      "[1: 890/1795] train lossD: -0.097512 lossG: 1.009393\n",
      "[1: 895/1795] train lossD: -0.338373 lossG: 1.212509\n",
      "[1: 900/1795] train lossD: -0.338672 lossG: 1.071005\n",
      "[1: 905/1795] train lossD: -0.200122 lossG: 0.771921\n",
      "[1: 910/1795] train lossD: -0.214930 lossG: 0.783654\n",
      "[1: 915/1795] train lossD: -0.184903 lossG: 1.038207\n",
      "[1: 920/1795] train lossD: -0.245277 lossG: 0.941114\n",
      "[1: 925/1795] train lossD: -0.310667 lossG: 1.131781\n",
      "[1: 930/1795] train lossD: -0.256316 lossG: 0.972683\n",
      "[1: 935/1795] train lossD: -0.269257 lossG: 0.925157\n",
      "[1: 940/1795] train lossD: -0.250582 lossG: 1.058640\n",
      "[1: 945/1795] train lossD: -0.337088 lossG: 0.964040\n",
      "[1: 950/1795] train lossD: -0.439709 lossG: 1.130860\n",
      "[1: 955/1795] train lossD: -0.370928 lossG: 0.943247\n",
      "[1: 960/1795] train lossD: -0.228090 lossG: 0.926834\n",
      "[1: 965/1795] train lossD: -0.340686 lossG: 0.898865\n",
      "[1: 970/1795] train lossD: -0.299988 lossG: 0.990736\n",
      "[1: 975/1795] train lossD: -0.277684 lossG: 0.829519\n",
      "[1: 980/1795] train lossD: -0.382190 lossG: 1.033354\n",
      "[1: 985/1795] train lossD: -0.300062 lossG: 0.985497\n",
      "[1: 990/1795] train lossD: -0.136783 lossG: 0.804649\n",
      "[1: 995/1795] train lossD: -0.278951 lossG: 1.063054\n",
      "[1: 1000/1795] train lossD: -0.290407 lossG: 0.938792\n",
      "[1: 1005/1795] train lossD: -0.222767 lossG: 1.092911\n",
      "[1: 1010/1795] train lossD: -0.140009 lossG: 0.998263\n",
      "[1: 1015/1795] train lossD: -0.258356 lossG: 1.044721\n",
      "[1: 1020/1795] train lossD: -0.199287 lossG: 1.001746\n",
      "[1: 1025/1795] train lossD: -0.116507 lossG: 0.909328\n",
      "[1: 1030/1795] train lossD: -0.260336 lossG: 1.075437\n",
      "[1: 1035/1795] train lossD: -0.220402 lossG: 0.900342\n",
      "[1: 1040/1795] train lossD: -0.365198 lossG: 0.875379\n",
      "[1: 1045/1795] train lossD: -0.179589 lossG: 0.821462\n",
      "[1: 1050/1795] train lossD: -0.433105 lossG: 0.964665\n",
      "[1: 1055/1795] train lossD: -0.227965 lossG: 0.772267\n",
      "[1: 1060/1795] train lossD: -0.104431 lossG: 1.085689\n",
      "[1: 1065/1795] train lossD: 0.328197 lossG: 1.025466\n",
      "[1: 1070/1795] train lossD: -0.310075 lossG: 1.056764\n",
      "[1: 1075/1795] train lossD: -0.214904 lossG: 0.762990\n",
      "[1: 1080/1795] train lossD: -0.290406 lossG: 0.854981\n",
      "[1: 1085/1795] train lossD: -0.296605 lossG: 0.831571\n",
      "[1: 1090/1795] train lossD: -0.331194 lossG: 1.078322\n",
      "[1: 1095/1795] train lossD: -0.223867 lossG: 0.909086\n",
      "[1: 1100/1795] train lossD: -0.378206 lossG: 0.964179\n",
      "[1: 1105/1795] train lossD: -0.231331 lossG: 0.830735\n",
      "[1: 1110/1795] train lossD: -0.165869 lossG: 0.798196\n",
      "[1: 1115/1795] train lossD: -0.232924 lossG: 0.859948\n",
      "[1: 1120/1795] train lossD: -0.244304 lossG: 0.952065\n",
      "[1: 1125/1795] train lossD: -0.313401 lossG: 0.994775\n",
      "[1: 1130/1795] train lossD: -0.196194 lossG: 0.889465\n",
      "[1: 1135/1795] train lossD: -0.341590 lossG: 0.888425\n",
      "[1: 1140/1795] train lossD: -0.257450 lossG: 0.846956\n",
      "[1: 1145/1795] train lossD: -0.266876 lossG: 1.197809\n",
      "[1: 1150/1795] train lossD: -0.148256 lossG: 1.156008\n",
      "[1: 1155/1795] train lossD: -0.021955 lossG: 0.942346\n",
      "[1: 1160/1795] train lossD: -0.220470 lossG: 0.858013\n",
      "[1: 1165/1795] train lossD: -0.221035 lossG: 1.073492\n",
      "[1: 1170/1795] train lossD: -0.270548 lossG: 0.976826\n",
      "[1: 1175/1795] train lossD: -0.297897 lossG: 0.798322\n",
      "[1: 1180/1795] train lossD: -0.298158 lossG: 0.702412\n",
      "[1: 1185/1795] train lossD: -0.279508 lossG: 0.882233\n",
      "[1: 1190/1795] train lossD: -0.299104 lossG: 0.774016\n",
      "[1: 1195/1795] train lossD: -0.321519 lossG: 1.000290\n",
      "[1: 1200/1795] train lossD: -0.326293 lossG: 0.742682\n",
      "[1: 1205/1795] train lossD: -0.351118 lossG: 0.924348\n",
      "[1: 1210/1795] train lossD: -0.399713 lossG: 0.976227\n",
      "[1: 1215/1795] train lossD: -0.351964 lossG: 1.033541\n",
      "[1: 1220/1795] train lossD: -0.317340 lossG: 0.880706\n",
      "[1: 1225/1795] train lossD: -0.344063 lossG: 0.937858\n",
      "[1: 1230/1795] train lossD: -0.180721 lossG: 0.838836\n",
      "[1: 1235/1795] train lossD: -0.161901 lossG: 0.993556\n",
      "[1: 1240/1795] train lossD: -0.286953 lossG: 1.021187\n",
      "[1: 1245/1795] train lossD: -0.247995 lossG: 0.874922\n",
      "[1: 1250/1795] train lossD: -0.361436 lossG: 0.990535\n",
      "[1: 1255/1795] train lossD: -0.232116 lossG: 1.118611\n",
      "[1: 1260/1795] train lossD: -0.301695 lossG: 1.074651\n",
      "[1: 1265/1795] train lossD: -0.220356 lossG: 0.963751\n",
      "[1: 1270/1795] train lossD: -0.304071 lossG: 1.073386\n",
      "[1: 1275/1795] train lossD: -0.220715 lossG: 1.048120\n",
      "[1: 1280/1795] train lossD: -0.284085 lossG: 1.031907\n",
      "[1: 1285/1795] train lossD: -0.228318 lossG: 1.106302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1: 1290/1795] train lossD: -0.106773 lossG: 0.868581\n",
      "[1: 1295/1795] train lossD: -0.153824 lossG: 0.920109\n",
      "[1: 1300/1795] train lossD: -0.271288 lossG: 0.926459\n",
      "[1: 1305/1795] train lossD: -0.284958 lossG: 1.042222\n",
      "[1: 1310/1795] train lossD: -0.210328 lossG: 0.922016\n",
      "[1: 1315/1795] train lossD: -0.189071 lossG: 0.946359\n",
      "[1: 1320/1795] train lossD: -0.275527 lossG: 0.906757\n",
      "[1: 1325/1795] train lossD: -0.199208 lossG: 0.888312\n",
      "[1: 1330/1795] train lossD: -0.261545 lossG: 1.097326\n",
      "[1: 1335/1795] train lossD: -0.264713 lossG: 1.093515\n",
      "[1: 1340/1795] train lossD: -0.299424 lossG: 1.007604\n",
      "[1: 1345/1795] train lossD: -0.258004 lossG: 1.013447\n",
      "[1: 1350/1795] train lossD: -0.220609 lossG: 0.876228\n",
      "[1: 1355/1795] train lossD: 0.176576 lossG: 0.694256\n",
      "[1: 1360/1795] train lossD: -0.210537 lossG: 0.729761\n",
      "[1: 1365/1795] train lossD: -0.201760 lossG: 1.064531\n",
      "[1: 1370/1795] train lossD: -0.243482 lossG: 0.884452\n",
      "[1: 1375/1795] train lossD: -0.312799 lossG: 0.879133\n",
      "[1: 1380/1795] train lossD: -0.239984 lossG: 0.874233\n",
      "[1: 1385/1795] train lossD: -0.181521 lossG: 0.958618\n",
      "[1: 1390/1795] train lossD: -0.172216 lossG: 1.164815\n",
      "[1: 1395/1795] train lossD: -0.180187 lossG: 0.824896\n",
      "[1: 1400/1795] train lossD: -0.189854 lossG: 0.823268\n",
      "[1: 1405/1795] train lossD: -0.195977 lossG: 1.117710\n",
      "[1: 1410/1795] train lossD: -0.165775 lossG: 0.785925\n",
      "[1: 1415/1795] train lossD: -0.236249 lossG: 0.693690\n",
      "[1: 1420/1795] train lossD: -0.119080 lossG: 0.686504\n",
      "[1: 1425/1795] train lossD: -0.191887 lossG: 0.739059\n",
      "[1: 1430/1795] train lossD: -0.135185 lossG: 0.745890\n",
      "[1: 1435/1795] train lossD: -0.254338 lossG: 0.924007\n",
      "[1: 1440/1795] train lossD: -0.199455 lossG: 1.003160\n",
      "[1: 1445/1795] train lossD: -0.199086 lossG: 0.843898\n",
      "[1: 1450/1795] train lossD: -0.171110 lossG: 0.697085\n",
      "[1: 1455/1795] train lossD: -0.251123 lossG: 0.863991\n",
      "[1: 1460/1795] train lossD: -0.164726 lossG: 0.724591\n",
      "[1: 1465/1795] train lossD: -0.274186 lossG: 0.846126\n",
      "[1: 1470/1795] train lossD: -0.331931 lossG: 0.783350\n",
      "[1: 1475/1795] train lossD: -0.295418 lossG: 0.820230\n",
      "[1: 1480/1795] train lossD: -0.233677 lossG: 0.933100\n",
      "[1: 1485/1795] train lossD: -0.247276 lossG: 0.945824\n",
      "[1: 1490/1795] train lossD: -0.165510 lossG: 0.916607\n",
      "[1: 1495/1795] train lossD: -0.271356 lossG: 0.918992\n",
      "[1: 1500/1795] train lossD: -0.104386 lossG: 0.776609\n",
      "[1: 1505/1795] train lossD: -0.232183 lossG: 0.671871\n",
      "[1: 1510/1795] train lossD: -0.153861 lossG: 0.682854\n",
      "[1: 1515/1795] train lossD: -0.241111 lossG: 0.791601\n",
      "[1: 1520/1795] train lossD: -0.207925 lossG: 0.627346\n",
      "[1: 1525/1795] train lossD: -0.210149 lossG: 0.799944\n",
      "[1: 1530/1795] train lossD: -0.232683 lossG: 0.691483\n",
      "[1: 1535/1795] train lossD: -0.236439 lossG: 0.759934\n",
      "[1: 1540/1795] train lossD: -0.218157 lossG: 0.836430\n",
      "[1: 1545/1795] train lossD: -0.310702 lossG: 0.672168\n",
      "[1: 1550/1795] train lossD: -0.151589 lossG: 0.707353\n",
      "[1: 1555/1795] train lossD: -0.164275 lossG: 0.619839\n",
      "[1: 1560/1795] train lossD: -0.197442 lossG: 0.665249\n",
      "[1: 1565/1795] train lossD: -0.318132 lossG: 0.914767\n",
      "[1: 1570/1795] train lossD: 0.059075 lossG: 0.839088\n",
      "[1: 1575/1795] train lossD: -0.178483 lossG: 0.706584\n",
      "[1: 1580/1795] train lossD: 0.082196 lossG: 0.579157\n",
      "[1: 1585/1795] train lossD: -0.190253 lossG: 0.715558\n",
      "[1: 1590/1795] train lossD: -0.229239 lossG: 0.714021\n",
      "[1: 1595/1795] train lossD: -0.189734 lossG: 0.774155\n",
      "[1: 1600/1795] train lossD: -0.278933 lossG: 0.952519\n",
      "[1: 1605/1795] train lossD: -0.040573 lossG: 0.829082\n",
      "[1: 1610/1795] train lossD: -0.237510 lossG: 0.781508\n",
      "[1: 1615/1795] train lossD: -0.226676 lossG: 0.684045\n",
      "[1: 1620/1795] train lossD: -0.143432 lossG: 0.715463\n",
      "[1: 1625/1795] train lossD: -0.191246 lossG: 0.904250\n",
      "[1: 1630/1795] train lossD: -0.279555 lossG: 0.722720\n",
      "[1: 1635/1795] train lossD: -0.239889 lossG: 0.877001\n",
      "[1: 1640/1795] train lossD: -0.245532 lossG: 0.715517\n",
      "[1: 1645/1795] train lossD: -0.179405 lossG: 0.643104\n",
      "[1: 1650/1795] train lossD: -0.228218 lossG: 0.801992\n",
      "[1: 1655/1795] train lossD: -0.033485 lossG: 0.825033\n",
      "[1: 1660/1795] train lossD: -0.226203 lossG: 0.811431\n",
      "[1: 1665/1795] train lossD: -0.233139 lossG: 0.824082\n",
      "[1: 1670/1795] train lossD: -0.139304 lossG: 0.795855\n",
      "[1: 1675/1795] train lossD: -0.133478 lossG: 0.731820\n",
      "[1: 1680/1795] train lossD: -0.271151 lossG: 0.684756\n",
      "[1: 1685/1795] train lossD: -0.171278 lossG: 0.700619\n",
      "[1: 1690/1795] train lossD: -0.189400 lossG: 0.912847\n",
      "[1: 1695/1795] train lossD: -0.186116 lossG: 0.782525\n",
      "[1: 1700/1795] train lossD: -0.026966 lossG: 0.618925\n",
      "[1: 1705/1795] train lossD: -0.293165 lossG: 0.851097\n",
      "[1: 1710/1795] train lossD: -0.220358 lossG: 0.802251\n",
      "[1: 1715/1795] train lossD: -0.149786 lossG: 0.805902\n",
      "[1: 1720/1795] train lossD: -0.146171 lossG: 0.656439\n",
      "[1: 1725/1795] train lossD: -0.229954 lossG: 1.016682\n",
      "[1: 1730/1795] train lossD: -0.130072 lossG: 0.583719\n",
      "[1: 1735/1795] train lossD: -0.195837 lossG: 0.778353\n",
      "[1: 1740/1795] train lossD: -0.167826 lossG: 0.769657\n",
      "[1: 1745/1795] train lossD: -0.245652 lossG: 0.847830\n",
      "[1: 1750/1795] train lossD: -0.185641 lossG: 0.631120\n",
      "[1: 1755/1795] train lossD: -0.229021 lossG: 0.822801\n",
      "[1: 1760/1795] train lossD: -0.072909 lossG: 0.664510\n",
      "[1: 1765/1795] train lossD: -0.173673 lossG: 0.776096\n",
      "[1: 1770/1795] train lossD: -0.161201 lossG: 1.068839\n",
      "[1: 1775/1795] train lossD: -0.229853 lossG: 0.825497\n",
      "[1: 1780/1795] train lossD: -0.168993 lossG: 0.806274\n",
      "[1: 1785/1795] train lossD: -0.144031 lossG: 0.963873\n",
      "[1: 1790/1795] train lossD: -0.205230 lossG: 0.689278\n",
      "0.04150030016899109\n",
      "[2: 0/1795] train lossD: -0.204710 lossG: 0.998658\n",
      "[2: 5/1795] train lossD: -0.246266 lossG: 0.871013\n",
      "[2: 10/1795] train lossD: -0.097173 lossG: 0.859684\n",
      "[2: 15/1795] train lossD: -0.204625 lossG: 0.691159\n",
      "[2: 20/1795] train lossD: -0.089712 lossG: 0.920144\n",
      "[2: 25/1795] train lossD: -0.191222 lossG: 0.700366\n",
      "[2: 30/1795] train lossD: -0.161931 lossG: 0.680406\n",
      "[2: 35/1795] train lossD: -0.240831 lossG: 0.962784\n",
      "[2: 40/1795] train lossD: -0.193097 lossG: 0.652858\n",
      "[2: 45/1795] train lossD: -0.209172 lossG: 0.687652\n",
      "[2: 50/1795] train lossD: -0.152169 lossG: 1.042884\n",
      "[2: 55/1795] train lossD: -0.150793 lossG: 0.754645\n",
      "[2: 60/1795] train lossD: -0.214929 lossG: 0.754402\n",
      "[2: 65/1795] train lossD: -0.235883 lossG: 0.968847\n",
      "[2: 70/1795] train lossD: -0.183615 lossG: 0.782044\n",
      "[2: 75/1795] train lossD: -0.190945 lossG: 1.017606\n",
      "[2: 80/1795] train lossD: -0.270698 lossG: 0.888895\n",
      "[2: 85/1795] train lossD: -0.266255 lossG: 0.820353\n",
      "[2: 90/1795] train lossD: -0.241866 lossG: 0.812167\n",
      "[2: 95/1795] train lossD: -0.188134 lossG: 0.720633\n",
      "[2: 100/1795] train lossD: -0.184398 lossG: 0.581578\n",
      "[2: 105/1795] train lossD: -0.228045 lossG: 0.957905\n",
      "[2: 110/1795] train lossD: -0.091205 lossG: 0.857609\n",
      "[2: 115/1795] train lossD: -0.150204 lossG: 0.680515\n",
      "[2: 120/1795] train lossD: -0.292247 lossG: 0.869675\n",
      "[2: 125/1795] train lossD: -0.238971 lossG: 0.789133\n",
      "[2: 130/1795] train lossD: -0.147794 lossG: 0.754441\n",
      "[2: 135/1795] train lossD: -0.174192 lossG: 0.896797\n",
      "[2: 140/1795] train lossD: -0.165364 lossG: 0.812668\n",
      "[2: 145/1795] train lossD: -0.153191 lossG: 0.751484\n",
      "[2: 150/1795] train lossD: -0.173046 lossG: 0.705707\n",
      "[2: 155/1795] train lossD: -0.193790 lossG: 0.727669\n",
      "[2: 160/1795] train lossD: -0.176797 lossG: 0.800903\n",
      "[2: 165/1795] train lossD: -0.284357 lossG: 0.847086\n",
      "[2: 170/1795] train lossD: -0.251134 lossG: 0.800189\n",
      "[2: 175/1795] train lossD: -0.147384 lossG: 0.845616\n",
      "[2: 180/1795] train lossD: -0.234974 lossG: 0.883318\n",
      "[2: 185/1795] train lossD: -0.164741 lossG: 0.809743\n",
      "[2: 190/1795] train lossD: -0.077474 lossG: 0.912514\n",
      "[2: 195/1795] train lossD: -0.118570 lossG: 0.776154\n",
      "[2: 200/1795] train lossD: -0.247150 lossG: 0.848959\n",
      "[2: 205/1795] train lossD: -0.172266 lossG: 0.808781\n",
      "[2: 210/1795] train lossD: -0.240146 lossG: 0.692378\n",
      "[2: 215/1795] train lossD: -0.124569 lossG: 0.603115\n",
      "[2: 220/1795] train lossD: -0.193354 lossG: 0.774144\n",
      "[2: 225/1795] train lossD: -0.191302 lossG: 0.645075\n",
      "[2: 230/1795] train lossD: -0.195827 lossG: 0.697728\n",
      "[2: 235/1795] train lossD: -0.154787 lossG: 0.697615\n",
      "[2: 240/1795] train lossD: -0.233659 lossG: 0.647961\n",
      "[2: 245/1795] train lossD: -0.217183 lossG: 0.751329\n",
      "[2: 250/1795] train lossD: -0.289657 lossG: 0.714401\n",
      "[2: 255/1795] train lossD: -0.165842 lossG: 0.530568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2: 260/1795] train lossD: -0.220340 lossG: 0.811285\n",
      "[2: 265/1795] train lossD: -0.227047 lossG: 0.802338\n",
      "[2: 270/1795] train lossD: -0.115197 lossG: 0.766503\n",
      "[2: 275/1795] train lossD: -0.201297 lossG: 0.831967\n",
      "[2: 280/1795] train lossD: -0.217749 lossG: 0.774383\n",
      "[2: 285/1795] train lossD: -0.243095 lossG: 0.815156\n",
      "[2: 290/1795] train lossD: -0.290526 lossG: 0.748628\n",
      "[2: 295/1795] train lossD: -0.152929 lossG: 0.657322\n",
      "[2: 300/1795] train lossD: -0.169883 lossG: 0.659335\n",
      "[2: 305/1795] train lossD: -0.215670 lossG: 0.727250\n",
      "[2: 310/1795] train lossD: -0.176551 lossG: 0.707061\n",
      "[2: 315/1795] train lossD: -0.198015 lossG: 0.488397\n",
      "[2: 320/1795] train lossD: -0.293542 lossG: 0.876242\n",
      "[2: 325/1795] train lossD: -0.185424 lossG: 0.705126\n",
      "[2: 330/1795] train lossD: -0.111558 lossG: 0.781845\n",
      "[2: 335/1795] train lossD: -0.138982 lossG: 0.742236\n",
      "[2: 340/1795] train lossD: -0.210698 lossG: 0.663538\n",
      "[2: 345/1795] train lossD: -0.229778 lossG: 0.800587\n",
      "[2: 350/1795] train lossD: -0.090665 lossG: 0.763719\n",
      "[2: 355/1795] train lossD: -0.255098 lossG: 0.742544\n",
      "[2: 360/1795] train lossD: -0.218804 lossG: 0.840243\n",
      "[2: 365/1795] train lossD: -0.221684 lossG: 0.870471\n",
      "[2: 370/1795] train lossD: -0.154049 lossG: 0.709852\n",
      "[2: 375/1795] train lossD: -0.175226 lossG: 1.057825\n",
      "[2: 380/1795] train lossD: -0.191723 lossG: 0.951831\n",
      "[2: 385/1795] train lossD: -0.285508 lossG: 0.974503\n",
      "[2: 390/1795] train lossD: -0.279742 lossG: 0.801275\n",
      "[2: 395/1795] train lossD: -0.122661 lossG: 0.759840\n",
      "[2: 400/1795] train lossD: -0.193398 lossG: 0.818161\n",
      "[2: 405/1795] train lossD: -0.304994 lossG: 0.725157\n",
      "[2: 410/1795] train lossD: -0.041160 lossG: 0.695912\n",
      "[2: 415/1795] train lossD: -0.187422 lossG: 0.822140\n",
      "[2: 420/1795] train lossD: -0.048605 lossG: 0.820876\n",
      "[2: 425/1795] train lossD: -0.255148 lossG: 0.889448\n",
      "[2: 430/1795] train lossD: -0.229595 lossG: 0.868436\n",
      "[2: 435/1795] train lossD: -0.190941 lossG: 0.727767\n",
      "[2: 440/1795] train lossD: -0.134117 lossG: 0.546849\n",
      "[2: 445/1795] train lossD: -0.168693 lossG: 0.635562\n",
      "[2: 450/1795] train lossD: -0.236682 lossG: 0.729509\n",
      "[2: 455/1795] train lossD: -0.254786 lossG: 0.784558\n",
      "[2: 460/1795] train lossD: -0.145692 lossG: 0.755663\n",
      "[2: 465/1795] train lossD: -0.103767 lossG: 1.047773\n",
      "[2: 470/1795] train lossD: -0.227569 lossG: 0.745390\n",
      "[2: 475/1795] train lossD: -0.122819 lossG: 0.725702\n",
      "[2: 480/1795] train lossD: -0.242362 lossG: 0.857341\n",
      "[2: 485/1795] train lossD: -0.140157 lossG: 0.844912\n",
      "[2: 490/1795] train lossD: -0.147815 lossG: 0.838278\n",
      "[2: 495/1795] train lossD: -0.143076 lossG: 0.695201\n",
      "[2: 500/1795] train lossD: -0.191225 lossG: 0.931116\n",
      "[2: 505/1795] train lossD: -0.241582 lossG: 0.882399\n",
      "[2: 510/1795] train lossD: -0.200044 lossG: 0.935964\n",
      "[2: 515/1795] train lossD: -0.260464 lossG: 0.785188\n",
      "[2: 520/1795] train lossD: -0.157494 lossG: 0.748456\n",
      "[2: 525/1795] train lossD: -0.209997 lossG: 0.759313\n",
      "[2: 530/1795] train lossD: -0.127314 lossG: 0.585617\n",
      "[2: 535/1795] train lossD: -0.226725 lossG: 0.805250\n",
      "[2: 540/1795] train lossD: -0.108647 lossG: 0.646305\n",
      "[2: 545/1795] train lossD: -0.151776 lossG: 0.732122\n",
      "[2: 550/1795] train lossD: -0.215503 lossG: 0.595912\n",
      "[2: 555/1795] train lossD: -0.117115 lossG: 0.639748\n",
      "[2: 560/1795] train lossD: -0.269699 lossG: 0.671288\n",
      "[2: 565/1795] train lossD: -0.163548 lossG: 0.728332\n",
      "[2: 570/1795] train lossD: -0.118495 lossG: 0.650878\n",
      "[2: 575/1795] train lossD: -0.229079 lossG: 0.553680\n",
      "[2: 580/1795] train lossD: -0.246975 lossG: 0.988948\n",
      "[2: 585/1795] train lossD: -0.227441 lossG: 0.776668\n",
      "[2: 590/1795] train lossD: -0.153768 lossG: 0.813030\n",
      "[2: 595/1795] train lossD: -0.173065 lossG: 0.754616\n",
      "[2: 600/1795] train lossD: -0.205722 lossG: 0.822110\n",
      "[2: 605/1795] train lossD: 0.029335 lossG: 0.576923\n",
      "[2: 610/1795] train lossD: -0.155617 lossG: 0.667606\n",
      "[2: 615/1795] train lossD: -0.200976 lossG: 1.054369\n",
      "[2: 620/1795] train lossD: -0.125068 lossG: 0.788604\n",
      "[2: 625/1795] train lossD: -0.162804 lossG: 0.824797\n",
      "[2: 630/1795] train lossD: 0.025304 lossG: 0.754085\n",
      "[2: 635/1795] train lossD: -0.224685 lossG: 0.898641\n",
      "[2: 640/1795] train lossD: -0.169651 lossG: 0.921806\n",
      "[2: 645/1795] train lossD: -0.166432 lossG: 0.839274\n",
      "[2: 650/1795] train lossD: -0.238296 lossG: 0.803007\n",
      "[2: 655/1795] train lossD: -0.214750 lossG: 0.905388\n",
      "[2: 660/1795] train lossD: -0.237198 lossG: 0.904099\n",
      "[2: 665/1795] train lossD: -0.280897 lossG: 0.832863\n",
      "[2: 670/1795] train lossD: -0.193661 lossG: 0.717646\n",
      "[2: 675/1795] train lossD: -0.153738 lossG: 0.922994\n",
      "[2: 680/1795] train lossD: -0.077950 lossG: 0.809530\n",
      "[2: 685/1795] train lossD: -0.166919 lossG: 0.904759\n",
      "[2: 690/1795] train lossD: -0.156577 lossG: 0.747590\n",
      "[2: 695/1795] train lossD: -0.163041 lossG: 0.718073\n",
      "[2: 700/1795] train lossD: -0.276887 lossG: 0.821069\n",
      "[2: 705/1795] train lossD: -0.235269 lossG: 0.880942\n",
      "[2: 710/1795] train lossD: -0.181659 lossG: 0.765392\n",
      "[2: 715/1795] train lossD: -0.131766 lossG: 0.802850\n",
      "[2: 720/1795] train lossD: -0.190801 lossG: 0.740546\n",
      "[2: 725/1795] train lossD: -0.202691 lossG: 0.815364\n",
      "[2: 730/1795] train lossD: -0.231567 lossG: 0.689773\n",
      "[2: 735/1795] train lossD: -0.231599 lossG: 0.704867\n",
      "[2: 740/1795] train lossD: -0.167836 lossG: 0.688876\n",
      "[2: 745/1795] train lossD: -0.210806 lossG: 0.653385\n",
      "[2: 750/1795] train lossD: -0.132058 lossG: 0.887176\n",
      "[2: 755/1795] train lossD: -0.259450 lossG: 0.932103\n",
      "[2: 760/1795] train lossD: -0.250204 lossG: 0.810137\n",
      "[2: 765/1795] train lossD: -0.191647 lossG: 0.797105\n",
      "[2: 770/1795] train lossD: -0.197163 lossG: 0.885042\n",
      "[2: 775/1795] train lossD: -0.083715 lossG: 0.672618\n",
      "[2: 780/1795] train lossD: -0.187243 lossG: 0.698036\n",
      "[2: 785/1795] train lossD: -0.215711 lossG: 0.546651\n",
      "[2: 790/1795] train lossD: -0.238889 lossG: 0.765911\n",
      "[2: 795/1795] train lossD: 0.021337 lossG: 0.563195\n",
      "[2: 800/1795] train lossD: -0.215955 lossG: 0.806747\n",
      "[2: 805/1795] train lossD: -0.198290 lossG: 0.839532\n",
      "[2: 810/1795] train lossD: -0.202178 lossG: 0.750129\n",
      "[2: 815/1795] train lossD: -0.200906 lossG: 0.779916\n",
      "[2: 820/1795] train lossD: -0.184316 lossG: 0.762702\n",
      "[2: 825/1795] train lossD: -0.222261 lossG: 0.875042\n",
      "[2: 830/1795] train lossD: -0.145981 lossG: 0.794465\n",
      "[2: 835/1795] train lossD: -0.118998 lossG: 0.886208\n",
      "[2: 840/1795] train lossD: -0.199505 lossG: 0.805368\n",
      "[2: 845/1795] train lossD: -0.153688 lossG: 0.791408\n",
      "[2: 850/1795] train lossD: -0.166333 lossG: 0.936846\n",
      "[2: 855/1795] train lossD: -0.194284 lossG: 0.889682\n",
      "[2: 860/1795] train lossD: -0.181192 lossG: 0.669160\n",
      "[2: 865/1795] train lossD: -0.167835 lossG: 0.885135\n",
      "[2: 870/1795] train lossD: -0.116331 lossG: 0.745250\n",
      "[2: 875/1795] train lossD: -0.190941 lossG: 0.649584\n",
      "[2: 880/1795] train lossD: -0.096852 lossG: 0.624555\n",
      "[2: 885/1795] train lossD: -0.208020 lossG: 0.685110\n",
      "[2: 890/1795] train lossD: -0.144780 lossG: 0.997001\n",
      "[2: 895/1795] train lossD: -0.193092 lossG: 0.784497\n",
      "[2: 900/1795] train lossD: -0.188591 lossG: 0.791905\n",
      "[2: 905/1795] train lossD: -0.265118 lossG: 0.684868\n",
      "[2: 910/1795] train lossD: -0.122397 lossG: 0.689650\n",
      "[2: 915/1795] train lossD: -0.137111 lossG: 0.734702\n",
      "[2: 920/1795] train lossD: -0.189150 lossG: 0.766791\n",
      "[2: 925/1795] train lossD: -0.225579 lossG: 0.762611\n",
      "[2: 930/1795] train lossD: -0.139203 lossG: 0.877780\n",
      "[2: 935/1795] train lossD: -0.213231 lossG: 0.745402\n",
      "[2: 940/1795] train lossD: -0.212662 lossG: 0.689041\n",
      "[2: 945/1795] train lossD: -0.075730 lossG: 0.847077\n",
      "[2: 950/1795] train lossD: -0.059220 lossG: 0.795090\n",
      "[2: 955/1795] train lossD: -0.207442 lossG: 0.837414\n",
      "[2: 960/1795] train lossD: -0.139230 lossG: 0.765756\n",
      "[2: 965/1795] train lossD: -0.161072 lossG: 0.826261\n",
      "[2: 970/1795] train lossD: -0.227628 lossG: 0.776621\n",
      "[2: 975/1795] train lossD: -0.150932 lossG: 0.797329\n",
      "[2: 980/1795] train lossD: -0.253245 lossG: 0.908519\n",
      "[2: 985/1795] train lossD: -0.189192 lossG: 0.759247\n",
      "[2: 990/1795] train lossD: -0.160883 lossG: 0.768850\n",
      "[2: 995/1795] train lossD: -0.207920 lossG: 0.670565\n",
      "[2: 1000/1795] train lossD: -0.179737 lossG: 0.988643\n",
      "[2: 1005/1795] train lossD: -0.110031 lossG: 0.750259\n",
      "[2: 1010/1795] train lossD: -0.180698 lossG: 0.736747\n",
      "[2: 1015/1795] train lossD: -0.197260 lossG: 0.740967\n",
      "[2: 1020/1795] train lossD: -0.211463 lossG: 0.873828\n",
      "[2: 1025/1795] train lossD: -0.131202 lossG: 0.806018\n",
      "[2: 1030/1795] train lossD: -0.212559 lossG: 0.868831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2: 1035/1795] train lossD: -0.127885 lossG: 0.757735\n",
      "[2: 1040/1795] train lossD: -0.201779 lossG: 0.791898\n",
      "[2: 1045/1795] train lossD: -0.226801 lossG: 0.718013\n",
      "[2: 1050/1795] train lossD: 0.081582 lossG: 0.646764\n",
      "[2: 1055/1795] train lossD: -0.149919 lossG: 0.720836\n",
      "[2: 1060/1795] train lossD: -0.055149 lossG: 0.683702\n",
      "[2: 1065/1795] train lossD: -0.153256 lossG: 0.785501\n",
      "[2: 1070/1795] train lossD: -0.132211 lossG: 0.843002\n",
      "[2: 1075/1795] train lossD: -0.216919 lossG: 0.842105\n",
      "[2: 1080/1795] train lossD: -0.195473 lossG: 0.877322\n",
      "[2: 1085/1795] train lossD: -0.212970 lossG: 0.722437\n",
      "[2: 1090/1795] train lossD: -0.109543 lossG: 0.673334\n",
      "[2: 1095/1795] train lossD: -0.233875 lossG: 0.744614\n",
      "[2: 1100/1795] train lossD: -0.222687 lossG: 0.899889\n",
      "[2: 1105/1795] train lossD: -0.198235 lossG: 1.063031\n",
      "[2: 1110/1795] train lossD: -0.243336 lossG: 0.874321\n",
      "[2: 1115/1795] train lossD: -0.127016 lossG: 0.756716\n",
      "[2: 1120/1795] train lossD: -0.127227 lossG: 0.824842\n",
      "[2: 1125/1795] train lossD: -0.205003 lossG: 0.719117\n",
      "[2: 1130/1795] train lossD: -0.188615 lossG: 0.859936\n",
      "[2: 1135/1795] train lossD: -0.139267 lossG: 0.726843\n",
      "[2: 1140/1795] train lossD: -0.171473 lossG: 0.834904\n",
      "[2: 1145/1795] train lossD: -0.269503 lossG: 0.736617\n",
      "[2: 1150/1795] train lossD: -0.197489 lossG: 0.791816\n",
      "[2: 1155/1795] train lossD: -0.040053 lossG: 0.623151\n",
      "[2: 1160/1795] train lossD: -0.204386 lossG: 0.540494\n",
      "[2: 1165/1795] train lossD: -0.276118 lossG: 0.699851\n",
      "[2: 1170/1795] train lossD: -0.206226 lossG: 0.770437\n",
      "[2: 1175/1795] train lossD: -0.184290 lossG: 0.585820\n",
      "[2: 1180/1795] train lossD: -0.273187 lossG: 0.873789\n",
      "[2: 1185/1795] train lossD: -0.164011 lossG: 0.757633\n",
      "[2: 1190/1795] train lossD: -0.189882 lossG: 0.738395\n",
      "[2: 1195/1795] train lossD: -0.258535 lossG: 0.683420\n",
      "[2: 1200/1795] train lossD: -0.217981 lossG: 0.753499\n",
      "[2: 1205/1795] train lossD: -0.274681 lossG: 0.788440\n",
      "[2: 1210/1795] train lossD: -0.104041 lossG: 0.934057\n",
      "[2: 1215/1795] train lossD: -0.152768 lossG: 0.664605\n",
      "[2: 1220/1795] train lossD: -0.036364 lossG: 0.753018\n",
      "[2: 1225/1795] train lossD: -0.063100 lossG: 0.618198\n",
      "[2: 1230/1795] train lossD: -0.135204 lossG: 0.834126\n",
      "[2: 1235/1795] train lossD: -0.127943 lossG: 0.697501\n",
      "[2: 1240/1795] train lossD: -0.080637 lossG: 0.877305\n",
      "[2: 1245/1795] train lossD: -0.150300 lossG: 0.834003\n",
      "[2: 1250/1795] train lossD: -0.082694 lossG: 0.793971\n",
      "[2: 1255/1795] train lossD: -0.210293 lossG: 0.765128\n",
      "[2: 1260/1795] train lossD: -0.204244 lossG: 0.900543\n",
      "[2: 1265/1795] train lossD: -0.198337 lossG: 0.852359\n",
      "[2: 1270/1795] train lossD: -0.202468 lossG: 0.722901\n",
      "[2: 1275/1795] train lossD: -0.179409 lossG: 0.775403\n",
      "[2: 1280/1795] train lossD: -0.242375 lossG: 0.760859\n",
      "[2: 1285/1795] train lossD: -0.114855 lossG: 0.588287\n",
      "[2: 1290/1795] train lossD: -0.123729 lossG: 0.794584\n",
      "[2: 1295/1795] train lossD: -0.211312 lossG: 0.859096\n",
      "[2: 1300/1795] train lossD: -0.258212 lossG: 0.880454\n",
      "[2: 1305/1795] train lossD: -0.215752 lossG: 0.820513\n",
      "[2: 1310/1795] train lossD: -0.029894 lossG: 0.836774\n",
      "[2: 1315/1795] train lossD: -0.103562 lossG: 0.995830\n",
      "[2: 1320/1795] train lossD: -0.251853 lossG: 0.995304\n",
      "[2: 1325/1795] train lossD: -0.192804 lossG: 0.846060\n",
      "[2: 1330/1795] train lossD: -0.222204 lossG: 0.829088\n",
      "[2: 1335/1795] train lossD: -0.226641 lossG: 0.740173\n",
      "[2: 1340/1795] train lossD: -0.210198 lossG: 0.905043\n",
      "[2: 1345/1795] train lossD: -0.115133 lossG: 0.770877\n",
      "[2: 1350/1795] train lossD: -0.183167 lossG: 0.775797\n",
      "[2: 1355/1795] train lossD: -0.224473 lossG: 0.706842\n",
      "[2: 1360/1795] train lossD: -0.192110 lossG: 0.706176\n",
      "[2: 1365/1795] train lossD: -0.057555 lossG: 0.569769\n",
      "[2: 1370/1795] train lossD: -0.178441 lossG: 0.679370\n",
      "[2: 1375/1795] train lossD: -0.076251 lossG: 0.761803\n",
      "[2: 1380/1795] train lossD: -0.196182 lossG: 0.674977\n",
      "[2: 1385/1795] train lossD: -0.192799 lossG: 0.647724\n",
      "[2: 1390/1795] train lossD: 0.022033 lossG: 0.864458\n",
      "[2: 1395/1795] train lossD: -0.217785 lossG: 0.831189\n",
      "[2: 1400/1795] train lossD: -0.076733 lossG: 0.739003\n",
      "[2: 1405/1795] train lossD: -0.195155 lossG: 0.691662\n",
      "[2: 1410/1795] train lossD: -0.284285 lossG: 0.776997\n",
      "[2: 1415/1795] train lossD: -0.194545 lossG: 0.689023\n",
      "[2: 1420/1795] train lossD: -0.029601 lossG: 0.707277\n",
      "[2: 1425/1795] train lossD: -0.021188 lossG: 0.769710\n",
      "[2: 1430/1795] train lossD: -0.185751 lossG: 0.706178\n",
      "[2: 1435/1795] train lossD: 0.015294 lossG: 0.675930\n",
      "[2: 1440/1795] train lossD: -0.197906 lossG: 0.757411\n",
      "[2: 1445/1795] train lossD: -0.311419 lossG: 0.616737\n",
      "[2: 1450/1795] train lossD: -0.090961 lossG: 0.768935\n",
      "[2: 1455/1795] train lossD: -0.087826 lossG: 0.607272\n",
      "[2: 1460/1795] train lossD: -0.173542 lossG: 0.803362\n",
      "[2: 1465/1795] train lossD: -0.200795 lossG: 0.804472\n",
      "[2: 1470/1795] train lossD: -0.217805 lossG: 0.665405\n",
      "[2: 1475/1795] train lossD: -0.171149 lossG: 0.750418\n",
      "[2: 1480/1795] train lossD: -0.197926 lossG: 0.753274\n",
      "[2: 1485/1795] train lossD: -0.155272 lossG: 0.597715\n",
      "[2: 1490/1795] train lossD: -0.104493 lossG: 0.856313\n",
      "[2: 1495/1795] train lossD: -0.203019 lossG: 0.957357\n",
      "[2: 1500/1795] train lossD: -0.176580 lossG: 0.839030\n",
      "[2: 1505/1795] train lossD: -0.166651 lossG: 0.693578\n",
      "[2: 1510/1795] train lossD: -0.149754 lossG: 0.816599\n",
      "[2: 1515/1795] train lossD: -0.210319 lossG: 0.937664\n",
      "[2: 1520/1795] train lossD: -0.179853 lossG: 0.824843\n",
      "[2: 1525/1795] train lossD: -0.169380 lossG: 0.671969\n",
      "[2: 1530/1795] train lossD: -0.048413 lossG: 0.899034\n",
      "[2: 1535/1795] train lossD: -0.150611 lossG: 0.822346\n",
      "[2: 1540/1795] train lossD: -0.264155 lossG: 0.826444\n",
      "[2: 1545/1795] train lossD: -0.120874 lossG: 0.740704\n",
      "[2: 1550/1795] train lossD: -0.224584 lossG: 0.853243\n",
      "[2: 1555/1795] train lossD: -0.156007 lossG: 0.721908\n",
      "[2: 1560/1795] train lossD: -0.208479 lossG: 0.751011\n",
      "[2: 1565/1795] train lossD: -0.282866 lossG: 0.761252\n",
      "[2: 1570/1795] train lossD: -0.099363 lossG: 0.693001\n",
      "[2: 1575/1795] train lossD: -0.182584 lossG: 1.070368\n",
      "[2: 1580/1795] train lossD: -0.187591 lossG: 0.775917\n",
      "[2: 1585/1795] train lossD: -0.185956 lossG: 0.800303\n",
      "[2: 1590/1795] train lossD: -0.210726 lossG: 0.870991\n",
      "[2: 1595/1795] train lossD: -0.116968 lossG: 0.904169\n",
      "[2: 1600/1795] train lossD: -0.174672 lossG: 0.897595\n",
      "[2: 1605/1795] train lossD: -0.209966 lossG: 0.748356\n",
      "[2: 1610/1795] train lossD: -0.137858 lossG: 0.861098\n",
      "[2: 1615/1795] train lossD: -0.160049 lossG: 0.770312\n",
      "[2: 1620/1795] train lossD: -0.216075 lossG: 0.739514\n",
      "[2: 1625/1795] train lossD: -0.112477 lossG: 0.629595\n",
      "[2: 1630/1795] train lossD: -0.265676 lossG: 0.601764\n",
      "[2: 1635/1795] train lossD: -0.183188 lossG: 0.676576\n",
      "[2: 1640/1795] train lossD: -0.053227 lossG: 0.660034\n",
      "[2: 1645/1795] train lossD: -0.090990 lossG: 0.865854\n",
      "[2: 1650/1795] train lossD: -0.128327 lossG: 0.653187\n",
      "[2: 1655/1795] train lossD: -0.156667 lossG: 0.692521\n",
      "[2: 1660/1795] train lossD: -0.199238 lossG: 0.853850\n",
      "[2: 1665/1795] train lossD: -0.219909 lossG: 0.832129\n",
      "[2: 1670/1795] train lossD: -0.259854 lossG: 0.823160\n",
      "[2: 1675/1795] train lossD: -0.142832 lossG: 0.564379\n",
      "[2: 1680/1795] train lossD: -0.133592 lossG: 0.790075\n",
      "[2: 1685/1795] train lossD: -0.159991 lossG: 0.668295\n",
      "[2: 1690/1795] train lossD: -0.116176 lossG: 0.648344\n",
      "[2: 1695/1795] train lossD: -0.195944 lossG: 0.785426\n",
      "[2: 1700/1795] train lossD: -0.239248 lossG: 0.852367\n",
      "[2: 1705/1795] train lossD: -0.168278 lossG: 0.755133\n",
      "[2: 1710/1795] train lossD: -0.185561 lossG: 0.737910\n",
      "[2: 1715/1795] train lossD: -0.148645 lossG: 0.701115\n",
      "[2: 1720/1795] train lossD: -0.183356 lossG: 0.691292\n",
      "[2: 1725/1795] train lossD: -0.103579 lossG: 0.659141\n",
      "[2: 1730/1795] train lossD: -0.197338 lossG: 0.623513\n",
      "[2: 1735/1795] train lossD: -0.151834 lossG: 0.787214\n",
      "[2: 1740/1795] train lossD: -0.260056 lossG: 0.878183\n",
      "[2: 1745/1795] train lossD: -0.215564 lossG: 0.833611\n",
      "[2: 1750/1795] train lossD: -0.184577 lossG: 0.745288\n",
      "[2: 1755/1795] train lossD: -0.113157 lossG: 0.603715\n",
      "[2: 1760/1795] train lossD: -0.240984 lossG: 0.750557\n",
      "[2: 1765/1795] train lossD: -0.180316 lossG: 0.786330\n",
      "[2: 1770/1795] train lossD: -0.264161 lossG: 0.691819\n",
      "[2: 1775/1795] train lossD: -0.132576 lossG: 0.617598\n",
      "[2: 1780/1795] train lossD: -0.165169 lossG: 0.777206\n",
      "[2: 1785/1795] train lossD: -0.184921 lossG: 1.031230\n",
      "[2: 1790/1795] train lossD: -0.222608 lossG: 0.806779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050314679741859436\n",
      "[3: 0/1795] train lossD: -0.246399 lossG: 0.703881\n",
      "[3: 5/1795] train lossD: -0.153360 lossG: 0.769534\n",
      "[3: 10/1795] train lossD: -0.201780 lossG: 0.684013\n",
      "[3: 15/1795] train lossD: -0.144316 lossG: 0.788218\n",
      "[3: 20/1795] train lossD: -0.202720 lossG: 0.617239\n",
      "[3: 25/1795] train lossD: -0.192550 lossG: 0.769433\n",
      "[3: 30/1795] train lossD: -0.156648 lossG: 0.745633\n",
      "[3: 35/1795] train lossD: -0.150789 lossG: 0.871348\n",
      "[3: 40/1795] train lossD: -0.235374 lossG: 0.868374\n",
      "[3: 45/1795] train lossD: -0.169892 lossG: 0.773265\n",
      "[3: 50/1795] train lossD: -0.193712 lossG: 0.689348\n",
      "[3: 55/1795] train lossD: -0.065457 lossG: 0.609027\n",
      "[3: 60/1795] train lossD: -0.215088 lossG: 0.583715\n",
      "[3: 65/1795] train lossD: -0.167442 lossG: 0.602405\n",
      "[3: 70/1795] train lossD: -0.192579 lossG: 0.792127\n",
      "[3: 75/1795] train lossD: -0.160417 lossG: 0.844968\n",
      "[3: 80/1795] train lossD: -0.161147 lossG: 0.754592\n",
      "[3: 85/1795] train lossD: -0.134440 lossG: 0.797390\n",
      "[3: 90/1795] train lossD: -0.213723 lossG: 0.880930\n",
      "[3: 95/1795] train lossD: -0.179916 lossG: 0.793314\n",
      "[3: 100/1795] train lossD: -0.144810 lossG: 0.768325\n",
      "[3: 105/1795] train lossD: -0.127334 lossG: 0.647806\n",
      "[3: 110/1795] train lossD: -0.269986 lossG: 0.764684\n",
      "[3: 115/1795] train lossD: -0.240885 lossG: 0.780422\n",
      "[3: 120/1795] train lossD: -0.172616 lossG: 0.933415\n",
      "[3: 125/1795] train lossD: -0.177683 lossG: 1.041786\n",
      "[3: 130/1795] train lossD: -0.174290 lossG: 0.754144\n",
      "[3: 135/1795] train lossD: -0.113142 lossG: 0.683543\n",
      "[3: 140/1795] train lossD: -0.140222 lossG: 0.919239\n",
      "[3: 145/1795] train lossD: -0.113865 lossG: 0.749152\n",
      "[3: 150/1795] train lossD: -0.169149 lossG: 0.739868\n",
      "[3: 155/1795] train lossD: -0.221019 lossG: 0.761237\n",
      "[3: 160/1795] train lossD: -0.224870 lossG: 0.818431\n",
      "[3: 165/1795] train lossD: -0.133583 lossG: 0.805425\n",
      "[3: 170/1795] train lossD: -0.107655 lossG: 0.624888\n",
      "[3: 175/1795] train lossD: -0.159918 lossG: 0.845034\n",
      "[3: 180/1795] train lossD: -0.238232 lossG: 0.846800\n",
      "[3: 185/1795] train lossD: -0.196585 lossG: 0.842739\n",
      "[3: 190/1795] train lossD: -0.189261 lossG: 0.743640\n",
      "[3: 195/1795] train lossD: -0.208895 lossG: 0.798737\n",
      "[3: 200/1795] train lossD: -0.124010 lossG: 0.818066\n",
      "[3: 205/1795] train lossD: -0.230544 lossG: 0.830663\n",
      "[3: 210/1795] train lossD: -0.114583 lossG: 0.774670\n",
      "[3: 215/1795] train lossD: -0.215481 lossG: 0.751944\n",
      "[3: 220/1795] train lossD: -0.249779 lossG: 0.728941\n",
      "[3: 225/1795] train lossD: -0.241486 lossG: 0.648095\n",
      "[3: 230/1795] train lossD: -0.132585 lossG: 0.696593\n",
      "[3: 235/1795] train lossD: -0.214874 lossG: 0.865293\n",
      "[3: 240/1795] train lossD: -0.098945 lossG: 0.651465\n",
      "[3: 245/1795] train lossD: -0.190765 lossG: 0.574350\n",
      "[3: 250/1795] train lossD: -0.164638 lossG: 0.770495\n",
      "[3: 255/1795] train lossD: -0.196048 lossG: 0.897299\n",
      "[3: 260/1795] train lossD: -0.221667 lossG: 0.806704\n",
      "[3: 265/1795] train lossD: -0.204794 lossG: 0.819793\n",
      "[3: 270/1795] train lossD: -0.166789 lossG: 0.848067\n",
      "[3: 275/1795] train lossD: -0.222643 lossG: 0.826230\n",
      "[3: 280/1795] train lossD: -0.097119 lossG: 0.759273\n",
      "[3: 285/1795] train lossD: -0.080405 lossG: 0.868687\n",
      "[3: 290/1795] train lossD: -0.158567 lossG: 0.728613\n",
      "[3: 295/1795] train lossD: -0.254590 lossG: 0.694050\n",
      "[3: 300/1795] train lossD: -0.173901 lossG: 0.787772\n",
      "[3: 305/1795] train lossD: -0.169987 lossG: 0.729078\n",
      "[3: 310/1795] train lossD: -0.195576 lossG: 0.954168\n",
      "[3: 315/1795] train lossD: -0.194627 lossG: 0.838006\n",
      "[3: 320/1795] train lossD: -0.034701 lossG: 0.832804\n",
      "[3: 325/1795] train lossD: -0.097593 lossG: 0.760197\n",
      "[3: 330/1795] train lossD: -0.182140 lossG: 0.884496\n",
      "[3: 335/1795] train lossD: -0.183914 lossG: 0.665704\n",
      "[3: 340/1795] train lossD: -0.102267 lossG: 0.751415\n",
      "[3: 345/1795] train lossD: -0.276191 lossG: 0.772380\n",
      "[3: 350/1795] train lossD: -0.189512 lossG: 0.736807\n",
      "[3: 355/1795] train lossD: -0.155410 lossG: 0.766961\n",
      "[3: 360/1795] train lossD: -0.153458 lossG: 0.799848\n",
      "[3: 365/1795] train lossD: -0.184892 lossG: 0.717006\n",
      "[3: 370/1795] train lossD: -0.170734 lossG: 0.838826\n",
      "[3: 375/1795] train lossD: -0.197738 lossG: 0.797764\n",
      "[3: 380/1795] train lossD: -0.109508 lossG: 0.746771\n",
      "[3: 385/1795] train lossD: -0.177438 lossG: 0.772762\n",
      "[3: 390/1795] train lossD: -0.177064 lossG: 0.754441\n",
      "[3: 395/1795] train lossD: -0.136723 lossG: 0.734601\n",
      "[3: 400/1795] train lossD: -0.206538 lossG: 0.630185\n",
      "[3: 405/1795] train lossD: -0.174787 lossG: 0.789161\n",
      "[3: 410/1795] train lossD: -0.037684 lossG: 0.839050\n",
      "[3: 415/1795] train lossD: -0.170711 lossG: 0.869918\n",
      "[3: 420/1795] train lossD: -0.187309 lossG: 0.822206\n",
      "[3: 425/1795] train lossD: -0.190558 lossG: 0.810773\n",
      "[3: 430/1795] train lossD: -0.131773 lossG: 0.673938\n",
      "[3: 435/1795] train lossD: -0.218877 lossG: 0.791795\n",
      "[3: 440/1795] train lossD: -0.146167 lossG: 0.904783\n",
      "[3: 445/1795] train lossD: -0.142659 lossG: 0.803314\n",
      "[3: 450/1795] train lossD: -0.149097 lossG: 0.733171\n",
      "[3: 455/1795] train lossD: -0.255998 lossG: 0.905401\n",
      "[3: 460/1795] train lossD: -0.123955 lossG: 0.566911\n",
      "[3: 465/1795] train lossD: -0.201284 lossG: 0.791336\n",
      "[3: 470/1795] train lossD: -0.160964 lossG: 0.687938\n",
      "[3: 475/1795] train lossD: -0.120973 lossG: 0.702234\n",
      "[3: 480/1795] train lossD: -0.128184 lossG: 0.640632\n",
      "[3: 485/1795] train lossD: -0.192939 lossG: 0.553093\n",
      "[3: 490/1795] train lossD: -0.112298 lossG: 0.606658\n",
      "[3: 495/1795] train lossD: -0.103848 lossG: 0.695562\n",
      "[3: 500/1795] train lossD: -0.137458 lossG: 0.738714\n",
      "[3: 505/1795] train lossD: -0.176403 lossG: 0.584783\n",
      "[3: 510/1795] train lossD: -0.152506 lossG: 0.716853\n",
      "[3: 515/1795] train lossD: -0.113900 lossG: 0.746105\n",
      "[3: 520/1795] train lossD: -0.166661 lossG: 0.761880\n",
      "[3: 525/1795] train lossD: -0.090676 lossG: 0.685238\n",
      "[3: 530/1795] train lossD: -0.191122 lossG: 0.805127\n",
      "[3: 535/1795] train lossD: -0.108234 lossG: 0.870184\n",
      "[3: 540/1795] train lossD: -0.152931 lossG: 0.764948\n",
      "[3: 545/1795] train lossD: -0.047480 lossG: 0.691532\n",
      "[3: 550/1795] train lossD: -0.267415 lossG: 0.838465\n",
      "[3: 555/1795] train lossD: -0.158401 lossG: 0.624286\n",
      "[3: 560/1795] train lossD: -0.194246 lossG: 0.641205\n",
      "[3: 565/1795] train lossD: -0.167656 lossG: 0.748158\n",
      "[3: 570/1795] train lossD: -0.184043 lossG: 0.837750\n",
      "[3: 575/1795] train lossD: -0.173628 lossG: 0.796417\n",
      "[3: 580/1795] train lossD: -0.198064 lossG: 1.012969\n",
      "[3: 585/1795] train lossD: -0.186947 lossG: 0.723768\n",
      "[3: 590/1795] train lossD: -0.162256 lossG: 0.815776\n",
      "[3: 595/1795] train lossD: -0.204698 lossG: 0.777096\n",
      "[3: 600/1795] train lossD: -0.091667 lossG: 0.746269\n",
      "[3: 605/1795] train lossD: -0.090431 lossG: 0.742293\n",
      "[3: 610/1795] train lossD: -0.139420 lossG: 0.699232\n",
      "[3: 615/1795] train lossD: -0.084602 lossG: 0.782888\n",
      "[3: 620/1795] train lossD: -0.250099 lossG: 0.750727\n",
      "[3: 625/1795] train lossD: -0.100167 lossG: 0.740059\n",
      "[3: 630/1795] train lossD: -0.151057 lossG: 0.763359\n",
      "[3: 635/1795] train lossD: -0.218057 lossG: 0.843385\n",
      "[3: 640/1795] train lossD: -0.171958 lossG: 0.706022\n",
      "[3: 645/1795] train lossD: -0.080042 lossG: 0.706375\n",
      "[3: 650/1795] train lossD: -0.226577 lossG: 0.622615\n",
      "[3: 655/1795] train lossD: -0.213835 lossG: 0.678565\n",
      "[3: 660/1795] train lossD: -0.023564 lossG: 0.582932\n",
      "[3: 665/1795] train lossD: -0.137859 lossG: 0.724830\n",
      "[3: 670/1795] train lossD: -0.147044 lossG: 0.743828\n",
      "[3: 675/1795] train lossD: -0.050007 lossG: 0.826111\n",
      "[3: 680/1795] train lossD: -0.220036 lossG: 0.742570\n",
      "[3: 685/1795] train lossD: -0.136168 lossG: 0.784285\n",
      "[3: 690/1795] train lossD: -0.166744 lossG: 0.758627\n",
      "[3: 695/1795] train lossD: -0.175381 lossG: 0.725252\n",
      "[3: 700/1795] train lossD: -0.211330 lossG: 0.675498\n",
      "[3: 705/1795] train lossD: -0.063724 lossG: 0.866366\n",
      "[3: 710/1795] train lossD: -0.211944 lossG: 0.831381\n",
      "[3: 715/1795] train lossD: -0.192073 lossG: 0.764082\n",
      "[3: 720/1795] train lossD: -0.121439 lossG: 0.744476\n",
      "[3: 725/1795] train lossD: -0.139167 lossG: 0.693348\n",
      "[3: 730/1795] train lossD: -0.126649 lossG: 0.687916\n",
      "[3: 735/1795] train lossD: -0.224120 lossG: 0.608260\n",
      "[3: 740/1795] train lossD: -0.167169 lossG: 0.651309\n",
      "[3: 745/1795] train lossD: -0.090163 lossG: 0.645909\n",
      "[3: 750/1795] train lossD: -0.242442 lossG: 0.800894\n",
      "[3: 755/1795] train lossD: -0.106822 lossG: 0.767340\n",
      "[3: 760/1795] train lossD: -0.160621 lossG: 0.804070\n",
      "[3: 765/1795] train lossD: -0.153428 lossG: 0.761145\n",
      "[3: 770/1795] train lossD: -0.100753 lossG: 0.760464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3: 775/1795] train lossD: -0.163006 lossG: 0.811678\n",
      "[3: 780/1795] train lossD: -0.158050 lossG: 0.835514\n",
      "[3: 785/1795] train lossD: -0.215603 lossG: 0.725694\n",
      "[3: 790/1795] train lossD: -0.165673 lossG: 0.790796\n",
      "[3: 795/1795] train lossD: -0.109005 lossG: 0.699958\n",
      "[3: 800/1795] train lossD: -0.096222 lossG: 0.632950\n",
      "[3: 805/1795] train lossD: -0.198851 lossG: 0.697915\n",
      "[3: 810/1795] train lossD: -0.054202 lossG: 0.648314\n",
      "[3: 815/1795] train lossD: -0.204274 lossG: 0.792202\n",
      "[3: 820/1795] train lossD: -0.161892 lossG: 0.658669\n",
      "[3: 825/1795] train lossD: -0.219375 lossG: 0.737341\n",
      "[3: 830/1795] train lossD: -0.116491 lossG: 0.764275\n",
      "[3: 835/1795] train lossD: -0.130091 lossG: 0.590415\n",
      "[3: 840/1795] train lossD: -0.218947 lossG: 0.589990\n",
      "[3: 845/1795] train lossD: -0.183706 lossG: 0.661416\n",
      "[3: 850/1795] train lossD: -0.135892 lossG: 0.685424\n",
      "[3: 855/1795] train lossD: -0.152005 lossG: 0.771927\n",
      "[3: 860/1795] train lossD: -0.183215 lossG: 0.638391\n",
      "[3: 865/1795] train lossD: -0.126696 lossG: 0.538419\n",
      "[3: 870/1795] train lossD: -0.104639 lossG: 0.626298\n",
      "[3: 875/1795] train lossD: -0.188438 lossG: 0.807426\n",
      "[3: 880/1795] train lossD: -0.192109 lossG: 0.714132\n",
      "[3: 885/1795] train lossD: -0.076283 lossG: 0.635123\n",
      "[3: 890/1795] train lossD: -0.085616 lossG: 0.612149\n",
      "[3: 895/1795] train lossD: -0.177224 lossG: 0.616819\n",
      "[3: 900/1795] train lossD: -0.134059 lossG: 0.716367\n",
      "[3: 905/1795] train lossD: -0.129647 lossG: 0.632298\n",
      "[3: 910/1795] train lossD: -0.179454 lossG: 0.752758\n",
      "[3: 915/1795] train lossD: -0.170835 lossG: 0.778791\n",
      "[3: 920/1795] train lossD: -0.052254 lossG: 0.889310\n",
      "[3: 925/1795] train lossD: -0.132908 lossG: 0.823047\n",
      "[3: 930/1795] train lossD: -0.118263 lossG: 0.635300\n",
      "[3: 935/1795] train lossD: -0.145764 lossG: 0.770991\n",
      "[3: 940/1795] train lossD: -0.205001 lossG: 0.686489\n",
      "[3: 945/1795] train lossD: -0.233672 lossG: 0.624970\n",
      "[3: 950/1795] train lossD: -0.217488 lossG: 0.696420\n",
      "[3: 955/1795] train lossD: -0.122222 lossG: 0.747300\n",
      "[3: 960/1795] train lossD: -0.208885 lossG: 0.604407\n",
      "[3: 965/1795] train lossD: -0.175181 lossG: 0.615495\n",
      "[3: 970/1795] train lossD: -0.200571 lossG: 0.562460\n",
      "[3: 975/1795] train lossD: -0.200208 lossG: 0.631878\n",
      "[3: 980/1795] train lossD: -0.181143 lossG: 0.687507\n",
      "[3: 985/1795] train lossD: -0.107598 lossG: 0.606832\n",
      "[3: 990/1795] train lossD: -0.156192 lossG: 0.796228\n",
      "[3: 995/1795] train lossD: -0.125682 lossG: 0.736336\n",
      "[3: 1000/1795] train lossD: -0.133764 lossG: 0.741330\n",
      "[3: 1005/1795] train lossD: -0.205950 lossG: 0.628546\n",
      "[3: 1010/1795] train lossD: -0.195629 lossG: 0.690577\n",
      "[3: 1015/1795] train lossD: -0.221666 lossG: 0.777775\n",
      "[3: 1020/1795] train lossD: -0.219674 lossG: 0.734889\n",
      "[3: 1025/1795] train lossD: -0.222460 lossG: 0.827959\n",
      "[3: 1030/1795] train lossD: -0.112881 lossG: 0.639006\n",
      "[3: 1035/1795] train lossD: -0.097295 lossG: 0.683898\n",
      "[3: 1040/1795] train lossD: -0.139945 lossG: 0.685389\n",
      "[3: 1045/1795] train lossD: -0.151877 lossG: 0.643338\n",
      "[3: 1050/1795] train lossD: -0.152044 lossG: 0.671447\n",
      "[3: 1055/1795] train lossD: -0.193246 lossG: 0.715634\n",
      "[3: 1060/1795] train lossD: -0.134429 lossG: 0.668887\n",
      "[3: 1065/1795] train lossD: -0.235553 lossG: 0.730382\n",
      "[3: 1070/1795] train lossD: -0.116792 lossG: 0.695409\n",
      "[3: 1075/1795] train lossD: -0.188272 lossG: 0.756955\n",
      "[3: 1080/1795] train lossD: -0.225441 lossG: 0.755661\n",
      "[3: 1085/1795] train lossD: -0.205285 lossG: 0.779196\n",
      "[3: 1090/1795] train lossD: -0.140972 lossG: 0.679538\n",
      "[3: 1095/1795] train lossD: -0.149728 lossG: 0.623813\n",
      "[3: 1100/1795] train lossD: -0.200652 lossG: 0.624699\n",
      "[3: 1105/1795] train lossD: -0.174908 lossG: 0.635161\n",
      "[3: 1110/1795] train lossD: -0.086878 lossG: 0.638515\n",
      "[3: 1115/1795] train lossD: -0.097549 lossG: 0.624695\n",
      "[3: 1120/1795] train lossD: -0.202117 lossG: 0.700474\n",
      "[3: 1125/1795] train lossD: -0.202089 lossG: 0.730868\n",
      "[3: 1130/1795] train lossD: -0.149977 lossG: 0.688140\n",
      "[3: 1135/1795] train lossD: -0.155754 lossG: 0.503628\n",
      "[3: 1140/1795] train lossD: -0.132479 lossG: 0.694800\n",
      "[3: 1145/1795] train lossD: -0.121825 lossG: 0.867273\n",
      "[3: 1150/1795] train lossD: -0.157484 lossG: 0.727916\n",
      "[3: 1155/1795] train lossD: -0.222251 lossG: 0.778039\n",
      "[3: 1160/1795] train lossD: -0.087292 lossG: 0.691901\n",
      "[3: 1165/1795] train lossD: -0.142213 lossG: 0.691292\n",
      "[3: 1170/1795] train lossD: -0.229190 lossG: 0.717266\n",
      "[3: 1175/1795] train lossD: 0.010507 lossG: 0.674596\n",
      "[3: 1180/1795] train lossD: -0.136929 lossG: 0.733277\n",
      "[3: 1185/1795] train lossD: -0.015904 lossG: 0.626917\n",
      "[3: 1190/1795] train lossD: -0.075701 lossG: 0.584416\n",
      "[3: 1195/1795] train lossD: -0.149716 lossG: 0.879046\n",
      "[3: 1200/1795] train lossD: -0.155732 lossG: 0.682221\n",
      "[3: 1205/1795] train lossD: -0.116356 lossG: 0.674943\n",
      "[3: 1210/1795] train lossD: -0.165954 lossG: 0.752688\n",
      "[3: 1215/1795] train lossD: -0.185239 lossG: 0.656480\n",
      "[3: 1220/1795] train lossD: -0.194369 lossG: 0.712015\n",
      "[3: 1225/1795] train lossD: -0.141610 lossG: 0.634311\n",
      "[3: 1230/1795] train lossD: -0.146934 lossG: 0.687087\n",
      "[3: 1235/1795] train lossD: -0.112421 lossG: 0.658979\n",
      "[3: 1240/1795] train lossD: -0.176044 lossG: 0.707838\n",
      "[3: 1245/1795] train lossD: -0.017978 lossG: 0.696956\n",
      "[3: 1250/1795] train lossD: -0.149989 lossG: 0.755965\n",
      "[3: 1255/1795] train lossD: 0.010266 lossG: 0.760406\n",
      "[3: 1260/1795] train lossD: -0.220580 lossG: 0.678698\n",
      "[3: 1265/1795] train lossD: -0.142348 lossG: 0.857006\n",
      "[3: 1270/1795] train lossD: -0.149531 lossG: 0.883822\n",
      "[3: 1275/1795] train lossD: -0.196962 lossG: 0.834057\n",
      "[3: 1280/1795] train lossD: -0.148727 lossG: 0.618752\n",
      "[3: 1285/1795] train lossD: -0.178083 lossG: 0.687281\n",
      "[3: 1290/1795] train lossD: -0.165094 lossG: 0.621768\n",
      "[3: 1295/1795] train lossD: -0.076039 lossG: 0.722859\n",
      "[3: 1300/1795] train lossD: -0.208305 lossG: 0.844142\n",
      "[3: 1305/1795] train lossD: -0.118739 lossG: 0.816859\n",
      "[3: 1310/1795] train lossD: -0.168844 lossG: 0.635996\n",
      "[3: 1315/1795] train lossD: -0.053627 lossG: 0.580842\n",
      "[3: 1320/1795] train lossD: -0.113432 lossG: 0.633479\n",
      "[3: 1325/1795] train lossD: -0.084833 lossG: 0.565091\n",
      "[3: 1330/1795] train lossD: -0.131783 lossG: 0.651295\n",
      "[3: 1335/1795] train lossD: -0.284755 lossG: 0.708013\n",
      "[3: 1340/1795] train lossD: -0.100801 lossG: 0.549393\n",
      "[3: 1345/1795] train lossD: -0.038553 lossG: 0.731918\n",
      "[3: 1350/1795] train lossD: -0.174534 lossG: 0.708354\n",
      "[3: 1355/1795] train lossD: -0.147684 lossG: 0.611223\n",
      "[3: 1360/1795] train lossD: -0.179851 lossG: 0.689439\n",
      "[3: 1365/1795] train lossD: -0.138238 lossG: 0.767823\n",
      "[3: 1370/1795] train lossD: -0.118333 lossG: 0.621379\n",
      "[3: 1375/1795] train lossD: -0.133642 lossG: 0.672970\n",
      "[3: 1380/1795] train lossD: -0.143973 lossG: 0.691559\n",
      "[3: 1385/1795] train lossD: -0.264920 lossG: 0.751970\n",
      "[3: 1390/1795] train lossD: -0.164918 lossG: 0.801206\n",
      "[3: 1395/1795] train lossD: -0.202521 lossG: 0.674359\n",
      "[3: 1400/1795] train lossD: -0.114399 lossG: 0.760163\n",
      "[3: 1405/1795] train lossD: -0.150763 lossG: 0.592769\n",
      "[3: 1410/1795] train lossD: 0.115966 lossG: 0.839388\n",
      "[3: 1415/1795] train lossD: -0.138440 lossG: 0.747675\n",
      "[3: 1420/1795] train lossD: -0.097626 lossG: 0.639794\n",
      "[3: 1425/1795] train lossD: -0.079894 lossG: 0.781544\n",
      "[3: 1430/1795] train lossD: -0.149544 lossG: 0.639367\n",
      "[3: 1435/1795] train lossD: -0.222142 lossG: 0.687075\n",
      "[3: 1440/1795] train lossD: -0.155617 lossG: 0.582098\n",
      "[3: 1445/1795] train lossD: -0.139825 lossG: 0.735851\n",
      "[3: 1450/1795] train lossD: -0.172232 lossG: 0.709668\n",
      "[3: 1455/1795] train lossD: -0.167408 lossG: 0.944088\n",
      "[3: 1460/1795] train lossD: -0.153672 lossG: 0.755384\n",
      "[3: 1465/1795] train lossD: -0.033131 lossG: 0.705448\n",
      "[3: 1470/1795] train lossD: -0.135118 lossG: 0.725773\n",
      "[3: 1475/1795] train lossD: -0.180659 lossG: 0.757043\n",
      "[3: 1480/1795] train lossD: -0.190122 lossG: 0.732244\n",
      "[3: 1485/1795] train lossD: -0.180207 lossG: 0.702372\n",
      "[3: 1490/1795] train lossD: -0.132628 lossG: 0.617548\n",
      "[3: 1495/1795] train lossD: -0.188891 lossG: 0.616096\n",
      "[3: 1500/1795] train lossD: -0.240103 lossG: 0.604125\n",
      "[3: 1505/1795] train lossD: -0.149534 lossG: 0.674663\n",
      "[3: 1510/1795] train lossD: -0.166441 lossG: 0.822441\n",
      "[3: 1515/1795] train lossD: -0.167771 lossG: 0.981824\n",
      "[3: 1520/1795] train lossD: -0.187116 lossG: 0.706834\n",
      "[3: 1525/1795] train lossD: -0.135165 lossG: 1.005987\n",
      "[3: 1530/1795] train lossD: -0.045363 lossG: 0.798716\n",
      "[3: 1535/1795] train lossD: -0.165285 lossG: 0.691427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3: 1540/1795] train lossD: -0.219773 lossG: 0.637565\n",
      "[3: 1545/1795] train lossD: -0.077647 lossG: 0.612853\n",
      "[3: 1550/1795] train lossD: -0.167085 lossG: 0.644458\n",
      "[3: 1555/1795] train lossD: -0.172100 lossG: 0.776636\n",
      "[3: 1560/1795] train lossD: -0.160192 lossG: 0.697322\n",
      "[3: 1565/1795] train lossD: -0.128594 lossG: 0.814574\n",
      "[3: 1570/1795] train lossD: -0.157165 lossG: 0.789875\n",
      "[3: 1575/1795] train lossD: -0.201918 lossG: 0.687499\n",
      "[3: 1580/1795] train lossD: -0.124815 lossG: 0.641560\n",
      "[3: 1585/1795] train lossD: -0.196073 lossG: 0.828449\n",
      "[3: 1590/1795] train lossD: -0.184167 lossG: 0.854734\n",
      "[3: 1595/1795] train lossD: -0.105129 lossG: 0.696350\n",
      "[3: 1600/1795] train lossD: -0.171634 lossG: 0.653728\n",
      "[3: 1605/1795] train lossD: -0.158604 lossG: 0.614812\n",
      "[3: 1610/1795] train lossD: -0.069237 lossG: 0.667394\n",
      "[3: 1615/1795] train lossD: -0.152280 lossG: 0.758494\n",
      "[3: 1620/1795] train lossD: -0.155512 lossG: 0.651717\n",
      "[3: 1625/1795] train lossD: -0.157248 lossG: 0.735166\n",
      "[3: 1630/1795] train lossD: -0.164122 lossG: 0.700336\n",
      "[3: 1635/1795] train lossD: -0.158604 lossG: 0.778938\n",
      "[3: 1640/1795] train lossD: -0.107271 lossG: 0.664500\n",
      "[3: 1645/1795] train lossD: -0.221080 lossG: 0.733220\n",
      "[3: 1650/1795] train lossD: -0.178273 lossG: 0.676811\n",
      "[3: 1655/1795] train lossD: -0.097767 lossG: 0.671604\n",
      "[3: 1660/1795] train lossD: -0.182617 lossG: 0.745551\n",
      "[3: 1665/1795] train lossD: -0.088723 lossG: 0.655988\n",
      "[3: 1670/1795] train lossD: -0.206340 lossG: 0.734828\n",
      "[3: 1675/1795] train lossD: -0.167242 lossG: 0.712689\n",
      "[3: 1680/1795] train lossD: -0.201040 lossG: 0.740096\n",
      "[3: 1685/1795] train lossD: -0.142938 lossG: 0.834954\n",
      "[3: 1690/1795] train lossD: -0.098110 lossG: 0.741824\n",
      "[3: 1695/1795] train lossD: -0.208569 lossG: 0.802303\n",
      "[3: 1700/1795] train lossD: -0.190518 lossG: 0.654232\n",
      "[3: 1705/1795] train lossD: -0.177396 lossG: 0.664320\n",
      "[3: 1710/1795] train lossD: 0.006944 lossG: 0.580668\n",
      "[3: 1715/1795] train lossD: -0.224808 lossG: 0.580580\n",
      "[3: 1720/1795] train lossD: -0.201959 lossG: 0.835194\n",
      "[3: 1725/1795] train lossD: -0.106455 lossG: 0.705069\n",
      "[3: 1730/1795] train lossD: -0.214279 lossG: 0.646750\n",
      "[3: 1735/1795] train lossD: -0.126813 lossG: 0.657800\n",
      "[3: 1740/1795] train lossD: -0.168328 lossG: 0.758241\n",
      "[3: 1745/1795] train lossD: -0.093010 lossG: 0.781466\n",
      "[3: 1750/1795] train lossD: -0.141005 lossG: 0.507433\n",
      "[3: 1755/1795] train lossD: -0.225373 lossG: 0.585817\n",
      "[3: 1760/1795] train lossD: -0.215341 lossG: 0.694737\n",
      "[3: 1765/1795] train lossD: -0.127769 lossG: 0.655581\n",
      "[3: 1770/1795] train lossD: -0.309152 lossG: 0.745328\n",
      "[3: 1775/1795] train lossD: -0.124598 lossG: 0.761352\n",
      "[3: 1780/1795] train lossD: -0.065438 lossG: 0.638652\n",
      "[3: 1785/1795] train lossD: -0.199673 lossG: 0.715760\n",
      "[3: 1790/1795] train lossD: -0.205598 lossG: 0.754875\n",
      "0.04303291440010071\n",
      "[4: 0/1795] train lossD: -0.210761 lossG: 0.591822\n",
      "[4: 5/1795] train lossD: -0.206725 lossG: 0.560315\n",
      "[4: 10/1795] train lossD: -0.046019 lossG: 0.597918\n",
      "[4: 15/1795] train lossD: -0.157882 lossG: 0.782380\n",
      "[4: 20/1795] train lossD: -0.159187 lossG: 0.785238\n",
      "[4: 25/1795] train lossD: -0.123709 lossG: 0.855434\n",
      "[4: 30/1795] train lossD: -0.106116 lossG: 0.798160\n",
      "[4: 35/1795] train lossD: 0.203333 lossG: 0.679714\n",
      "[4: 40/1795] train lossD: -0.168972 lossG: 0.723876\n",
      "[4: 45/1795] train lossD: -0.124176 lossG: 0.833229\n",
      "[4: 50/1795] train lossD: -0.179295 lossG: 0.714939\n",
      "[4: 55/1795] train lossD: -0.163807 lossG: 0.676934\n",
      "[4: 60/1795] train lossD: -0.153673 lossG: 0.726247\n",
      "[4: 65/1795] train lossD: -0.178625 lossG: 0.703861\n",
      "[4: 70/1795] train lossD: -0.206514 lossG: 0.618436\n",
      "[4: 75/1795] train lossD: -0.115256 lossG: 0.729923\n",
      "[4: 80/1795] train lossD: -0.129570 lossG: 0.633387\n",
      "[4: 85/1795] train lossD: -0.103900 lossG: 0.747929\n",
      "[4: 90/1795] train lossD: -0.201016 lossG: 0.681933\n",
      "[4: 95/1795] train lossD: -0.192626 lossG: 0.706782\n",
      "[4: 100/1795] train lossD: -0.137993 lossG: 0.718241\n",
      "[4: 105/1795] train lossD: -0.095076 lossG: 0.719791\n",
      "[4: 110/1795] train lossD: -0.179355 lossG: 0.812489\n",
      "[4: 115/1795] train lossD: -0.114530 lossG: 0.705358\n",
      "[4: 120/1795] train lossD: -0.136537 lossG: 0.720387\n",
      "[4: 125/1795] train lossD: -0.167953 lossG: 0.796572\n",
      "[4: 130/1795] train lossD: -0.194616 lossG: 0.764352\n",
      "[4: 135/1795] train lossD: -0.180073 lossG: 0.770900\n",
      "[4: 140/1795] train lossD: -0.181990 lossG: 0.825899\n",
      "[4: 145/1795] train lossD: -0.224401 lossG: 0.676723\n",
      "[4: 150/1795] train lossD: -0.172769 lossG: 0.730524\n",
      "[4: 155/1795] train lossD: -0.110452 lossG: 0.813339\n",
      "[4: 160/1795] train lossD: -0.201217 lossG: 0.723683\n",
      "[4: 165/1795] train lossD: -0.167677 lossG: 0.585847\n",
      "[4: 170/1795] train lossD: -0.108564 lossG: 0.779138\n",
      "[4: 175/1795] train lossD: -0.099230 lossG: 0.894127\n",
      "[4: 180/1795] train lossD: -0.089343 lossG: 0.789091\n",
      "[4: 185/1795] train lossD: -0.167180 lossG: 0.766555\n",
      "[4: 190/1795] train lossD: -0.149773 lossG: 0.745501\n",
      "[4: 195/1795] train lossD: -0.229054 lossG: 0.917532\n",
      "[4: 200/1795] train lossD: -0.136438 lossG: 0.738238\n",
      "[4: 205/1795] train lossD: -0.128517 lossG: 0.594509\n",
      "[4: 210/1795] train lossD: -0.139108 lossG: 0.593449\n",
      "[4: 215/1795] train lossD: -0.170025 lossG: 0.681656\n",
      "[4: 220/1795] train lossD: -0.217146 lossG: 0.764513\n",
      "[4: 225/1795] train lossD: -0.130984 lossG: 0.722463\n",
      "[4: 230/1795] train lossD: -0.153015 lossG: 0.774705\n",
      "[4: 235/1795] train lossD: -0.204651 lossG: 0.894086\n",
      "[4: 240/1795] train lossD: -0.080192 lossG: 0.888337\n",
      "[4: 245/1795] train lossD: -0.157857 lossG: 0.772902\n",
      "[4: 250/1795] train lossD: -0.074440 lossG: 0.720675\n",
      "[4: 255/1795] train lossD: -0.156458 lossG: 0.674155\n",
      "[4: 260/1795] train lossD: -0.140602 lossG: 0.644662\n",
      "[4: 265/1795] train lossD: -0.100111 lossG: 0.626888\n",
      "[4: 270/1795] train lossD: -0.171408 lossG: 0.841278\n",
      "[4: 275/1795] train lossD: -0.226113 lossG: 0.803887\n",
      "[4: 280/1795] train lossD: -0.237200 lossG: 0.720744\n",
      "[4: 285/1795] train lossD: -0.099521 lossG: 0.734897\n",
      "[4: 290/1795] train lossD: -0.150022 lossG: 0.691535\n",
      "[4: 295/1795] train lossD: -0.184638 lossG: 0.740694\n",
      "[4: 300/1795] train lossD: -0.149789 lossG: 0.692214\n",
      "[4: 305/1795] train lossD: -0.099608 lossG: 0.597439\n",
      "[4: 310/1795] train lossD: -0.193631 lossG: 0.649601\n",
      "[4: 315/1795] train lossD: -0.175164 lossG: 0.653630\n",
      "[4: 320/1795] train lossD: -0.138516 lossG: 0.747134\n",
      "[4: 325/1795] train lossD: -0.103258 lossG: 0.708890\n",
      "[4: 330/1795] train lossD: -0.115641 lossG: 0.670758\n",
      "[4: 335/1795] train lossD: -0.218603 lossG: 0.801545\n",
      "[4: 340/1795] train lossD: -0.204322 lossG: 0.771772\n",
      "[4: 345/1795] train lossD: -0.125127 lossG: 0.698427\n",
      "[4: 350/1795] train lossD: -0.120307 lossG: 0.654073\n",
      "[4: 355/1795] train lossD: -0.162292 lossG: 0.592100\n",
      "[4: 360/1795] train lossD: -0.183607 lossG: 0.616570\n",
      "[4: 365/1795] train lossD: -0.112250 lossG: 0.694655\n",
      "[4: 370/1795] train lossD: -0.099049 lossG: 0.698664\n",
      "[4: 375/1795] train lossD: -0.194424 lossG: 0.794558\n",
      "[4: 380/1795] train lossD: -0.193912 lossG: 0.746375\n",
      "[4: 385/1795] train lossD: -0.132519 lossG: 0.806439\n",
      "[4: 390/1795] train lossD: -0.121700 lossG: 0.722374\n",
      "[4: 395/1795] train lossD: -0.157477 lossG: 0.742783\n",
      "[4: 400/1795] train lossD: -0.167035 lossG: 0.681349\n",
      "[4: 405/1795] train lossD: -0.164401 lossG: 0.747801\n",
      "[4: 410/1795] train lossD: -0.045353 lossG: 0.620414\n",
      "[4: 415/1795] train lossD: -0.156273 lossG: 0.719076\n",
      "[4: 420/1795] train lossD: -0.164056 lossG: 0.611605\n",
      "[4: 425/1795] train lossD: -0.071968 lossG: 0.546459\n",
      "[4: 430/1795] train lossD: -0.120869 lossG: 0.672969\n",
      "[4: 435/1795] train lossD: -0.145294 lossG: 0.663650\n",
      "[4: 440/1795] train lossD: -0.138370 lossG: 0.668670\n",
      "[4: 445/1795] train lossD: -0.248272 lossG: 0.952074\n",
      "[4: 450/1795] train lossD: -0.168745 lossG: 0.848264\n",
      "[4: 455/1795] train lossD: -0.220023 lossG: 0.735445\n",
      "[4: 460/1795] train lossD: 0.050932 lossG: 0.666543\n",
      "[4: 465/1795] train lossD: -0.127535 lossG: 0.686913\n",
      "[4: 470/1795] train lossD: -0.144089 lossG: 0.873007\n",
      "[4: 475/1795] train lossD: -0.153653 lossG: 0.729732\n",
      "[4: 480/1795] train lossD: -0.226116 lossG: 0.650981\n",
      "[4: 485/1795] train lossD: -0.064800 lossG: 0.651881\n",
      "[4: 490/1795] train lossD: -0.119600 lossG: 0.647002\n",
      "[4: 495/1795] train lossD: -0.031918 lossG: 0.638818\n",
      "[4: 500/1795] train lossD: -0.051546 lossG: 0.694583\n",
      "[4: 505/1795] train lossD: -0.180290 lossG: 0.627358\n",
      "[4: 510/1795] train lossD: -0.251695 lossG: 0.711249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4: 515/1795] train lossD: -0.177685 lossG: 0.701671\n",
      "[4: 520/1795] train lossD: -0.140681 lossG: 0.687777\n",
      "[4: 525/1795] train lossD: -0.218080 lossG: 0.983695\n",
      "[4: 530/1795] train lossD: -0.160779 lossG: 0.814653\n",
      "[4: 535/1795] train lossD: -0.155370 lossG: 0.657819\n",
      "[4: 540/1795] train lossD: -0.092986 lossG: 0.693455\n",
      "[4: 545/1795] train lossD: -0.156206 lossG: 0.723321\n",
      "[4: 550/1795] train lossD: -0.097574 lossG: 0.743744\n",
      "[4: 555/1795] train lossD: -0.160107 lossG: 0.654860\n",
      "[4: 560/1795] train lossD: -0.087147 lossG: 0.562322\n",
      "[4: 565/1795] train lossD: -0.124129 lossG: 0.699960\n",
      "[4: 570/1795] train lossD: -0.049868 lossG: 0.641448\n",
      "[4: 575/1795] train lossD: -0.145356 lossG: 0.651417\n",
      "[4: 580/1795] train lossD: -0.117041 lossG: 0.558846\n",
      "[4: 585/1795] train lossD: -0.168704 lossG: 0.723167\n",
      "[4: 590/1795] train lossD: -0.173859 lossG: 0.674603\n",
      "[4: 595/1795] train lossD: -0.221381 lossG: 0.760941\n",
      "[4: 600/1795] train lossD: -0.060362 lossG: 0.560108\n",
      "[4: 605/1795] train lossD: -0.227938 lossG: 0.605570\n",
      "[4: 610/1795] train lossD: -0.160094 lossG: 0.709172\n",
      "[4: 615/1795] train lossD: -0.165937 lossG: 0.637615\n",
      "[4: 620/1795] train lossD: -0.237047 lossG: 0.587989\n",
      "[4: 625/1795] train lossD: -0.099536 lossG: 0.571260\n",
      "[4: 630/1795] train lossD: -0.155727 lossG: 0.663447\n",
      "[4: 635/1795] train lossD: -0.083911 lossG: 0.724082\n",
      "[4: 640/1795] train lossD: -0.108409 lossG: 0.725342\n",
      "[4: 645/1795] train lossD: -0.143493 lossG: 0.721265\n",
      "[4: 650/1795] train lossD: -0.159092 lossG: 0.738315\n",
      "[4: 655/1795] train lossD: -0.227903 lossG: 0.821148\n",
      "[4: 660/1795] train lossD: -0.196822 lossG: 0.770179\n",
      "[4: 665/1795] train lossD: -0.195823 lossG: 0.657529\n",
      "[4: 670/1795] train lossD: -0.051987 lossG: 0.641638\n",
      "[4: 675/1795] train lossD: -0.116053 lossG: 0.672182\n",
      "[4: 680/1795] train lossD: -0.181514 lossG: 0.695046\n",
      "[4: 685/1795] train lossD: -0.209936 lossG: 0.686719\n",
      "[4: 690/1795] train lossD: -0.139668 lossG: 0.710197\n",
      "[4: 695/1795] train lossD: -0.116127 lossG: 0.729547\n",
      "[4: 700/1795] train lossD: -0.161406 lossG: 0.790331\n",
      "[4: 705/1795] train lossD: -0.161999 lossG: 0.667852\n",
      "[4: 710/1795] train lossD: -0.115319 lossG: 0.681945\n",
      "[4: 715/1795] train lossD: -0.095548 lossG: 0.638232\n",
      "[4: 720/1795] train lossD: -0.201206 lossG: 0.658926\n",
      "[4: 725/1795] train lossD: -0.150802 lossG: 0.624884\n",
      "[4: 730/1795] train lossD: -0.148880 lossG: 0.774721\n",
      "[4: 735/1795] train lossD: -0.118706 lossG: 0.787051\n",
      "[4: 740/1795] train lossD: -0.189485 lossG: 0.591625\n",
      "[4: 745/1795] train lossD: -0.198014 lossG: 0.626217\n",
      "[4: 750/1795] train lossD: -0.174406 lossG: 0.710891\n",
      "[4: 755/1795] train lossD: -0.192393 lossG: 0.702588\n",
      "[4: 760/1795] train lossD: -0.215896 lossG: 0.706289\n",
      "[4: 765/1795] train lossD: -0.135376 lossG: 0.731661\n",
      "[4: 770/1795] train lossD: -0.127155 lossG: 0.692644\n",
      "[4: 775/1795] train lossD: -0.173180 lossG: 0.731634\n",
      "[4: 780/1795] train lossD: -0.186645 lossG: 0.671562\n",
      "[4: 785/1795] train lossD: -0.177833 lossG: 0.817444\n",
      "[4: 790/1795] train lossD: -0.144740 lossG: 0.601719\n",
      "[4: 795/1795] train lossD: -0.148683 lossG: 0.556871\n",
      "[4: 800/1795] train lossD: -0.145687 lossG: 0.605877\n",
      "[4: 805/1795] train lossD: -0.070646 lossG: 0.632648\n",
      "[4: 810/1795] train lossD: -0.218100 lossG: 0.821837\n",
      "[4: 815/1795] train lossD: -0.096527 lossG: 0.703792\n",
      "[4: 820/1795] train lossD: -0.177919 lossG: 0.874292\n",
      "[4: 825/1795] train lossD: -0.085185 lossG: 0.902538\n",
      "[4: 830/1795] train lossD: -0.153378 lossG: 0.663122\n",
      "[4: 835/1795] train lossD: -0.118103 lossG: 0.570413\n",
      "[4: 840/1795] train lossD: -0.048406 lossG: 0.641799\n",
      "[4: 845/1795] train lossD: -0.197836 lossG: 0.677932\n",
      "[4: 850/1795] train lossD: 0.061336 lossG: 0.645000\n",
      "[4: 855/1795] train lossD: -0.131559 lossG: 0.619509\n",
      "[4: 860/1795] train lossD: -0.151874 lossG: 0.680421\n",
      "[4: 865/1795] train lossD: -0.152192 lossG: 0.733379\n",
      "[4: 870/1795] train lossD: -0.181579 lossG: 0.727897\n",
      "[4: 875/1795] train lossD: -0.073461 lossG: 0.805622\n",
      "[4: 880/1795] train lossD: -0.178137 lossG: 0.730914\n",
      "[4: 885/1795] train lossD: -0.146241 lossG: 0.798309\n",
      "[4: 890/1795] train lossD: -0.172573 lossG: 0.769246\n",
      "[4: 895/1795] train lossD: -0.123615 lossG: 0.647449\n",
      "[4: 900/1795] train lossD: -0.163108 lossG: 0.700023\n",
      "[4: 905/1795] train lossD: -0.083922 lossG: 0.612547\n",
      "[4: 910/1795] train lossD: -0.172963 lossG: 0.912624\n",
      "[4: 915/1795] train lossD: -0.171605 lossG: 0.735911\n",
      "[4: 920/1795] train lossD: -0.054293 lossG: 0.556641\n",
      "[4: 925/1795] train lossD: -0.212982 lossG: 0.673990\n",
      "[4: 930/1795] train lossD: -0.101605 lossG: 0.625746\n",
      "[4: 935/1795] train lossD: -0.178208 lossG: 0.710784\n",
      "[4: 940/1795] train lossD: -0.198532 lossG: 0.828470\n",
      "[4: 945/1795] train lossD: -0.173539 lossG: 0.765758\n",
      "[4: 950/1795] train lossD: 0.067721 lossG: 0.732568\n",
      "[4: 955/1795] train lossD: -0.156028 lossG: 0.797979\n",
      "[4: 960/1795] train lossD: -0.097580 lossG: 0.726129\n",
      "[4: 965/1795] train lossD: -0.137586 lossG: 0.661940\n",
      "[4: 970/1795] train lossD: -0.091025 lossG: 0.574224\n",
      "[4: 975/1795] train lossD: -0.170641 lossG: 0.674422\n",
      "[4: 980/1795] train lossD: -0.182823 lossG: 0.803378\n",
      "[4: 985/1795] train lossD: -0.122744 lossG: 0.825669\n",
      "[4: 990/1795] train lossD: -0.121524 lossG: 0.829224\n",
      "[4: 995/1795] train lossD: -0.181778 lossG: 0.848803\n",
      "[4: 1000/1795] train lossD: -0.147504 lossG: 0.710472\n",
      "[4: 1005/1795] train lossD: -0.062169 lossG: 0.581052\n",
      "[4: 1010/1795] train lossD: -0.141949 lossG: 0.548674\n",
      "[4: 1015/1795] train lossD: -0.187979 lossG: 0.732766\n",
      "[4: 1020/1795] train lossD: -0.141641 lossG: 0.655782\n",
      "[4: 1025/1795] train lossD: -0.043221 lossG: 0.622321\n",
      "[4: 1030/1795] train lossD: -0.104472 lossG: 0.623268\n",
      "[4: 1035/1795] train lossD: -0.167269 lossG: 0.737799\n",
      "[4: 1040/1795] train lossD: -0.143280 lossG: 0.696695\n",
      "[4: 1045/1795] train lossD: -0.121877 lossG: 0.838555\n",
      "[4: 1050/1795] train lossD: -0.167059 lossG: 0.770880\n",
      "[4: 1055/1795] train lossD: -0.207016 lossG: 0.794272\n",
      "[4: 1060/1795] train lossD: -0.201299 lossG: 0.800279\n",
      "[4: 1065/1795] train lossD: -0.192041 lossG: 0.778879\n",
      "[4: 1070/1795] train lossD: -0.092703 lossG: 0.710989\n",
      "[4: 1075/1795] train lossD: -0.186128 lossG: 0.694277\n",
      "[4: 1080/1795] train lossD: -0.147630 lossG: 0.654795\n",
      "[4: 1085/1795] train lossD: -0.112030 lossG: 0.684884\n",
      "[4: 1090/1795] train lossD: -0.116118 lossG: 0.690307\n",
      "[4: 1095/1795] train lossD: -0.191784 lossG: 0.663555\n",
      "[4: 1100/1795] train lossD: -0.121755 lossG: 0.710999\n",
      "[4: 1105/1795] train lossD: -0.102787 lossG: 0.636803\n",
      "[4: 1110/1795] train lossD: -0.178233 lossG: 0.714602\n",
      "[4: 1115/1795] train lossD: -0.232471 lossG: 0.711555\n",
      "[4: 1120/1795] train lossD: -0.126482 lossG: 0.707173\n",
      "[4: 1125/1795] train lossD: -0.138643 lossG: 0.664658\n",
      "[4: 1130/1795] train lossD: -0.007597 lossG: 0.743633\n",
      "[4: 1135/1795] train lossD: -0.112052 lossG: 0.607626\n",
      "[4: 1140/1795] train lossD: -0.156915 lossG: 0.650987\n",
      "[4: 1145/1795] train lossD: -0.139206 lossG: 0.642576\n",
      "[4: 1150/1795] train lossD: -0.127285 lossG: 0.704626\n",
      "[4: 1155/1795] train lossD: -0.185322 lossG: 0.676726\n",
      "[4: 1160/1795] train lossD: -0.186649 lossG: 0.732376\n",
      "[4: 1165/1795] train lossD: -0.140291 lossG: 0.774151\n",
      "[4: 1170/1795] train lossD: -0.134365 lossG: 0.804823\n",
      "[4: 1175/1795] train lossD: -0.149623 lossG: 0.757205\n",
      "[4: 1180/1795] train lossD: -0.103302 lossG: 0.774739\n",
      "[4: 1185/1795] train lossD: -0.134117 lossG: 0.698283\n",
      "[4: 1190/1795] train lossD: -0.160161 lossG: 0.761255\n",
      "[4: 1195/1795] train lossD: -0.209767 lossG: 0.672331\n",
      "[4: 1200/1795] train lossD: -0.179223 lossG: 0.632180\n",
      "[4: 1205/1795] train lossD: -0.229235 lossG: 0.702991\n",
      "[4: 1210/1795] train lossD: -0.142307 lossG: 0.625764\n",
      "[4: 1215/1795] train lossD: -0.260218 lossG: 0.745982\n",
      "[4: 1220/1795] train lossD: -0.144079 lossG: 0.756837\n",
      "[4: 1225/1795] train lossD: -0.173431 lossG: 0.755048\n",
      "[4: 1230/1795] train lossD: -0.237843 lossG: 0.834473\n",
      "[4: 1235/1795] train lossD: -0.133944 lossG: 0.548484\n",
      "[4: 1240/1795] train lossD: 0.007758 lossG: 0.708107\n",
      "[4: 1245/1795] train lossD: -0.132321 lossG: 0.755966\n",
      "[4: 1250/1795] train lossD: -0.120212 lossG: 0.587829\n",
      "[4: 1255/1795] train lossD: -0.102402 lossG: 0.606265\n",
      "[4: 1260/1795] train lossD: -0.140720 lossG: 0.726223\n",
      "[4: 1265/1795] train lossD: -0.181423 lossG: 0.710804\n",
      "[4: 1270/1795] train lossD: -0.169614 lossG: 0.569417\n",
      "[4: 1275/1795] train lossD: -0.190466 lossG: 0.645199\n",
      "[4: 1280/1795] train lossD: -0.079691 lossG: 0.780901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4: 1285/1795] train lossD: -0.137969 lossG: 0.751482\n",
      "[4: 1290/1795] train lossD: -0.113596 lossG: 0.671845\n",
      "[4: 1295/1795] train lossD: -0.105200 lossG: 0.583106\n",
      "[4: 1300/1795] train lossD: -0.223044 lossG: 0.858874\n",
      "[4: 1305/1795] train lossD: -0.094607 lossG: 0.520415\n",
      "[4: 1310/1795] train lossD: -0.131732 lossG: 0.643651\n",
      "[4: 1315/1795] train lossD: -0.119235 lossG: 0.710381\n",
      "[4: 1320/1795] train lossD: -0.204170 lossG: 0.726894\n",
      "[4: 1325/1795] train lossD: -0.187453 lossG: 0.749551\n",
      "[4: 1330/1795] train lossD: -0.172727 lossG: 0.765500\n",
      "[4: 1335/1795] train lossD: -0.059671 lossG: 0.747572\n",
      "[4: 1340/1795] train lossD: -0.173306 lossG: 0.650038\n",
      "[4: 1345/1795] train lossD: -0.185515 lossG: 0.566114\n",
      "[4: 1350/1795] train lossD: -0.012075 lossG: 0.553550\n",
      "[4: 1355/1795] train lossD: -0.148280 lossG: 0.662669\n",
      "[4: 1360/1795] train lossD: -0.169558 lossG: 0.671502\n",
      "[4: 1365/1795] train lossD: -0.081386 lossG: 0.737612\n",
      "[4: 1370/1795] train lossD: -0.149494 lossG: 0.725138\n",
      "[4: 1375/1795] train lossD: -0.167141 lossG: 0.594447\n",
      "[4: 1380/1795] train lossD: -0.099333 lossG: 0.837650\n",
      "[4: 1385/1795] train lossD: -0.186931 lossG: 0.599004\n",
      "[4: 1390/1795] train lossD: -0.127546 lossG: 0.768185\n",
      "[4: 1395/1795] train lossD: -0.025217 lossG: 0.601062\n",
      "[4: 1400/1795] train lossD: -0.103972 lossG: 0.717896\n",
      "[4: 1405/1795] train lossD: -0.197091 lossG: 0.803792\n",
      "[4: 1410/1795] train lossD: -0.200045 lossG: 0.647712\n",
      "[4: 1415/1795] train lossD: -0.152786 lossG: 0.788780\n",
      "[4: 1420/1795] train lossD: -0.083802 lossG: 0.736912\n",
      "[4: 1425/1795] train lossD: 0.046319 lossG: 0.624557\n",
      "[4: 1430/1795] train lossD: -0.082261 lossG: 0.634242\n",
      "[4: 1435/1795] train lossD: 0.004569 lossG: 0.558351\n",
      "[4: 1440/1795] train lossD: -0.153440 lossG: 0.704635\n",
      "[4: 1445/1795] train lossD: -0.083623 lossG: 0.552195\n",
      "[4: 1450/1795] train lossD: -0.110756 lossG: 0.837571\n",
      "[4: 1455/1795] train lossD: -0.125930 lossG: 0.629838\n",
      "[4: 1460/1795] train lossD: -0.126545 lossG: 0.739985\n",
      "[4: 1465/1795] train lossD: -0.115290 lossG: 0.653873\n",
      "[4: 1470/1795] train lossD: -0.110840 lossG: 0.568265\n",
      "[4: 1475/1795] train lossD: -0.103162 lossG: 0.622229\n",
      "[4: 1480/1795] train lossD: -0.168145 lossG: 0.783967\n",
      "[4: 1485/1795] train lossD: -0.167650 lossG: 0.764201\n",
      "[4: 1490/1795] train lossD: -0.219747 lossG: 0.696400\n",
      "[4: 1495/1795] train lossD: -0.152165 lossG: 0.576105\n",
      "[4: 1500/1795] train lossD: -0.135787 lossG: 0.598169\n",
      "[4: 1505/1795] train lossD: -0.175814 lossG: 0.628421\n",
      "[4: 1510/1795] train lossD: -0.050573 lossG: 0.594298\n",
      "[4: 1515/1795] train lossD: -0.188274 lossG: 0.600981\n",
      "[4: 1520/1795] train lossD: -0.153385 lossG: 0.591511\n",
      "[4: 1525/1795] train lossD: -0.242097 lossG: 0.618761\n",
      "[4: 1530/1795] train lossD: -0.248798 lossG: 0.694097\n",
      "[4: 1535/1795] train lossD: -0.240111 lossG: 0.740823\n",
      "[4: 1540/1795] train lossD: -0.033978 lossG: 0.610498\n",
      "[4: 1545/1795] train lossD: -0.142785 lossG: 0.634771\n",
      "[4: 1550/1795] train lossD: -0.137487 lossG: 0.609616\n",
      "[4: 1555/1795] train lossD: -0.160030 lossG: 0.515137\n",
      "[4: 1560/1795] train lossD: -0.215664 lossG: 0.770749\n",
      "[4: 1565/1795] train lossD: -0.093857 lossG: 0.711180\n",
      "[4: 1570/1795] train lossD: -0.199074 lossG: 0.682990\n",
      "[4: 1575/1795] train lossD: -0.161758 lossG: 0.657635\n",
      "[4: 1580/1795] train lossD: -0.162585 lossG: 0.690161\n",
      "[4: 1585/1795] train lossD: -0.110196 lossG: 0.531778\n",
      "[4: 1590/1795] train lossD: -0.165732 lossG: 0.639608\n",
      "[4: 1595/1795] train lossD: -0.143792 lossG: 0.580250\n",
      "[4: 1600/1795] train lossD: -0.176498 lossG: 0.675082\n",
      "[4: 1605/1795] train lossD: -0.133453 lossG: 0.732881\n",
      "[4: 1610/1795] train lossD: -0.092231 lossG: 0.654942\n",
      "[4: 1615/1795] train lossD: -0.156930 lossG: 0.706364\n",
      "[4: 1620/1795] train lossD: -0.228139 lossG: 0.760030\n",
      "[4: 1625/1795] train lossD: -0.084995 lossG: 0.542975\n",
      "[4: 1630/1795] train lossD: -0.170904 lossG: 0.635528\n",
      "[4: 1635/1795] train lossD: -0.087147 lossG: 0.522659\n",
      "[4: 1640/1795] train lossD: -0.137969 lossG: 0.496063\n",
      "[4: 1645/1795] train lossD: -0.198898 lossG: 0.717971\n",
      "[4: 1650/1795] train lossD: -0.099841 lossG: 0.516312\n",
      "[4: 1655/1795] train lossD: -0.142462 lossG: 0.697590\n",
      "[4: 1660/1795] train lossD: -0.143288 lossG: 0.640670\n",
      "[4: 1665/1795] train lossD: -0.088858 lossG: 0.654306\n",
      "[4: 1670/1795] train lossD: -0.167729 lossG: 0.687408\n",
      "[4: 1675/1795] train lossD: -0.198098 lossG: 0.645172\n",
      "[4: 1680/1795] train lossD: -0.194584 lossG: 0.678110\n",
      "[4: 1685/1795] train lossD: -0.030736 lossG: 0.881327\n",
      "[4: 1690/1795] train lossD: -0.145721 lossG: 0.687298\n",
      "[4: 1695/1795] train lossD: -0.098641 lossG: 0.718782\n",
      "[4: 1700/1795] train lossD: -0.114865 lossG: 0.662696\n",
      "[4: 1705/1795] train lossD: -0.166116 lossG: 0.736949\n",
      "[4: 1710/1795] train lossD: -0.165540 lossG: 0.606668\n",
      "[4: 1715/1795] train lossD: -0.116229 lossG: 0.592050\n",
      "[4: 1720/1795] train lossD: -0.182527 lossG: 0.621056\n",
      "[4: 1725/1795] train lossD: -0.065270 lossG: 0.914229\n",
      "[4: 1730/1795] train lossD: -0.167909 lossG: 0.755113\n",
      "[4: 1735/1795] train lossD: -0.156326 lossG: 0.741860\n",
      "[4: 1740/1795] train lossD: -0.136894 lossG: 0.627791\n",
      "[4: 1745/1795] train lossD: -0.159400 lossG: 0.717273\n",
      "[4: 1750/1795] train lossD: -0.048203 lossG: 0.624414\n",
      "[4: 1755/1795] train lossD: -0.143901 lossG: 0.680603\n",
      "[4: 1760/1795] train lossD: -0.255699 lossG: 0.710193\n",
      "[4: 1765/1795] train lossD: -0.127476 lossG: 0.601338\n",
      "[4: 1770/1795] train lossD: -0.139060 lossG: 0.580842\n",
      "[4: 1775/1795] train lossD: -0.142177 lossG: 0.618461\n",
      "[4: 1780/1795] train lossD: -0.161835 lossG: 0.678603\n",
      "[4: 1785/1795] train lossD: -0.185664 lossG: 0.613750\n",
      "[4: 1790/1795] train lossD: -0.131986 lossG: 0.742034\n",
      "0.03097650408744812\n",
      "[5: 0/1795] train lossD: -0.188994 lossG: 0.793520\n",
      "[5: 5/1795] train lossD: -0.164515 lossG: 0.697611\n",
      "[5: 10/1795] train lossD: -0.125923 lossG: 0.612368\n",
      "[5: 15/1795] train lossD: -0.030180 lossG: 0.726267\n",
      "[5: 20/1795] train lossD: -0.148676 lossG: 0.651343\n",
      "[5: 25/1795] train lossD: -0.152262 lossG: 0.653357\n",
      "[5: 30/1795] train lossD: -0.211352 lossG: 0.617020\n",
      "[5: 35/1795] train lossD: -0.161714 lossG: 0.609243\n",
      "[5: 40/1795] train lossD: -0.084308 lossG: 0.686609\n",
      "[5: 45/1795] train lossD: -0.153125 lossG: 0.770010\n",
      "[5: 50/1795] train lossD: -0.159221 lossG: 0.733441\n",
      "[5: 55/1795] train lossD: -0.075227 lossG: 0.703556\n",
      "[5: 60/1795] train lossD: -0.184572 lossG: 0.704868\n",
      "[5: 65/1795] train lossD: -0.038622 lossG: 0.571770\n",
      "[5: 70/1795] train lossD: -0.138364 lossG: 0.594905\n",
      "[5: 75/1795] train lossD: -0.126631 lossG: 0.729784\n",
      "[5: 80/1795] train lossD: -0.170971 lossG: 0.570976\n",
      "[5: 85/1795] train lossD: -0.089479 lossG: 0.793919\n",
      "[5: 90/1795] train lossD: -0.193928 lossG: 0.688547\n",
      "[5: 95/1795] train lossD: -0.094319 lossG: 0.643382\n",
      "[5: 100/1795] train lossD: -0.119170 lossG: 0.555533\n",
      "[5: 105/1795] train lossD: -0.094672 lossG: 0.770162\n",
      "[5: 110/1795] train lossD: -0.161645 lossG: 0.675215\n",
      "[5: 115/1795] train lossD: -0.207240 lossG: 0.643206\n",
      "[5: 120/1795] train lossD: -0.143937 lossG: 0.634679\n",
      "[5: 125/1795] train lossD: -0.082258 lossG: 0.760193\n",
      "[5: 130/1795] train lossD: -0.169798 lossG: 0.744797\n",
      "[5: 135/1795] train lossD: -0.008838 lossG: 0.638047\n",
      "[5: 140/1795] train lossD: -0.196846 lossG: 0.742120\n",
      "[5: 145/1795] train lossD: -0.030850 lossG: 0.686960\n",
      "[5: 150/1795] train lossD: -0.106865 lossG: 0.615858\n",
      "[5: 155/1795] train lossD: -0.161825 lossG: 0.677217\n",
      "[5: 160/1795] train lossD: -0.168339 lossG: 0.729846\n",
      "[5: 165/1795] train lossD: -0.146492 lossG: 0.912304\n",
      "[5: 170/1795] train lossD: -0.129307 lossG: 0.769669\n",
      "[5: 175/1795] train lossD: -0.170435 lossG: 0.683257\n",
      "[5: 180/1795] train lossD: -0.062752 lossG: 0.629090\n",
      "[5: 185/1795] train lossD: -0.151964 lossG: 0.664877\n",
      "[5: 190/1795] train lossD: -0.135435 lossG: 0.656066\n",
      "[5: 195/1795] train lossD: -0.154271 lossG: 0.698163\n",
      "[5: 200/1795] train lossD: -0.131296 lossG: 0.699219\n",
      "[5: 205/1795] train lossD: -0.174180 lossG: 0.794098\n",
      "[5: 210/1795] train lossD: -0.121649 lossG: 0.719558\n",
      "[5: 215/1795] train lossD: -0.019257 lossG: 0.602425\n",
      "[5: 220/1795] train lossD: -0.162575 lossG: 0.483211\n",
      "[5: 225/1795] train lossD: -0.103186 lossG: 0.663938\n",
      "[5: 230/1795] train lossD: -0.181832 lossG: 0.657689\n",
      "[5: 235/1795] train lossD: -0.128407 lossG: 0.585447\n",
      "[5: 240/1795] train lossD: -0.136289 lossG: 0.627625\n",
      "[5: 245/1795] train lossD: -0.004585 lossG: 0.629965\n",
      "[5: 250/1795] train lossD: -0.111675 lossG: 0.572050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5: 255/1795] train lossD: -0.097632 lossG: 0.664514\n",
      "[5: 260/1795] train lossD: -0.114120 lossG: 0.784050\n",
      "[5: 265/1795] train lossD: -0.075364 lossG: 0.572087\n",
      "[5: 270/1795] train lossD: -0.126064 lossG: 0.559351\n",
      "[5: 275/1795] train lossD: -0.164050 lossG: 0.710514\n",
      "[5: 280/1795] train lossD: -0.209870 lossG: 0.630163\n",
      "[5: 285/1795] train lossD: -0.198031 lossG: 0.592652\n",
      "[5: 290/1795] train lossD: -0.130445 lossG: 0.635634\n",
      "[5: 295/1795] train lossD: -0.077613 lossG: 0.512588\n",
      "[5: 300/1795] train lossD: -0.158369 lossG: 0.637742\n",
      "[5: 305/1795] train lossD: -0.151154 lossG: 0.648228\n",
      "[5: 310/1795] train lossD: -0.179237 lossG: 0.698383\n",
      "[5: 315/1795] train lossD: -0.017754 lossG: 0.616020\n",
      "[5: 320/1795] train lossD: -0.071657 lossG: 0.657997\n",
      "[5: 325/1795] train lossD: -0.131509 lossG: 0.614296\n",
      "[5: 330/1795] train lossD: -0.152700 lossG: 0.553218\n",
      "[5: 335/1795] train lossD: -0.136287 lossG: 0.626442\n",
      "[5: 340/1795] train lossD: -0.148041 lossG: 0.567530\n",
      "[5: 345/1795] train lossD: -0.087683 lossG: 0.656315\n",
      "[5: 350/1795] train lossD: -0.164979 lossG: 0.631285\n",
      "[5: 355/1795] train lossD: -0.137215 lossG: 0.655891\n",
      "[5: 360/1795] train lossD: -0.121745 lossG: 0.726112\n",
      "[5: 365/1795] train lossD: -0.156205 lossG: 0.568478\n",
      "[5: 370/1795] train lossD: -0.130251 lossG: 0.687519\n",
      "[5: 375/1795] train lossD: -0.100944 lossG: 0.643840\n",
      "[5: 380/1795] train lossD: -0.081127 lossG: 0.651620\n",
      "[5: 385/1795] train lossD: -0.186442 lossG: 0.750440\n",
      "[5: 390/1795] train lossD: -0.134740 lossG: 0.574393\n",
      "[5: 395/1795] train lossD: -0.168460 lossG: 0.609160\n",
      "[5: 400/1795] train lossD: -0.063979 lossG: 0.543457\n",
      "[5: 405/1795] train lossD: -0.205709 lossG: 0.669802\n",
      "[5: 410/1795] train lossD: -0.143016 lossG: 0.741980\n",
      "[5: 415/1795] train lossD: -0.162723 lossG: 0.659038\n",
      "[5: 420/1795] train lossD: -0.127482 lossG: 0.622778\n",
      "[5: 425/1795] train lossD: -0.063908 lossG: 0.660080\n",
      "[5: 430/1795] train lossD: -0.174827 lossG: 0.637041\n",
      "[5: 435/1795] train lossD: -0.158354 lossG: 0.607703\n",
      "[5: 440/1795] train lossD: -0.173145 lossG: 0.668718\n",
      "[5: 445/1795] train lossD: -0.084319 lossG: 0.714745\n",
      "[5: 450/1795] train lossD: -0.147383 lossG: 0.666413\n",
      "[5: 455/1795] train lossD: -0.140745 lossG: 0.629589\n",
      "[5: 460/1795] train lossD: -0.119308 lossG: 0.768594\n",
      "[5: 465/1795] train lossD: -0.140636 lossG: 0.755873\n",
      "[5: 470/1795] train lossD: -0.122168 lossG: 0.699223\n",
      "[5: 475/1795] train lossD: -0.087477 lossG: 0.582021\n",
      "[5: 480/1795] train lossD: -0.083439 lossG: 0.577810\n",
      "[5: 485/1795] train lossD: -0.134130 lossG: 0.656973\n",
      "[5: 490/1795] train lossD: -0.158654 lossG: 0.600756\n",
      "[5: 495/1795] train lossD: -0.104914 lossG: 0.678310\n",
      "[5: 500/1795] train lossD: -0.132567 lossG: 0.669262\n",
      "[5: 505/1795] train lossD: -0.176069 lossG: 0.745442\n",
      "[5: 510/1795] train lossD: -0.213458 lossG: 0.673038\n",
      "[5: 515/1795] train lossD: -0.069756 lossG: 0.685919\n",
      "[5: 520/1795] train lossD: -0.119685 lossG: 0.626216\n",
      "[5: 525/1795] train lossD: -0.135965 lossG: 0.591413\n",
      "[5: 530/1795] train lossD: -0.122682 lossG: 0.783251\n",
      "[5: 535/1795] train lossD: -0.148721 lossG: 0.685276\n",
      "[5: 540/1795] train lossD: -0.182264 lossG: 0.690733\n",
      "[5: 545/1795] train lossD: -0.151502 lossG: 0.671488\n",
      "[5: 550/1795] train lossD: -0.208446 lossG: 0.633585\n",
      "[5: 555/1795] train lossD: -0.122579 lossG: 0.516745\n",
      "[5: 560/1795] train lossD: -0.153426 lossG: 0.619278\n",
      "[5: 565/1795] train lossD: -0.149843 lossG: 0.563650\n",
      "[5: 570/1795] train lossD: -0.157109 lossG: 0.563921\n",
      "[5: 575/1795] train lossD: -0.056023 lossG: 0.627432\n",
      "[5: 580/1795] train lossD: -0.180057 lossG: 0.638195\n",
      "[5: 585/1795] train lossD: -0.170603 lossG: 0.684396\n",
      "[5: 590/1795] train lossD: -0.075638 lossG: 0.626447\n",
      "[5: 595/1795] train lossD: -0.105874 lossG: 0.675989\n",
      "[5: 600/1795] train lossD: -0.170717 lossG: 0.624841\n",
      "[5: 605/1795] train lossD: -0.103928 lossG: 0.556106\n",
      "[5: 610/1795] train lossD: -0.120012 lossG: 0.604340\n",
      "[5: 615/1795] train lossD: -0.106093 lossG: 0.618540\n",
      "[5: 620/1795] train lossD: -0.198098 lossG: 0.689460\n",
      "[5: 625/1795] train lossD: -0.107737 lossG: 0.606043\n",
      "[5: 630/1795] train lossD: -0.127034 lossG: 0.571637\n",
      "[5: 635/1795] train lossD: -0.105865 lossG: 0.666180\n",
      "[5: 640/1795] train lossD: -0.122062 lossG: 0.660991\n",
      "[5: 645/1795] train lossD: -0.117655 lossG: 0.825737\n",
      "[5: 650/1795] train lossD: -0.149502 lossG: 0.638050\n",
      "[5: 655/1795] train lossD: -0.153430 lossG: 0.593835\n",
      "[5: 660/1795] train lossD: -0.127795 lossG: 0.633758\n",
      "[5: 665/1795] train lossD: -0.098431 lossG: 0.712188\n",
      "[5: 670/1795] train lossD: -0.128604 lossG: 0.730577\n",
      "[5: 675/1795] train lossD: -0.074390 lossG: 0.686530\n",
      "[5: 680/1795] train lossD: -0.167469 lossG: 0.729191\n",
      "[5: 685/1795] train lossD: -0.133189 lossG: 0.671723\n",
      "[5: 690/1795] train lossD: -0.172604 lossG: 0.690622\n",
      "[5: 695/1795] train lossD: -0.120377 lossG: 0.654136\n",
      "[5: 700/1795] train lossD: -0.098812 lossG: 0.930767\n",
      "[5: 705/1795] train lossD: -0.128079 lossG: 0.696890\n",
      "[5: 710/1795] train lossD: -0.157601 lossG: 0.645079\n",
      "[5: 715/1795] train lossD: -0.150356 lossG: 0.654433\n",
      "[5: 720/1795] train lossD: -0.169854 lossG: 0.794459\n",
      "[5: 725/1795] train lossD: -0.060933 lossG: 0.589051\n",
      "[5: 730/1795] train lossD: -0.139836 lossG: 0.625600\n",
      "[5: 735/1795] train lossD: -0.098659 lossG: 0.792418\n",
      "[5: 740/1795] train lossD: -0.134947 lossG: 0.770203\n",
      "[5: 745/1795] train lossD: -0.171858 lossG: 0.705331\n",
      "[5: 750/1795] train lossD: -0.039071 lossG: 0.689079\n",
      "[5: 755/1795] train lossD: -0.162794 lossG: 0.663086\n",
      "[5: 760/1795] train lossD: -0.095389 lossG: 0.469217\n",
      "[5: 765/1795] train lossD: -0.162633 lossG: 0.605212\n",
      "[5: 770/1795] train lossD: -0.107966 lossG: 0.682288\n",
      "[5: 775/1795] train lossD: -0.129549 lossG: 0.703020\n",
      "[5: 780/1795] train lossD: -0.098832 lossG: 0.667900\n",
      "[5: 785/1795] train lossD: -0.113823 lossG: 0.700493\n",
      "[5: 790/1795] train lossD: -0.150945 lossG: 0.654550\n",
      "[5: 795/1795] train lossD: -0.111785 lossG: 0.578643\n",
      "[5: 800/1795] train lossD: -0.177963 lossG: 0.568092\n",
      "[5: 805/1795] train lossD: -0.064749 lossG: 0.578349\n",
      "[5: 810/1795] train lossD: 0.017858 lossG: 0.516882\n",
      "[5: 815/1795] train lossD: -0.065212 lossG: 0.542242\n",
      "[5: 820/1795] train lossD: -0.094901 lossG: 0.682375\n",
      "[5: 825/1795] train lossD: -0.124547 lossG: 0.624288\n",
      "[5: 830/1795] train lossD: -0.062788 lossG: 0.706145\n",
      "[5: 835/1795] train lossD: -0.121486 lossG: 0.636515\n",
      "[5: 840/1795] train lossD: -0.057191 lossG: 0.663438\n",
      "[5: 845/1795] train lossD: -0.152802 lossG: 0.608187\n",
      "[5: 850/1795] train lossD: -0.144295 lossG: 0.679595\n",
      "[5: 855/1795] train lossD: -0.180340 lossG: 0.653833\n",
      "[5: 860/1795] train lossD: -0.178304 lossG: 0.684102\n",
      "[5: 865/1795] train lossD: -0.159797 lossG: 0.652237\n",
      "[5: 870/1795] train lossD: -0.226770 lossG: 0.797127\n",
      "[5: 875/1795] train lossD: -0.109622 lossG: 0.665621\n",
      "[5: 880/1795] train lossD: -0.157817 lossG: 0.630815\n",
      "[5: 885/1795] train lossD: -0.134595 lossG: 0.706948\n",
      "[5: 890/1795] train lossD: -0.137875 lossG: 0.632374\n",
      "[5: 895/1795] train lossD: -0.155993 lossG: 0.683860\n",
      "[5: 900/1795] train lossD: -0.159621 lossG: 0.803608\n",
      "[5: 905/1795] train lossD: -0.112202 lossG: 0.588359\n",
      "[5: 910/1795] train lossD: -0.170599 lossG: 0.776325\n",
      "[5: 915/1795] train lossD: -0.161423 lossG: 0.685388\n",
      "[5: 920/1795] train lossD: -0.119824 lossG: 0.687778\n",
      "[5: 925/1795] train lossD: -0.143599 lossG: 0.668524\n",
      "[5: 930/1795] train lossD: -0.111806 lossG: 0.599395\n",
      "[5: 935/1795] train lossD: -0.147072 lossG: 0.680285\n",
      "[5: 940/1795] train lossD: -0.096459 lossG: 0.675493\n",
      "[5: 945/1795] train lossD: -0.155166 lossG: 0.626191\n",
      "[5: 950/1795] train lossD: -0.080025 lossG: 0.529040\n",
      "[5: 955/1795] train lossD: -0.156186 lossG: 0.646205\n",
      "[5: 960/1795] train lossD: -0.142418 lossG: 0.645950\n",
      "[5: 965/1795] train lossD: -0.139616 lossG: 0.634444\n",
      "[5: 970/1795] train lossD: -0.069051 lossG: 0.604008\n",
      "[5: 975/1795] train lossD: -0.081869 lossG: 0.504064\n",
      "[5: 980/1795] train lossD: -0.157236 lossG: 0.667307\n",
      "[5: 985/1795] train lossD: -0.170280 lossG: 0.545257\n",
      "[5: 990/1795] train lossD: -0.131024 lossG: 0.714633\n",
      "[5: 995/1795] train lossD: -0.166226 lossG: 0.607057\n",
      "[5: 1000/1795] train lossD: -0.098611 lossG: 0.566138\n",
      "[5: 1005/1795] train lossD: -0.143611 lossG: 0.755849\n",
      "[5: 1010/1795] train lossD: -0.113274 lossG: 0.587854\n",
      "[5: 1015/1795] train lossD: -0.148387 lossG: 0.663012\n",
      "[5: 1020/1795] train lossD: -0.088250 lossG: 0.689117\n",
      "[5: 1025/1795] train lossD: -0.102686 lossG: 0.669145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5: 1030/1795] train lossD: -0.174739 lossG: 0.700487\n",
      "[5: 1035/1795] train lossD: -0.142515 lossG: 0.680274\n",
      "[5: 1040/1795] train lossD: -0.119395 lossG: 0.587154\n",
      "[5: 1045/1795] train lossD: -0.103628 lossG: 0.678552\n",
      "[5: 1050/1795] train lossD: -0.176552 lossG: 0.637315\n",
      "[5: 1055/1795] train lossD: -0.145652 lossG: 0.650260\n",
      "[5: 1060/1795] train lossD: -0.072054 lossG: 0.559381\n",
      "[5: 1065/1795] train lossD: -0.109278 lossG: 0.614165\n",
      "[5: 1070/1795] train lossD: -0.183832 lossG: 0.493273\n",
      "[5: 1075/1795] train lossD: -0.111839 lossG: 0.698898\n",
      "[5: 1080/1795] train lossD: -0.155689 lossG: 0.453145\n",
      "[5: 1085/1795] train lossD: -0.116622 lossG: 0.606774\n",
      "[5: 1090/1795] train lossD: -0.159726 lossG: 0.652651\n",
      "[5: 1095/1795] train lossD: -0.076692 lossG: 0.562263\n",
      "[5: 1100/1795] train lossD: -0.090200 lossG: 0.669398\n",
      "[5: 1105/1795] train lossD: -0.149351 lossG: 0.758795\n",
      "[5: 1110/1795] train lossD: -0.114975 lossG: 0.670416\n",
      "[5: 1115/1795] train lossD: -0.126180 lossG: 0.555290\n",
      "[5: 1120/1795] train lossD: -0.202526 lossG: 0.478533\n",
      "[5: 1125/1795] train lossD: -0.157788 lossG: 0.605683\n",
      "[5: 1130/1795] train lossD: -0.124916 lossG: 0.581950\n",
      "[5: 1135/1795] train lossD: -0.172082 lossG: 0.692632\n",
      "[5: 1140/1795] train lossD: -0.145876 lossG: 0.619233\n",
      "[5: 1145/1795] train lossD: -0.049774 lossG: 0.717125\n",
      "[5: 1150/1795] train lossD: -0.137664 lossG: 0.778686\n",
      "[5: 1155/1795] train lossD: -0.109499 lossG: 0.576042\n",
      "[5: 1160/1795] train lossD: -0.141126 lossG: 0.537663\n",
      "[5: 1165/1795] train lossD: -0.146791 lossG: 0.664156\n",
      "[5: 1170/1795] train lossD: -0.060907 lossG: 0.752322\n",
      "[5: 1175/1795] train lossD: -0.134704 lossG: 0.632145\n",
      "[5: 1180/1795] train lossD: -0.148402 lossG: 0.675155\n",
      "[5: 1185/1795] train lossD: -0.060936 lossG: 0.613949\n",
      "[5: 1190/1795] train lossD: -0.178982 lossG: 0.647918\n",
      "[5: 1195/1795] train lossD: -0.135538 lossG: 0.656231\n",
      "[5: 1200/1795] train lossD: -0.102576 lossG: 0.668177\n",
      "[5: 1205/1795] train lossD: -0.151896 lossG: 0.568819\n",
      "[5: 1210/1795] train lossD: -0.187100 lossG: 0.534507\n",
      "[5: 1215/1795] train lossD: -0.128102 lossG: 0.510570\n",
      "[5: 1220/1795] train lossD: -0.092769 lossG: 0.621543\n",
      "[5: 1225/1795] train lossD: -0.162304 lossG: 0.609607\n",
      "[5: 1230/1795] train lossD: -0.143914 lossG: 0.519466\n",
      "[5: 1235/1795] train lossD: -0.162167 lossG: 0.541455\n",
      "[5: 1240/1795] train lossD: -0.143281 lossG: 0.549996\n",
      "[5: 1245/1795] train lossD: -0.140473 lossG: 0.555366\n",
      "[5: 1250/1795] train lossD: -0.109419 lossG: 0.619521\n",
      "[5: 1255/1795] train lossD: -0.113190 lossG: 0.583483\n",
      "[5: 1260/1795] train lossD: -0.008938 lossG: 0.470263\n",
      "[5: 1265/1795] train lossD: -0.024108 lossG: 0.570315\n",
      "[5: 1270/1795] train lossD: -0.121458 lossG: 0.542327\n",
      "[5: 1275/1795] train lossD: -0.116700 lossG: 0.608305\n",
      "[5: 1280/1795] train lossD: -0.032922 lossG: 0.502761\n",
      "[5: 1285/1795] train lossD: -0.160325 lossG: 0.564571\n",
      "[5: 1290/1795] train lossD: -0.091515 lossG: 0.624610\n",
      "[5: 1295/1795] train lossD: -0.123615 lossG: 0.509046\n",
      "[5: 1300/1795] train lossD: -0.144057 lossG: 0.550696\n",
      "[5: 1305/1795] train lossD: -0.097281 lossG: 0.631226\n",
      "[5: 1310/1795] train lossD: -0.144649 lossG: 0.526715\n",
      "[5: 1315/1795] train lossD: -0.113417 lossG: 0.562848\n",
      "[5: 1320/1795] train lossD: -0.118682 lossG: 0.441765\n",
      "[5: 1325/1795] train lossD: -0.109204 lossG: 0.481964\n",
      "[5: 1330/1795] train lossD: -0.007722 lossG: 0.467245\n",
      "[5: 1335/1795] train lossD: -0.136601 lossG: 0.564599\n",
      "[5: 1340/1795] train lossD: -0.127234 lossG: 0.583771\n",
      "[5: 1345/1795] train lossD: -0.137499 lossG: 0.602608\n",
      "[5: 1350/1795] train lossD: -0.160171 lossG: 0.635798\n",
      "[5: 1355/1795] train lossD: -0.115034 lossG: 0.493186\n",
      "[5: 1360/1795] train lossD: 0.326603 lossG: 0.785523\n",
      "[5: 1365/1795] train lossD: -0.117653 lossG: 0.774924\n",
      "[5: 1370/1795] train lossD: -0.080212 lossG: 0.766110\n",
      "[5: 1375/1795] train lossD: -0.172231 lossG: 0.734971\n",
      "[5: 1380/1795] train lossD: -0.127391 lossG: 0.619250\n",
      "[5: 1385/1795] train lossD: -0.151912 lossG: 0.795525\n",
      "[5: 1390/1795] train lossD: -0.133043 lossG: 0.697840\n",
      "[5: 1395/1795] train lossD: -0.198494 lossG: 0.663959\n",
      "[5: 1400/1795] train lossD: -0.165750 lossG: 0.548581\n",
      "[5: 1405/1795] train lossD: -0.157085 lossG: 0.699665\n",
      "[5: 1410/1795] train lossD: -0.062332 lossG: 0.638658\n",
      "[5: 1415/1795] train lossD: -0.174794 lossG: 0.629258\n",
      "[5: 1420/1795] train lossD: -0.091770 lossG: 0.540092\n",
      "[5: 1425/1795] train lossD: -0.127021 lossG: 0.601046\n",
      "[5: 1430/1795] train lossD: -0.140322 lossG: 0.588802\n",
      "[5: 1435/1795] train lossD: -0.116319 lossG: 0.561837\n",
      "[5: 1440/1795] train lossD: -0.178999 lossG: 0.638409\n",
      "[5: 1445/1795] train lossD: -0.178578 lossG: 0.648201\n",
      "[5: 1450/1795] train lossD: -0.025906 lossG: 0.491102\n",
      "[5: 1455/1795] train lossD: -0.145780 lossG: 0.518672\n",
      "[5: 1460/1795] train lossD: -0.178596 lossG: 0.470045\n",
      "[5: 1465/1795] train lossD: -0.079700 lossG: 0.589918\n",
      "[5: 1470/1795] train lossD: -0.118556 lossG: 0.529855\n",
      "[5: 1475/1795] train lossD: -0.073916 lossG: 0.446812\n",
      "[5: 1480/1795] train lossD: -0.164046 lossG: 0.467171\n",
      "[5: 1485/1795] train lossD: -0.033802 lossG: 0.526232\n",
      "[5: 1490/1795] train lossD: -0.188380 lossG: 0.584388\n",
      "[5: 1495/1795] train lossD: -0.057729 lossG: 0.532843\n",
      "[5: 1500/1795] train lossD: -0.111963 lossG: 0.403362\n",
      "[5: 1505/1795] train lossD: -0.174412 lossG: 0.505482\n",
      "[5: 1510/1795] train lossD: -0.169390 lossG: 0.497970\n",
      "[5: 1515/1795] train lossD: -0.140503 lossG: 0.739398\n",
      "[5: 1520/1795] train lossD: -0.089973 lossG: 0.574256\n",
      "[5: 1525/1795] train lossD: -0.121835 lossG: 0.528160\n",
      "[5: 1530/1795] train lossD: -0.130227 lossG: 0.565983\n",
      "[5: 1535/1795] train lossD: -0.139603 lossG: 0.553608\n",
      "[5: 1540/1795] train lossD: -0.150649 lossG: 0.585765\n",
      "[5: 1545/1795] train lossD: -0.110708 lossG: 0.604529\n",
      "[5: 1550/1795] train lossD: -0.086506 lossG: 0.509644\n",
      "[5: 1555/1795] train lossD: -0.155587 lossG: 0.631474\n",
      "[5: 1560/1795] train lossD: -0.111003 lossG: 0.571121\n",
      "[5: 1565/1795] train lossD: 0.055676 lossG: 0.600689\n",
      "[5: 1570/1795] train lossD: -0.061784 lossG: 0.402669\n",
      "[5: 1575/1795] train lossD: -0.128126 lossG: 0.515761\n",
      "[5: 1580/1795] train lossD: -0.113211 lossG: 0.616410\n",
      "[5: 1585/1795] train lossD: -0.078481 lossG: 0.537432\n",
      "[5: 1590/1795] train lossD: -0.149850 lossG: 0.435439\n",
      "[5: 1595/1795] train lossD: -0.167265 lossG: 0.507098\n",
      "[5: 1600/1795] train lossD: -0.038054 lossG: 0.641998\n",
      "[5: 1605/1795] train lossD: -0.105540 lossG: 0.664142\n",
      "[5: 1610/1795] train lossD: -0.057712 lossG: 0.555036\n",
      "[5: 1615/1795] train lossD: -0.064860 lossG: 0.585798\n",
      "[5: 1620/1795] train lossD: -0.127437 lossG: 0.613502\n",
      "[5: 1625/1795] train lossD: -0.121830 lossG: 0.533117\n",
      "[5: 1630/1795] train lossD: -0.090570 lossG: 0.605748\n",
      "[5: 1635/1795] train lossD: 0.056138 lossG: 0.635009\n",
      "[5: 1640/1795] train lossD: -0.089726 lossG: 0.668203\n",
      "[5: 1645/1795] train lossD: -0.097489 lossG: 0.598341\n",
      "[5: 1650/1795] train lossD: -0.154722 lossG: 0.645432\n",
      "[5: 1655/1795] train lossD: -0.123883 lossG: 0.539255\n",
      "[5: 1660/1795] train lossD: -0.090756 lossG: 0.686516\n",
      "[5: 1665/1795] train lossD: -0.107757 lossG: 0.582067\n",
      "[5: 1670/1795] train lossD: -0.118048 lossG: 0.648962\n",
      "[5: 1675/1795] train lossD: -0.151820 lossG: 0.521133\n",
      "[5: 1680/1795] train lossD: -0.092265 lossG: 0.588666\n",
      "[5: 1685/1795] train lossD: -0.186505 lossG: 0.549023\n",
      "[5: 1690/1795] train lossD: -0.105083 lossG: 0.648353\n",
      "[5: 1695/1795] train lossD: -0.082345 lossG: 0.627005\n",
      "[5: 1700/1795] train lossD: -0.116140 lossG: 0.624962\n",
      "[5: 1705/1795] train lossD: -0.193346 lossG: 0.618401\n",
      "[5: 1710/1795] train lossD: -0.136605 lossG: 0.537637\n",
      "[5: 1715/1795] train lossD: -0.076396 lossG: 0.594593\n",
      "[5: 1720/1795] train lossD: -0.020059 lossG: 0.435023\n",
      "[5: 1725/1795] train lossD: -0.124205 lossG: 0.579647\n",
      "[5: 1730/1795] train lossD: -0.097378 lossG: 0.530124\n",
      "[5: 1735/1795] train lossD: 0.034072 lossG: 0.869738\n",
      "[5: 1740/1795] train lossD: -0.104193 lossG: 0.563653\n",
      "[5: 1745/1795] train lossD: -0.124191 lossG: 0.547805\n",
      "[5: 1750/1795] train lossD: -0.090509 lossG: 0.399683\n",
      "[5: 1755/1795] train lossD: -0.105377 lossG: 0.511598\n",
      "[5: 1760/1795] train lossD: -0.142869 lossG: 0.579941\n",
      "[5: 1765/1795] train lossD: -0.071130 lossG: 0.446759\n",
      "[5: 1770/1795] train lossD: -0.113697 lossG: 0.515830\n",
      "[5: 1775/1795] train lossD: -0.144969 lossG: 0.599977\n",
      "[5: 1780/1795] train lossD: -0.190418 lossG: 0.625112\n",
      "[5: 1785/1795] train lossD: -0.101861 lossG: 0.460933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5: 1790/1795] train lossD: -0.139936 lossG: 0.481640\n",
      "0.037385858595371246\n",
      "[6: 0/1795] train lossD: -0.020827 lossG: 0.509927\n",
      "[6: 5/1795] train lossD: -0.152710 lossG: 0.531977\n",
      "[6: 10/1795] train lossD: -0.173704 lossG: 0.423268\n",
      "[6: 15/1795] train lossD: -0.117393 lossG: 0.443094\n",
      "[6: 20/1795] train lossD: -0.154037 lossG: 0.501619\n",
      "[6: 25/1795] train lossD: -0.065733 lossG: 0.547052\n",
      "[6: 30/1795] train lossD: -0.111792 lossG: 0.532073\n",
      "[6: 35/1795] train lossD: -0.186383 lossG: 0.498464\n",
      "[6: 40/1795] train lossD: -0.075525 lossG: 0.475713\n",
      "[6: 45/1795] train lossD: -0.072572 lossG: 0.509453\n",
      "[6: 50/1795] train lossD: -0.101691 lossG: 0.488355\n",
      "[6: 55/1795] train lossD: -0.134349 lossG: 0.506049\n",
      "[6: 60/1795] train lossD: -0.087873 lossG: 0.547014\n",
      "[6: 65/1795] train lossD: -0.120700 lossG: 0.578394\n",
      "[6: 70/1795] train lossD: -0.171359 lossG: 0.601194\n",
      "[6: 75/1795] train lossD: -0.188387 lossG: 0.573362\n",
      "[6: 80/1795] train lossD: -0.157484 lossG: 0.603063\n",
      "[6: 85/1795] train lossD: -0.144903 lossG: 0.586531\n",
      "[6: 90/1795] train lossD: -0.096930 lossG: 0.537295\n",
      "[6: 95/1795] train lossD: -0.062251 lossG: 0.534838\n",
      "[6: 100/1795] train lossD: -0.148070 lossG: 0.475743\n",
      "[6: 105/1795] train lossD: -0.122190 lossG: 0.563512\n",
      "[6: 110/1795] train lossD: -0.157180 lossG: 0.434689\n",
      "[6: 115/1795] train lossD: -0.147055 lossG: 0.486501\n",
      "[6: 120/1795] train lossD: -0.119891 lossG: 0.508227\n",
      "[6: 125/1795] train lossD: -0.139167 lossG: 0.588569\n",
      "[6: 130/1795] train lossD: -0.078798 lossG: 0.497492\n",
      "[6: 135/1795] train lossD: -0.171564 lossG: 0.550647\n",
      "[6: 140/1795] train lossD: -0.140659 lossG: 0.638862\n",
      "[6: 145/1795] train lossD: -0.129896 lossG: 0.520501\n",
      "[6: 150/1795] train lossD: -0.100732 lossG: 0.465830\n",
      "[6: 155/1795] train lossD: -0.091846 lossG: 0.594469\n",
      "[6: 160/1795] train lossD: -0.146089 lossG: 0.524897\n",
      "[6: 165/1795] train lossD: -0.177764 lossG: 0.646404\n",
      "[6: 170/1795] train lossD: -0.156865 lossG: 0.477746\n",
      "[6: 175/1795] train lossD: -0.073516 lossG: 0.545039\n",
      "[6: 180/1795] train lossD: -0.112841 lossG: 0.479738\n",
      "[6: 185/1795] train lossD: -0.128168 lossG: 0.392189\n",
      "[6: 190/1795] train lossD: -0.140575 lossG: 0.583081\n",
      "[6: 195/1795] train lossD: 0.046477 lossG: 0.495409\n",
      "[6: 200/1795] train lossD: -0.118930 lossG: 0.548767\n",
      "[6: 205/1795] train lossD: -0.082178 lossG: 0.488712\n",
      "[6: 210/1795] train lossD: -0.106415 lossG: 0.472380\n",
      "[6: 215/1795] train lossD: -0.095522 lossG: 0.502986\n",
      "[6: 220/1795] train lossD: -0.070445 lossG: 0.531410\n",
      "[6: 225/1795] train lossD: -0.072558 lossG: 0.541000\n",
      "[6: 230/1795] train lossD: -0.154376 lossG: 0.536553\n",
      "[6: 235/1795] train lossD: -0.145898 lossG: 0.513080\n",
      "[6: 240/1795] train lossD: -0.155492 lossG: 0.541100\n",
      "[6: 245/1795] train lossD: -0.128311 lossG: 0.537989\n",
      "[6: 250/1795] train lossD: -0.057149 lossG: 0.428582\n",
      "[6: 255/1795] train lossD: -0.148579 lossG: 0.571617\n",
      "[6: 260/1795] train lossD: -0.058511 lossG: 0.495984\n",
      "[6: 265/1795] train lossD: -0.150621 lossG: 0.390353\n",
      "[6: 270/1795] train lossD: -0.137858 lossG: 0.482958\n",
      "[6: 275/1795] train lossD: -0.111507 lossG: 0.454999\n",
      "[6: 280/1795] train lossD: -0.118994 lossG: 0.540145\n",
      "[6: 285/1795] train lossD: -0.121165 lossG: 0.574678\n",
      "[6: 290/1795] train lossD: -0.046920 lossG: 0.489083\n",
      "[6: 295/1795] train lossD: -0.094590 lossG: 0.458300\n",
      "[6: 300/1795] train lossD: -0.196437 lossG: 0.619455\n",
      "[6: 305/1795] train lossD: -0.008936 lossG: 0.408750\n",
      "[6: 310/1795] train lossD: -0.175131 lossG: 0.521309\n",
      "[6: 315/1795] train lossD: -0.163070 lossG: 0.598738\n",
      "[6: 320/1795] train lossD: -0.139991 lossG: 0.493281\n",
      "[6: 325/1795] train lossD: -0.095111 lossG: 0.448311\n",
      "[6: 330/1795] train lossD: -0.100618 lossG: 0.506761\n",
      "[6: 335/1795] train lossD: -0.172028 lossG: 0.534894\n",
      "[6: 340/1795] train lossD: -0.120825 lossG: 0.465164\n",
      "[6: 345/1795] train lossD: -0.064551 lossG: 0.557092\n",
      "[6: 350/1795] train lossD: -0.161219 lossG: 0.679392\n",
      "[6: 355/1795] train lossD: -0.029715 lossG: 0.542862\n",
      "[6: 360/1795] train lossD: -0.185977 lossG: 0.470904\n",
      "[6: 365/1795] train lossD: -0.101406 lossG: 0.477142\n",
      "[6: 370/1795] train lossD: -0.097331 lossG: 0.407852\n",
      "[6: 375/1795] train lossD: -0.096772 lossG: 0.495426\n",
      "[6: 380/1795] train lossD: -0.071606 lossG: 0.476774\n",
      "[6: 385/1795] train lossD: -0.089915 lossG: 0.540583\n",
      "[6: 390/1795] train lossD: -0.100570 lossG: 0.539700\n",
      "[6: 395/1795] train lossD: -0.142795 lossG: 0.598995\n",
      "[6: 400/1795] train lossD: -0.057749 lossG: 0.440109\n",
      "[6: 405/1795] train lossD: -0.098843 lossG: 0.524219\n",
      "[6: 410/1795] train lossD: -0.160695 lossG: 0.576013\n",
      "[6: 415/1795] train lossD: -0.147366 lossG: 0.600972\n",
      "[6: 420/1795] train lossD: 0.051130 lossG: 0.420090\n",
      "[6: 425/1795] train lossD: -0.077848 lossG: 0.589139\n",
      "[6: 430/1795] train lossD: -0.011903 lossG: 0.634629\n",
      "[6: 435/1795] train lossD: -0.095707 lossG: 0.579547\n",
      "[6: 440/1795] train lossD: -0.200462 lossG: 0.558330\n",
      "[6: 445/1795] train lossD: -0.152912 lossG: 0.468340\n",
      "[6: 450/1795] train lossD: -0.076700 lossG: 0.464235\n",
      "[6: 455/1795] train lossD: -0.126968 lossG: 0.599643\n",
      "[6: 460/1795] train lossD: -0.095256 lossG: 0.617329\n",
      "[6: 465/1795] train lossD: -0.116679 lossG: 0.524013\n",
      "[6: 470/1795] train lossD: -0.023919 lossG: 0.495388\n",
      "[6: 475/1795] train lossD: -0.043065 lossG: 0.640420\n",
      "[6: 480/1795] train lossD: -0.136573 lossG: 0.579936\n",
      "[6: 485/1795] train lossD: -0.188192 lossG: 0.592116\n",
      "[6: 490/1795] train lossD: -0.117834 lossG: 0.578932\n",
      "[6: 495/1795] train lossD: -0.125475 lossG: 0.549351\n",
      "[6: 500/1795] train lossD: -0.087047 lossG: 0.569842\n",
      "[6: 505/1795] train lossD: -0.052870 lossG: 0.439197\n",
      "[6: 510/1795] train lossD: -0.143495 lossG: 0.505258\n",
      "[6: 515/1795] train lossD: -0.095354 lossG: 0.572077\n",
      "[6: 520/1795] train lossD: -0.134818 lossG: 0.514352\n",
      "[6: 525/1795] train lossD: 0.089970 lossG: 0.687687\n",
      "[6: 530/1795] train lossD: -0.107097 lossG: 0.673044\n",
      "[6: 535/1795] train lossD: -0.093584 lossG: 0.511719\n",
      "[6: 540/1795] train lossD: -0.166977 lossG: 0.564890\n",
      "[6: 545/1795] train lossD: -0.114791 lossG: 0.430879\n",
      "[6: 550/1795] train lossD: -0.123828 lossG: 0.451324\n",
      "[6: 555/1795] train lossD: -0.135018 lossG: 0.574209\n",
      "[6: 560/1795] train lossD: -0.138254 lossG: 0.573384\n",
      "[6: 565/1795] train lossD: -0.100211 lossG: 0.515974\n",
      "[6: 570/1795] train lossD: -0.118868 lossG: 0.635523\n",
      "[6: 575/1795] train lossD: -0.116323 lossG: 0.549192\n",
      "[6: 580/1795] train lossD: -0.142382 lossG: 0.515255\n",
      "[6: 585/1795] train lossD: -0.115069 lossG: 0.506855\n",
      "[6: 590/1795] train lossD: -0.011982 lossG: 0.543313\n",
      "[6: 595/1795] train lossD: -0.102037 lossG: 0.578022\n",
      "[6: 600/1795] train lossD: -0.076875 lossG: 0.646625\n",
      "[6: 605/1795] train lossD: -0.136659 lossG: 0.580765\n",
      "[6: 610/1795] train lossD: -0.087823 lossG: 0.673995\n",
      "[6: 615/1795] train lossD: -0.130947 lossG: 0.610545\n",
      "[6: 620/1795] train lossD: -0.123063 lossG: 0.604388\n",
      "[6: 625/1795] train lossD: -0.142782 lossG: 0.497793\n",
      "[6: 630/1795] train lossD: -0.136839 lossG: 0.714384\n",
      "[6: 635/1795] train lossD: -0.099846 lossG: 0.572377\n",
      "[6: 640/1795] train lossD: -0.064425 lossG: 0.566181\n",
      "[6: 645/1795] train lossD: -0.204131 lossG: 0.596053\n",
      "[6: 650/1795] train lossD: -0.063592 lossG: 0.585302\n",
      "[6: 655/1795] train lossD: -0.141570 lossG: 0.560743\n",
      "[6: 660/1795] train lossD: -0.131912 lossG: 0.473518\n",
      "[6: 665/1795] train lossD: -0.119870 lossG: 0.603997\n",
      "[6: 670/1795] train lossD: -0.107259 lossG: 0.548682\n",
      "[6: 675/1795] train lossD: -0.104566 lossG: 0.459004\n",
      "[6: 680/1795] train lossD: -0.075124 lossG: 0.635886\n",
      "[6: 685/1795] train lossD: -0.076925 lossG: 0.534210\n",
      "[6: 690/1795] train lossD: -0.114087 lossG: 0.613832\n",
      "[6: 695/1795] train lossD: -0.149574 lossG: 0.439339\n",
      "[6: 700/1795] train lossD: -0.129440 lossG: 0.540006\n",
      "[6: 705/1795] train lossD: -0.090106 lossG: 0.472749\n",
      "[6: 710/1795] train lossD: -0.126993 lossG: 0.533231\n",
      "[6: 715/1795] train lossD: -0.138692 lossG: 0.516448\n",
      "[6: 720/1795] train lossD: -0.075319 lossG: 0.435409\n",
      "[6: 725/1795] train lossD: -0.106029 lossG: 0.502370\n",
      "[6: 730/1795] train lossD: -0.158091 lossG: 0.487588\n",
      "[6: 735/1795] train lossD: -0.143151 lossG: 0.488535\n",
      "[6: 740/1795] train lossD: 0.001698 lossG: 0.449724\n",
      "[6: 745/1795] train lossD: -0.007409 lossG: 0.484079\n",
      "[6: 750/1795] train lossD: -0.095775 lossG: 0.575266\n",
      "[6: 755/1795] train lossD: -0.147340 lossG: 0.507790\n",
      "[6: 760/1795] train lossD: -0.163950 lossG: 0.535286\n",
      "[6: 765/1795] train lossD: -0.177454 lossG: 0.518899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6: 770/1795] train lossD: -0.158777 lossG: 0.451274\n",
      "[6: 775/1795] train lossD: -0.131150 lossG: 0.516762\n",
      "[6: 780/1795] train lossD: -0.144906 lossG: 0.562904\n",
      "[6: 785/1795] train lossD: -0.122096 lossG: 0.597073\n",
      "[6: 790/1795] train lossD: -0.154577 lossG: 0.580909\n",
      "[6: 795/1795] train lossD: -0.096815 lossG: 0.627589\n",
      "[6: 800/1795] train lossD: -0.152079 lossG: 0.704122\n",
      "[6: 805/1795] train lossD: -0.086432 lossG: 0.493081\n",
      "[6: 810/1795] train lossD: -0.153909 lossG: 0.617756\n",
      "[6: 815/1795] train lossD: -0.048331 lossG: 0.527569\n",
      "[6: 820/1795] train lossD: -0.140429 lossG: 0.655279\n",
      "[6: 825/1795] train lossD: -0.139495 lossG: 0.581204\n",
      "[6: 830/1795] train lossD: -0.178907 lossG: 0.644387\n",
      "[6: 835/1795] train lossD: -0.051988 lossG: 0.587591\n",
      "[6: 840/1795] train lossD: -0.151061 lossG: 0.406490\n",
      "[6: 845/1795] train lossD: -0.083066 lossG: 0.460183\n",
      "[6: 850/1795] train lossD: -0.018356 lossG: 0.463730\n",
      "[6: 855/1795] train lossD: -0.114548 lossG: 0.452552\n",
      "[6: 860/1795] train lossD: -0.113599 lossG: 0.480444\n",
      "[6: 865/1795] train lossD: -0.014211 lossG: 0.480205\n",
      "[6: 870/1795] train lossD: -0.098911 lossG: 0.493947\n",
      "[6: 875/1795] train lossD: -0.056325 lossG: 0.507263\n",
      "[6: 880/1795] train lossD: -0.107517 lossG: 0.546922\n",
      "[6: 885/1795] train lossD: -0.085456 lossG: 0.463808\n",
      "[6: 890/1795] train lossD: -0.162093 lossG: 0.472652\n",
      "[6: 895/1795] train lossD: -0.125325 lossG: 0.602589\n",
      "[6: 900/1795] train lossD: -0.070541 lossG: 0.386132\n",
      "[6: 905/1795] train lossD: -0.075756 lossG: 0.394063\n",
      "[6: 910/1795] train lossD: -0.024679 lossG: 0.474675\n",
      "[6: 915/1795] train lossD: -0.125710 lossG: 0.425278\n",
      "[6: 920/1795] train lossD: -0.089460 lossG: 0.522008\n",
      "[6: 925/1795] train lossD: -0.051710 lossG: 0.664533\n",
      "[6: 930/1795] train lossD: -0.114618 lossG: 0.626607\n",
      "[6: 935/1795] train lossD: -0.144710 lossG: 0.437926\n",
      "[6: 940/1795] train lossD: -0.167492 lossG: 0.487005\n",
      "[6: 945/1795] train lossD: -0.175457 lossG: 0.569776\n",
      "[6: 950/1795] train lossD: -0.002127 lossG: 0.496100\n",
      "[6: 955/1795] train lossD: -0.113234 lossG: 0.469562\n",
      "[6: 960/1795] train lossD: -0.083911 lossG: 0.465672\n",
      "[6: 965/1795] train lossD: -0.111833 lossG: 0.496164\n",
      "[6: 970/1795] train lossD: -0.119372 lossG: 0.475668\n",
      "[6: 975/1795] train lossD: -0.153692 lossG: 0.506026\n",
      "[6: 980/1795] train lossD: -0.026134 lossG: 0.511238\n",
      "[6: 985/1795] train lossD: -0.118938 lossG: 0.406095\n",
      "[6: 990/1795] train lossD: -0.080541 lossG: 0.377735\n",
      "[6: 995/1795] train lossD: -0.123600 lossG: 0.521859\n",
      "[6: 1000/1795] train lossD: -0.136197 lossG: 0.384426\n",
      "[6: 1005/1795] train lossD: -0.157300 lossG: 0.401913\n",
      "[6: 1010/1795] train lossD: -0.187139 lossG: 0.394961\n",
      "[6: 1015/1795] train lossD: -0.113266 lossG: 0.447027\n",
      "[6: 1020/1795] train lossD: -0.036247 lossG: 0.550632\n",
      "[6: 1025/1795] train lossD: -0.104596 lossG: 0.488292\n",
      "[6: 1030/1795] train lossD: -0.169430 lossG: 0.442143\n",
      "[6: 1035/1795] train lossD: 0.041018 lossG: 0.486994\n",
      "[6: 1040/1795] train lossD: -0.099209 lossG: 0.497735\n",
      "[6: 1045/1795] train lossD: -0.057875 lossG: 0.396309\n",
      "[6: 1050/1795] train lossD: -0.069737 lossG: 0.620071\n",
      "[6: 1055/1795] train lossD: -0.156282 lossG: 0.604738\n",
      "[6: 1060/1795] train lossD: -0.057413 lossG: 0.749300\n",
      "[6: 1065/1795] train lossD: -0.120546 lossG: 0.447143\n",
      "[6: 1070/1795] train lossD: -0.112718 lossG: 0.457661\n",
      "[6: 1075/1795] train lossD: -0.119023 lossG: 0.517143\n",
      "[6: 1080/1795] train lossD: -0.042664 lossG: 0.418435\n",
      "[6: 1085/1795] train lossD: -0.150622 lossG: 0.452690\n",
      "[6: 1090/1795] train lossD: -0.102129 lossG: 0.462839\n",
      "[6: 1095/1795] train lossD: -0.078618 lossG: 0.419836\n",
      "[6: 1100/1795] train lossD: -0.110972 lossG: 0.487769\n",
      "[6: 1105/1795] train lossD: -0.073576 lossG: 0.450018\n",
      "[6: 1110/1795] train lossD: -0.132849 lossG: 0.547480\n",
      "[6: 1115/1795] train lossD: -0.149678 lossG: 0.549219\n",
      "[6: 1120/1795] train lossD: -0.147154 lossG: 0.475322\n",
      "[6: 1125/1795] train lossD: -0.115752 lossG: 0.382885\n",
      "[6: 1130/1795] train lossD: -0.093027 lossG: 0.406694\n",
      "[6: 1135/1795] train lossD: -0.161948 lossG: 0.518073\n",
      "[6: 1140/1795] train lossD: -0.145729 lossG: 0.489286\n",
      "[6: 1145/1795] train lossD: -0.081913 lossG: 0.574224\n",
      "[6: 1150/1795] train lossD: -0.104662 lossG: 0.558778\n",
      "[6: 1155/1795] train lossD: -0.093610 lossG: 0.446244\n",
      "[6: 1160/1795] train lossD: -0.096312 lossG: 0.510128\n",
      "[6: 1165/1795] train lossD: -0.169372 lossG: 0.387922\n",
      "[6: 1170/1795] train lossD: -0.051065 lossG: 0.389605\n",
      "[6: 1175/1795] train lossD: -0.139399 lossG: 0.558651\n",
      "[6: 1180/1795] train lossD: -0.010666 lossG: 0.398129\n",
      "[6: 1185/1795] train lossD: -0.160258 lossG: 0.384609\n",
      "[6: 1190/1795] train lossD: -0.168649 lossG: 0.401935\n",
      "[6: 1195/1795] train lossD: -0.168779 lossG: 0.384229\n",
      "[6: 1200/1795] train lossD: -0.088276 lossG: 0.375746\n",
      "[6: 1205/1795] train lossD: 0.042955 lossG: 0.486158\n",
      "[6: 1210/1795] train lossD: -0.108023 lossG: 0.452386\n",
      "[6: 1215/1795] train lossD: -0.161663 lossG: 0.434429\n",
      "[6: 1220/1795] train lossD: -0.126843 lossG: 0.490842\n",
      "[6: 1225/1795] train lossD: -0.107238 lossG: 0.407784\n",
      "[6: 1230/1795] train lossD: -0.133933 lossG: 0.445783\n",
      "[6: 1235/1795] train lossD: -0.103989 lossG: 0.441148\n",
      "[6: 1240/1795] train lossD: -0.091400 lossG: 0.533922\n",
      "[6: 1245/1795] train lossD: -0.124837 lossG: 0.500223\n",
      "[6: 1250/1795] train lossD: -0.148163 lossG: 0.426285\n",
      "[6: 1255/1795] train lossD: -0.002946 lossG: 0.441857\n",
      "[6: 1260/1795] train lossD: -0.101224 lossG: 0.610502\n",
      "[6: 1265/1795] train lossD: -0.148068 lossG: 0.535163\n",
      "[6: 1270/1795] train lossD: -0.068396 lossG: 0.416071\n",
      "[6: 1275/1795] train lossD: -0.148967 lossG: 0.448121\n",
      "[6: 1280/1795] train lossD: -0.165893 lossG: 0.612304\n",
      "[6: 1285/1795] train lossD: -0.157173 lossG: 0.503492\n",
      "[6: 1290/1795] train lossD: -0.160579 lossG: 0.520745\n",
      "[6: 1295/1795] train lossD: -0.196177 lossG: 0.470470\n",
      "[6: 1300/1795] train lossD: -0.067836 lossG: 0.383691\n",
      "[6: 1305/1795] train lossD: -0.098115 lossG: 0.463689\n",
      "[6: 1310/1795] train lossD: -0.120405 lossG: 0.531528\n",
      "[6: 1315/1795] train lossD: -0.074967 lossG: 0.582710\n",
      "[6: 1320/1795] train lossD: -0.102003 lossG: 0.442025\n",
      "[6: 1325/1795] train lossD: -0.080531 lossG: 0.449679\n",
      "[6: 1330/1795] train lossD: -0.156794 lossG: 0.466313\n",
      "[6: 1335/1795] train lossD: -0.061294 lossG: 0.523756\n",
      "[6: 1340/1795] train lossD: -0.141486 lossG: 0.550908\n",
      "[6: 1345/1795] train lossD: -0.113236 lossG: 0.427246\n",
      "[6: 1350/1795] train lossD: -0.105147 lossG: 0.420402\n",
      "[6: 1355/1795] train lossD: -0.122927 lossG: 0.535669\n",
      "[6: 1360/1795] train lossD: -0.092453 lossG: 0.478241\n",
      "[6: 1365/1795] train lossD: -0.139845 lossG: 0.515689\n",
      "[6: 1370/1795] train lossD: -0.049533 lossG: 0.410078\n",
      "[6: 1375/1795] train lossD: -0.136245 lossG: 0.512320\n",
      "[6: 1380/1795] train lossD: -0.054747 lossG: 0.659996\n",
      "[6: 1385/1795] train lossD: -0.122189 lossG: 0.592034\n",
      "[6: 1390/1795] train lossD: -0.077367 lossG: 0.492370\n",
      "[6: 1395/1795] train lossD: -0.124504 lossG: 0.451861\n",
      "[6: 1400/1795] train lossD: -0.097714 lossG: 0.479045\n",
      "[6: 1405/1795] train lossD: -0.107954 lossG: 0.523545\n",
      "[6: 1410/1795] train lossD: -0.051482 lossG: 0.404012\n",
      "[6: 1415/1795] train lossD: -0.105369 lossG: 0.469251\n",
      "[6: 1420/1795] train lossD: -0.160458 lossG: 0.547799\n",
      "[6: 1425/1795] train lossD: -0.141022 lossG: 0.443384\n",
      "[6: 1430/1795] train lossD: -0.104135 lossG: 0.419568\n",
      "[6: 1435/1795] train lossD: -0.160738 lossG: 0.580470\n",
      "[6: 1440/1795] train lossD: -0.154128 lossG: 0.492706\n",
      "[6: 1445/1795] train lossD: -0.119246 lossG: 0.376612\n",
      "[6: 1450/1795] train lossD: -0.171106 lossG: 0.487027\n",
      "[6: 1455/1795] train lossD: -0.152724 lossG: 0.421241\n",
      "[6: 1460/1795] train lossD: -0.041582 lossG: 0.422296\n",
      "[6: 1465/1795] train lossD: -0.157364 lossG: 0.453899\n",
      "[6: 1470/1795] train lossD: -0.150127 lossG: 0.451673\n",
      "[6: 1475/1795] train lossD: -0.052222 lossG: 0.443406\n",
      "[6: 1480/1795] train lossD: -0.064279 lossG: 0.447670\n",
      "[6: 1485/1795] train lossD: -0.090279 lossG: 0.413494\n",
      "[6: 1490/1795] train lossD: -0.044679 lossG: 0.421031\n",
      "[6: 1495/1795] train lossD: -0.093750 lossG: 0.511642\n",
      "[6: 1500/1795] train lossD: -0.078730 lossG: 0.458821\n",
      "[6: 1505/1795] train lossD: -0.152757 lossG: 0.444624\n",
      "[6: 1510/1795] train lossD: -0.178674 lossG: 0.458733\n",
      "[6: 1515/1795] train lossD: -0.178617 lossG: 0.423251\n",
      "[6: 1520/1795] train lossD: -0.097661 lossG: 0.427409\n",
      "[6: 1525/1795] train lossD: -0.034292 lossG: 0.308941\n",
      "[6: 1530/1795] train lossD: -0.083418 lossG: 0.456012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6: 1535/1795] train lossD: -0.096457 lossG: 0.505429\n",
      "[6: 1540/1795] train lossD: -0.067747 lossG: 0.543292\n",
      "[6: 1545/1795] train lossD: -0.143037 lossG: 0.604351\n",
      "[6: 1550/1795] train lossD: -0.137480 lossG: 0.511815\n",
      "[6: 1555/1795] train lossD: -0.123372 lossG: 0.538804\n",
      "[6: 1560/1795] train lossD: -0.123439 lossG: 0.510555\n",
      "[6: 1565/1795] train lossD: -0.124446 lossG: 0.536299\n",
      "[6: 1570/1795] train lossD: -0.087800 lossG: 0.450335\n",
      "[6: 1575/1795] train lossD: -0.117688 lossG: 0.486200\n",
      "[6: 1580/1795] train lossD: -0.057056 lossG: 0.395692\n",
      "[6: 1585/1795] train lossD: -0.113847 lossG: 0.531044\n",
      "[6: 1590/1795] train lossD: -0.068475 lossG: 0.478139\n",
      "[6: 1595/1795] train lossD: -0.104126 lossG: 0.576664\n",
      "[6: 1600/1795] train lossD: -0.135322 lossG: 0.526210\n",
      "[6: 1605/1795] train lossD: -0.063987 lossG: 0.531637\n",
      "[6: 1610/1795] train lossD: -0.141223 lossG: 0.524286\n",
      "[6: 1615/1795] train lossD: -0.082418 lossG: 0.426154\n",
      "[6: 1620/1795] train lossD: -0.148487 lossG: 0.443907\n",
      "[6: 1625/1795] train lossD: -0.137236 lossG: 0.491024\n",
      "[6: 1630/1795] train lossD: -0.115737 lossG: 0.434217\n",
      "[6: 1635/1795] train lossD: -0.142752 lossG: 0.489006\n",
      "[6: 1640/1795] train lossD: -0.161281 lossG: 0.416934\n",
      "[6: 1645/1795] train lossD: -0.144527 lossG: 0.515027\n",
      "[6: 1650/1795] train lossD: -0.130335 lossG: 0.490279\n",
      "[6: 1655/1795] train lossD: -0.134727 lossG: 0.417913\n",
      "[6: 1660/1795] train lossD: -0.104468 lossG: 0.506867\n",
      "[6: 1665/1795] train lossD: -0.102193 lossG: 0.485343\n",
      "[6: 1670/1795] train lossD: -0.145637 lossG: 0.535501\n",
      "[6: 1675/1795] train lossD: -0.129794 lossG: 0.535756\n",
      "[6: 1680/1795] train lossD: -0.129801 lossG: 0.389233\n",
      "[6: 1685/1795] train lossD: -0.136871 lossG: 0.433239\n",
      "[6: 1690/1795] train lossD: -0.078844 lossG: 0.506511\n",
      "[6: 1695/1795] train lossD: -0.092965 lossG: 0.485319\n",
      "[6: 1700/1795] train lossD: -0.135086 lossG: 0.501547\n",
      "[6: 1705/1795] train lossD: -0.178333 lossG: 0.487324\n",
      "[6: 1710/1795] train lossD: -0.140107 lossG: 0.479545\n",
      "[6: 1715/1795] train lossD: -0.173271 lossG: 0.532689\n",
      "[6: 1720/1795] train lossD: -0.131813 lossG: 0.434056\n",
      "[6: 1725/1795] train lossD: -0.107584 lossG: 0.489344\n",
      "[6: 1730/1795] train lossD: -0.122107 lossG: 0.524059\n",
      "[6: 1735/1795] train lossD: -0.037626 lossG: 0.606486\n",
      "[6: 1740/1795] train lossD: -0.162113 lossG: 0.557421\n",
      "[6: 1745/1795] train lossD: -0.121149 lossG: 0.457092\n",
      "[6: 1750/1795] train lossD: -0.106818 lossG: 0.478474\n",
      "[6: 1755/1795] train lossD: -0.141539 lossG: 0.523416\n",
      "[6: 1760/1795] train lossD: -0.098642 lossG: 0.410229\n",
      "[6: 1765/1795] train lossD: -0.145708 lossG: 0.369999\n",
      "[6: 1770/1795] train lossD: -0.127035 lossG: 0.466576\n",
      "[6: 1775/1795] train lossD: -0.028550 lossG: 0.463968\n",
      "[6: 1780/1795] train lossD: -0.111230 lossG: 0.398331\n",
      "[6: 1785/1795] train lossD: -0.146673 lossG: 0.481439\n",
      "[6: 1790/1795] train lossD: -0.110000 lossG: 0.671408\n",
      "0.04351937025785446\n",
      "[7: 0/1795] train lossD: -0.121468 lossG: 0.476213\n",
      "[7: 5/1795] train lossD: -0.080405 lossG: 0.549353\n",
      "[7: 10/1795] train lossD: -0.171110 lossG: 0.462239\n",
      "[7: 15/1795] train lossD: -0.104781 lossG: 0.434590\n",
      "[7: 20/1795] train lossD: -0.180800 lossG: 0.514040\n",
      "[7: 25/1795] train lossD: -0.150689 lossG: 0.456066\n",
      "[7: 30/1795] train lossD: -0.128940 lossG: 0.528175\n",
      "[7: 35/1795] train lossD: -0.019039 lossG: 0.534189\n",
      "[7: 40/1795] train lossD: -0.119793 lossG: 0.480233\n",
      "[7: 45/1795] train lossD: -0.124776 lossG: 0.594345\n",
      "[7: 50/1795] train lossD: -0.124855 lossG: 0.452927\n",
      "[7: 55/1795] train lossD: -0.102536 lossG: 0.407348\n",
      "[7: 60/1795] train lossD: -0.112095 lossG: 0.411393\n",
      "[7: 65/1795] train lossD: -0.114451 lossG: 0.444144\n",
      "[7: 70/1795] train lossD: -0.115778 lossG: 0.432967\n",
      "[7: 75/1795] train lossD: -0.186894 lossG: 0.465962\n",
      "[7: 80/1795] train lossD: -0.113593 lossG: 0.544553\n",
      "[7: 85/1795] train lossD: -0.114694 lossG: 0.422275\n",
      "[7: 90/1795] train lossD: -0.044621 lossG: 0.593370\n",
      "[7: 95/1795] train lossD: -0.143598 lossG: 0.425916\n",
      "[7: 100/1795] train lossD: -0.088432 lossG: 0.452702\n",
      "[7: 105/1795] train lossD: -0.129300 lossG: 0.491763\n",
      "[7: 110/1795] train lossD: -0.134321 lossG: 0.544272\n",
      "[7: 115/1795] train lossD: -0.090855 lossG: 0.540641\n",
      "[7: 120/1795] train lossD: -0.105206 lossG: 0.481950\n",
      "[7: 125/1795] train lossD: -0.076571 lossG: 0.442464\n",
      "[7: 130/1795] train lossD: -0.070852 lossG: 0.367962\n",
      "[7: 135/1795] train lossD: -0.120265 lossG: 0.417429\n",
      "[7: 140/1795] train lossD: -0.154072 lossG: 0.443510\n",
      "[7: 145/1795] train lossD: -0.006318 lossG: 0.441953\n",
      "[7: 150/1795] train lossD: -0.143602 lossG: 0.405731\n",
      "[7: 155/1795] train lossD: -0.090859 lossG: 0.345335\n",
      "[7: 160/1795] train lossD: -0.130214 lossG: 0.515889\n",
      "[7: 165/1795] train lossD: -0.104975 lossG: 0.421656\n",
      "[7: 170/1795] train lossD: -0.092571 lossG: 0.451762\n",
      "[7: 175/1795] train lossD: -0.184620 lossG: 0.545434\n",
      "[7: 180/1795] train lossD: -0.089056 lossG: 0.405501\n",
      "[7: 185/1795] train lossD: -0.051601 lossG: 0.424763\n",
      "[7: 190/1795] train lossD: -0.139657 lossG: 0.437838\n",
      "[7: 195/1795] train lossD: -0.144969 lossG: 0.378961\n",
      "[7: 200/1795] train lossD: -0.109696 lossG: 0.525034\n",
      "[7: 205/1795] train lossD: -0.140324 lossG: 0.471218\n",
      "[7: 210/1795] train lossD: -0.043178 lossG: 0.462450\n",
      "[7: 215/1795] train lossD: -0.112235 lossG: 0.377386\n",
      "[7: 220/1795] train lossD: -0.110611 lossG: 0.487168\n",
      "[7: 225/1795] train lossD: -0.102547 lossG: 0.467275\n",
      "[7: 230/1795] train lossD: -0.037989 lossG: 0.413957\n",
      "[7: 235/1795] train lossD: -0.047902 lossG: 0.415385\n",
      "[7: 240/1795] train lossD: -0.103814 lossG: 0.367708\n",
      "[7: 245/1795] train lossD: -0.103601 lossG: 0.383231\n",
      "[7: 250/1795] train lossD: -0.104596 lossG: 0.434381\n",
      "[7: 255/1795] train lossD: -0.138585 lossG: 0.474688\n",
      "[7: 260/1795] train lossD: -0.065078 lossG: 0.411732\n",
      "[7: 265/1795] train lossD: -0.079977 lossG: 0.492762\n",
      "[7: 270/1795] train lossD: -0.075592 lossG: 0.496691\n",
      "[7: 275/1795] train lossD: -0.145430 lossG: 0.430922\n",
      "[7: 280/1795] train lossD: -0.117272 lossG: 0.332866\n",
      "[7: 285/1795] train lossD: -0.183616 lossG: 0.328514\n",
      "[7: 290/1795] train lossD: -0.137757 lossG: 0.468226\n",
      "[7: 295/1795] train lossD: -0.078835 lossG: 0.406261\n",
      "[7: 300/1795] train lossD: -0.159267 lossG: 0.332810\n",
      "[7: 305/1795] train lossD: -0.101927 lossG: 0.420465\n",
      "[7: 310/1795] train lossD: -0.155828 lossG: 0.400076\n",
      "[7: 315/1795] train lossD: -0.087038 lossG: 0.456947\n",
      "[7: 320/1795] train lossD: -0.155719 lossG: 0.367212\n",
      "[7: 325/1795] train lossD: 0.183327 lossG: 0.367561\n",
      "[7: 330/1795] train lossD: -0.111715 lossG: 0.408066\n",
      "[7: 335/1795] train lossD: -0.135112 lossG: 0.469877\n",
      "[7: 340/1795] train lossD: 0.155908 lossG: 0.258959\n",
      "[7: 345/1795] train lossD: -0.069140 lossG: 0.461069\n",
      "[7: 350/1795] train lossD: -0.109469 lossG: 0.459934\n",
      "[7: 355/1795] train lossD: -0.122480 lossG: 0.448650\n",
      "[7: 360/1795] train lossD: -0.131516 lossG: 0.459429\n",
      "[7: 365/1795] train lossD: -0.086318 lossG: 0.357155\n",
      "[7: 370/1795] train lossD: -0.163681 lossG: 0.439327\n",
      "[7: 375/1795] train lossD: -0.099246 lossG: 0.522086\n",
      "[7: 380/1795] train lossD: -0.111949 lossG: 0.537034\n",
      "[7: 385/1795] train lossD: -0.096857 lossG: 0.463821\n",
      "[7: 390/1795] train lossD: -0.055756 lossG: 0.544630\n",
      "[7: 395/1795] train lossD: -0.154438 lossG: 0.519106\n",
      "[7: 400/1795] train lossD: -0.145228 lossG: 0.543864\n",
      "[7: 405/1795] train lossD: -0.074098 lossG: 0.344246\n",
      "[7: 410/1795] train lossD: -0.059411 lossG: 0.401514\n",
      "[7: 415/1795] train lossD: -0.105418 lossG: 0.444716\n",
      "[7: 420/1795] train lossD: -0.169997 lossG: 0.523484\n",
      "[7: 425/1795] train lossD: -0.151935 lossG: 0.468681\n",
      "[7: 430/1795] train lossD: -0.174785 lossG: 0.460937\n",
      "[7: 435/1795] train lossD: -0.062971 lossG: 0.464008\n",
      "[7: 440/1795] train lossD: -0.149336 lossG: 0.521706\n",
      "[7: 445/1795] train lossD: -0.109751 lossG: 0.467615\n",
      "[7: 450/1795] train lossD: -0.129368 lossG: 0.455152\n",
      "[7: 455/1795] train lossD: -0.039665 lossG: 0.710752\n",
      "[7: 460/1795] train lossD: -0.086885 lossG: 0.366628\n",
      "[7: 465/1795] train lossD: -0.159370 lossG: 0.466667\n",
      "[7: 470/1795] train lossD: -0.083952 lossG: 0.494082\n",
      "[7: 475/1795] train lossD: -0.100643 lossG: 0.477982\n",
      "[7: 480/1795] train lossD: -0.091337 lossG: 0.688874\n",
      "[7: 485/1795] train lossD: -0.100935 lossG: 0.490276\n",
      "[7: 490/1795] train lossD: -0.107023 lossG: 0.426984\n",
      "[7: 495/1795] train lossD: -0.103143 lossG: 0.370631\n",
      "[7: 500/1795] train lossD: -0.091393 lossG: 0.418433\n",
      "[7: 505/1795] train lossD: -0.130159 lossG: 0.609944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7: 510/1795] train lossD: -0.158310 lossG: 0.527361\n",
      "[7: 515/1795] train lossD: -0.141966 lossG: 0.444162\n",
      "[7: 520/1795] train lossD: -0.121274 lossG: 0.447095\n",
      "[7: 525/1795] train lossD: -0.156148 lossG: 0.537346\n",
      "[7: 530/1795] train lossD: -0.151877 lossG: 0.520483\n",
      "[7: 535/1795] train lossD: -0.162775 lossG: 0.423407\n",
      "[7: 540/1795] train lossD: -0.054384 lossG: 0.412589\n",
      "[7: 545/1795] train lossD: -0.117679 lossG: 0.574895\n",
      "[7: 550/1795] train lossD: -0.167029 lossG: 0.468451\n",
      "[7: 555/1795] train lossD: -0.088986 lossG: 0.455606\n",
      "[7: 560/1795] train lossD: -0.121869 lossG: 0.402924\n",
      "[7: 565/1795] train lossD: -0.053117 lossG: 0.404554\n",
      "[7: 570/1795] train lossD: -0.173187 lossG: 0.556694\n",
      "[7: 575/1795] train lossD: -0.125926 lossG: 0.449617\n",
      "[7: 580/1795] train lossD: -0.149074 lossG: 0.493967\n",
      "[7: 585/1795] train lossD: -0.116294 lossG: 0.366711\n",
      "[7: 590/1795] train lossD: -0.118964 lossG: 0.444171\n",
      "[7: 595/1795] train lossD: -0.119640 lossG: 0.385639\n",
      "[7: 600/1795] train lossD: -0.182478 lossG: 0.494574\n",
      "[7: 605/1795] train lossD: -0.070066 lossG: 0.551635\n",
      "[7: 610/1795] train lossD: -0.023291 lossG: 0.464234\n",
      "[7: 615/1795] train lossD: -0.125252 lossG: 0.501371\n",
      "[7: 620/1795] train lossD: -0.123281 lossG: 0.488888\n",
      "[7: 625/1795] train lossD: -0.112389 lossG: 0.531390\n",
      "[7: 630/1795] train lossD: -0.124391 lossG: 0.478487\n",
      "[7: 635/1795] train lossD: -0.092413 lossG: 0.391895\n",
      "[7: 640/1795] train lossD: -0.106131 lossG: 0.421343\n",
      "[7: 645/1795] train lossD: -0.100874 lossG: 0.669873\n",
      "[7: 650/1795] train lossD: -0.137394 lossG: 0.550561\n",
      "[7: 655/1795] train lossD: -0.120264 lossG: 0.599605\n",
      "[7: 660/1795] train lossD: -0.096713 lossG: 0.488723\n",
      "[7: 665/1795] train lossD: -0.135411 lossG: 0.426074\n",
      "[7: 670/1795] train lossD: -0.091920 lossG: 0.420799\n",
      "[7: 675/1795] train lossD: -0.083107 lossG: 0.581761\n",
      "[7: 680/1795] train lossD: -0.111202 lossG: 0.597934\n",
      "[7: 685/1795] train lossD: -0.100770 lossG: 0.447817\n",
      "[7: 690/1795] train lossD: -0.184102 lossG: 0.489298\n",
      "[7: 695/1795] train lossD: -0.085685 lossG: 0.402465\n",
      "[7: 700/1795] train lossD: -0.133130 lossG: 0.547650\n",
      "[7: 705/1795] train lossD: -0.153989 lossG: 0.454416\n",
      "[7: 710/1795] train lossD: -0.081580 lossG: 0.466195\n",
      "[7: 715/1795] train lossD: -0.058187 lossG: 0.510926\n",
      "[7: 720/1795] train lossD: -0.128167 lossG: 0.522906\n",
      "[7: 725/1795] train lossD: -0.116027 lossG: 0.436191\n",
      "[7: 730/1795] train lossD: -0.102244 lossG: 0.470193\n",
      "[7: 735/1795] train lossD: -0.116102 lossG: 0.426854\n",
      "[7: 740/1795] train lossD: -0.125434 lossG: 0.398400\n",
      "[7: 745/1795] train lossD: -0.089851 lossG: 0.377506\n",
      "[7: 750/1795] train lossD: -0.137866 lossG: 0.448645\n",
      "[7: 755/1795] train lossD: -0.118508 lossG: 0.525992\n",
      "[7: 760/1795] train lossD: -0.105154 lossG: 0.431336\n",
      "[7: 765/1795] train lossD: -0.107117 lossG: 0.528498\n",
      "[7: 770/1795] train lossD: -0.138889 lossG: 0.454776\n",
      "[7: 775/1795] train lossD: -0.101692 lossG: 0.319496\n",
      "[7: 780/1795] train lossD: -0.140544 lossG: 0.618460\n",
      "[7: 785/1795] train lossD: -0.127582 lossG: 0.444496\n",
      "[7: 790/1795] train lossD: -0.144314 lossG: 0.381249\n",
      "[7: 795/1795] train lossD: -0.039073 lossG: 0.278351\n",
      "[7: 800/1795] train lossD: -0.068455 lossG: 0.417581\n",
      "[7: 805/1795] train lossD: -0.090537 lossG: 0.432042\n",
      "[7: 810/1795] train lossD: -0.134820 lossG: 0.376419\n",
      "[7: 815/1795] train lossD: -0.161590 lossG: 0.455569\n",
      "[7: 820/1795] train lossD: -0.151073 lossG: 0.325569\n",
      "[7: 825/1795] train lossD: -0.119623 lossG: 0.414864\n",
      "[7: 830/1795] train lossD: -0.038310 lossG: 0.408945\n",
      "[7: 835/1795] train lossD: -0.092378 lossG: 0.443470\n",
      "[7: 840/1795] train lossD: -0.030362 lossG: 0.394021\n",
      "[7: 845/1795] train lossD: -0.117888 lossG: 0.403815\n",
      "[7: 850/1795] train lossD: -0.165753 lossG: 0.472177\n",
      "[7: 855/1795] train lossD: -0.071850 lossG: 0.406823\n",
      "[7: 860/1795] train lossD: -0.149716 lossG: 0.563628\n",
      "[7: 865/1795] train lossD: -0.122722 lossG: 0.342197\n",
      "[7: 870/1795] train lossD: -0.152649 lossG: 0.506694\n",
      "[7: 875/1795] train lossD: -0.112709 lossG: 0.466139\n",
      "[7: 880/1795] train lossD: -0.133325 lossG: 0.510714\n",
      "[7: 885/1795] train lossD: -0.112867 lossG: 0.352331\n",
      "[7: 890/1795] train lossD: -0.181429 lossG: 0.326221\n",
      "[7: 895/1795] train lossD: -0.128011 lossG: 0.466114\n",
      "[7: 900/1795] train lossD: -0.098938 lossG: 0.447663\n",
      "[7: 905/1795] train lossD: -0.197056 lossG: 0.442003\n",
      "[7: 910/1795] train lossD: -0.142254 lossG: 0.392544\n",
      "[7: 915/1795] train lossD: -0.138716 lossG: 0.427255\n",
      "[7: 920/1795] train lossD: -0.014194 lossG: 0.475707\n",
      "[7: 925/1795] train lossD: -0.159571 lossG: 0.479252\n",
      "[7: 930/1795] train lossD: -0.114995 lossG: 0.364625\n",
      "[7: 935/1795] train lossD: 0.025920 lossG: 0.388289\n",
      "[7: 940/1795] train lossD: -0.135549 lossG: 0.455942\n",
      "[7: 945/1795] train lossD: -0.148874 lossG: 0.498531\n",
      "[7: 950/1795] train lossD: -0.118264 lossG: 0.354217\n",
      "[7: 955/1795] train lossD: -0.142190 lossG: 0.423998\n",
      "[7: 960/1795] train lossD: -0.170865 lossG: 0.454031\n",
      "[7: 965/1795] train lossD: -0.055388 lossG: 0.444377\n",
      "[7: 970/1795] train lossD: -0.110931 lossG: 0.505065\n",
      "[7: 975/1795] train lossD: -0.098303 lossG: 0.486199\n",
      "[7: 980/1795] train lossD: -0.132288 lossG: 0.511097\n",
      "[7: 985/1795] train lossD: -0.096374 lossG: 0.462896\n",
      "[7: 990/1795] train lossD: -0.091484 lossG: 0.411708\n",
      "[7: 995/1795] train lossD: -0.129654 lossG: 0.361598\n",
      "[7: 1000/1795] train lossD: -0.180697 lossG: 0.590771\n",
      "[7: 1005/1795] train lossD: -0.101610 lossG: 0.297062\n",
      "[7: 1010/1795] train lossD: -0.056154 lossG: 0.338234\n",
      "[7: 1015/1795] train lossD: -0.071529 lossG: 0.371903\n",
      "[7: 1020/1795] train lossD: -0.086621 lossG: 0.349651\n",
      "[7: 1025/1795] train lossD: -0.122913 lossG: 0.309364\n",
      "[7: 1030/1795] train lossD: -0.089719 lossG: 0.379919\n",
      "[7: 1035/1795] train lossD: -0.162526 lossG: 0.355232\n",
      "[7: 1040/1795] train lossD: -0.108590 lossG: 0.363587\n",
      "[7: 1045/1795] train lossD: -0.101469 lossG: 0.386357\n",
      "[7: 1050/1795] train lossD: -0.086985 lossG: 0.460822\n",
      "[7: 1055/1795] train lossD: -0.109445 lossG: 0.388157\n",
      "[7: 1060/1795] train lossD: -0.044512 lossG: 0.442022\n",
      "[7: 1065/1795] train lossD: -0.088810 lossG: 0.528290\n",
      "[7: 1070/1795] train lossD: -0.104172 lossG: 0.356276\n",
      "[7: 1075/1795] train lossD: -0.087576 lossG: 0.356145\n",
      "[7: 1080/1795] train lossD: -0.119655 lossG: 0.388290\n",
      "[7: 1085/1795] train lossD: -0.087565 lossG: 0.362131\n",
      "[7: 1090/1795] train lossD: -0.144007 lossG: 0.379126\n",
      "[7: 1095/1795] train lossD: -0.110885 lossG: 0.490145\n",
      "[7: 1100/1795] train lossD: -0.053718 lossG: 0.366622\n",
      "[7: 1105/1795] train lossD: -0.139509 lossG: 0.368063\n",
      "[7: 1110/1795] train lossD: -0.025282 lossG: 0.402697\n",
      "[7: 1115/1795] train lossD: -0.111577 lossG: 0.380037\n",
      "[7: 1120/1795] train lossD: -0.043843 lossG: 0.439399\n",
      "[7: 1125/1795] train lossD: -0.153849 lossG: 0.373730\n",
      "[7: 1130/1795] train lossD: -0.150438 lossG: 0.494755\n",
      "[7: 1135/1795] train lossD: -0.076694 lossG: 0.358259\n",
      "[7: 1140/1795] train lossD: -0.160537 lossG: 0.363698\n",
      "[7: 1145/1795] train lossD: -0.130667 lossG: 0.341824\n",
      "[7: 1150/1795] train lossD: -0.137315 lossG: 0.455458\n",
      "[7: 1155/1795] train lossD: -0.068207 lossG: 0.411772\n",
      "[7: 1160/1795] train lossD: -0.133230 lossG: 0.445557\n",
      "[7: 1165/1795] train lossD: -0.138953 lossG: 0.438214\n",
      "[7: 1170/1795] train lossD: -0.132266 lossG: 0.356117\n",
      "[7: 1175/1795] train lossD: -0.193141 lossG: 0.424247\n",
      "[7: 1180/1795] train lossD: -0.091012 lossG: 0.467896\n",
      "[7: 1185/1795] train lossD: -0.083051 lossG: 0.397864\n",
      "[7: 1190/1795] train lossD: -0.119604 lossG: 0.503526\n",
      "[7: 1195/1795] train lossD: -0.132309 lossG: 0.499478\n",
      "[7: 1200/1795] train lossD: -0.177299 lossG: 0.392232\n",
      "[7: 1205/1795] train lossD: -0.115995 lossG: 0.512064\n",
      "[7: 1210/1795] train lossD: -0.069207 lossG: 0.546848\n",
      "[7: 1215/1795] train lossD: -0.173273 lossG: 0.566432\n",
      "[7: 1220/1795] train lossD: -0.113985 lossG: 0.446991\n",
      "[7: 1225/1795] train lossD: -0.053788 lossG: 0.442360\n",
      "[7: 1230/1795] train lossD: -0.120996 lossG: 0.498577\n",
      "[7: 1235/1795] train lossD: -0.035426 lossG: 0.530807\n",
      "[7: 1240/1795] train lossD: -0.130663 lossG: 0.499569\n",
      "[7: 1245/1795] train lossD: -0.091904 lossG: 0.418352\n",
      "[7: 1250/1795] train lossD: -0.106503 lossG: 0.533982\n",
      "[7: 1255/1795] train lossD: -0.104939 lossG: 0.517043\n",
      "[7: 1260/1795] train lossD: -0.161748 lossG: 0.575702\n",
      "[7: 1265/1795] train lossD: -0.150068 lossG: 0.495608\n",
      "[7: 1270/1795] train lossD: -0.121322 lossG: 0.453578\n",
      "[7: 1275/1795] train lossD: 0.012203 lossG: 0.338417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7: 1280/1795] train lossD: -0.096671 lossG: 0.453697\n",
      "[7: 1285/1795] train lossD: -0.020113 lossG: 0.491240\n",
      "[7: 1290/1795] train lossD: -0.043287 lossG: 0.592761\n",
      "[7: 1295/1795] train lossD: -0.098194 lossG: 0.409791\n",
      "[7: 1300/1795] train lossD: -0.024266 lossG: 0.586619\n",
      "[7: 1305/1795] train lossD: -0.027859 lossG: 0.538174\n",
      "[7: 1310/1795] train lossD: -0.108756 lossG: 0.411572\n",
      "[7: 1315/1795] train lossD: -0.148290 lossG: 0.467880\n",
      "[7: 1320/1795] train lossD: -0.066046 lossG: 0.320979\n",
      "[7: 1325/1795] train lossD: -0.136391 lossG: 0.309098\n",
      "[7: 1330/1795] train lossD: -0.109339 lossG: 0.343585\n",
      "[7: 1335/1795] train lossD: -0.137463 lossG: 0.379895\n",
      "[7: 1340/1795] train lossD: -0.096869 lossG: 0.431551\n",
      "[7: 1345/1795] train lossD: -0.079527 lossG: 0.335521\n",
      "[7: 1350/1795] train lossD: -0.211539 lossG: 0.334261\n",
      "[7: 1355/1795] train lossD: -0.126416 lossG: 0.373986\n",
      "[7: 1360/1795] train lossD: -0.152427 lossG: 0.375981\n",
      "[7: 1365/1795] train lossD: -0.127048 lossG: 0.389388\n",
      "[7: 1370/1795] train lossD: -0.098063 lossG: 0.390835\n",
      "[7: 1375/1795] train lossD: -0.101705 lossG: 0.433334\n",
      "[7: 1380/1795] train lossD: -0.116058 lossG: 0.440608\n",
      "[7: 1385/1795] train lossD: -0.145000 lossG: 0.412704\n",
      "[7: 1390/1795] train lossD: -0.154354 lossG: 0.501480\n",
      "[7: 1395/1795] train lossD: -0.110050 lossG: 0.330756\n",
      "[7: 1400/1795] train lossD: -0.073974 lossG: 0.522708\n",
      "[7: 1405/1795] train lossD: -0.067785 lossG: 0.444154\n",
      "[7: 1410/1795] train lossD: -0.104762 lossG: 0.385237\n",
      "[7: 1415/1795] train lossD: -0.177711 lossG: 0.430331\n",
      "[7: 1420/1795] train lossD: -0.180283 lossG: 0.481260\n",
      "[7: 1425/1795] train lossD: -0.024951 lossG: 0.354069\n",
      "[7: 1430/1795] train lossD: -0.142791 lossG: 0.361543\n",
      "[7: 1435/1795] train lossD: -0.080366 lossG: 0.366282\n",
      "[7: 1440/1795] train lossD: -0.127074 lossG: 0.490278\n",
      "[7: 1445/1795] train lossD: -0.115262 lossG: 0.493492\n",
      "[7: 1450/1795] train lossD: -0.122133 lossG: 0.314366\n",
      "[7: 1455/1795] train lossD: -0.109925 lossG: 0.426704\n",
      "[7: 1460/1795] train lossD: -0.058793 lossG: 0.369196\n",
      "[7: 1465/1795] train lossD: -0.132227 lossG: 0.417938\n",
      "[7: 1470/1795] train lossD: -0.077866 lossG: 0.432957\n",
      "[7: 1475/1795] train lossD: -0.074073 lossG: 0.400300\n",
      "[7: 1480/1795] train lossD: -0.109122 lossG: 0.449756\n",
      "[7: 1485/1795] train lossD: -0.081504 lossG: 0.404785\n",
      "[7: 1490/1795] train lossD: -0.046480 lossG: 0.550085\n",
      "[7: 1495/1795] train lossD: -0.165684 lossG: 0.470078\n",
      "[7: 1500/1795] train lossD: -0.051990 lossG: 0.546634\n",
      "[7: 1505/1795] train lossD: -0.082647 lossG: 0.373092\n",
      "[7: 1510/1795] train lossD: 0.032556 lossG: 0.450225\n",
      "[7: 1515/1795] train lossD: -0.114042 lossG: 0.386727\n",
      "[7: 1520/1795] train lossD: -0.075344 lossG: 0.346799\n",
      "[7: 1525/1795] train lossD: -0.176365 lossG: 0.363174\n",
      "[7: 1530/1795] train lossD: -0.142220 lossG: 0.428380\n",
      "[7: 1535/1795] train lossD: -0.066692 lossG: 0.377818\n",
      "[7: 1540/1795] train lossD: -0.104708 lossG: 0.382608\n",
      "[7: 1545/1795] train lossD: -0.151544 lossG: 0.515050\n",
      "[7: 1550/1795] train lossD: -0.189506 lossG: 0.467310\n",
      "[7: 1555/1795] train lossD: -0.090768 lossG: 0.452696\n",
      "[7: 1560/1795] train lossD: -0.136606 lossG: 0.649273\n",
      "[7: 1565/1795] train lossD: -0.120626 lossG: 0.466002\n",
      "[7: 1570/1795] train lossD: -0.072315 lossG: 0.529296\n",
      "[7: 1575/1795] train lossD: -0.087361 lossG: 0.581485\n",
      "[7: 1580/1795] train lossD: -0.134236 lossG: 0.539346\n",
      "[7: 1585/1795] train lossD: -0.076979 lossG: 0.541000\n",
      "[7: 1590/1795] train lossD: -0.058317 lossG: 0.518855\n",
      "[7: 1595/1795] train lossD: -0.162677 lossG: 0.441635\n",
      "[7: 1600/1795] train lossD: -0.066253 lossG: 0.520482\n",
      "[7: 1605/1795] train lossD: -0.154449 lossG: 0.585191\n",
      "[7: 1610/1795] train lossD: -0.147854 lossG: 0.360862\n",
      "[7: 1615/1795] train lossD: -0.120752 lossG: 0.378693\n",
      "[7: 1620/1795] train lossD: -0.094305 lossG: 0.517573\n",
      "[7: 1625/1795] train lossD: -0.035588 lossG: 0.556498\n",
      "[7: 1630/1795] train lossD: -0.089197 lossG: 0.448332\n",
      "[7: 1635/1795] train lossD: -0.138953 lossG: 0.385245\n",
      "[7: 1640/1795] train lossD: -0.096818 lossG: 0.546612\n",
      "[7: 1645/1795] train lossD: -0.104521 lossG: 0.676833\n",
      "[7: 1650/1795] train lossD: -0.131229 lossG: 0.521105\n",
      "[7: 1655/1795] train lossD: -0.156789 lossG: 0.580392\n",
      "[7: 1660/1795] train lossD: -0.130949 lossG: 0.451665\n",
      "[7: 1665/1795] train lossD: -0.059372 lossG: 0.703083\n",
      "[7: 1670/1795] train lossD: -0.106224 lossG: 0.427275\n",
      "[7: 1675/1795] train lossD: -0.153501 lossG: 0.511287\n",
      "[7: 1680/1795] train lossD: -0.096953 lossG: 0.539112\n",
      "[7: 1685/1795] train lossD: -0.200994 lossG: 0.566767\n",
      "[7: 1690/1795] train lossD: -0.113128 lossG: 0.408556\n",
      "[7: 1695/1795] train lossD: -0.076069 lossG: 0.405625\n",
      "[7: 1700/1795] train lossD: -0.032114 lossG: 0.437454\n",
      "[7: 1705/1795] train lossD: -0.171168 lossG: 0.451820\n",
      "[7: 1710/1795] train lossD: -0.171450 lossG: 0.393938\n",
      "[7: 1715/1795] train lossD: -0.152470 lossG: 0.502278\n",
      "[7: 1720/1795] train lossD: -0.125975 lossG: 0.380304\n",
      "[7: 1725/1795] train lossD: -0.109057 lossG: 0.305135\n",
      "[7: 1730/1795] train lossD: -0.101096 lossG: 0.449812\n",
      "[7: 1735/1795] train lossD: -0.139284 lossG: 0.469453\n",
      "[7: 1740/1795] train lossD: -0.046241 lossG: 0.375979\n",
      "[7: 1745/1795] train lossD: -0.132508 lossG: 0.423728\n",
      "[7: 1750/1795] train lossD: -0.138791 lossG: 0.486039\n",
      "[7: 1755/1795] train lossD: -0.000517 lossG: 0.752235\n",
      "[7: 1760/1795] train lossD: -0.113041 lossG: 0.501420\n",
      "[7: 1765/1795] train lossD: -0.120506 lossG: 0.483392\n",
      "[7: 1770/1795] train lossD: -0.065091 lossG: 0.472695\n",
      "[7: 1775/1795] train lossD: -0.086360 lossG: 0.590499\n",
      "[7: 1780/1795] train lossD: -0.156947 lossG: 0.513135\n",
      "[7: 1785/1795] train lossD: -0.119425 lossG: 0.341907\n",
      "[7: 1790/1795] train lossD: -0.142895 lossG: 0.458913\n",
      "0.038115449249744415\n",
      "[8: 0/1795] train lossD: -0.099336 lossG: 0.450208\n",
      "[8: 5/1795] train lossD: -0.151521 lossG: 0.503798\n",
      "[8: 10/1795] train lossD: -0.071539 lossG: 0.476318\n",
      "[8: 15/1795] train lossD: -0.101172 lossG: 0.418265\n",
      "[8: 20/1795] train lossD: -0.038571 lossG: 0.563269\n",
      "[8: 25/1795] train lossD: -0.123392 lossG: 0.421731\n",
      "[8: 30/1795] train lossD: 0.040805 lossG: 0.406713\n",
      "[8: 35/1795] train lossD: -0.015001 lossG: 0.497521\n",
      "[8: 40/1795] train lossD: -0.099782 lossG: 0.471911\n",
      "[8: 45/1795] train lossD: -0.081913 lossG: 0.549159\n",
      "[8: 50/1795] train lossD: -0.087811 lossG: 0.478372\n",
      "[8: 55/1795] train lossD: -0.059614 lossG: 0.374674\n",
      "[8: 60/1795] train lossD: -0.147958 lossG: 0.430287\n",
      "[8: 65/1795] train lossD: -0.127753 lossG: 0.440741\n",
      "[8: 70/1795] train lossD: -0.115436 lossG: 0.410380\n",
      "[8: 75/1795] train lossD: -0.123616 lossG: 0.460089\n",
      "[8: 80/1795] train lossD: -0.179473 lossG: 0.424859\n",
      "[8: 85/1795] train lossD: -0.164121 lossG: 0.486572\n",
      "[8: 90/1795] train lossD: -0.024931 lossG: 0.479489\n",
      "[8: 95/1795] train lossD: -0.176605 lossG: 0.475015\n",
      "[8: 100/1795] train lossD: -0.147583 lossG: 0.435032\n",
      "[8: 105/1795] train lossD: -0.124723 lossG: 0.362772\n",
      "[8: 110/1795] train lossD: -0.125795 lossG: 0.492749\n",
      "[8: 115/1795] train lossD: -0.152982 lossG: 0.511629\n",
      "[8: 120/1795] train lossD: -0.101360 lossG: 0.454057\n",
      "[8: 125/1795] train lossD: -0.132946 lossG: 0.293332\n",
      "[8: 130/1795] train lossD: -0.107072 lossG: 0.364950\n",
      "[8: 135/1795] train lossD: -0.083881 lossG: 0.305717\n",
      "[8: 140/1795] train lossD: -0.092800 lossG: 0.455099\n",
      "[8: 145/1795] train lossD: -0.111071 lossG: 0.473737\n",
      "[8: 150/1795] train lossD: -0.067396 lossG: 0.461958\n",
      "[8: 155/1795] train lossD: -0.045836 lossG: 0.416078\n",
      "[8: 160/1795] train lossD: -0.139410 lossG: 0.480097\n",
      "[8: 165/1795] train lossD: -0.124433 lossG: 0.534289\n",
      "[8: 170/1795] train lossD: -0.069712 lossG: 0.449004\n",
      "[8: 175/1795] train lossD: -0.152657 lossG: 0.465880\n",
      "[8: 180/1795] train lossD: -0.133524 lossG: 0.435634\n",
      "[8: 185/1795] train lossD: -0.171766 lossG: 0.413504\n",
      "[8: 190/1795] train lossD: -0.194774 lossG: 0.535689\n",
      "[8: 195/1795] train lossD: -0.047479 lossG: 0.439162\n",
      "[8: 200/1795] train lossD: -0.153627 lossG: 0.456450\n",
      "[8: 205/1795] train lossD: -0.084190 lossG: 0.411132\n",
      "[8: 210/1795] train lossD: -0.120615 lossG: 0.375013\n",
      "[8: 215/1795] train lossD: -0.099567 lossG: 0.493716\n",
      "[8: 220/1795] train lossD: -0.126956 lossG: 0.396251\n",
      "[8: 225/1795] train lossD: -0.114930 lossG: 0.495079\n",
      "[8: 230/1795] train lossD: -0.061469 lossG: 0.339954\n",
      "[8: 235/1795] train lossD: -0.121961 lossG: 0.437371\n",
      "[8: 240/1795] train lossD: -0.089608 lossG: 0.568489\n",
      "[8: 245/1795] train lossD: -0.092440 lossG: 0.454349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8: 250/1795] train lossD: -0.102489 lossG: 0.427289\n",
      "[8: 255/1795] train lossD: -0.081909 lossG: 0.407410\n",
      "[8: 260/1795] train lossD: -0.107755 lossG: 0.396031\n",
      "[8: 265/1795] train lossD: -0.055301 lossG: 0.391457\n",
      "[8: 270/1795] train lossD: -0.109125 lossG: 0.351170\n",
      "[8: 275/1795] train lossD: -0.099802 lossG: 0.370742\n",
      "[8: 280/1795] train lossD: -0.155433 lossG: 0.408250\n",
      "[8: 285/1795] train lossD: -0.113949 lossG: 0.372559\n",
      "[8: 290/1795] train lossD: -0.085328 lossG: 0.429862\n",
      "[8: 295/1795] train lossD: -0.155262 lossG: 0.513444\n",
      "[8: 300/1795] train lossD: -0.066746 lossG: 0.386387\n",
      "[8: 305/1795] train lossD: -0.052011 lossG: 0.330103\n",
      "[8: 310/1795] train lossD: -0.200785 lossG: 0.581233\n",
      "[8: 315/1795] train lossD: -0.121726 lossG: 0.456481\n",
      "[8: 320/1795] train lossD: -0.096177 lossG: 0.340942\n",
      "[8: 325/1795] train lossD: -0.098767 lossG: 0.380073\n",
      "[8: 330/1795] train lossD: -0.066847 lossG: 0.331905\n",
      "[8: 335/1795] train lossD: -0.073214 lossG: 0.389456\n",
      "[8: 340/1795] train lossD: -0.102077 lossG: 0.430504\n",
      "[8: 345/1795] train lossD: 0.074012 lossG: 0.456974\n",
      "[8: 350/1795] train lossD: -0.105105 lossG: 0.520782\n",
      "[8: 355/1795] train lossD: -0.126871 lossG: 0.476672\n",
      "[8: 360/1795] train lossD: -0.115843 lossG: 0.393615\n",
      "[8: 365/1795] train lossD: -0.124314 lossG: 0.420616\n",
      "[8: 370/1795] train lossD: -0.009280 lossG: 0.475576\n",
      "[8: 375/1795] train lossD: -0.115141 lossG: 0.494495\n",
      "[8: 380/1795] train lossD: -0.102084 lossG: 0.407448\n",
      "[8: 385/1795] train lossD: -0.066447 lossG: 0.565440\n",
      "[8: 390/1795] train lossD: -0.147267 lossG: 0.444864\n",
      "[8: 395/1795] train lossD: -0.109627 lossG: 0.518942\n",
      "[8: 400/1795] train lossD: -0.096107 lossG: 0.394756\n",
      "[8: 405/1795] train lossD: -0.094263 lossG: 0.460654\n",
      "[8: 410/1795] train lossD: -0.068512 lossG: 0.489872\n",
      "[8: 415/1795] train lossD: -0.159547 lossG: 0.534197\n",
      "[8: 420/1795] train lossD: -0.096476 lossG: 0.598691\n",
      "[8: 425/1795] train lossD: -0.137631 lossG: 0.607081\n",
      "[8: 430/1795] train lossD: -0.070888 lossG: 0.404925\n",
      "[8: 435/1795] train lossD: -0.120007 lossG: 0.451837\n",
      "[8: 440/1795] train lossD: -0.081710 lossG: 0.474297\n",
      "[8: 445/1795] train lossD: -0.067955 lossG: 0.442655\n",
      "[8: 450/1795] train lossD: 0.039774 lossG: 0.469371\n",
      "[8: 455/1795] train lossD: -0.096944 lossG: 0.559842\n",
      "[8: 460/1795] train lossD: -0.115444 lossG: 0.416859\n",
      "[8: 465/1795] train lossD: -0.090504 lossG: 0.538267\n",
      "[8: 470/1795] train lossD: -0.040505 lossG: 0.450079\n",
      "[8: 475/1795] train lossD: -0.111456 lossG: 0.344270\n",
      "[8: 480/1795] train lossD: -0.105547 lossG: 0.484576\n",
      "[8: 485/1795] train lossD: -0.162498 lossG: 0.519068\n",
      "[8: 490/1795] train lossD: -0.055636 lossG: 0.449162\n",
      "[8: 495/1795] train lossD: -0.163541 lossG: 0.536116\n",
      "[8: 500/1795] train lossD: -0.112448 lossG: 0.459074\n",
      "[8: 505/1795] train lossD: -0.203100 lossG: 0.555499\n",
      "[8: 510/1795] train lossD: -0.096995 lossG: 0.341806\n",
      "[8: 515/1795] train lossD: -0.082459 lossG: 0.434238\n",
      "[8: 520/1795] train lossD: -0.128819 lossG: 0.480045\n",
      "[8: 525/1795] train lossD: -0.083706 lossG: 0.446393\n",
      "[8: 530/1795] train lossD: -0.121887 lossG: 0.303241\n",
      "[8: 535/1795] train lossD: 0.141029 lossG: 0.582959\n",
      "[8: 540/1795] train lossD: -0.087884 lossG: 0.452721\n",
      "[8: 545/1795] train lossD: -0.140225 lossG: 0.405264\n",
      "[8: 550/1795] train lossD: -0.106235 lossG: 0.445319\n",
      "[8: 555/1795] train lossD: -0.127621 lossG: 0.602463\n",
      "[8: 560/1795] train lossD: -0.146021 lossG: 0.379141\n",
      "[8: 565/1795] train lossD: -0.105085 lossG: 0.395411\n",
      "[8: 570/1795] train lossD: -0.117699 lossG: 0.362119\n",
      "[8: 575/1795] train lossD: -0.064837 lossG: 0.492552\n",
      "[8: 580/1795] train lossD: -0.124023 lossG: 0.444295\n",
      "[8: 585/1795] train lossD: -0.007979 lossG: 0.322102\n",
      "[8: 590/1795] train lossD: -0.062190 lossG: 0.477907\n",
      "[8: 595/1795] train lossD: -0.085405 lossG: 0.381477\n",
      "[8: 600/1795] train lossD: -0.091857 lossG: 0.449864\n",
      "[8: 605/1795] train lossD: -0.072806 lossG: 0.440756\n",
      "[8: 610/1795] train lossD: -0.128439 lossG: 0.356338\n",
      "[8: 615/1795] train lossD: -0.028769 lossG: 0.311852\n",
      "[8: 620/1795] train lossD: -0.061787 lossG: 0.389221\n",
      "[8: 625/1795] train lossD: -0.193292 lossG: 0.405659\n",
      "[8: 630/1795] train lossD: -0.125106 lossG: 0.452179\n",
      "[8: 635/1795] train lossD: -0.047208 lossG: 0.453191\n",
      "[8: 640/1795] train lossD: -0.111672 lossG: 0.519353\n",
      "[8: 645/1795] train lossD: -0.107170 lossG: 0.406278\n",
      "[8: 650/1795] train lossD: -0.185741 lossG: 0.488734\n",
      "[8: 655/1795] train lossD: -0.112772 lossG: 0.362417\n",
      "[8: 660/1795] train lossD: -0.137728 lossG: 0.379860\n",
      "[8: 665/1795] train lossD: -0.039575 lossG: 0.454839\n",
      "[8: 670/1795] train lossD: -0.087868 lossG: 0.478459\n",
      "[8: 675/1795] train lossD: -0.098051 lossG: 0.563116\n",
      "[8: 680/1795] train lossD: -0.056346 lossG: 0.284208\n",
      "[8: 685/1795] train lossD: -0.121942 lossG: 0.436191\n",
      "[8: 690/1795] train lossD: -0.109779 lossG: 0.374124\n",
      "[8: 695/1795] train lossD: -0.089452 lossG: 0.399060\n",
      "[8: 700/1795] train lossD: -0.103388 lossG: 0.415576\n",
      "[8: 705/1795] train lossD: -0.171034 lossG: 0.421058\n",
      "[8: 710/1795] train lossD: -0.072971 lossG: 0.388341\n",
      "[8: 715/1795] train lossD: -0.094446 lossG: 0.540706\n",
      "[8: 720/1795] train lossD: -0.057752 lossG: 0.441044\n",
      "[8: 725/1795] train lossD: -0.115073 lossG: 0.409536\n",
      "[8: 730/1795] train lossD: -0.107597 lossG: 0.360785\n",
      "[8: 735/1795] train lossD: -0.139747 lossG: 0.489212\n",
      "[8: 740/1795] train lossD: -0.094216 lossG: 0.568412\n",
      "[8: 745/1795] train lossD: -0.092343 lossG: 0.367317\n",
      "[8: 750/1795] train lossD: -0.141578 lossG: 0.419265\n",
      "[8: 755/1795] train lossD: 0.023269 lossG: 0.421727\n",
      "[8: 760/1795] train lossD: -0.146083 lossG: 0.511889\n",
      "[8: 765/1795] train lossD: -0.116511 lossG: 0.385807\n",
      "[8: 770/1795] train lossD: -0.146505 lossG: 0.399099\n",
      "[8: 775/1795] train lossD: -0.073607 lossG: 0.405935\n",
      "[8: 780/1795] train lossD: -0.119037 lossG: 0.484711\n",
      "[8: 785/1795] train lossD: -0.130230 lossG: 0.442156\n",
      "[8: 790/1795] train lossD: -0.062861 lossG: 0.513485\n",
      "[8: 795/1795] train lossD: -0.119747 lossG: 0.422012\n",
      "[8: 800/1795] train lossD: -0.090370 lossG: 0.396419\n",
      "[8: 805/1795] train lossD: -0.145754 lossG: 0.476874\n",
      "[8: 810/1795] train lossD: -0.091697 lossG: 0.445587\n",
      "[8: 815/1795] train lossD: -0.161242 lossG: 0.438814\n",
      "[8: 820/1795] train lossD: -0.064733 lossG: 0.476931\n",
      "[8: 825/1795] train lossD: -0.148903 lossG: 0.596522\n",
      "[8: 830/1795] train lossD: -0.109209 lossG: 0.600683\n",
      "[8: 835/1795] train lossD: -0.035171 lossG: 0.462109\n",
      "[8: 840/1795] train lossD: -0.081567 lossG: 0.443183\n",
      "[8: 845/1795] train lossD: -0.139463 lossG: 0.509552\n",
      "[8: 850/1795] train lossD: -0.123390 lossG: 0.566967\n",
      "[8: 855/1795] train lossD: -0.131992 lossG: 0.502718\n",
      "[8: 860/1795] train lossD: -0.087042 lossG: 0.588612\n",
      "[8: 865/1795] train lossD: -0.062926 lossG: 0.532544\n",
      "[8: 870/1795] train lossD: -0.089045 lossG: 0.428950\n",
      "[8: 875/1795] train lossD: -0.105898 lossG: 0.402283\n",
      "[8: 880/1795] train lossD: -0.175842 lossG: 0.464642\n",
      "[8: 885/1795] train lossD: -0.059067 lossG: 0.569539\n",
      "[8: 890/1795] train lossD: -0.090863 lossG: 0.612940\n",
      "[8: 895/1795] train lossD: -0.135876 lossG: 0.424807\n",
      "[8: 900/1795] train lossD: -0.147445 lossG: 0.452682\n",
      "[8: 905/1795] train lossD: -0.096433 lossG: 0.512158\n",
      "[8: 910/1795] train lossD: -0.089641 lossG: 0.429124\n",
      "[8: 915/1795] train lossD: -0.117842 lossG: 0.490047\n",
      "[8: 920/1795] train lossD: -0.090174 lossG: 0.464275\n",
      "[8: 925/1795] train lossD: -0.102102 lossG: 0.520636\n",
      "[8: 930/1795] train lossD: -0.092942 lossG: 0.537140\n",
      "[8: 935/1795] train lossD: -0.128900 lossG: 0.432536\n",
      "[8: 940/1795] train lossD: -0.126162 lossG: 0.487609\n",
      "[8: 945/1795] train lossD: -0.034615 lossG: 0.448142\n",
      "[8: 950/1795] train lossD: -0.133170 lossG: 0.513017\n",
      "[8: 955/1795] train lossD: -0.110478 lossG: 0.437844\n",
      "[8: 960/1795] train lossD: -0.019722 lossG: 0.451975\n",
      "[8: 965/1795] train lossD: -0.109209 lossG: 0.441584\n",
      "[8: 970/1795] train lossD: -0.062788 lossG: 0.482731\n",
      "[8: 975/1795] train lossD: -0.093852 lossG: 0.441035\n",
      "[8: 980/1795] train lossD: -0.130243 lossG: 0.368373\n",
      "[8: 985/1795] train lossD: -0.161149 lossG: 0.449994\n",
      "[8: 990/1795] train lossD: -0.093685 lossG: 0.404953\n",
      "[8: 995/1795] train lossD: -0.154079 lossG: 0.464912\n",
      "[8: 1000/1795] train lossD: -0.039964 lossG: 0.426463\n",
      "[8: 1005/1795] train lossD: -0.096073 lossG: 0.297486\n",
      "[8: 1010/1795] train lossD: -0.156739 lossG: 0.542825\n",
      "[8: 1015/1795] train lossD: -0.167203 lossG: 0.530054\n",
      "[8: 1020/1795] train lossD: -0.099709 lossG: 0.493023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8: 1025/1795] train lossD: -0.032193 lossG: 0.499149\n",
      "[8: 1030/1795] train lossD: -0.090499 lossG: 0.427511\n",
      "[8: 1035/1795] train lossD: -0.054759 lossG: 0.540520\n",
      "[8: 1040/1795] train lossD: -0.094334 lossG: 0.499193\n",
      "[8: 1045/1795] train lossD: -0.145498 lossG: 0.457227\n",
      "[8: 1050/1795] train lossD: -0.064459 lossG: 0.631730\n",
      "[8: 1055/1795] train lossD: -0.120818 lossG: 0.443349\n",
      "[8: 1060/1795] train lossD: -0.094180 lossG: 0.480930\n",
      "[8: 1065/1795] train lossD: -0.067944 lossG: 0.616658\n",
      "[8: 1070/1795] train lossD: -0.113093 lossG: 0.493457\n",
      "[8: 1075/1795] train lossD: -0.134752 lossG: 0.535281\n",
      "[8: 1080/1795] train lossD: -0.147611 lossG: 0.536875\n",
      "[8: 1085/1795] train lossD: -0.117790 lossG: 0.583327\n",
      "[8: 1090/1795] train lossD: -0.135009 lossG: 0.438894\n",
      "[8: 1095/1795] train lossD: -0.130089 lossG: 0.342966\n",
      "[8: 1100/1795] train lossD: -0.154269 lossG: 0.438076\n",
      "[8: 1105/1795] train lossD: -0.106376 lossG: 0.563620\n",
      "[8: 1110/1795] train lossD: -0.167655 lossG: 0.458448\n",
      "[8: 1115/1795] train lossD: -0.113537 lossG: 0.519474\n",
      "[8: 1120/1795] train lossD: -0.025759 lossG: 0.411445\n",
      "[8: 1125/1795] train lossD: -0.112022 lossG: 0.457390\n",
      "[8: 1130/1795] train lossD: -0.086756 lossG: 0.440164\n",
      "[8: 1135/1795] train lossD: 0.005342 lossG: 0.249577\n",
      "[8: 1140/1795] train lossD: -0.061451 lossG: 0.525155\n",
      "[8: 1145/1795] train lossD: -0.050768 lossG: 0.417715\n",
      "[8: 1150/1795] train lossD: -0.135406 lossG: 0.507779\n",
      "[8: 1155/1795] train lossD: -0.100175 lossG: 0.507496\n",
      "[8: 1160/1795] train lossD: -0.150756 lossG: 0.450839\n",
      "[8: 1165/1795] train lossD: -0.054835 lossG: 0.464595\n",
      "[8: 1170/1795] train lossD: -0.109897 lossG: 0.515777\n",
      "[8: 1175/1795] train lossD: -0.072720 lossG: 0.500653\n",
      "[8: 1180/1795] train lossD: -0.108408 lossG: 0.548549\n",
      "[8: 1185/1795] train lossD: -0.188325 lossG: 0.414183\n",
      "[8: 1190/1795] train lossD: -0.039761 lossG: 0.426296\n",
      "[8: 1195/1795] train lossD: -0.080421 lossG: 0.422130\n",
      "[8: 1200/1795] train lossD: -0.121441 lossG: 0.470363\n",
      "[8: 1205/1795] train lossD: -0.122179 lossG: 0.391137\n",
      "[8: 1210/1795] train lossD: -0.129057 lossG: 0.364750\n",
      "[8: 1215/1795] train lossD: -0.132983 lossG: 0.334300\n",
      "[8: 1220/1795] train lossD: -0.109816 lossG: 0.435628\n",
      "[8: 1225/1795] train lossD: -0.150232 lossG: 0.419076\n",
      "[8: 1230/1795] train lossD: -0.136512 lossG: 0.316826\n",
      "[8: 1235/1795] train lossD: -0.108101 lossG: 0.531130\n",
      "[8: 1240/1795] train lossD: -0.088888 lossG: 0.417123\n",
      "[8: 1245/1795] train lossD: -0.120068 lossG: 0.397338\n",
      "[8: 1250/1795] train lossD: -0.125073 lossG: 0.398360\n",
      "[8: 1255/1795] train lossD: -0.096508 lossG: 0.356171\n",
      "[8: 1260/1795] train lossD: -0.076100 lossG: 0.445156\n",
      "[8: 1265/1795] train lossD: -0.159898 lossG: 0.361115\n",
      "[8: 1270/1795] train lossD: -0.073169 lossG: 0.434268\n",
      "[8: 1275/1795] train lossD: -0.130911 lossG: 0.439396\n",
      "[8: 1280/1795] train lossD: -0.048558 lossG: 0.337592\n",
      "[8: 1285/1795] train lossD: -0.112755 lossG: 0.499953\n",
      "[8: 1290/1795] train lossD: -0.125476 lossG: 0.487747\n",
      "[8: 1295/1795] train lossD: -0.121905 lossG: 0.500763\n",
      "[8: 1300/1795] train lossD: -0.074856 lossG: 0.486862\n",
      "[8: 1305/1795] train lossD: -0.124085 lossG: 0.615559\n",
      "[8: 1310/1795] train lossD: -0.147502 lossG: 0.595306\n",
      "[8: 1315/1795] train lossD: -0.109959 lossG: 0.570741\n",
      "[8: 1320/1795] train lossD: -0.060678 lossG: 0.453280\n",
      "[8: 1325/1795] train lossD: -0.050503 lossG: 0.413879\n",
      "[8: 1330/1795] train lossD: -0.116176 lossG: 0.382265\n",
      "[8: 1335/1795] train lossD: -0.030846 lossG: 0.482416\n",
      "[8: 1340/1795] train lossD: -0.086589 lossG: 0.433463\n",
      "[8: 1345/1795] train lossD: -0.115329 lossG: 0.428289\n",
      "[8: 1350/1795] train lossD: -0.066730 lossG: 0.456858\n",
      "[8: 1355/1795] train lossD: -0.096720 lossG: 0.421361\n",
      "[8: 1360/1795] train lossD: -0.138841 lossG: 0.547105\n",
      "[8: 1365/1795] train lossD: -0.065351 lossG: 0.507348\n",
      "[8: 1370/1795] train lossD: -0.117538 lossG: 0.595726\n",
      "[8: 1375/1795] train lossD: -0.142392 lossG: 0.517493\n",
      "[8: 1380/1795] train lossD: -0.149145 lossG: 0.506047\n",
      "[8: 1385/1795] train lossD: -0.123533 lossG: 0.412377\n",
      "[8: 1390/1795] train lossD: -0.127182 lossG: 0.368000\n",
      "[8: 1395/1795] train lossD: -0.135532 lossG: 0.416043\n",
      "[8: 1400/1795] train lossD: -0.124711 lossG: 0.661811\n",
      "[8: 1405/1795] train lossD: -0.130804 lossG: 0.425927\n",
      "[8: 1410/1795] train lossD: -0.123513 lossG: 0.407952\n",
      "[8: 1415/1795] train lossD: -0.049284 lossG: 0.477650\n",
      "[8: 1420/1795] train lossD: -0.132116 lossG: 0.476979\n",
      "[8: 1425/1795] train lossD: -0.110778 lossG: 0.471776\n",
      "[8: 1430/1795] train lossD: -0.085795 lossG: 0.392572\n",
      "[8: 1435/1795] train lossD: -0.115094 lossG: 0.335367\n",
      "[8: 1440/1795] train lossD: -0.084974 lossG: 0.424820\n",
      "[8: 1445/1795] train lossD: -0.094884 lossG: 0.427936\n",
      "[8: 1450/1795] train lossD: 0.034607 lossG: 0.595209\n",
      "[8: 1455/1795] train lossD: -0.065556 lossG: 0.410475\n",
      "[8: 1460/1795] train lossD: -0.114171 lossG: 0.419571\n",
      "[8: 1465/1795] train lossD: -0.121092 lossG: 0.507691\n",
      "[8: 1470/1795] train lossD: -0.138351 lossG: 0.421975\n",
      "[8: 1475/1795] train lossD: -0.130291 lossG: 0.405398\n",
      "[8: 1480/1795] train lossD: -0.081177 lossG: 0.379350\n",
      "[8: 1485/1795] train lossD: -0.156539 lossG: 0.412280\n",
      "[8: 1490/1795] train lossD: -0.085662 lossG: 0.457730\n",
      "[8: 1495/1795] train lossD: -0.150455 lossG: 0.413706\n",
      "[8: 1500/1795] train lossD: -0.064125 lossG: 0.378785\n",
      "[8: 1505/1795] train lossD: -0.117635 lossG: 0.453635\n",
      "[8: 1510/1795] train lossD: -0.095489 lossG: 0.416155\n",
      "[8: 1515/1795] train lossD: -0.088225 lossG: 0.498513\n",
      "[8: 1520/1795] train lossD: -0.135035 lossG: 0.552125\n",
      "[8: 1525/1795] train lossD: -0.088571 lossG: 0.621551\n",
      "[8: 1530/1795] train lossD: -0.115996 lossG: 0.482033\n",
      "[8: 1535/1795] train lossD: -0.170228 lossG: 0.471004\n",
      "[8: 1540/1795] train lossD: -0.124270 lossG: 0.425007\n",
      "[8: 1545/1795] train lossD: -0.099193 lossG: 0.383204\n",
      "[8: 1550/1795] train lossD: -0.109999 lossG: 0.518298\n",
      "[8: 1555/1795] train lossD: -0.079832 lossG: 0.476376\n",
      "[8: 1560/1795] train lossD: -0.130484 lossG: 0.358165\n",
      "[8: 1565/1795] train lossD: -0.050390 lossG: 0.330210\n",
      "[8: 1570/1795] train lossD: -0.097684 lossG: 0.391641\n",
      "[8: 1575/1795] train lossD: -0.152043 lossG: 0.455370\n",
      "[8: 1580/1795] train lossD: -0.135638 lossG: 0.487140\n",
      "[8: 1585/1795] train lossD: -0.066681 lossG: 0.430522\n",
      "[8: 1590/1795] train lossD: -0.107022 lossG: 0.493317\n",
      "[8: 1595/1795] train lossD: -0.103576 lossG: 0.460541\n",
      "[8: 1600/1795] train lossD: -0.096994 lossG: 0.437848\n",
      "[8: 1605/1795] train lossD: -0.138466 lossG: 0.484349\n",
      "[8: 1610/1795] train lossD: -0.080801 lossG: 0.471024\n",
      "[8: 1615/1795] train lossD: -0.056245 lossG: 0.590025\n",
      "[8: 1620/1795] train lossD: -0.136343 lossG: 0.477645\n",
      "[8: 1625/1795] train lossD: 0.014680 lossG: 0.374128\n",
      "[8: 1630/1795] train lossD: -0.077640 lossG: 0.445459\n",
      "[8: 1635/1795] train lossD: -0.139940 lossG: 0.468991\n",
      "[8: 1640/1795] train lossD: -0.107554 lossG: 0.507098\n",
      "[8: 1645/1795] train lossD: -0.120711 lossG: 0.556131\n",
      "[8: 1650/1795] train lossD: -0.123604 lossG: 0.530230\n",
      "[8: 1655/1795] train lossD: -0.124692 lossG: 0.422752\n",
      "[8: 1660/1795] train lossD: -0.129914 lossG: 0.399857\n",
      "[8: 1665/1795] train lossD: -0.171750 lossG: 0.412186\n",
      "[8: 1670/1795] train lossD: -0.037410 lossG: 0.568952\n",
      "[8: 1675/1795] train lossD: -0.157141 lossG: 0.526799\n",
      "[8: 1680/1795] train lossD: -0.097170 lossG: 0.509366\n",
      "[8: 1685/1795] train lossD: -0.033082 lossG: 0.651390\n",
      "[8: 1690/1795] train lossD: -0.121883 lossG: 0.598241\n",
      "[8: 1695/1795] train lossD: -0.087856 lossG: 0.427858\n",
      "[8: 1700/1795] train lossD: -0.063616 lossG: 0.420304\n",
      "[8: 1705/1795] train lossD: -0.033966 lossG: 0.516627\n",
      "[8: 1710/1795] train lossD: -0.113300 lossG: 0.490404\n",
      "[8: 1715/1795] train lossD: -0.121960 lossG: 0.467681\n",
      "[8: 1720/1795] train lossD: -0.118130 lossG: 0.581083\n",
      "[8: 1725/1795] train lossD: -0.090061 lossG: 0.468468\n",
      "[8: 1730/1795] train lossD: -0.082956 lossG: 0.367387\n",
      "[8: 1735/1795] train lossD: -0.038376 lossG: 0.365395\n",
      "[8: 1740/1795] train lossD: -0.090854 lossG: 0.450501\n",
      "[8: 1745/1795] train lossD: -0.106574 lossG: 0.342359\n",
      "[8: 1750/1795] train lossD: -0.107837 lossG: 0.541791\n",
      "[8: 1755/1795] train lossD: -0.095832 lossG: 0.416879\n",
      "[8: 1760/1795] train lossD: -0.156858 lossG: 0.508487\n",
      "[8: 1765/1795] train lossD: -0.100086 lossG: 0.423873\n",
      "[8: 1770/1795] train lossD: -0.133530 lossG: 0.500605\n",
      "[8: 1775/1795] train lossD: -0.107873 lossG: 0.403854\n",
      "[8: 1780/1795] train lossD: -0.145320 lossG: 0.573895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8: 1785/1795] train lossD: -0.122079 lossG: 0.467436\n",
      "[8: 1790/1795] train lossD: -0.150829 lossG: 0.473755\n",
      "0.03754439949989319\n",
      "[9: 0/1795] train lossD: -0.107531 lossG: 0.408992\n",
      "[9: 5/1795] train lossD: -0.100912 lossG: 0.518877\n",
      "[9: 10/1795] train lossD: -0.046303 lossG: 0.437023\n",
      "[9: 15/1795] train lossD: -0.092049 lossG: 0.500211\n",
      "[9: 20/1795] train lossD: -0.087315 lossG: 0.410442\n",
      "[9: 25/1795] train lossD: -0.115446 lossG: 0.429426\n",
      "[9: 30/1795] train lossD: -0.056957 lossG: 0.326242\n",
      "[9: 35/1795] train lossD: -0.180557 lossG: 0.381822\n",
      "[9: 40/1795] train lossD: -0.074899 lossG: 0.459872\n",
      "[9: 45/1795] train lossD: -0.073579 lossG: 0.454068\n",
      "[9: 50/1795] train lossD: -0.086465 lossG: 0.407918\n",
      "[9: 55/1795] train lossD: -0.104277 lossG: 0.361936\n",
      "[9: 60/1795] train lossD: -0.083911 lossG: 0.490352\n",
      "[9: 65/1795] train lossD: -0.080697 lossG: 0.380707\n",
      "[9: 70/1795] train lossD: -0.079139 lossG: 0.437073\n",
      "[9: 75/1795] train lossD: -0.167678 lossG: 0.458262\n",
      "[9: 80/1795] train lossD: -0.144544 lossG: 0.404382\n",
      "[9: 85/1795] train lossD: -0.041324 lossG: 0.464503\n",
      "[9: 90/1795] train lossD: -0.121603 lossG: 0.384634\n",
      "[9: 95/1795] train lossD: -0.096353 lossG: 0.402569\n",
      "[9: 100/1795] train lossD: -0.145358 lossG: 0.401901\n",
      "[9: 105/1795] train lossD: -0.111903 lossG: 0.483475\n",
      "[9: 110/1795] train lossD: -0.103673 lossG: 0.400433\n",
      "[9: 115/1795] train lossD: -0.118902 lossG: 0.491999\n",
      "[9: 120/1795] train lossD: -0.104001 lossG: 0.385436\n",
      "[9: 125/1795] train lossD: -0.052478 lossG: 0.343117\n",
      "[9: 130/1795] train lossD: -0.006255 lossG: 0.534067\n",
      "[9: 135/1795] train lossD: -0.028321 lossG: 0.344785\n",
      "[9: 140/1795] train lossD: -0.076206 lossG: 0.439576\n",
      "[9: 145/1795] train lossD: -0.108493 lossG: 0.641626\n",
      "[9: 150/1795] train lossD: -0.134845 lossG: 0.547046\n",
      "[9: 155/1795] train lossD: -0.026494 lossG: 0.616249\n",
      "[9: 160/1795] train lossD: -0.130523 lossG: 0.524115\n",
      "[9: 165/1795] train lossD: -0.104648 lossG: 0.525886\n",
      "[9: 170/1795] train lossD: -0.036678 lossG: 0.565731\n",
      "[9: 175/1795] train lossD: -0.096917 lossG: 0.366311\n",
      "[9: 180/1795] train lossD: -0.099286 lossG: 0.427886\n",
      "[9: 185/1795] train lossD: -0.101358 lossG: 0.386603\n",
      "[9: 190/1795] train lossD: -0.050299 lossG: 0.384160\n",
      "[9: 195/1795] train lossD: -0.139740 lossG: 0.523189\n",
      "[9: 200/1795] train lossD: -0.027083 lossG: 0.427915\n",
      "[9: 205/1795] train lossD: -0.115576 lossG: 0.486986\n",
      "[9: 210/1795] train lossD: -0.090879 lossG: 0.435779\n",
      "[9: 215/1795] train lossD: -0.079070 lossG: 0.471560\n",
      "[9: 220/1795] train lossD: -0.100479 lossG: 0.490437\n",
      "[9: 225/1795] train lossD: -0.147538 lossG: 0.406932\n",
      "[9: 230/1795] train lossD: -0.082520 lossG: 0.530891\n",
      "[9: 235/1795] train lossD: -0.143665 lossG: 0.474157\n",
      "[9: 240/1795] train lossD: -0.092644 lossG: 0.324320\n",
      "[9: 245/1795] train lossD: -0.060853 lossG: 0.627728\n",
      "[9: 250/1795] train lossD: -0.083352 lossG: 0.409727\n",
      "[9: 255/1795] train lossD: -0.188478 lossG: 0.541134\n",
      "[9: 260/1795] train lossD: -0.131958 lossG: 0.427662\n",
      "[9: 265/1795] train lossD: -0.070502 lossG: 0.448375\n",
      "[9: 270/1795] train lossD: -0.114240 lossG: 0.389058\n",
      "[9: 275/1795] train lossD: -0.119178 lossG: 0.354379\n",
      "[9: 280/1795] train lossD: 0.075003 lossG: 0.267878\n",
      "[9: 285/1795] train lossD: -0.136990 lossG: 0.333611\n",
      "[9: 290/1795] train lossD: -0.069088 lossG: 0.510376\n",
      "[9: 295/1795] train lossD: -0.116892 lossG: 0.373867\n",
      "[9: 300/1795] train lossD: -0.095078 lossG: 0.382891\n",
      "[9: 305/1795] train lossD: -0.100183 lossG: 0.385317\n",
      "[9: 310/1795] train lossD: -0.172802 lossG: 0.393823\n",
      "[9: 315/1795] train lossD: -0.078184 lossG: 0.392167\n",
      "[9: 320/1795] train lossD: -0.053967 lossG: 0.549162\n",
      "[9: 325/1795] train lossD: -0.157243 lossG: 0.440740\n",
      "[9: 330/1795] train lossD: -0.049162 lossG: 0.449787\n",
      "[9: 335/1795] train lossD: -0.102612 lossG: 0.364631\n",
      "[9: 340/1795] train lossD: -0.140982 lossG: 0.458388\n",
      "[9: 345/1795] train lossD: -0.117148 lossG: 0.458728\n",
      "[9: 350/1795] train lossD: -0.058339 lossG: 0.471818\n",
      "[9: 355/1795] train lossD: -0.140613 lossG: 0.497511\n",
      "[9: 360/1795] train lossD: -0.072807 lossG: 0.335724\n",
      "[9: 365/1795] train lossD: -0.141270 lossG: 0.405147\n",
      "[9: 370/1795] train lossD: -0.072184 lossG: 0.477268\n",
      "[9: 375/1795] train lossD: -0.116975 lossG: 0.406324\n",
      "[9: 380/1795] train lossD: -0.070167 lossG: 0.444470\n",
      "[9: 385/1795] train lossD: -0.117194 lossG: 0.466396\n",
      "[9: 390/1795] train lossD: -0.091953 lossG: 0.424539\n",
      "[9: 395/1795] train lossD: -0.043188 lossG: 0.571416\n",
      "[9: 400/1795] train lossD: -0.101605 lossG: 0.488767\n",
      "[9: 405/1795] train lossD: -0.061423 lossG: 0.505385\n",
      "[9: 410/1795] train lossD: -0.056312 lossG: 0.499997\n",
      "[9: 415/1795] train lossD: -0.162770 lossG: 0.383778\n",
      "[9: 420/1795] train lossD: -0.131757 lossG: 0.465548\n",
      "[9: 425/1795] train lossD: -0.106591 lossG: 0.429402\n",
      "[9: 430/1795] train lossD: -0.136515 lossG: 0.456845\n",
      "[9: 435/1795] train lossD: -0.103059 lossG: 0.406241\n",
      "[9: 440/1795] train lossD: -0.081668 lossG: 0.553209\n",
      "[9: 445/1795] train lossD: -0.069644 lossG: 0.427464\n",
      "[9: 450/1795] train lossD: -0.141437 lossG: 0.429381\n",
      "[9: 455/1795] train lossD: -0.034665 lossG: 0.535215\n",
      "[9: 460/1795] train lossD: -0.119598 lossG: 0.413573\n",
      "[9: 465/1795] train lossD: -0.128994 lossG: 0.497354\n",
      "[9: 470/1795] train lossD: -0.061179 lossG: 0.356159\n",
      "[9: 475/1795] train lossD: -0.146795 lossG: 0.696132\n",
      "[9: 480/1795] train lossD: -0.085245 lossG: 0.417019\n",
      "[9: 485/1795] train lossD: -0.141050 lossG: 0.443752\n",
      "[9: 490/1795] train lossD: -0.134898 lossG: 0.386732\n",
      "[9: 495/1795] train lossD: -0.138156 lossG: 0.389930\n",
      "[9: 500/1795] train lossD: -0.176358 lossG: 0.440419\n",
      "[9: 505/1795] train lossD: -0.178880 lossG: 0.385218\n",
      "[9: 510/1795] train lossD: -0.072905 lossG: 0.418578\n",
      "[9: 515/1795] train lossD: -0.096686 lossG: 0.337704\n",
      "[9: 520/1795] train lossD: -0.138395 lossG: 0.320259\n",
      "[9: 525/1795] train lossD: -0.127606 lossG: 0.495400\n",
      "[9: 530/1795] train lossD: 0.044808 lossG: 0.456192\n",
      "[9: 535/1795] train lossD: -0.128126 lossG: 0.419730\n",
      "[9: 540/1795] train lossD: -0.084106 lossG: 0.505921\n",
      "[9: 545/1795] train lossD: -0.117063 lossG: 0.356212\n",
      "[9: 550/1795] train lossD: -0.044166 lossG: 0.375709\n",
      "[9: 555/1795] train lossD: -0.152860 lossG: 0.356837\n",
      "[9: 560/1795] train lossD: -0.055224 lossG: 0.315818\n",
      "[9: 565/1795] train lossD: -0.099050 lossG: 0.450478\n",
      "[9: 570/1795] train lossD: -0.162756 lossG: 0.530349\n",
      "[9: 575/1795] train lossD: -0.053505 lossG: 0.450757\n",
      "[9: 580/1795] train lossD: -0.137113 lossG: 0.417969\n",
      "[9: 585/1795] train lossD: -0.151088 lossG: 0.497031\n",
      "[9: 590/1795] train lossD: -0.137486 lossG: 0.329105\n",
      "[9: 595/1795] train lossD: -0.067351 lossG: 0.403551\n",
      "[9: 600/1795] train lossD: -0.006924 lossG: 0.346558\n",
      "[9: 605/1795] train lossD: -0.107095 lossG: 0.301485\n",
      "[9: 610/1795] train lossD: -0.178250 lossG: 0.498224\n",
      "[9: 615/1795] train lossD: -0.104384 lossG: 0.402972\n",
      "[9: 620/1795] train lossD: -0.086597 lossG: 0.407116\n",
      "[9: 625/1795] train lossD: -0.080177 lossG: 0.438008\n",
      "[9: 630/1795] train lossD: -0.079694 lossG: 0.571981\n",
      "[9: 635/1795] train lossD: -0.096472 lossG: 0.315246\n",
      "[9: 640/1795] train lossD: -0.068275 lossG: 0.647918\n",
      "[9: 645/1795] train lossD: -0.064467 lossG: 0.324310\n",
      "[9: 650/1795] train lossD: -0.069944 lossG: 0.415081\n",
      "[9: 655/1795] train lossD: -0.139977 lossG: 0.439975\n",
      "[9: 660/1795] train lossD: -0.126678 lossG: 0.500978\n",
      "[9: 665/1795] train lossD: -0.106146 lossG: 0.386460\n",
      "[9: 670/1795] train lossD: -0.084277 lossG: 0.336152\n",
      "[9: 675/1795] train lossD: -0.076762 lossG: 0.322394\n",
      "[9: 680/1795] train lossD: -0.112895 lossG: 0.362715\n",
      "[9: 685/1795] train lossD: -0.111591 lossG: 0.462822\n",
      "[9: 690/1795] train lossD: -0.086593 lossG: 0.364897\n",
      "[9: 695/1795] train lossD: -0.089681 lossG: 0.450881\n",
      "[9: 700/1795] train lossD: -0.089015 lossG: 0.642994\n",
      "[9: 705/1795] train lossD: -0.089515 lossG: 0.454877\n",
      "[9: 710/1795] train lossD: -0.040415 lossG: 0.347227\n",
      "[9: 715/1795] train lossD: -0.094992 lossG: 0.374745\n",
      "[9: 720/1795] train lossD: -0.107373 lossG: 0.423050\n",
      "[9: 725/1795] train lossD: -0.131852 lossG: 0.449154\n",
      "[9: 730/1795] train lossD: -0.060632 lossG: 0.407693\n",
      "[9: 735/1795] train lossD: -0.123950 lossG: 0.560455\n",
      "[9: 740/1795] train lossD: -0.137330 lossG: 0.534097\n",
      "[9: 745/1795] train lossD: -0.126942 lossG: 0.579810\n",
      "[9: 750/1795] train lossD: -0.121880 lossG: 0.554642\n",
      "[9: 755/1795] train lossD: -0.106613 lossG: 0.562064\n",
      "[9: 760/1795] train lossD: -0.115028 lossG: 0.377571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9: 765/1795] train lossD: -0.126885 lossG: 0.594299\n",
      "[9: 770/1795] train lossD: -0.036296 lossG: 0.591085\n",
      "[9: 775/1795] train lossD: -0.065596 lossG: 0.435729\n",
      "[9: 780/1795] train lossD: -0.113267 lossG: 0.552087\n",
      "[9: 785/1795] train lossD: -0.028382 lossG: 0.305145\n",
      "[9: 790/1795] train lossD: -0.081748 lossG: 0.433126\n",
      "[9: 795/1795] train lossD: -0.103405 lossG: 0.436541\n",
      "[9: 800/1795] train lossD: -0.075788 lossG: 0.497608\n",
      "[9: 805/1795] train lossD: -0.114511 lossG: 0.474588\n",
      "[9: 810/1795] train lossD: -0.125313 lossG: 0.470450\n",
      "[9: 815/1795] train lossD: -0.079646 lossG: 0.464069\n",
      "[9: 820/1795] train lossD: -0.108525 lossG: 0.449083\n",
      "[9: 825/1795] train lossD: -0.071538 lossG: 0.471289\n",
      "[9: 830/1795] train lossD: -0.114459 lossG: 0.435966\n",
      "[9: 835/1795] train lossD: -0.105147 lossG: 0.474577\n",
      "[9: 840/1795] train lossD: -0.116108 lossG: 0.479606\n",
      "[9: 845/1795] train lossD: -0.117126 lossG: 0.526150\n",
      "[9: 850/1795] train lossD: -0.109672 lossG: 0.414558\n",
      "[9: 855/1795] train lossD: -0.162817 lossG: 0.481462\n",
      "[9: 860/1795] train lossD: -0.167746 lossG: 0.559148\n",
      "[9: 865/1795] train lossD: -0.161802 lossG: 0.519277\n",
      "[9: 870/1795] train lossD: -0.094255 lossG: 0.469820\n",
      "[9: 875/1795] train lossD: -0.155068 lossG: 0.509405\n",
      "[9: 880/1795] train lossD: 0.043037 lossG: 0.501345\n",
      "[9: 885/1795] train lossD: -0.024939 lossG: 0.310281\n",
      "[9: 890/1795] train lossD: -0.090411 lossG: 0.435228\n",
      "[9: 895/1795] train lossD: -0.128935 lossG: 0.338039\n",
      "[9: 900/1795] train lossD: -0.115594 lossG: 0.401597\n",
      "[9: 905/1795] train lossD: -0.079230 lossG: 0.428510\n",
      "[9: 910/1795] train lossD: -0.084554 lossG: 0.391511\n",
      "[9: 915/1795] train lossD: -0.130197 lossG: 0.414865\n",
      "[9: 920/1795] train lossD: -0.113402 lossG: 0.481479\n",
      "[9: 925/1795] train lossD: -0.154142 lossG: 0.381878\n",
      "[9: 930/1795] train lossD: -0.127907 lossG: 0.456829\n",
      "[9: 935/1795] train lossD: -0.037276 lossG: 0.528761\n",
      "[9: 940/1795] train lossD: -0.120968 lossG: 0.409801\n",
      "[9: 945/1795] train lossD: -0.111787 lossG: 0.370918\n",
      "[9: 950/1795] train lossD: -0.094390 lossG: 0.479504\n",
      "[9: 955/1795] train lossD: -0.069883 lossG: 0.570214\n",
      "[9: 960/1795] train lossD: -0.114447 lossG: 0.499018\n",
      "[9: 965/1795] train lossD: -0.041864 lossG: 0.571589\n",
      "[9: 970/1795] train lossD: -0.138366 lossG: 0.514515\n",
      "[9: 975/1795] train lossD: -0.070198 lossG: 0.488220\n",
      "[9: 980/1795] train lossD: -0.122992 lossG: 0.623209\n",
      "[9: 985/1795] train lossD: -0.123048 lossG: 0.399298\n",
      "[9: 990/1795] train lossD: -0.018007 lossG: 0.607385\n",
      "[9: 995/1795] train lossD: -0.082362 lossG: 0.560300\n",
      "[9: 1000/1795] train lossD: -0.012845 lossG: 0.394984\n",
      "[9: 1005/1795] train lossD: -0.082892 lossG: 0.444142\n",
      "[9: 1010/1795] train lossD: -0.043791 lossG: 0.392060\n",
      "[9: 1015/1795] train lossD: -0.129322 lossG: 0.444934\n",
      "[9: 1020/1795] train lossD: -0.104678 lossG: 0.449649\n",
      "[9: 1025/1795] train lossD: -0.035092 lossG: 0.454153\n",
      "[9: 1030/1795] train lossD: -0.125900 lossG: 0.373815\n",
      "[9: 1035/1795] train lossD: -0.089167 lossG: 0.391971\n",
      "[9: 1040/1795] train lossD: -0.124360 lossG: 0.546737\n",
      "[9: 1045/1795] train lossD: -0.054969 lossG: 0.466706\n",
      "[9: 1050/1795] train lossD: -0.126597 lossG: 0.467358\n",
      "[9: 1055/1795] train lossD: -0.082209 lossG: 0.388507\n",
      "[9: 1060/1795] train lossD: -0.118872 lossG: 0.446306\n",
      "[9: 1065/1795] train lossD: -0.207151 lossG: 0.526306\n",
      "[9: 1070/1795] train lossD: -0.127915 lossG: 0.367799\n",
      "[9: 1075/1795] train lossD: -0.126964 lossG: 0.367444\n",
      "[9: 1080/1795] train lossD: -0.096327 lossG: 0.607788\n",
      "[9: 1085/1795] train lossD: -0.116625 lossG: 0.502219\n",
      "[9: 1090/1795] train lossD: -0.054998 lossG: 0.432355\n",
      "[9: 1095/1795] train lossD: -0.162286 lossG: 0.455555\n",
      "[9: 1100/1795] train lossD: -0.105913 lossG: 0.438728\n",
      "[9: 1105/1795] train lossD: -0.105846 lossG: 0.443888\n",
      "[9: 1110/1795] train lossD: -0.121798 lossG: 0.440666\n",
      "[9: 1115/1795] train lossD: -0.139888 lossG: 0.602087\n",
      "[9: 1120/1795] train lossD: -0.137078 lossG: 0.594111\n",
      "[9: 1125/1795] train lossD: -0.078852 lossG: 0.473413\n",
      "[9: 1130/1795] train lossD: -0.116506 lossG: 0.385364\n",
      "[9: 1135/1795] train lossD: -0.109623 lossG: 0.410843\n",
      "[9: 1140/1795] train lossD: -0.165014 lossG: 0.432557\n",
      "[9: 1145/1795] train lossD: -0.077741 lossG: 0.409435\n",
      "[9: 1150/1795] train lossD: -0.160167 lossG: 0.431555\n",
      "[9: 1155/1795] train lossD: -0.031527 lossG: 0.271235\n",
      "[9: 1160/1795] train lossD: -0.140845 lossG: 0.437925\n",
      "[9: 1165/1795] train lossD: -0.150259 lossG: 0.360605\n",
      "[9: 1170/1795] train lossD: -0.065440 lossG: 0.385725\n",
      "[9: 1175/1795] train lossD: -0.104596 lossG: 0.414977\n",
      "[9: 1180/1795] train lossD: 0.001073 lossG: 0.317173\n",
      "[9: 1185/1795] train lossD: -0.186391 lossG: 0.385437\n",
      "[9: 1190/1795] train lossD: -0.067334 lossG: 0.433826\n",
      "[9: 1195/1795] train lossD: -0.157578 lossG: 0.489161\n",
      "[9: 1200/1795] train lossD: -0.084181 lossG: 0.637344\n",
      "[9: 1205/1795] train lossD: -0.027831 lossG: 0.533032\n",
      "[9: 1210/1795] train lossD: -0.109346 lossG: 0.516279\n",
      "[9: 1215/1795] train lossD: -0.063615 lossG: 0.405425\n",
      "[9: 1220/1795] train lossD: -0.054107 lossG: 0.364848\n",
      "[9: 1225/1795] train lossD: -0.115613 lossG: 0.463068\n",
      "[9: 1230/1795] train lossD: -0.127032 lossG: 0.539700\n",
      "[9: 1235/1795] train lossD: -0.110926 lossG: 0.354023\n",
      "[9: 1240/1795] train lossD: 0.006920 lossG: 0.532235\n",
      "[9: 1245/1795] train lossD: -0.112229 lossG: 0.341919\n",
      "[9: 1250/1795] train lossD: -0.157333 lossG: 0.402335\n",
      "[9: 1255/1795] train lossD: -0.068702 lossG: 0.401479\n",
      "[9: 1260/1795] train lossD: -0.122553 lossG: 0.514082\n",
      "[9: 1265/1795] train lossD: -0.143221 lossG: 0.613788\n",
      "[9: 1270/1795] train lossD: -0.047500 lossG: 0.470538\n",
      "[9: 1275/1795] train lossD: -0.091078 lossG: 0.408634\n",
      "[9: 1280/1795] train lossD: -0.133003 lossG: 0.428958\n",
      "[9: 1285/1795] train lossD: -0.053027 lossG: 0.363149\n",
      "[9: 1290/1795] train lossD: -0.117593 lossG: 0.504511\n",
      "[9: 1295/1795] train lossD: -0.121589 lossG: 0.433590\n",
      "[9: 1300/1795] train lossD: -0.074470 lossG: 0.470639\n",
      "[9: 1305/1795] train lossD: -0.106670 lossG: 0.385837\n",
      "[9: 1310/1795] train lossD: -0.149612 lossG: 0.364730\n",
      "[9: 1315/1795] train lossD: -0.039590 lossG: 0.490779\n",
      "[9: 1320/1795] train lossD: -0.057830 lossG: 0.429254\n",
      "[9: 1325/1795] train lossD: -0.032643 lossG: 0.385512\n",
      "[9: 1330/1795] train lossD: -0.018369 lossG: 0.440878\n",
      "[9: 1335/1795] train lossD: -0.092101 lossG: 0.435093\n",
      "[9: 1340/1795] train lossD: -0.021828 lossG: 0.388942\n",
      "[9: 1345/1795] train lossD: -0.085294 lossG: 0.614937\n",
      "[9: 1350/1795] train lossD: -0.128621 lossG: 0.482116\n",
      "[9: 1355/1795] train lossD: -0.069100 lossG: 0.489311\n",
      "[9: 1360/1795] train lossD: -0.103932 lossG: 0.427530\n",
      "[9: 1365/1795] train lossD: -0.103640 lossG: 0.703498\n",
      "[9: 1370/1795] train lossD: -0.084950 lossG: 0.466193\n",
      "[9: 1375/1795] train lossD: -0.141814 lossG: 0.468599\n",
      "[9: 1380/1795] train lossD: -0.202087 lossG: 0.416841\n",
      "[9: 1385/1795] train lossD: -0.095439 lossG: 0.441688\n",
      "[9: 1390/1795] train lossD: -0.087621 lossG: 0.317380\n",
      "[9: 1395/1795] train lossD: -0.125029 lossG: 0.383167\n",
      "[9: 1400/1795] train lossD: -0.079343 lossG: 0.488658\n",
      "[9: 1405/1795] train lossD: -0.045837 lossG: 0.529896\n",
      "[9: 1410/1795] train lossD: -0.143653 lossG: 0.482405\n",
      "[9: 1415/1795] train lossD: -0.124019 lossG: 0.412637\n",
      "[9: 1420/1795] train lossD: -0.125449 lossG: 0.458997\n",
      "[9: 1425/1795] train lossD: -0.094274 lossG: 0.330219\n",
      "[9: 1430/1795] train lossD: -0.138873 lossG: 0.354835\n",
      "[9: 1435/1795] train lossD: -0.040029 lossG: 0.443290\n",
      "[9: 1440/1795] train lossD: -0.063097 lossG: 0.478942\n",
      "[9: 1445/1795] train lossD: -0.098622 lossG: 0.450580\n",
      "[9: 1450/1795] train lossD: -0.075883 lossG: 0.438088\n",
      "[9: 1455/1795] train lossD: -0.101381 lossG: 0.380638\n",
      "[9: 1460/1795] train lossD: -0.091186 lossG: 0.456163\n",
      "[9: 1465/1795] train lossD: -0.070831 lossG: 0.451575\n",
      "[9: 1470/1795] train lossD: -0.111851 lossG: 0.313059\n",
      "[9: 1475/1795] train lossD: -0.067224 lossG: 0.475369\n",
      "[9: 1480/1795] train lossD: -0.152483 lossG: 0.429812\n",
      "[9: 1485/1795] train lossD: -0.119198 lossG: 0.426594\n",
      "[9: 1490/1795] train lossD: -0.146062 lossG: 0.518404\n",
      "[9: 1495/1795] train lossD: -0.096952 lossG: 0.379044\n",
      "[9: 1500/1795] train lossD: -0.087335 lossG: 0.384673\n",
      "[9: 1505/1795] train lossD: -0.114052 lossG: 0.542326\n",
      "[9: 1510/1795] train lossD: -0.042012 lossG: 0.551122\n",
      "[9: 1515/1795] train lossD: -0.100900 lossG: 0.576781\n",
      "[9: 1520/1795] train lossD: -0.134055 lossG: 0.486791\n",
      "[9: 1525/1795] train lossD: -0.123353 lossG: 0.313468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9: 1530/1795] train lossD: -0.140272 lossG: 0.388541\n",
      "[9: 1535/1795] train lossD: -0.116678 lossG: 0.388369\n",
      "[9: 1540/1795] train lossD: -0.120399 lossG: 0.378081\n",
      "[9: 1545/1795] train lossD: -0.067140 lossG: 0.381828\n",
      "[9: 1550/1795] train lossD: -0.157470 lossG: 0.438708\n",
      "[9: 1555/1795] train lossD: -0.099311 lossG: 0.493056\n",
      "[9: 1560/1795] train lossD: -0.101333 lossG: 0.554694\n",
      "[9: 1565/1795] train lossD: -0.115653 lossG: 0.301276\n",
      "[9: 1570/1795] train lossD: -0.082935 lossG: 0.271216\n",
      "[9: 1575/1795] train lossD: -0.130541 lossG: 0.384585\n",
      "[9: 1580/1795] train lossD: -0.125265 lossG: 0.425875\n",
      "[9: 1585/1795] train lossD: -0.001106 lossG: 0.369829\n",
      "[9: 1590/1795] train lossD: -0.065838 lossG: 0.371137\n",
      "[9: 1595/1795] train lossD: -0.133947 lossG: 0.427055\n",
      "[9: 1600/1795] train lossD: -0.121384 lossG: 0.515521\n",
      "[9: 1605/1795] train lossD: -0.153843 lossG: 0.488338\n",
      "[9: 1610/1795] train lossD: -0.081874 lossG: 0.559852\n",
      "[9: 1615/1795] train lossD: -0.102384 lossG: 0.519609\n",
      "[9: 1620/1795] train lossD: -0.051903 lossG: 0.506393\n",
      "[9: 1625/1795] train lossD: -0.066631 lossG: 0.459517\n",
      "[9: 1630/1795] train lossD: -0.130672 lossG: 0.458529\n",
      "[9: 1635/1795] train lossD: -0.082876 lossG: 0.394899\n",
      "[9: 1640/1795] train lossD: -0.018656 lossG: 0.474238\n",
      "[9: 1645/1795] train lossD: -0.079149 lossG: 0.393873\n",
      "[9: 1650/1795] train lossD: -0.114879 lossG: 0.389067\n",
      "[9: 1655/1795] train lossD: -0.119487 lossG: 0.367027\n",
      "[9: 1660/1795] train lossD: -0.058691 lossG: 0.549363\n",
      "[9: 1665/1795] train lossD: -0.164835 lossG: 0.518811\n",
      "[9: 1670/1795] train lossD: -0.120947 lossG: 0.472080\n",
      "[9: 1675/1795] train lossD: -0.086470 lossG: 0.615943\n",
      "[9: 1680/1795] train lossD: -0.107756 lossG: 0.449045\n",
      "[9: 1685/1795] train lossD: 0.073113 lossG: 0.576935\n",
      "[9: 1690/1795] train lossD: -0.067739 lossG: 0.558334\n",
      "[9: 1695/1795] train lossD: -0.148813 lossG: 0.568034\n",
      "[9: 1700/1795] train lossD: -0.049132 lossG: 0.465001\n",
      "[9: 1705/1795] train lossD: -0.145256 lossG: 0.464240\n",
      "[9: 1710/1795] train lossD: -0.088499 lossG: 0.476052\n",
      "[9: 1715/1795] train lossD: -0.103670 lossG: 0.533790\n",
      "[9: 1720/1795] train lossD: -0.177590 lossG: 0.535102\n",
      "[9: 1725/1795] train lossD: -0.111157 lossG: 0.437807\n",
      "[9: 1730/1795] train lossD: -0.124696 lossG: 0.378388\n",
      "[9: 1735/1795] train lossD: -0.145843 lossG: 0.569683\n",
      "[9: 1740/1795] train lossD: -0.098619 lossG: 0.434099\n",
      "[9: 1745/1795] train lossD: -0.114575 lossG: 0.542076\n",
      "[9: 1750/1795] train lossD: -0.101668 lossG: 0.398817\n",
      "[9: 1755/1795] train lossD: -0.082747 lossG: 0.536638\n",
      "[9: 1760/1795] train lossD: -0.101729 lossG: 0.588394\n",
      "[9: 1765/1795] train lossD: -0.099382 lossG: 0.589330\n",
      "[9: 1770/1795] train lossD: -0.022298 lossG: 0.455043\n",
      "[9: 1775/1795] train lossD: -0.106434 lossG: 0.407282\n",
      "[9: 1780/1795] train lossD: -0.123005 lossG: 0.461802\n",
      "[9: 1785/1795] train lossD: -0.031080 lossG: 0.407905\n",
      "[9: 1790/1795] train lossD: -0.071725 lossG: 0.508498\n",
      "0.03710556402802467\n",
      "[10: 0/1795] train lossD: -0.103272 lossG: 0.491682\n",
      "[10: 5/1795] train lossD: -0.130752 lossG: 0.535063\n",
      "[10: 10/1795] train lossD: -0.080166 lossG: 0.400805\n",
      "[10: 15/1795] train lossD: -0.048630 lossG: 0.409742\n",
      "[10: 20/1795] train lossD: -0.110396 lossG: 0.447985\n",
      "[10: 25/1795] train lossD: -0.064032 lossG: 0.401075\n",
      "[10: 30/1795] train lossD: -0.025533 lossG: 0.459270\n",
      "[10: 35/1795] train lossD: -0.092431 lossG: 0.505334\n",
      "[10: 40/1795] train lossD: -0.127812 lossG: 0.575490\n",
      "[10: 45/1795] train lossD: -0.074486 lossG: 0.489497\n",
      "[10: 50/1795] train lossD: -0.136336 lossG: 0.414548\n",
      "[10: 55/1795] train lossD: -0.098457 lossG: 0.575745\n",
      "[10: 60/1795] train lossD: -0.091855 lossG: 0.406343\n",
      "[10: 65/1795] train lossD: -0.096187 lossG: 0.384749\n",
      "[10: 70/1795] train lossD: -0.102413 lossG: 0.388162\n",
      "[10: 75/1795] train lossD: -0.095078 lossG: 0.371842\n",
      "[10: 80/1795] train lossD: 0.074182 lossG: 0.405797\n",
      "[10: 85/1795] train lossD: -0.096948 lossG: 0.506024\n",
      "[10: 90/1795] train lossD: -0.086351 lossG: 0.516601\n",
      "[10: 95/1795] train lossD: -0.122752 lossG: 0.569327\n",
      "[10: 100/1795] train lossD: -0.047112 lossG: 0.517011\n",
      "[10: 105/1795] train lossD: -0.097910 lossG: 0.448595\n",
      "[10: 110/1795] train lossD: -0.073551 lossG: 0.454933\n",
      "[10: 115/1795] train lossD: -0.150354 lossG: 0.525291\n",
      "[10: 120/1795] train lossD: -0.111463 lossG: 0.487284\n",
      "[10: 125/1795] train lossD: -0.093304 lossG: 0.347413\n",
      "[10: 130/1795] train lossD: -0.066826 lossG: 0.357297\n",
      "[10: 135/1795] train lossD: -0.076867 lossG: 0.391514\n",
      "[10: 140/1795] train lossD: -0.075274 lossG: 0.422122\n",
      "[10: 145/1795] train lossD: -0.005884 lossG: 0.353953\n",
      "[10: 150/1795] train lossD: -0.081003 lossG: 0.512896\n",
      "[10: 155/1795] train lossD: -0.140316 lossG: 0.489912\n",
      "[10: 160/1795] train lossD: -0.144626 lossG: 0.457674\n",
      "[10: 165/1795] train lossD: -0.123375 lossG: 0.465822\n",
      "[10: 170/1795] train lossD: -0.118972 lossG: 0.522594\n",
      "[10: 175/1795] train lossD: 0.002919 lossG: 0.482727\n",
      "[10: 180/1795] train lossD: -0.065644 lossG: 0.466687\n",
      "[10: 185/1795] train lossD: -0.093124 lossG: 0.550326\n",
      "[10: 190/1795] train lossD: -0.120849 lossG: 0.518946\n",
      "[10: 195/1795] train lossD: -0.118155 lossG: 0.436959\n",
      "[10: 200/1795] train lossD: -0.089982 lossG: 0.561331\n",
      "[10: 205/1795] train lossD: -0.143391 lossG: 0.478431\n",
      "[10: 210/1795] train lossD: -0.069698 lossG: 0.412843\n",
      "[10: 215/1795] train lossD: -0.157779 lossG: 0.410063\n",
      "[10: 220/1795] train lossD: -0.086246 lossG: 0.289450\n",
      "[10: 225/1795] train lossD: -0.126480 lossG: 0.452778\n",
      "[10: 230/1795] train lossD: -0.082341 lossG: 0.405730\n",
      "[10: 235/1795] train lossD: -0.086706 lossG: 0.497619\n",
      "[10: 240/1795] train lossD: -0.045609 lossG: 0.433907\n",
      "[10: 245/1795] train lossD: -0.130781 lossG: 0.533032\n",
      "[10: 250/1795] train lossD: -0.103600 lossG: 0.460166\n",
      "[10: 255/1795] train lossD: -0.089125 lossG: 0.461828\n",
      "[10: 260/1795] train lossD: -0.183716 lossG: 0.499902\n",
      "[10: 265/1795] train lossD: -0.083650 lossG: 0.474905\n",
      "[10: 270/1795] train lossD: -0.117423 lossG: 0.465431\n",
      "[10: 275/1795] train lossD: -0.057727 lossG: 0.564288\n",
      "[10: 280/1795] train lossD: -0.129293 lossG: 0.539864\n",
      "[10: 285/1795] train lossD: -0.137828 lossG: 0.530800\n",
      "[10: 290/1795] train lossD: -0.103595 lossG: 0.492780\n",
      "[10: 295/1795] train lossD: -0.071766 lossG: 0.426702\n",
      "[10: 300/1795] train lossD: -0.093216 lossG: 0.520771\n",
      "[10: 305/1795] train lossD: -0.027810 lossG: 0.371975\n",
      "[10: 310/1795] train lossD: -0.114251 lossG: 0.455048\n",
      "[10: 315/1795] train lossD: -0.133915 lossG: 0.314560\n",
      "[10: 320/1795] train lossD: -0.104813 lossG: 0.440147\n",
      "[10: 325/1795] train lossD: -0.076085 lossG: 0.413348\n",
      "[10: 330/1795] train lossD: -0.115060 lossG: 0.407229\n",
      "[10: 335/1795] train lossD: -0.098898 lossG: 0.482607\n",
      "[10: 340/1795] train lossD: -0.118781 lossG: 0.332967\n",
      "[10: 345/1795] train lossD: -0.036795 lossG: 0.401532\n",
      "[10: 350/1795] train lossD: -0.145727 lossG: 0.468241\n",
      "[10: 355/1795] train lossD: -0.154820 lossG: 0.419110\n",
      "[10: 360/1795] train lossD: -0.083669 lossG: 0.478962\n",
      "[10: 365/1795] train lossD: -0.078318 lossG: 0.456602\n",
      "[10: 370/1795] train lossD: -0.150248 lossG: 0.520579\n",
      "[10: 375/1795] train lossD: -0.128503 lossG: 0.390839\n",
      "[10: 380/1795] train lossD: -0.084760 lossG: 0.518789\n",
      "[10: 385/1795] train lossD: -0.103740 lossG: 0.419185\n",
      "[10: 390/1795] train lossD: -0.059612 lossG: 0.537652\n",
      "[10: 395/1795] train lossD: -0.058585 lossG: 0.428077\n",
      "[10: 400/1795] train lossD: -0.122074 lossG: 0.435596\n",
      "[10: 405/1795] train lossD: -0.114603 lossG: 0.365601\n",
      "[10: 410/1795] train lossD: -0.091743 lossG: 0.435503\n",
      "[10: 415/1795] train lossD: -0.037572 lossG: 0.418359\n",
      "[10: 420/1795] train lossD: -0.162719 lossG: 0.443563\n",
      "[10: 425/1795] train lossD: -0.081124 lossG: 0.410566\n",
      "[10: 430/1795] train lossD: -0.095710 lossG: 0.433137\n",
      "[10: 435/1795] train lossD: -0.082122 lossG: 0.448963\n",
      "[10: 440/1795] train lossD: -0.121801 lossG: 0.394833\n",
      "[10: 445/1795] train lossD: -0.111509 lossG: 0.550178\n",
      "[10: 450/1795] train lossD: -0.079481 lossG: 0.449464\n",
      "[10: 455/1795] train lossD: -0.121848 lossG: 0.467670\n",
      "[10: 460/1795] train lossD: -0.101580 lossG: 0.347281\n",
      "[10: 465/1795] train lossD: -0.113821 lossG: 0.419305\n",
      "[10: 470/1795] train lossD: -0.097941 lossG: 0.425287\n",
      "[10: 475/1795] train lossD: -0.076524 lossG: 0.397376\n",
      "[10: 480/1795] train lossD: -0.062355 lossG: 0.370425\n",
      "[10: 485/1795] train lossD: 0.000275 lossG: 0.295756\n",
      "[10: 490/1795] train lossD: -0.071002 lossG: 0.316311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10: 495/1795] train lossD: -0.085266 lossG: 0.353870\n",
      "[10: 500/1795] train lossD: -0.092402 lossG: 0.412852\n",
      "[10: 505/1795] train lossD: -0.094117 lossG: 0.330767\n",
      "[10: 510/1795] train lossD: -0.031576 lossG: 0.589769\n",
      "[10: 515/1795] train lossD: -0.179799 lossG: 0.497749\n",
      "[10: 520/1795] train lossD: -0.112469 lossG: 0.450848\n",
      "[10: 525/1795] train lossD: -0.085773 lossG: 0.484599\n",
      "[10: 530/1795] train lossD: -0.074465 lossG: 0.437073\n",
      "[10: 535/1795] train lossD: -0.045909 lossG: 0.457059\n",
      "[10: 540/1795] train lossD: -0.131998 lossG: 0.497779\n",
      "[10: 545/1795] train lossD: -0.040948 lossG: 0.416331\n",
      "[10: 550/1795] train lossD: -0.052712 lossG: 0.411970\n",
      "[10: 555/1795] train lossD: -0.119927 lossG: 0.434322\n",
      "[10: 560/1795] train lossD: -0.106885 lossG: 0.417717\n",
      "[10: 565/1795] train lossD: -0.075426 lossG: 0.545161\n",
      "[10: 570/1795] train lossD: -0.088756 lossG: 0.524667\n",
      "[10: 575/1795] train lossD: -0.093357 lossG: 0.427287\n",
      "[10: 580/1795] train lossD: -0.105714 lossG: 0.451916\n",
      "[10: 585/1795] train lossD: -0.082716 lossG: 0.396506\n",
      "[10: 590/1795] train lossD: -0.122587 lossG: 0.559307\n",
      "[10: 595/1795] train lossD: -0.032307 lossG: 0.546832\n",
      "[10: 600/1795] train lossD: -0.096881 lossG: 0.458001\n",
      "[10: 605/1795] train lossD: -0.045431 lossG: 0.315816\n",
      "[10: 610/1795] train lossD: -0.085322 lossG: 0.459599\n",
      "[10: 615/1795] train lossD: -0.098553 lossG: 0.415679\n",
      "[10: 620/1795] train lossD: -0.114334 lossG: 0.389283\n",
      "[10: 625/1795] train lossD: -0.109432 lossG: 0.394992\n",
      "[10: 630/1795] train lossD: -0.109055 lossG: 0.458630\n",
      "[10: 635/1795] train lossD: -0.119213 lossG: 0.458991\n",
      "[10: 640/1795] train lossD: -0.100257 lossG: 0.454204\n",
      "[10: 645/1795] train lossD: -0.145873 lossG: 0.441402\n",
      "[10: 650/1795] train lossD: -0.066213 lossG: 0.463231\n",
      "[10: 655/1795] train lossD: -0.084773 lossG: 0.486798\n",
      "[10: 660/1795] train lossD: -0.136266 lossG: 0.412536\n",
      "[10: 665/1795] train lossD: -0.108758 lossG: 0.471700\n",
      "[10: 670/1795] train lossD: -0.110362 lossG: 0.399473\n",
      "[10: 675/1795] train lossD: -0.127514 lossG: 0.370420\n",
      "[10: 680/1795] train lossD: -0.072935 lossG: 0.414969\n",
      "[10: 685/1795] train lossD: -0.065671 lossG: 0.428157\n",
      "[10: 690/1795] train lossD: -0.061992 lossG: 0.422927\n",
      "[10: 695/1795] train lossD: 0.008670 lossG: 0.564718\n",
      "[10: 700/1795] train lossD: -0.103526 lossG: 0.375038\n",
      "[10: 705/1795] train lossD: -0.121580 lossG: 0.520562\n",
      "[10: 710/1795] train lossD: -0.107380 lossG: 0.435869\n",
      "[10: 715/1795] train lossD: -0.091276 lossG: 0.449885\n",
      "[10: 720/1795] train lossD: -0.152704 lossG: 0.513018\n",
      "[10: 725/1795] train lossD: 0.020993 lossG: 0.459760\n",
      "[10: 730/1795] train lossD: -0.092560 lossG: 0.414793\n",
      "[10: 735/1795] train lossD: -0.102577 lossG: 0.477581\n",
      "[10: 740/1795] train lossD: -0.111894 lossG: 0.432462\n",
      "[10: 745/1795] train lossD: -0.116024 lossG: 0.441513\n",
      "[10: 750/1795] train lossD: -0.083909 lossG: 0.389300\n",
      "[10: 755/1795] train lossD: -0.143878 lossG: 0.444256\n",
      "[10: 760/1795] train lossD: -0.163250 lossG: 0.471578\n",
      "[10: 765/1795] train lossD: -0.094096 lossG: 0.480101\n",
      "[10: 770/1795] train lossD: -0.140873 lossG: 0.424446\n",
      "[10: 775/1795] train lossD: -0.151660 lossG: 0.514374\n",
      "[10: 780/1795] train lossD: -0.147095 lossG: 0.412071\n",
      "[10: 785/1795] train lossD: -0.080355 lossG: 0.537978\n",
      "[10: 790/1795] train lossD: -0.053794 lossG: 0.485543\n",
      "[10: 795/1795] train lossD: -0.113095 lossG: 0.606046\n",
      "[10: 800/1795] train lossD: -0.137866 lossG: 0.506338\n",
      "[10: 805/1795] train lossD: -0.075631 lossG: 0.360505\n",
      "[10: 810/1795] train lossD: -0.083997 lossG: 0.476808\n",
      "[10: 815/1795] train lossD: 0.015011 lossG: 0.420783\n",
      "[10: 820/1795] train lossD: -0.110434 lossG: 0.463831\n",
      "[10: 825/1795] train lossD: -0.057741 lossG: 0.599374\n",
      "[10: 830/1795] train lossD: -0.012460 lossG: 0.561850\n",
      "[10: 835/1795] train lossD: -0.066675 lossG: 0.386641\n",
      "[10: 840/1795] train lossD: -0.006819 lossG: 0.457670\n",
      "[10: 845/1795] train lossD: -0.125266 lossG: 0.440761\n",
      "[10: 850/1795] train lossD: -0.116066 lossG: 0.377791\n",
      "[10: 855/1795] train lossD: -0.001593 lossG: 0.496681\n",
      "[10: 860/1795] train lossD: -0.124732 lossG: 0.506615\n",
      "[10: 865/1795] train lossD: -0.088095 lossG: 0.496618\n",
      "[10: 870/1795] train lossD: -0.086978 lossG: 0.480552\n",
      "[10: 875/1795] train lossD: -0.048743 lossG: 0.484498\n",
      "[10: 880/1795] train lossD: -0.104317 lossG: 0.415515\n",
      "[10: 885/1795] train lossD: -0.088519 lossG: 0.425029\n",
      "[10: 890/1795] train lossD: -0.102004 lossG: 0.509144\n",
      "[10: 895/1795] train lossD: -0.110463 lossG: 0.493795\n",
      "[10: 900/1795] train lossD: -0.202290 lossG: 0.403626\n",
      "[10: 905/1795] train lossD: -0.122181 lossG: 0.578073\n",
      "[10: 910/1795] train lossD: -0.061369 lossG: 0.439881\n",
      "[10: 915/1795] train lossD: -0.141201 lossG: 0.446611\n",
      "[10: 920/1795] train lossD: -0.125146 lossG: 0.559310\n",
      "[10: 925/1795] train lossD: -0.140195 lossG: 0.390638\n",
      "[10: 930/1795] train lossD: -0.090691 lossG: 0.398118\n",
      "[10: 935/1795] train lossD: -0.041725 lossG: 0.446918\n",
      "[10: 940/1795] train lossD: -0.109792 lossG: 0.397995\n",
      "[10: 945/1795] train lossD: -0.099071 lossG: 0.465288\n",
      "[10: 950/1795] train lossD: -0.170665 lossG: 0.341170\n",
      "[10: 955/1795] train lossD: -0.092897 lossG: 0.462016\n",
      "[10: 960/1795] train lossD: -0.141548 lossG: 0.630142\n",
      "[10: 965/1795] train lossD: -0.014204 lossG: 0.613729\n",
      "[10: 970/1795] train lossD: -0.126493 lossG: 0.498278\n",
      "[10: 975/1795] train lossD: -0.053860 lossG: 0.496742\n",
      "[10: 980/1795] train lossD: -0.120690 lossG: 0.493737\n",
      "[10: 985/1795] train lossD: -0.073319 lossG: 0.460488\n",
      "[10: 990/1795] train lossD: -0.126714 lossG: 0.314511\n",
      "[10: 995/1795] train lossD: -0.070433 lossG: 0.386871\n",
      "[10: 1000/1795] train lossD: -0.134877 lossG: 0.449345\n",
      "[10: 1005/1795] train lossD: -0.090119 lossG: 0.466643\n",
      "[10: 1010/1795] train lossD: -0.102004 lossG: 0.449851\n",
      "[10: 1015/1795] train lossD: -0.017801 lossG: 0.300251\n",
      "[10: 1020/1795] train lossD: -0.067928 lossG: 0.371641\n",
      "[10: 1025/1795] train lossD: -0.082953 lossG: 0.386702\n",
      "[10: 1030/1795] train lossD: -0.105499 lossG: 0.423244\n",
      "[10: 1035/1795] train lossD: -0.121599 lossG: 0.398968\n",
      "[10: 1040/1795] train lossD: -0.092944 lossG: 0.490202\n",
      "[10: 1045/1795] train lossD: -0.123633 lossG: 0.518632\n",
      "[10: 1050/1795] train lossD: -0.091173 lossG: 0.460014\n",
      "[10: 1055/1795] train lossD: -0.142040 lossG: 0.397408\n",
      "[10: 1060/1795] train lossD: -0.039273 lossG: 0.500806\n",
      "[10: 1065/1795] train lossD: -0.087929 lossG: 0.408581\n",
      "[10: 1070/1795] train lossD: -0.047945 lossG: 0.420663\n",
      "[10: 1075/1795] train lossD: -0.052696 lossG: 0.452374\n",
      "[10: 1080/1795] train lossD: -0.142871 lossG: 0.492349\n",
      "[10: 1085/1795] train lossD: 0.215961 lossG: 0.369964\n",
      "[10: 1090/1795] train lossD: -0.082235 lossG: 0.549180\n",
      "[10: 1095/1795] train lossD: -0.131954 lossG: 0.451237\n",
      "[10: 1100/1795] train lossD: -0.093920 lossG: 0.473743\n",
      "[10: 1105/1795] train lossD: -0.099610 lossG: 0.466315\n",
      "[10: 1110/1795] train lossD: -0.139592 lossG: 0.413226\n",
      "[10: 1115/1795] train lossD: -0.057312 lossG: 0.435624\n",
      "[10: 1120/1795] train lossD: -0.096600 lossG: 0.497323\n",
      "[10: 1125/1795] train lossD: -0.105194 lossG: 0.391242\n",
      "[10: 1130/1795] train lossD: -0.091249 lossG: 0.444653\n",
      "[10: 1135/1795] train lossD: -0.080838 lossG: 0.495909\n",
      "[10: 1140/1795] train lossD: -0.087207 lossG: 0.488160\n",
      "[10: 1145/1795] train lossD: -0.086818 lossG: 0.319326\n",
      "[10: 1150/1795] train lossD: -0.094841 lossG: 0.426200\n",
      "[10: 1155/1795] train lossD: -0.115249 lossG: 0.349387\n",
      "[10: 1160/1795] train lossD: -0.142907 lossG: 0.424621\n",
      "[10: 1165/1795] train lossD: -0.117830 lossG: 0.368867\n",
      "[10: 1170/1795] train lossD: -0.066704 lossG: 0.470717\n",
      "[10: 1175/1795] train lossD: -0.108834 lossG: 0.293806\n",
      "[10: 1180/1795] train lossD: -0.130832 lossG: 0.559266\n",
      "[10: 1185/1795] train lossD: -0.076656 lossG: 0.499734\n",
      "[10: 1190/1795] train lossD: -0.119731 lossG: 0.457146\n",
      "[10: 1195/1795] train lossD: -0.130171 lossG: 0.486596\n",
      "[10: 1200/1795] train lossD: -0.146407 lossG: 0.432369\n",
      "[10: 1205/1795] train lossD: -0.111834 lossG: 0.434423\n",
      "[10: 1210/1795] train lossD: -0.136885 lossG: 0.539317\n",
      "[10: 1215/1795] train lossD: -0.087016 lossG: 0.351767\n",
      "[10: 1220/1795] train lossD: -0.090370 lossG: 0.427075\n",
      "[10: 1225/1795] train lossD: -0.085454 lossG: 0.456367\n",
      "[10: 1230/1795] train lossD: -0.032605 lossG: 0.435001\n",
      "[10: 1235/1795] train lossD: -0.100176 lossG: 0.421249\n",
      "[10: 1240/1795] train lossD: -0.041137 lossG: 0.396354\n",
      "[10: 1245/1795] train lossD: -0.096688 lossG: 0.406642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10: 1250/1795] train lossD: -0.120666 lossG: 0.392874\n",
      "[10: 1255/1795] train lossD: -0.127926 lossG: 0.394198\n",
      "[10: 1260/1795] train lossD: -0.083434 lossG: 0.577127\n",
      "[10: 1265/1795] train lossD: -0.012665 lossG: 0.426301\n",
      "[10: 1270/1795] train lossD: -0.062744 lossG: 0.405432\n",
      "[10: 1275/1795] train lossD: -0.143774 lossG: 0.408187\n",
      "[10: 1280/1795] train lossD: -0.113255 lossG: 0.411698\n",
      "[10: 1285/1795] train lossD: -0.092346 lossG: 0.513083\n",
      "[10: 1290/1795] train lossD: -0.136102 lossG: 0.465879\n",
      "[10: 1295/1795] train lossD: -0.055872 lossG: 0.496032\n",
      "[10: 1300/1795] train lossD: -0.132197 lossG: 0.499754\n",
      "[10: 1305/1795] train lossD: -0.062757 lossG: 0.456773\n",
      "[10: 1310/1795] train lossD: -0.118839 lossG: 0.507543\n",
      "[10: 1315/1795] train lossD: -0.033570 lossG: 0.383659\n",
      "[10: 1320/1795] train lossD: -0.072219 lossG: 0.311132\n",
      "[10: 1325/1795] train lossD: -0.103632 lossG: 0.475551\n",
      "[10: 1330/1795] train lossD: -0.130350 lossG: 0.493490\n",
      "[10: 1335/1795] train lossD: -0.127221 lossG: 0.583043\n",
      "[10: 1340/1795] train lossD: -0.003100 lossG: 0.342801\n",
      "[10: 1345/1795] train lossD: -0.098135 lossG: 0.363511\n",
      "[10: 1350/1795] train lossD: -0.145886 lossG: 0.353278\n",
      "[10: 1355/1795] train lossD: -0.095860 lossG: 0.467869\n",
      "[10: 1360/1795] train lossD: -0.118223 lossG: 0.509022\n",
      "[10: 1365/1795] train lossD: -0.082386 lossG: 0.427454\n",
      "[10: 1370/1795] train lossD: -0.084475 lossG: 0.501958\n",
      "[10: 1375/1795] train lossD: -0.092911 lossG: 0.317493\n",
      "[10: 1380/1795] train lossD: -0.097743 lossG: 0.338223\n",
      "[10: 1385/1795] train lossD: -0.080913 lossG: 0.216776\n",
      "[10: 1390/1795] train lossD: -0.106937 lossG: 0.390799\n",
      "[10: 1395/1795] train lossD: -0.000431 lossG: 0.282745\n",
      "[10: 1400/1795] train lossD: -0.078977 lossG: 0.397945\n",
      "[10: 1405/1795] train lossD: -0.135975 lossG: 0.401660\n",
      "[10: 1410/1795] train lossD: -0.092409 lossG: 0.366101\n",
      "[10: 1415/1795] train lossD: -0.062993 lossG: 0.390372\n",
      "[10: 1420/1795] train lossD: -0.098851 lossG: 0.367509\n",
      "[10: 1425/1795] train lossD: -0.025680 lossG: 0.341948\n",
      "[10: 1430/1795] train lossD: -0.071005 lossG: 0.298279\n",
      "[10: 1435/1795] train lossD: -0.138058 lossG: 0.309590\n",
      "[10: 1440/1795] train lossD: -0.032899 lossG: 0.490151\n",
      "[10: 1445/1795] train lossD: -0.119825 lossG: 0.362202\n",
      "[10: 1450/1795] train lossD: -0.101179 lossG: 0.318427\n",
      "[10: 1455/1795] train lossD: -0.013248 lossG: 0.339156\n",
      "[10: 1460/1795] train lossD: -0.155635 lossG: 0.469851\n",
      "[10: 1465/1795] train lossD: -0.139746 lossG: 0.471089\n",
      "[10: 1470/1795] train lossD: -0.130550 lossG: 0.429850\n",
      "[10: 1475/1795] train lossD: -0.147097 lossG: 0.355575\n",
      "[10: 1480/1795] train lossD: -0.025157 lossG: 0.559854\n",
      "[10: 1485/1795] train lossD: -0.044346 lossG: 0.483460\n",
      "[10: 1490/1795] train lossD: -0.125610 lossG: 0.468133\n",
      "[10: 1495/1795] train lossD: -0.096488 lossG: 0.472524\n",
      "[10: 1500/1795] train lossD: -0.128730 lossG: 0.434710\n",
      "[10: 1505/1795] train lossD: -0.108394 lossG: 0.515195\n",
      "[10: 1510/1795] train lossD: -0.121866 lossG: 0.593316\n",
      "[10: 1515/1795] train lossD: -0.049130 lossG: 0.394818\n",
      "[10: 1520/1795] train lossD: -0.137128 lossG: 0.557728\n",
      "[10: 1525/1795] train lossD: -0.119349 lossG: 0.385302\n",
      "[10: 1530/1795] train lossD: -0.111561 lossG: 0.488025\n",
      "[10: 1535/1795] train lossD: -0.087773 lossG: 0.359004\n",
      "[10: 1540/1795] train lossD: -0.094470 lossG: 0.395840\n",
      "[10: 1545/1795] train lossD: -0.096067 lossG: 0.372273\n",
      "[10: 1550/1795] train lossD: -0.073743 lossG: 0.374995\n",
      "[10: 1555/1795] train lossD: -0.087922 lossG: 0.324812\n",
      "[10: 1560/1795] train lossD: 0.047114 lossG: 0.321092\n",
      "[10: 1565/1795] train lossD: 0.039244 lossG: 0.460018\n",
      "[10: 1570/1795] train lossD: -0.136254 lossG: 0.509115\n",
      "[10: 1575/1795] train lossD: -0.139214 lossG: 0.442973\n",
      "[10: 1580/1795] train lossD: -0.113458 lossG: 0.398829\n",
      "[10: 1585/1795] train lossD: -0.088142 lossG: 0.382145\n",
      "[10: 1590/1795] train lossD: 0.033669 lossG: 0.705598\n",
      "[10: 1595/1795] train lossD: -0.145024 lossG: 0.499510\n",
      "[10: 1600/1795] train lossD: -0.130320 lossG: 0.405496\n",
      "[10: 1605/1795] train lossD: -0.102172 lossG: 0.516096\n",
      "[10: 1610/1795] train lossD: -0.173681 lossG: 0.456100\n",
      "[10: 1615/1795] train lossD: -0.130675 lossG: 0.454682\n",
      "[10: 1620/1795] train lossD: -0.085058 lossG: 0.337796\n",
      "[10: 1625/1795] train lossD: -0.095598 lossG: 0.457884\n",
      "[10: 1630/1795] train lossD: -0.076805 lossG: 0.335275\n",
      "[10: 1635/1795] train lossD: -0.096211 lossG: 0.426179\n",
      "[10: 1640/1795] train lossD: -0.130056 lossG: 0.500347\n",
      "[10: 1645/1795] train lossD: -0.085256 lossG: 0.391669\n",
      "[10: 1650/1795] train lossD: -0.046474 lossG: 0.364806\n",
      "[10: 1655/1795] train lossD: -0.109479 lossG: 0.379843\n",
      "[10: 1660/1795] train lossD: -0.092579 lossG: 0.527823\n",
      "[10: 1665/1795] train lossD: -0.155373 lossG: 0.487510\n",
      "[10: 1670/1795] train lossD: -0.133466 lossG: 0.451164\n",
      "[10: 1675/1795] train lossD: -0.039428 lossG: 0.452352\n",
      "[10: 1680/1795] train lossD: -0.169428 lossG: 0.351962\n",
      "[10: 1685/1795] train lossD: -0.114429 lossG: 0.420094\n",
      "[10: 1690/1795] train lossD: -0.113709 lossG: 0.398216\n",
      "[10: 1695/1795] train lossD: -0.061779 lossG: 0.520118\n",
      "[10: 1700/1795] train lossD: -0.105953 lossG: 0.501885\n",
      "[10: 1705/1795] train lossD: -0.141520 lossG: 0.401792\n",
      "[10: 1710/1795] train lossD: -0.084576 lossG: 0.527313\n",
      "[10: 1715/1795] train lossD: -0.101582 lossG: 0.362031\n",
      "[10: 1720/1795] train lossD: -0.130700 lossG: 0.452828\n",
      "[10: 1725/1795] train lossD: -0.114441 lossG: 0.483837\n",
      "[10: 1730/1795] train lossD: -0.120270 lossG: 0.385729\n",
      "[10: 1735/1795] train lossD: -0.066777 lossG: 0.542267\n",
      "[10: 1740/1795] train lossD: -0.127838 lossG: 0.391658\n",
      "[10: 1745/1795] train lossD: -0.115850 lossG: 0.508646\n",
      "[10: 1750/1795] train lossD: -0.079886 lossG: 0.389122\n",
      "[10: 1755/1795] train lossD: -0.125379 lossG: 0.412098\n",
      "[10: 1760/1795] train lossD: -0.092374 lossG: 0.419424\n",
      "[10: 1765/1795] train lossD: -0.098411 lossG: 0.400343\n",
      "[10: 1770/1795] train lossD: -0.115034 lossG: 0.389656\n",
      "[10: 1775/1795] train lossD: -0.129446 lossG: 0.370882\n",
      "[10: 1780/1795] train lossD: -0.048570 lossG: 0.437137\n",
      "[10: 1785/1795] train lossD: -0.011563 lossG: 0.377056\n",
      "[10: 1790/1795] train lossD: -0.100932 lossG: 0.353499\n",
      "0.05840221047401428\n",
      "[11: 0/1795] train lossD: -0.184159 lossG: 0.369793\n",
      "[11: 5/1795] train lossD: -0.131493 lossG: 0.337795\n",
      "[11: 10/1795] train lossD: -0.084041 lossG: 0.377027\n",
      "[11: 15/1795] train lossD: -0.084078 lossG: 0.367439\n",
      "[11: 20/1795] train lossD: -0.096675 lossG: 0.452605\n",
      "[11: 25/1795] train lossD: -0.100119 lossG: 0.384413\n",
      "[11: 30/1795] train lossD: -0.055099 lossG: 0.549635\n",
      "[11: 35/1795] train lossD: -0.081052 lossG: 0.418390\n",
      "[11: 40/1795] train lossD: -0.094492 lossG: 0.465348\n",
      "[11: 45/1795] train lossD: -0.094300 lossG: 0.388369\n",
      "[11: 50/1795] train lossD: -0.125479 lossG: 0.304194\n",
      "[11: 55/1795] train lossD: 0.317052 lossG: 0.479534\n",
      "[11: 60/1795] train lossD: -0.074205 lossG: 0.463626\n",
      "[11: 65/1795] train lossD: -0.081526 lossG: 0.451236\n",
      "[11: 70/1795] train lossD: -0.074429 lossG: 0.457775\n",
      "[11: 75/1795] train lossD: -0.086534 lossG: 0.511479\n",
      "[11: 80/1795] train lossD: -0.139423 lossG: 0.467147\n",
      "[11: 85/1795] train lossD: -0.068208 lossG: 0.444649\n",
      "[11: 90/1795] train lossD: -0.023421 lossG: 0.380241\n",
      "[11: 95/1795] train lossD: -0.059869 lossG: 0.479903\n",
      "[11: 100/1795] train lossD: -0.118190 lossG: 0.471988\n",
      "[11: 105/1795] train lossD: -0.122934 lossG: 0.497003\n",
      "[11: 110/1795] train lossD: -0.114596 lossG: 0.608660\n",
      "[11: 115/1795] train lossD: -0.049964 lossG: 0.458919\n",
      "[11: 120/1795] train lossD: -0.086071 lossG: 0.347454\n",
      "[11: 125/1795] train lossD: -0.072765 lossG: 0.549973\n",
      "[11: 130/1795] train lossD: -0.081811 lossG: 0.440139\n",
      "[11: 135/1795] train lossD: -0.051769 lossG: 0.580275\n",
      "[11: 140/1795] train lossD: -0.038171 lossG: 0.324809\n",
      "[11: 145/1795] train lossD: -0.022400 lossG: 0.294692\n",
      "[11: 150/1795] train lossD: -0.038645 lossG: 0.382423\n",
      "[11: 155/1795] train lossD: -0.035097 lossG: 0.596362\n",
      "[11: 160/1795] train lossD: -0.068497 lossG: 0.430448\n",
      "[11: 165/1795] train lossD: -0.104820 lossG: 0.512677\n",
      "[11: 170/1795] train lossD: -0.144478 lossG: 0.425242\n",
      "[11: 175/1795] train lossD: -0.098263 lossG: 0.463553\n",
      "[11: 180/1795] train lossD: -0.031744 lossG: 0.460552\n",
      "[11: 185/1795] train lossD: -0.082073 lossG: 0.418341\n",
      "[11: 190/1795] train lossD: -0.111865 lossG: 0.473537\n",
      "[11: 195/1795] train lossD: -0.108623 lossG: 0.335410\n",
      "[11: 200/1795] train lossD: -0.047446 lossG: 0.288108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11: 205/1795] train lossD: -0.083704 lossG: 0.327142\n",
      "[11: 210/1795] train lossD: 0.120907 lossG: 0.364857\n",
      "[11: 215/1795] train lossD: -0.087061 lossG: 0.400846\n",
      "[11: 220/1795] train lossD: -0.062322 lossG: 0.400443\n",
      "[11: 225/1795] train lossD: -0.087151 lossG: 0.470978\n",
      "[11: 230/1795] train lossD: -0.138245 lossG: 0.491848\n",
      "[11: 235/1795] train lossD: -0.132179 lossG: 0.544953\n",
      "[11: 240/1795] train lossD: -0.114493 lossG: 0.405099\n",
      "[11: 245/1795] train lossD: -0.132780 lossG: 0.464332\n",
      "[11: 250/1795] train lossD: -0.165592 lossG: 0.416441\n",
      "[11: 255/1795] train lossD: -0.095822 lossG: 0.413333\n",
      "[11: 260/1795] train lossD: -0.092077 lossG: 0.400455\n",
      "[11: 265/1795] train lossD: -0.119939 lossG: 0.342825\n",
      "[11: 270/1795] train lossD: -0.146175 lossG: 0.397391\n",
      "[11: 275/1795] train lossD: -0.147164 lossG: 0.442608\n",
      "[11: 280/1795] train lossD: -0.119985 lossG: 0.348694\n",
      "[11: 285/1795] train lossD: -0.022594 lossG: 0.346783\n",
      "[11: 290/1795] train lossD: -0.052384 lossG: 0.373246\n",
      "[11: 295/1795] train lossD: -0.163651 lossG: 0.425998\n",
      "[11: 300/1795] train lossD: -0.136371 lossG: 0.358615\n",
      "[11: 305/1795] train lossD: -0.097581 lossG: 0.420589\n",
      "[11: 310/1795] train lossD: -0.083519 lossG: 0.293520\n",
      "[11: 315/1795] train lossD: -0.076731 lossG: 0.356818\n",
      "[11: 320/1795] train lossD: -0.104061 lossG: 0.398367\n",
      "[11: 325/1795] train lossD: -0.138690 lossG: 0.303431\n",
      "[11: 330/1795] train lossD: -0.061218 lossG: 0.239399\n",
      "[11: 335/1795] train lossD: -0.095465 lossG: 0.327319\n",
      "[11: 340/1795] train lossD: -0.083670 lossG: 0.430700\n",
      "[11: 345/1795] train lossD: -0.116891 lossG: 0.356103\n",
      "[11: 350/1795] train lossD: -0.159974 lossG: 0.352298\n",
      "[11: 355/1795] train lossD: -0.096768 lossG: 0.365525\n",
      "[11: 360/1795] train lossD: -0.019980 lossG: 0.364575\n",
      "[11: 365/1795] train lossD: -0.143630 lossG: 0.346512\n",
      "[11: 370/1795] train lossD: -0.096793 lossG: 0.413877\n",
      "[11: 375/1795] train lossD: -0.108668 lossG: 0.300882\n",
      "[11: 380/1795] train lossD: -0.141756 lossG: 0.405951\n",
      "[11: 385/1795] train lossD: -0.122557 lossG: 0.377519\n",
      "[11: 390/1795] train lossD: -0.120959 lossG: 0.339009\n",
      "[11: 395/1795] train lossD: -0.114192 lossG: 0.420000\n",
      "[11: 400/1795] train lossD: -0.098460 lossG: 0.359790\n",
      "[11: 405/1795] train lossD: -0.111982 lossG: 0.473278\n",
      "[11: 410/1795] train lossD: -0.106304 lossG: 0.346065\n",
      "[11: 415/1795] train lossD: -0.079431 lossG: 0.446025\n",
      "[11: 420/1795] train lossD: -0.084477 lossG: 0.458067\n",
      "[11: 425/1795] train lossD: -0.024249 lossG: 0.307291\n",
      "[11: 430/1795] train lossD: -0.129514 lossG: 0.393914\n",
      "[11: 435/1795] train lossD: -0.087773 lossG: 0.428232\n",
      "[11: 440/1795] train lossD: -0.068102 lossG: 0.417978\n",
      "[11: 445/1795] train lossD: -0.132995 lossG: 0.461524\n",
      "[11: 450/1795] train lossD: -0.129104 lossG: 0.483029\n",
      "[11: 455/1795] train lossD: -0.081016 lossG: 0.431125\n",
      "[11: 460/1795] train lossD: -0.145359 lossG: 0.474048\n",
      "[11: 465/1795] train lossD: -0.125873 lossG: 0.386714\n",
      "[11: 470/1795] train lossD: -0.112048 lossG: 0.494097\n",
      "[11: 475/1795] train lossD: -0.077928 lossG: 0.444010\n",
      "[11: 480/1795] train lossD: -0.066267 lossG: 0.409259\n",
      "[11: 485/1795] train lossD: -0.074389 lossG: 0.482800\n",
      "[11: 490/1795] train lossD: -0.103523 lossG: 0.407647\n",
      "[11: 495/1795] train lossD: -0.089135 lossG: 0.513893\n",
      "[11: 500/1795] train lossD: -0.111296 lossG: 0.368491\n",
      "[11: 505/1795] train lossD: -0.089549 lossG: 0.543500\n",
      "[11: 510/1795] train lossD: -0.086938 lossG: 0.405477\n",
      "[11: 515/1795] train lossD: -0.102480 lossG: 0.401366\n",
      "[11: 520/1795] train lossD: -0.118886 lossG: 0.400860\n",
      "[11: 525/1795] train lossD: -0.081007 lossG: 0.269162\n",
      "[11: 530/1795] train lossD: -0.153577 lossG: 0.367263\n",
      "[11: 535/1795] train lossD: -0.072070 lossG: 0.505823\n",
      "[11: 540/1795] train lossD: -0.117065 lossG: 0.396537\n",
      "[11: 545/1795] train lossD: -0.075841 lossG: 0.434877\n",
      "[11: 550/1795] train lossD: -0.046907 lossG: 0.323462\n",
      "[11: 555/1795] train lossD: -0.078777 lossG: 0.319375\n",
      "[11: 560/1795] train lossD: -0.058357 lossG: 0.354026\n",
      "[11: 565/1795] train lossD: -0.132951 lossG: 0.297180\n",
      "[11: 570/1795] train lossD: -0.154408 lossG: 0.469383\n",
      "[11: 575/1795] train lossD: -0.109197 lossG: 0.308307\n",
      "[11: 580/1795] train lossD: -0.106908 lossG: 0.327768\n",
      "[11: 585/1795] train lossD: -0.181492 lossG: 0.481908\n",
      "[11: 590/1795] train lossD: -0.137434 lossG: 0.396296\n",
      "[11: 595/1795] train lossD: -0.061777 lossG: 0.470281\n",
      "[11: 600/1795] train lossD: -0.076350 lossG: 0.458674\n",
      "[11: 605/1795] train lossD: -0.137763 lossG: 0.487622\n",
      "[11: 610/1795] train lossD: -0.078737 lossG: 0.388200\n",
      "[11: 615/1795] train lossD: -0.094189 lossG: 0.419711\n",
      "[11: 620/1795] train lossD: -0.230221 lossG: 0.513044\n",
      "[11: 625/1795] train lossD: -0.071603 lossG: 0.479036\n",
      "[11: 630/1795] train lossD: -0.110868 lossG: 0.436748\n",
      "[11: 635/1795] train lossD: 0.010516 lossG: 0.467247\n",
      "[11: 640/1795] train lossD: -0.108615 lossG: 0.391747\n",
      "[11: 645/1795] train lossD: -0.187027 lossG: 0.501196\n",
      "[11: 650/1795] train lossD: -0.114319 lossG: 0.425171\n",
      "[11: 655/1795] train lossD: -0.087701 lossG: 0.391594\n",
      "[11: 660/1795] train lossD: -0.125978 lossG: 0.383337\n",
      "[11: 665/1795] train lossD: -0.031825 lossG: 0.374540\n",
      "[11: 670/1795] train lossD: -0.094319 lossG: 0.340058\n",
      "[11: 675/1795] train lossD: -0.162415 lossG: 0.333521\n",
      "[11: 680/1795] train lossD: -0.144809 lossG: 0.290164\n",
      "[11: 685/1795] train lossD: -0.108344 lossG: 0.333696\n",
      "[11: 690/1795] train lossD: -0.032981 lossG: 0.415207\n",
      "[11: 695/1795] train lossD: -0.084376 lossG: 0.518700\n",
      "[11: 700/1795] train lossD: -0.134570 lossG: 0.468320\n",
      "[11: 705/1795] train lossD: -0.114723 lossG: 0.399155\n",
      "[11: 710/1795] train lossD: -0.150593 lossG: 0.390582\n",
      "[11: 715/1795] train lossD: -0.032483 lossG: 0.387947\n",
      "[11: 720/1795] train lossD: -0.077270 lossG: 0.483948\n",
      "[11: 725/1795] train lossD: 0.011195 lossG: 0.269168\n",
      "[11: 730/1795] train lossD: -0.124664 lossG: 0.411429\n",
      "[11: 735/1795] train lossD: -0.055146 lossG: 0.307462\n",
      "[11: 740/1795] train lossD: -0.067931 lossG: 0.337018\n",
      "[11: 745/1795] train lossD: -0.053115 lossG: 0.510792\n",
      "[11: 750/1795] train lossD: -0.114753 lossG: 0.345389\n",
      "[11: 755/1795] train lossD: -0.131998 lossG: 0.338562\n",
      "[11: 760/1795] train lossD: -0.138193 lossG: 0.281131\n",
      "[11: 765/1795] train lossD: -0.094804 lossG: 0.281047\n",
      "[11: 770/1795] train lossD: -0.073100 lossG: 0.270609\n",
      "[11: 775/1795] train lossD: 0.012522 lossG: 0.366491\n",
      "[11: 780/1795] train lossD: -0.098661 lossG: 0.400548\n",
      "[11: 785/1795] train lossD: -0.119635 lossG: 0.262610\n",
      "[11: 790/1795] train lossD: -0.037636 lossG: 0.358902\n",
      "[11: 795/1795] train lossD: -0.160246 lossG: 0.365979\n",
      "[11: 800/1795] train lossD: -0.123429 lossG: 0.284937\n",
      "[11: 805/1795] train lossD: 0.084352 lossG: 0.546418\n",
      "[11: 810/1795] train lossD: -0.042329 lossG: 0.500023\n",
      "[11: 815/1795] train lossD: -0.129518 lossG: 0.461022\n",
      "[11: 820/1795] train lossD: -0.053972 lossG: 0.356911\n",
      "[11: 825/1795] train lossD: -0.091101 lossG: 0.333609\n",
      "[11: 830/1795] train lossD: -0.077752 lossG: 0.374054\n",
      "[11: 835/1795] train lossD: -0.078428 lossG: 0.230671\n",
      "[11: 840/1795] train lossD: -0.113857 lossG: 0.339940\n",
      "[11: 845/1795] train lossD: -0.132306 lossG: 0.353606\n",
      "[11: 850/1795] train lossD: -0.021206 lossG: 0.378652\n",
      "[11: 855/1795] train lossD: -0.072368 lossG: 0.380082\n",
      "[11: 860/1795] train lossD: -0.066717 lossG: 0.311359\n",
      "[11: 865/1795] train lossD: -0.081347 lossG: 0.400189\n",
      "[11: 870/1795] train lossD: -0.107208 lossG: 0.271201\n",
      "[11: 875/1795] train lossD: -0.063227 lossG: 0.292280\n",
      "[11: 880/1795] train lossD: -0.131397 lossG: 0.424615\n",
      "[11: 885/1795] train lossD: -0.097670 lossG: 0.292439\n",
      "[11: 890/1795] train lossD: -0.119828 lossG: 0.426720\n",
      "[11: 895/1795] train lossD: -0.122769 lossG: 0.343854\n",
      "[11: 900/1795] train lossD: -0.136739 lossG: 0.365897\n",
      "[11: 905/1795] train lossD: -0.107164 lossG: 0.299157\n",
      "[11: 910/1795] train lossD: -0.073170 lossG: 0.422143\n",
      "[11: 915/1795] train lossD: -0.102380 lossG: 0.327309\n",
      "[11: 920/1795] train lossD: -0.095456 lossG: 0.413741\n",
      "[11: 925/1795] train lossD: -0.009431 lossG: 0.404329\n",
      "[11: 930/1795] train lossD: -0.147628 lossG: 0.437540\n",
      "[11: 935/1795] train lossD: -0.133057 lossG: 0.358308\n",
      "[11: 940/1795] train lossD: -0.062289 lossG: 0.354198\n",
      "[11: 945/1795] train lossD: -0.101416 lossG: 0.363727\n",
      "[11: 950/1795] train lossD: -0.056151 lossG: 0.377927\n",
      "[11: 955/1795] train lossD: -0.100861 lossG: 0.343633\n",
      "[11: 960/1795] train lossD: -0.151252 lossG: 0.389621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11: 965/1795] train lossD: -0.054677 lossG: 0.378932\n",
      "[11: 970/1795] train lossD: -0.121221 lossG: 0.471986\n",
      "[11: 975/1795] train lossD: -0.086377 lossG: 0.411162\n",
      "[11: 980/1795] train lossD: -0.114691 lossG: 0.345284\n",
      "[11: 985/1795] train lossD: -0.056769 lossG: 0.514150\n",
      "[11: 990/1795] train lossD: -0.088678 lossG: 0.409650\n",
      "[11: 995/1795] train lossD: -0.126299 lossG: 0.469066\n",
      "[11: 1000/1795] train lossD: -0.101501 lossG: 0.380183\n",
      "[11: 1005/1795] train lossD: -0.100563 lossG: 0.394619\n",
      "[11: 1010/1795] train lossD: -0.101760 lossG: 0.300542\n",
      "[11: 1015/1795] train lossD: -0.090566 lossG: 0.304183\n",
      "[11: 1020/1795] train lossD: -0.181405 lossG: 0.433390\n",
      "[11: 1025/1795] train lossD: -0.148090 lossG: 0.377248\n",
      "[11: 1030/1795] train lossD: -0.097662 lossG: 0.449522\n",
      "[11: 1035/1795] train lossD: -0.182966 lossG: 0.468554\n",
      "[11: 1040/1795] train lossD: -0.124890 lossG: 0.468432\n",
      "[11: 1045/1795] train lossD: -0.172224 lossG: 0.480810\n",
      "[11: 1050/1795] train lossD: -0.089374 lossG: 0.499067\n",
      "[11: 1055/1795] train lossD: -0.039656 lossG: 0.429211\n",
      "[11: 1060/1795] train lossD: -0.179100 lossG: 0.430054\n",
      "[11: 1065/1795] train lossD: -0.098699 lossG: 0.411856\n",
      "[11: 1070/1795] train lossD: -0.113495 lossG: 0.368418\n",
      "[11: 1075/1795] train lossD: -0.131240 lossG: 0.490840\n",
      "[11: 1080/1795] train lossD: -0.133119 lossG: 0.343985\n",
      "[11: 1085/1795] train lossD: -0.136867 lossG: 0.299739\n",
      "[11: 1090/1795] train lossD: -0.114662 lossG: 0.332302\n",
      "[11: 1095/1795] train lossD: -0.056358 lossG: 0.362800\n",
      "[11: 1100/1795] train lossD: -0.102854 lossG: 0.458703\n",
      "[11: 1105/1795] train lossD: -0.133232 lossG: 0.350101\n",
      "[11: 1110/1795] train lossD: -0.131497 lossG: 0.424097\n",
      "[11: 1115/1795] train lossD: -0.073767 lossG: 0.336878\n",
      "[11: 1120/1795] train lossD: -0.100929 lossG: 0.396465\n",
      "[11: 1125/1795] train lossD: -0.103619 lossG: 0.280039\n",
      "[11: 1130/1795] train lossD: -0.130989 lossG: 0.442148\n",
      "[11: 1135/1795] train lossD: -0.074461 lossG: 0.391924\n",
      "[11: 1140/1795] train lossD: -0.120403 lossG: 0.356832\n",
      "[11: 1145/1795] train lossD: -0.108976 lossG: 0.469549\n",
      "[11: 1150/1795] train lossD: -0.172542 lossG: 0.410970\n",
      "[11: 1155/1795] train lossD: -0.095731 lossG: 0.368673\n",
      "[11: 1160/1795] train lossD: -0.085045 lossG: 0.339623\n",
      "[11: 1165/1795] train lossD: -0.062354 lossG: 0.490422\n",
      "[11: 1170/1795] train lossD: -0.117008 lossG: 0.500843\n",
      "[11: 1175/1795] train lossD: -0.129774 lossG: 0.428792\n",
      "[11: 1180/1795] train lossD: 0.037419 lossG: 0.593676\n",
      "[11: 1185/1795] train lossD: -0.111103 lossG: 0.316179\n",
      "[11: 1190/1795] train lossD: -0.116767 lossG: 0.387994\n",
      "[11: 1195/1795] train lossD: -0.071390 lossG: 0.607982\n",
      "[11: 1200/1795] train lossD: -0.081206 lossG: 0.407067\n",
      "[11: 1205/1795] train lossD: -0.120448 lossG: 0.468452\n",
      "[11: 1210/1795] train lossD: -0.107344 lossG: 0.400088\n",
      "[11: 1215/1795] train lossD: -0.130638 lossG: 0.367272\n",
      "[11: 1220/1795] train lossD: -0.036433 lossG: 0.410205\n",
      "[11: 1225/1795] train lossD: -0.136079 lossG: 0.436347\n",
      "[11: 1230/1795] train lossD: -0.175610 lossG: 0.377920\n",
      "[11: 1235/1795] train lossD: -0.109869 lossG: 0.436599\n",
      "[11: 1240/1795] train lossD: -0.134074 lossG: 0.484904\n",
      "[11: 1245/1795] train lossD: -0.130771 lossG: 0.349422\n",
      "[11: 1250/1795] train lossD: -0.118157 lossG: 0.491160\n",
      "[11: 1255/1795] train lossD: -0.090798 lossG: 0.421168\n",
      "[11: 1260/1795] train lossD: -0.053059 lossG: 0.507845\n",
      "[11: 1265/1795] train lossD: -0.107172 lossG: 0.410819\n",
      "[11: 1270/1795] train lossD: -0.069226 lossG: 0.353814\n",
      "[11: 1275/1795] train lossD: -0.081274 lossG: 0.428153\n",
      "[11: 1280/1795] train lossD: -0.102562 lossG: 0.350676\n",
      "[11: 1285/1795] train lossD: -0.135348 lossG: 0.420862\n",
      "[11: 1290/1795] train lossD: -0.078552 lossG: 0.399721\n",
      "[11: 1295/1795] train lossD: -0.037927 lossG: 0.363080\n",
      "[11: 1300/1795] train lossD: -0.112818 lossG: 0.354395\n",
      "[11: 1305/1795] train lossD: -0.049362 lossG: 0.296092\n",
      "[11: 1310/1795] train lossD: -0.109370 lossG: 0.346060\n",
      "[11: 1315/1795] train lossD: -0.124952 lossG: 0.355714\n",
      "[11: 1320/1795] train lossD: -0.047561 lossG: 0.404951\n",
      "[11: 1325/1795] train lossD: -0.089821 lossG: 0.454340\n",
      "[11: 1330/1795] train lossD: -0.126873 lossG: 0.278610\n",
      "[11: 1335/1795] train lossD: -0.071358 lossG: 0.320517\n",
      "[11: 1340/1795] train lossD: -0.094216 lossG: 0.421958\n",
      "[11: 1345/1795] train lossD: -0.115365 lossG: 0.342955\n",
      "[11: 1350/1795] train lossD: -0.133109 lossG: 0.443928\n",
      "[11: 1355/1795] train lossD: -0.073962 lossG: 0.442587\n",
      "[11: 1360/1795] train lossD: -0.111030 lossG: 0.329061\n",
      "[11: 1365/1795] train lossD: -0.122161 lossG: 0.400016\n",
      "[11: 1370/1795] train lossD: -0.056088 lossG: 0.412490\n",
      "[11: 1375/1795] train lossD: -0.146811 lossG: 0.488473\n",
      "[11: 1380/1795] train lossD: -0.148403 lossG: 0.430679\n",
      "[11: 1385/1795] train lossD: -0.131503 lossG: 0.519263\n",
      "[11: 1390/1795] train lossD: -0.136445 lossG: 0.426282\n",
      "[11: 1395/1795] train lossD: -0.099498 lossG: 0.429830\n",
      "[11: 1400/1795] train lossD: -0.146055 lossG: 0.548866\n",
      "[11: 1405/1795] train lossD: -0.136827 lossG: 0.410652\n",
      "[11: 1410/1795] train lossD: -0.161789 lossG: 0.372577\n",
      "[11: 1415/1795] train lossD: -0.057206 lossG: 0.425531\n",
      "[11: 1420/1795] train lossD: -0.120888 lossG: 0.423580\n",
      "[11: 1425/1795] train lossD: -0.102896 lossG: 0.365296\n",
      "[11: 1430/1795] train lossD: -0.092274 lossG: 0.445188\n",
      "[11: 1435/1795] train lossD: -0.020809 lossG: 0.454831\n",
      "[11: 1440/1795] train lossD: -0.117509 lossG: 0.398537\n",
      "[11: 1445/1795] train lossD: -0.069177 lossG: 0.432412\n",
      "[11: 1450/1795] train lossD: 0.163974 lossG: 0.471819\n",
      "[11: 1455/1795] train lossD: -0.134600 lossG: 0.396888\n",
      "[11: 1460/1795] train lossD: -0.107614 lossG: 0.405466\n",
      "[11: 1465/1795] train lossD: -0.119599 lossG: 0.360749\n",
      "[11: 1470/1795] train lossD: -0.050780 lossG: 0.492842\n",
      "[11: 1475/1795] train lossD: -0.078958 lossG: 0.344285\n",
      "[11: 1480/1795] train lossD: -0.082134 lossG: 0.440889\n",
      "[11: 1485/1795] train lossD: -0.113582 lossG: 0.387787\n",
      "[11: 1490/1795] train lossD: -0.061377 lossG: 0.338983\n",
      "[11: 1495/1795] train lossD: -0.049081 lossG: 0.341445\n",
      "[11: 1500/1795] train lossD: -0.104577 lossG: 0.319236\n",
      "[11: 1505/1795] train lossD: -0.038947 lossG: 0.398685\n",
      "[11: 1510/1795] train lossD: -0.103387 lossG: 0.385043\n",
      "[11: 1515/1795] train lossD: -0.157917 lossG: 0.316310\n",
      "[11: 1520/1795] train lossD: 0.029185 lossG: 0.505033\n",
      "[11: 1525/1795] train lossD: -0.122664 lossG: 0.373357\n",
      "[11: 1530/1795] train lossD: -0.093353 lossG: 0.414537\n",
      "[11: 1535/1795] train lossD: -0.174100 lossG: 0.400074\n",
      "[11: 1540/1795] train lossD: -0.097612 lossG: 0.333538\n",
      "[11: 1545/1795] train lossD: -0.070637 lossG: 0.564811\n",
      "[11: 1550/1795] train lossD: -0.063156 lossG: 0.470952\n",
      "[11: 1555/1795] train lossD: -0.103148 lossG: 0.434015\n",
      "[11: 1560/1795] train lossD: -0.128671 lossG: 0.356697\n",
      "[11: 1565/1795] train lossD: -0.156810 lossG: 0.354780\n",
      "[11: 1570/1795] train lossD: -0.057916 lossG: 0.340189\n",
      "[11: 1575/1795] train lossD: -0.110746 lossG: 0.416888\n",
      "[11: 1580/1795] train lossD: -0.181404 lossG: 0.404990\n",
      "[11: 1585/1795] train lossD: -0.089880 lossG: 0.488090\n",
      "[11: 1590/1795] train lossD: -0.084785 lossG: 0.412947\n",
      "[11: 1595/1795] train lossD: -0.112480 lossG: 0.420152\n",
      "[11: 1600/1795] train lossD: -0.085121 lossG: 0.436248\n",
      "[11: 1605/1795] train lossD: -0.102785 lossG: 0.336196\n",
      "[11: 1610/1795] train lossD: -0.085861 lossG: 0.436369\n",
      "[11: 1615/1795] train lossD: -0.081893 lossG: 0.361930\n",
      "[11: 1620/1795] train lossD: -0.133960 lossG: 0.455578\n",
      "[11: 1625/1795] train lossD: -0.113255 lossG: 0.420512\n",
      "[11: 1630/1795] train lossD: -0.104721 lossG: 0.479129\n",
      "[11: 1635/1795] train lossD: -0.097816 lossG: 0.504745\n",
      "[11: 1640/1795] train lossD: -0.100565 lossG: 0.388342\n",
      "[11: 1645/1795] train lossD: -0.069762 lossG: 0.477537\n",
      "[11: 1650/1795] train lossD: -0.088505 lossG: 0.450050\n",
      "[11: 1655/1795] train lossD: -0.117915 lossG: 0.353245\n",
      "[11: 1660/1795] train lossD: -0.115185 lossG: 0.309237\n",
      "[11: 1665/1795] train lossD: -0.108499 lossG: 0.463226\n",
      "[11: 1670/1795] train lossD: -0.100270 lossG: 0.477771\n",
      "[11: 1675/1795] train lossD: -0.101804 lossG: 0.437033\n",
      "[11: 1680/1795] train lossD: -0.129404 lossG: 0.500058\n",
      "[11: 1685/1795] train lossD: -0.106266 lossG: 0.489299\n",
      "[11: 1690/1795] train lossD: -0.069732 lossG: 0.428427\n",
      "[11: 1695/1795] train lossD: -0.113438 lossG: 0.430721\n",
      "[11: 1700/1795] train lossD: -0.053356 lossG: 0.398548\n",
      "[11: 1705/1795] train lossD: -0.111466 lossG: 0.426630\n",
      "[11: 1710/1795] train lossD: -0.055363 lossG: 0.322210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11: 1715/1795] train lossD: -0.093462 lossG: 0.261794\n",
      "[11: 1720/1795] train lossD: -0.007766 lossG: 0.571234\n",
      "[11: 1725/1795] train lossD: -0.099347 lossG: 0.396147\n",
      "[11: 1730/1795] train lossD: -0.161538 lossG: 0.490929\n",
      "[11: 1735/1795] train lossD: -0.126614 lossG: 0.352902\n",
      "[11: 1740/1795] train lossD: -0.066313 lossG: 0.297585\n",
      "[11: 1745/1795] train lossD: 0.033305 lossG: 0.356458\n",
      "[11: 1750/1795] train lossD: -0.083511 lossG: 0.287059\n",
      "[11: 1755/1795] train lossD: -0.051286 lossG: 0.396292\n",
      "[11: 1760/1795] train lossD: -0.096718 lossG: 0.388329\n",
      "[11: 1765/1795] train lossD: -0.087121 lossG: 0.386121\n",
      "[11: 1770/1795] train lossD: -0.062403 lossG: 0.314468\n",
      "[11: 1775/1795] train lossD: -0.002186 lossG: 0.352907\n",
      "[11: 1780/1795] train lossD: -0.119462 lossG: 0.396416\n",
      "[11: 1785/1795] train lossD: -0.095825 lossG: 0.401118\n",
      "[11: 1790/1795] train lossD: -0.068262 lossG: 0.499256\n",
      "0.04416750371456146\n",
      "[12: 0/1795] train lossD: -0.125364 lossG: 0.483735\n",
      "[12: 5/1795] train lossD: -0.010900 lossG: 0.410057\n",
      "[12: 10/1795] train lossD: -0.082665 lossG: 0.473639\n",
      "[12: 15/1795] train lossD: -0.168031 lossG: 0.427036\n",
      "[12: 20/1795] train lossD: -0.088798 lossG: 0.358333\n",
      "[12: 25/1795] train lossD: -0.132098 lossG: 0.481739\n",
      "[12: 30/1795] train lossD: -0.036893 lossG: 0.456878\n",
      "[12: 35/1795] train lossD: -0.121034 lossG: 0.439816\n",
      "[12: 40/1795] train lossD: -0.012630 lossG: 0.401347\n",
      "[12: 45/1795] train lossD: -0.122010 lossG: 0.371521\n",
      "[12: 50/1795] train lossD: -0.154450 lossG: 0.428837\n",
      "[12: 55/1795] train lossD: -0.085768 lossG: 0.437079\n",
      "[12: 60/1795] train lossD: -0.068234 lossG: 0.371266\n",
      "[12: 65/1795] train lossD: -0.115235 lossG: 0.433088\n",
      "[12: 70/1795] train lossD: -0.063039 lossG: 0.312350\n",
      "[12: 75/1795] train lossD: -0.126554 lossG: 0.450029\n",
      "[12: 80/1795] train lossD: 0.011824 lossG: 0.363337\n",
      "[12: 85/1795] train lossD: -0.030032 lossG: 0.420453\n",
      "[12: 90/1795] train lossD: 0.074000 lossG: 0.428573\n",
      "[12: 95/1795] train lossD: -0.106882 lossG: 0.498921\n",
      "[12: 100/1795] train lossD: -0.044719 lossG: 0.419421\n",
      "[12: 105/1795] train lossD: -0.147628 lossG: 0.346329\n",
      "[12: 110/1795] train lossD: -0.100695 lossG: 0.477131\n",
      "[12: 115/1795] train lossD: -0.066243 lossG: 0.455785\n",
      "[12: 120/1795] train lossD: -0.110307 lossG: 0.363841\n",
      "[12: 125/1795] train lossD: -0.087666 lossG: 0.374432\n",
      "[12: 130/1795] train lossD: -0.123821 lossG: 0.367912\n",
      "[12: 135/1795] train lossD: -0.074686 lossG: 0.343307\n",
      "[12: 140/1795] train lossD: -0.105047 lossG: 0.330186\n",
      "[12: 145/1795] train lossD: -0.112791 lossG: 0.489436\n",
      "[12: 150/1795] train lossD: -0.059182 lossG: 0.406792\n",
      "[12: 155/1795] train lossD: -0.145786 lossG: 0.502882\n",
      "[12: 160/1795] train lossD: -0.110845 lossG: 0.461404\n",
      "[12: 165/1795] train lossD: -0.088107 lossG: 0.374590\n",
      "[12: 170/1795] train lossD: -0.089307 lossG: 0.456522\n",
      "[12: 175/1795] train lossD: -0.047681 lossG: 0.364230\n",
      "[12: 180/1795] train lossD: -0.159198 lossG: 0.371344\n",
      "[12: 185/1795] train lossD: -0.080015 lossG: 0.385743\n",
      "[12: 190/1795] train lossD: -0.122978 lossG: 0.345385\n",
      "[12: 195/1795] train lossD: -0.086925 lossG: 0.343223\n",
      "[12: 200/1795] train lossD: -0.067068 lossG: 0.295180\n",
      "[12: 205/1795] train lossD: -0.090332 lossG: 0.304352\n",
      "[12: 210/1795] train lossD: -0.092316 lossG: 0.386031\n",
      "[12: 215/1795] train lossD: -0.069386 lossG: 0.359127\n",
      "[12: 220/1795] train lossD: -0.058134 lossG: 0.333149\n",
      "[12: 225/1795] train lossD: -0.140266 lossG: 0.371011\n",
      "[12: 230/1795] train lossD: -0.033117 lossG: 0.465666\n",
      "[12: 235/1795] train lossD: -0.145387 lossG: 0.373433\n",
      "[12: 240/1795] train lossD: -0.083964 lossG: 0.416854\n",
      "[12: 245/1795] train lossD: -0.148406 lossG: 0.389388\n",
      "[12: 250/1795] train lossD: -0.067502 lossG: 0.396016\n",
      "[12: 255/1795] train lossD: -0.107386 lossG: 0.409388\n",
      "[12: 260/1795] train lossD: -0.100710 lossG: 0.354647\n",
      "[12: 265/1795] train lossD: -0.118605 lossG: 0.356142\n",
      "[12: 270/1795] train lossD: -0.127964 lossG: 0.392857\n",
      "[12: 275/1795] train lossD: -0.149257 lossG: 0.322299\n",
      "[12: 280/1795] train lossD: -0.073002 lossG: 0.390902\n",
      "[12: 285/1795] train lossD: -0.071933 lossG: 0.340656\n",
      "[12: 290/1795] train lossD: -0.094406 lossG: 0.507005\n",
      "[12: 295/1795] train lossD: -0.056460 lossG: 0.416092\n",
      "[12: 300/1795] train lossD: -0.092168 lossG: 0.364365\n",
      "[12: 305/1795] train lossD: -0.165903 lossG: 0.506445\n",
      "[12: 310/1795] train lossD: -0.130505 lossG: 0.439567\n",
      "[12: 315/1795] train lossD: -0.098323 lossG: 0.487357\n",
      "[12: 320/1795] train lossD: -0.086820 lossG: 0.421274\n",
      "[12: 325/1795] train lossD: -0.077053 lossG: 0.404142\n",
      "[12: 330/1795] train lossD: -0.100670 lossG: 0.309838\n",
      "[12: 335/1795] train lossD: -0.118700 lossG: 0.332699\n",
      "[12: 340/1795] train lossD: -0.081018 lossG: 0.322046\n",
      "[12: 345/1795] train lossD: -0.151260 lossG: 0.367753\n",
      "[12: 350/1795] train lossD: -0.066041 lossG: 0.395862\n",
      "[12: 355/1795] train lossD: -0.100156 lossG: 0.318708\n",
      "[12: 360/1795] train lossD: -0.116750 lossG: 0.551704\n",
      "[12: 365/1795] train lossD: -0.154600 lossG: 0.294988\n",
      "[12: 370/1795] train lossD: -0.155599 lossG: 0.417149\n",
      "[12: 375/1795] train lossD: -0.120205 lossG: 0.464121\n",
      "[12: 380/1795] train lossD: -0.118992 lossG: 0.480379\n",
      "[12: 385/1795] train lossD: -0.137195 lossG: 0.447218\n",
      "[12: 390/1795] train lossD: -0.115326 lossG: 0.347214\n",
      "[12: 395/1795] train lossD: -0.159490 lossG: 0.489262\n",
      "[12: 400/1795] train lossD: -0.121357 lossG: 0.437388\n",
      "[12: 405/1795] train lossD: -0.085490 lossG: 0.341164\n",
      "[12: 410/1795] train lossD: -0.054437 lossG: 0.298782\n",
      "[12: 415/1795] train lossD: -0.101317 lossG: 0.374385\n",
      "[12: 420/1795] train lossD: -0.097620 lossG: 0.529765\n",
      "[12: 425/1795] train lossD: -0.057767 lossG: 0.373123\n",
      "[12: 430/1795] train lossD: -0.105130 lossG: 0.436002\n",
      "[12: 435/1795] train lossD: -0.084990 lossG: 0.348085\n",
      "[12: 440/1795] train lossD: -0.044150 lossG: 0.490109\n",
      "[12: 445/1795] train lossD: -0.013616 lossG: 0.351390\n",
      "[12: 450/1795] train lossD: -0.130605 lossG: 0.293424\n",
      "[12: 455/1795] train lossD: -0.074032 lossG: 0.361330\n",
      "[12: 460/1795] train lossD: -0.084467 lossG: 0.369623\n",
      "[12: 465/1795] train lossD: -0.104454 lossG: 0.379465\n",
      "[12: 470/1795] train lossD: -0.127193 lossG: 0.432397\n",
      "[12: 475/1795] train lossD: -0.133635 lossG: 0.442231\n",
      "[12: 480/1795] train lossD: -0.079549 lossG: 0.364972\n",
      "[12: 485/1795] train lossD: -0.044058 lossG: 0.285193\n",
      "[12: 490/1795] train lossD: -0.077733 lossG: 0.428237\n",
      "[12: 495/1795] train lossD: -0.073250 lossG: 0.277025\n",
      "[12: 500/1795] train lossD: -0.135777 lossG: 0.408548\n",
      "[12: 505/1795] train lossD: -0.147478 lossG: 0.444568\n",
      "[12: 510/1795] train lossD: -0.016927 lossG: 0.448238\n",
      "[12: 515/1795] train lossD: -0.175521 lossG: 0.345081\n",
      "[12: 520/1795] train lossD: -0.053697 lossG: 0.351555\n",
      "[12: 525/1795] train lossD: -0.166309 lossG: 0.409663\n",
      "[12: 530/1795] train lossD: -0.074517 lossG: 0.284314\n",
      "[12: 535/1795] train lossD: -0.127428 lossG: 0.453080\n",
      "[12: 540/1795] train lossD: -0.134865 lossG: 0.401605\n",
      "[12: 545/1795] train lossD: -0.028527 lossG: 0.285119\n",
      "[12: 550/1795] train lossD: -0.146267 lossG: 0.417994\n",
      "[12: 555/1795] train lossD: -0.048724 lossG: 0.352989\n",
      "[12: 560/1795] train lossD: -0.074167 lossG: 0.281096\n",
      "[12: 565/1795] train lossD: -0.098610 lossG: 0.244662\n",
      "[12: 570/1795] train lossD: -0.048214 lossG: 0.364023\n",
      "[12: 575/1795] train lossD: -0.113116 lossG: 0.319524\n",
      "[12: 580/1795] train lossD: -0.124621 lossG: 0.456813\n",
      "[12: 585/1795] train lossD: -0.095346 lossG: 0.236026\n",
      "[12: 590/1795] train lossD: -0.049913 lossG: 0.189574\n",
      "[12: 595/1795] train lossD: -0.086910 lossG: 0.211630\n",
      "[12: 600/1795] train lossD: -0.128160 lossG: 0.302023\n",
      "[12: 605/1795] train lossD: -0.134827 lossG: 0.457419\n",
      "[12: 610/1795] train lossD: -0.098393 lossG: 0.298919\n",
      "[12: 615/1795] train lossD: -0.079832 lossG: 0.463351\n",
      "[12: 620/1795] train lossD: -0.048491 lossG: 0.397289\n",
      "[12: 625/1795] train lossD: -0.066306 lossG: 0.297680\n",
      "[12: 630/1795] train lossD: -0.087588 lossG: 0.290037\n",
      "[12: 635/1795] train lossD: -0.079652 lossG: 0.327390\n",
      "[12: 640/1795] train lossD: -0.087358 lossG: 0.379205\n",
      "[12: 645/1795] train lossD: -0.127974 lossG: 0.380846\n",
      "[12: 650/1795] train lossD: -0.140813 lossG: 0.283802\n",
      "[12: 655/1795] train lossD: -0.102195 lossG: 0.470270\n",
      "[12: 660/1795] train lossD: -0.052204 lossG: 0.334637\n",
      "[12: 665/1795] train lossD: -0.195159 lossG: 0.486903\n",
      "[12: 670/1795] train lossD: -0.120542 lossG: 0.370968\n",
      "[12: 675/1795] train lossD: -0.054448 lossG: 0.334786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12: 680/1795] train lossD: -0.050428 lossG: 0.302755\n",
      "[12: 685/1795] train lossD: -0.051766 lossG: 0.309526\n",
      "[12: 690/1795] train lossD: -0.102388 lossG: 0.355831\n",
      "[12: 695/1795] train lossD: -0.107368 lossG: 0.327607\n",
      "[12: 700/1795] train lossD: -0.100131 lossG: 0.318041\n",
      "[12: 705/1795] train lossD: -0.125624 lossG: 0.277865\n",
      "[12: 710/1795] train lossD: -0.071217 lossG: 0.385090\n",
      "[12: 715/1795] train lossD: -0.101859 lossG: 0.318755\n",
      "[12: 720/1795] train lossD: -0.121859 lossG: 0.350131\n",
      "[12: 725/1795] train lossD: -0.045611 lossG: 0.396854\n",
      "[12: 730/1795] train lossD: -0.063335 lossG: 0.412067\n",
      "[12: 735/1795] train lossD: -0.129429 lossG: 0.301133\n",
      "[12: 740/1795] train lossD: -0.090528 lossG: 0.304901\n",
      "[12: 745/1795] train lossD: -0.082173 lossG: 0.306157\n",
      "[12: 750/1795] train lossD: -0.068105 lossG: 0.360219\n",
      "[12: 755/1795] train lossD: -0.135978 lossG: 0.458266\n",
      "[12: 760/1795] train lossD: -0.092020 lossG: 0.385891\n",
      "[12: 765/1795] train lossD: -0.120378 lossG: 0.340443\n",
      "[12: 770/1795] train lossD: -0.020510 lossG: 0.484623\n",
      "[12: 775/1795] train lossD: -0.100179 lossG: 0.468087\n",
      "[12: 780/1795] train lossD: -0.127758 lossG: 0.257135\n",
      "[12: 785/1795] train lossD: -0.112471 lossG: 0.299021\n",
      "[12: 790/1795] train lossD: -0.114391 lossG: 0.319986\n",
      "[12: 795/1795] train lossD: -0.104843 lossG: 0.265023\n",
      "[12: 800/1795] train lossD: -0.148396 lossG: 0.405420\n",
      "[12: 805/1795] train lossD: -0.081461 lossG: 0.380236\n",
      "[12: 810/1795] train lossD: -0.173329 lossG: 0.414914\n",
      "[12: 815/1795] train lossD: -0.085734 lossG: 0.456639\n",
      "[12: 820/1795] train lossD: -0.039453 lossG: 0.412949\n",
      "[12: 825/1795] train lossD: -0.045837 lossG: 0.390115\n",
      "[12: 830/1795] train lossD: -0.119964 lossG: 0.390084\n",
      "[12: 835/1795] train lossD: -0.097409 lossG: 0.404054\n",
      "[12: 840/1795] train lossD: -0.062978 lossG: 0.346105\n",
      "[12: 845/1795] train lossD: -0.065780 lossG: 0.429638\n",
      "[12: 850/1795] train lossD: -0.144174 lossG: 0.472128\n",
      "[12: 855/1795] train lossD: -0.059403 lossG: 0.365470\n",
      "[12: 860/1795] train lossD: -0.101428 lossG: 0.347824\n",
      "[12: 865/1795] train lossD: -0.008465 lossG: 0.410986\n",
      "[12: 870/1795] train lossD: -0.117182 lossG: 0.443965\n",
      "[12: 875/1795] train lossD: -0.055603 lossG: 0.358072\n",
      "[12: 880/1795] train lossD: -0.101051 lossG: 0.309097\n",
      "[12: 885/1795] train lossD: -0.050441 lossG: 0.456000\n",
      "[12: 890/1795] train lossD: -0.117872 lossG: 0.297662\n",
      "[12: 895/1795] train lossD: -0.145247 lossG: 0.361120\n",
      "[12: 900/1795] train lossD: 0.199277 lossG: 0.370178\n",
      "[12: 905/1795] train lossD: -0.066342 lossG: 0.390637\n",
      "[12: 910/1795] train lossD: -0.107288 lossG: 0.317481\n",
      "[12: 915/1795] train lossD: -0.096460 lossG: 0.256725\n",
      "[12: 920/1795] train lossD: -0.139799 lossG: 0.323572\n",
      "[12: 925/1795] train lossD: -0.109116 lossG: 0.266842\n",
      "[12: 930/1795] train lossD: -0.064683 lossG: 0.264120\n",
      "[12: 935/1795] train lossD: -0.119009 lossG: 0.369938\n",
      "[12: 940/1795] train lossD: -0.100174 lossG: 0.316806\n",
      "[12: 945/1795] train lossD: -0.138947 lossG: 0.262159\n",
      "[12: 950/1795] train lossD: 0.031470 lossG: 0.584438\n",
      "[12: 955/1795] train lossD: -0.069252 lossG: 0.396766\n",
      "[12: 960/1795] train lossD: -0.080841 lossG: 0.315654\n",
      "[12: 965/1795] train lossD: -0.127036 lossG: 0.422654\n",
      "[12: 970/1795] train lossD: -0.046829 lossG: 0.318689\n",
      "[12: 975/1795] train lossD: -0.062750 lossG: 0.364589\n",
      "[12: 980/1795] train lossD: -0.125965 lossG: 0.401461\n",
      "[12: 985/1795] train lossD: -0.122859 lossG: 0.332678\n",
      "[12: 990/1795] train lossD: -0.084101 lossG: 0.369108\n",
      "[12: 995/1795] train lossD: -0.135834 lossG: 0.335221\n",
      "[12: 1000/1795] train lossD: -0.098472 lossG: 0.453483\n",
      "[12: 1005/1795] train lossD: -0.048600 lossG: 0.410102\n",
      "[12: 1010/1795] train lossD: -0.119985 lossG: 0.463651\n",
      "[12: 1015/1795] train lossD: -0.118917 lossG: 0.435700\n",
      "[12: 1020/1795] train lossD: -0.081479 lossG: 0.491403\n",
      "[12: 1025/1795] train lossD: -0.052581 lossG: 0.445003\n",
      "[12: 1030/1795] train lossD: -0.083287 lossG: 0.364056\n",
      "[12: 1035/1795] train lossD: -0.108980 lossG: 0.428273\n",
      "[12: 1040/1795] train lossD: -0.102202 lossG: 0.383548\n",
      "[12: 1045/1795] train lossD: -0.055793 lossG: 0.283947\n",
      "[12: 1050/1795] train lossD: -0.117594 lossG: 0.366992\n",
      "[12: 1055/1795] train lossD: -0.085807 lossG: 0.291925\n",
      "[12: 1060/1795] train lossD: -0.130800 lossG: 0.377817\n",
      "[12: 1065/1795] train lossD: -0.014226 lossG: 0.279638\n",
      "[12: 1070/1795] train lossD: -0.038921 lossG: 0.340645\n",
      "[12: 1075/1795] train lossD: -0.143838 lossG: 0.466569\n",
      "[12: 1080/1795] train lossD: -0.180169 lossG: 0.421242\n",
      "[12: 1085/1795] train lossD: -0.075535 lossG: 0.424416\n",
      "[12: 1090/1795] train lossD: -0.136423 lossG: 0.476883\n",
      "[12: 1095/1795] train lossD: -0.074388 lossG: 0.494001\n",
      "[12: 1100/1795] train lossD: -0.116052 lossG: 0.353348\n",
      "[12: 1105/1795] train lossD: -0.073530 lossG: 0.415203\n",
      "[12: 1110/1795] train lossD: -0.113930 lossG: 0.365661\n",
      "[12: 1115/1795] train lossD: -0.076039 lossG: 0.425701\n",
      "[12: 1120/1795] train lossD: -0.184422 lossG: 0.356652\n",
      "[12: 1125/1795] train lossD: -0.107349 lossG: 0.359353\n",
      "[12: 1130/1795] train lossD: -0.129571 lossG: 0.453041\n",
      "[12: 1135/1795] train lossD: -0.130325 lossG: 0.346741\n",
      "[12: 1140/1795] train lossD: -0.124441 lossG: 0.392677\n",
      "[12: 1145/1795] train lossD: -0.060619 lossG: 0.279698\n",
      "[12: 1150/1795] train lossD: -0.087760 lossG: 0.334491\n",
      "[12: 1155/1795] train lossD: -0.060584 lossG: 0.408094\n",
      "[12: 1160/1795] train lossD: -0.065767 lossG: 0.397941\n",
      "[12: 1165/1795] train lossD: -0.070116 lossG: 0.358182\n",
      "[12: 1170/1795] train lossD: -0.112410 lossG: 0.461217\n",
      "[12: 1175/1795] train lossD: -0.189796 lossG: 0.371070\n",
      "[12: 1180/1795] train lossD: 0.046707 lossG: 0.645716\n",
      "[12: 1185/1795] train lossD: -0.113816 lossG: 0.457011\n",
      "[12: 1190/1795] train lossD: -0.064635 lossG: 0.474892\n",
      "[12: 1195/1795] train lossD: -0.110163 lossG: 0.376693\n",
      "[12: 1200/1795] train lossD: -0.174330 lossG: 0.442359\n",
      "[12: 1205/1795] train lossD: -0.113991 lossG: 0.365266\n",
      "[12: 1210/1795] train lossD: -0.116742 lossG: 0.389186\n",
      "[12: 1215/1795] train lossD: -0.091428 lossG: 0.406670\n",
      "[12: 1220/1795] train lossD: -0.111420 lossG: 0.306483\n",
      "[12: 1225/1795] train lossD: -0.136171 lossG: 0.372333\n",
      "[12: 1230/1795] train lossD: -0.084501 lossG: 0.290547\n",
      "[12: 1235/1795] train lossD: -0.163205 lossG: 0.402509\n",
      "[12: 1240/1795] train lossD: -0.117623 lossG: 0.335059\n",
      "[12: 1245/1795] train lossD: -0.105787 lossG: 0.358370\n",
      "[12: 1250/1795] train lossD: 0.095969 lossG: 0.367327\n",
      "[12: 1255/1795] train lossD: -0.049764 lossG: 0.461057\n",
      "[12: 1260/1795] train lossD: -0.075884 lossG: 0.370405\n",
      "[12: 1265/1795] train lossD: -0.082643 lossG: 0.313965\n",
      "[12: 1270/1795] train lossD: -0.123586 lossG: 0.388640\n",
      "[12: 1275/1795] train lossD: -0.052509 lossG: 0.353385\n",
      "[12: 1280/1795] train lossD: -0.084530 lossG: 0.447732\n",
      "[12: 1285/1795] train lossD: -0.056283 lossG: 0.472036\n",
      "[12: 1290/1795] train lossD: -0.125151 lossG: 0.450695\n",
      "[12: 1295/1795] train lossD: -0.155438 lossG: 0.442116\n",
      "[12: 1300/1795] train lossD: -0.070851 lossG: 0.448566\n",
      "[12: 1305/1795] train lossD: -0.125749 lossG: 0.326825\n",
      "[12: 1310/1795] train lossD: -0.154549 lossG: 0.371742\n",
      "[12: 1315/1795] train lossD: -0.098584 lossG: 0.450743\n",
      "[12: 1320/1795] train lossD: -0.142779 lossG: 0.310762\n",
      "[12: 1325/1795] train lossD: -0.116111 lossG: 0.298645\n",
      "[12: 1330/1795] train lossD: -0.123044 lossG: 0.422223\n",
      "[12: 1335/1795] train lossD: -0.040290 lossG: 0.372147\n",
      "[12: 1340/1795] train lossD: -0.027581 lossG: 0.358936\n",
      "[12: 1345/1795] train lossD: -0.071164 lossG: 0.383921\n",
      "[12: 1350/1795] train lossD: -0.113700 lossG: 0.411680\n",
      "[12: 1355/1795] train lossD: -0.128107 lossG: 0.319376\n",
      "[12: 1360/1795] train lossD: -0.117668 lossG: 0.318083\n",
      "[12: 1365/1795] train lossD: -0.083291 lossG: 0.387921\n",
      "[12: 1370/1795] train lossD: -0.132519 lossG: 0.335109\n",
      "[12: 1375/1795] train lossD: -0.131432 lossG: 0.375536\n",
      "[12: 1380/1795] train lossD: -0.112018 lossG: 0.404066\n",
      "[12: 1385/1795] train lossD: -0.101089 lossG: 0.369449\n",
      "[12: 1390/1795] train lossD: -0.040314 lossG: 0.396034\n",
      "[12: 1395/1795] train lossD: -0.116649 lossG: 0.463070\n",
      "[12: 1400/1795] train lossD: -0.088105 lossG: 0.349606\n",
      "[12: 1405/1795] train lossD: -0.064941 lossG: 0.374767\n",
      "[12: 1410/1795] train lossD: -0.062104 lossG: 0.275911\n",
      "[12: 1415/1795] train lossD: -0.085507 lossG: 0.316181\n",
      "[12: 1420/1795] train lossD: -0.081810 lossG: 0.396386\n",
      "[12: 1425/1795] train lossD: -0.150767 lossG: 0.268817\n",
      "[12: 1430/1795] train lossD: -0.150283 lossG: 0.458643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12: 1435/1795] train lossD: -0.055673 lossG: 0.470168\n",
      "[12: 1440/1795] train lossD: -0.122178 lossG: 0.343031\n",
      "[12: 1445/1795] train lossD: 0.023533 lossG: 0.345514\n",
      "[12: 1450/1795] train lossD: -0.121330 lossG: 0.340091\n",
      "[12: 1455/1795] train lossD: -0.085732 lossG: 0.360305\n",
      "[12: 1460/1795] train lossD: -0.103504 lossG: 0.376865\n",
      "[12: 1465/1795] train lossD: -0.039425 lossG: 0.364235\n",
      "[12: 1470/1795] train lossD: -0.104510 lossG: 0.424264\n",
      "[12: 1475/1795] train lossD: -0.065763 lossG: 0.412028\n",
      "[12: 1480/1795] train lossD: -0.130106 lossG: 0.330282\n",
      "[12: 1485/1795] train lossD: -0.187978 lossG: 0.408241\n",
      "[12: 1490/1795] train lossD: -0.096571 lossG: 0.238919\n",
      "[12: 1495/1795] train lossD: -0.177834 lossG: 0.513417\n",
      "[12: 1500/1795] train lossD: -0.103743 lossG: 0.418698\n",
      "[12: 1505/1795] train lossD: -0.139761 lossG: 0.443967\n",
      "[12: 1510/1795] train lossD: -0.090633 lossG: 0.303168\n",
      "[12: 1515/1795] train lossD: -0.133634 lossG: 0.362126\n",
      "[12: 1520/1795] train lossD: -0.096254 lossG: 0.513335\n",
      "[12: 1525/1795] train lossD: -0.109252 lossG: 0.347554\n",
      "[12: 1530/1795] train lossD: -0.089050 lossG: 0.291653\n",
      "[12: 1535/1795] train lossD: -0.181135 lossG: 0.381708\n",
      "[12: 1540/1795] train lossD: -0.043411 lossG: 0.522520\n",
      "[12: 1545/1795] train lossD: -0.153861 lossG: 0.485924\n",
      "[12: 1550/1795] train lossD: -0.133585 lossG: 0.371606\n",
      "[12: 1555/1795] train lossD: -0.069359 lossG: 0.271090\n",
      "[12: 1560/1795] train lossD: -0.151995 lossG: 0.405926\n",
      "[12: 1565/1795] train lossD: -0.138105 lossG: 0.323842\n",
      "[12: 1570/1795] train lossD: -0.070349 lossG: 0.281911\n",
      "[12: 1575/1795] train lossD: -0.108584 lossG: 0.288021\n",
      "[12: 1580/1795] train lossD: -0.129694 lossG: 0.421351\n",
      "[12: 1585/1795] train lossD: -0.066358 lossG: 0.374708\n",
      "[12: 1590/1795] train lossD: -0.064435 lossG: 0.336251\n",
      "[12: 1595/1795] train lossD: -0.175318 lossG: 0.390709\n",
      "[12: 1600/1795] train lossD: -0.123172 lossG: 0.359095\n",
      "[12: 1605/1795] train lossD: -0.122126 lossG: 0.288596\n",
      "[12: 1610/1795] train lossD: -0.116744 lossG: 0.277802\n",
      "[12: 1615/1795] train lossD: -0.032570 lossG: 0.430328\n",
      "[12: 1620/1795] train lossD: -0.076129 lossG: 0.375324\n",
      "[12: 1625/1795] train lossD: -0.163322 lossG: 0.452661\n",
      "[12: 1630/1795] train lossD: -0.138619 lossG: 0.330134\n",
      "[12: 1635/1795] train lossD: -0.119576 lossG: 0.515381\n",
      "[12: 1640/1795] train lossD: -0.146199 lossG: 0.410119\n",
      "[12: 1645/1795] train lossD: -0.109613 lossG: 0.401478\n",
      "[12: 1650/1795] train lossD: -0.119383 lossG: 0.470520\n",
      "[12: 1655/1795] train lossD: -0.136296 lossG: 0.399116\n",
      "[12: 1660/1795] train lossD: -0.081284 lossG: 0.360190\n",
      "[12: 1665/1795] train lossD: -0.056490 lossG: 0.421124\n",
      "[12: 1670/1795] train lossD: -0.023742 lossG: 0.563713\n",
      "[12: 1675/1795] train lossD: -0.074909 lossG: 0.339381\n",
      "[12: 1680/1795] train lossD: -0.111673 lossG: 0.398284\n",
      "[12: 1685/1795] train lossD: -0.085208 lossG: 0.297150\n",
      "[12: 1690/1795] train lossD: -0.089384 lossG: 0.290579\n",
      "[12: 1695/1795] train lossD: -0.080027 lossG: 0.382291\n",
      "[12: 1700/1795] train lossD: -0.084134 lossG: 0.391474\n",
      "[12: 1705/1795] train lossD: -0.122313 lossG: 0.283216\n",
      "[12: 1710/1795] train lossD: -0.024667 lossG: 0.328322\n",
      "[12: 1715/1795] train lossD: -0.037413 lossG: 0.261226\n",
      "[12: 1720/1795] train lossD: -0.056750 lossG: 0.348395\n",
      "[12: 1725/1795] train lossD: -0.063096 lossG: 0.330570\n",
      "[12: 1730/1795] train lossD: -0.114073 lossG: 0.332617\n",
      "[12: 1735/1795] train lossD: -0.096639 lossG: 0.257298\n",
      "[12: 1740/1795] train lossD: -0.105784 lossG: 0.349977\n",
      "[12: 1745/1795] train lossD: -0.095857 lossG: 0.381970\n",
      "[12: 1750/1795] train lossD: -0.094588 lossG: 0.493731\n",
      "[12: 1755/1795] train lossD: -0.149433 lossG: 0.361388\n",
      "[12: 1760/1795] train lossD: -0.151176 lossG: 0.346829\n",
      "[12: 1765/1795] train lossD: -0.018346 lossG: 0.374789\n",
      "[12: 1770/1795] train lossD: -0.087733 lossG: 0.417172\n",
      "[12: 1775/1795] train lossD: -0.098391 lossG: 0.370943\n",
      "[12: 1780/1795] train lossD: -0.096326 lossG: 0.262014\n",
      "[12: 1785/1795] train lossD: -0.109945 lossG: 0.296926\n",
      "[12: 1790/1795] train lossD: -0.074640 lossG: 0.369001\n",
      "0.04391780495643616\n",
      "[13: 0/1795] train lossD: -0.067002 lossG: 0.292296\n",
      "[13: 5/1795] train lossD: -0.101654 lossG: 0.340183\n",
      "[13: 10/1795] train lossD: -0.000764 lossG: 0.373731\n",
      "[13: 15/1795] train lossD: -0.105635 lossG: 0.398046\n",
      "[13: 20/1795] train lossD: -0.102925 lossG: 0.306841\n",
      "[13: 25/1795] train lossD: -0.105832 lossG: 0.356525\n",
      "[13: 30/1795] train lossD: -0.085923 lossG: 0.302184\n",
      "[13: 35/1795] train lossD: -0.080247 lossG: 0.494630\n",
      "[13: 40/1795] train lossD: -0.125307 lossG: 0.370164\n",
      "[13: 45/1795] train lossD: -0.073593 lossG: 0.291715\n",
      "[13: 50/1795] train lossD: -0.132904 lossG: 0.365934\n",
      "[13: 55/1795] train lossD: -0.132830 lossG: 0.406515\n",
      "[13: 60/1795] train lossD: 0.417248 lossG: 0.439373\n",
      "[13: 65/1795] train lossD: -0.060440 lossG: 0.402174\n",
      "[13: 70/1795] train lossD: -0.074089 lossG: 0.243922\n",
      "[13: 75/1795] train lossD: -0.087958 lossG: 0.251000\n",
      "[13: 80/1795] train lossD: -0.109871 lossG: 0.293145\n",
      "[13: 85/1795] train lossD: -0.029082 lossG: 0.422791\n",
      "[13: 90/1795] train lossD: -0.027503 lossG: 0.465434\n",
      "[13: 95/1795] train lossD: -0.107561 lossG: 0.515873\n",
      "[13: 100/1795] train lossD: -0.085678 lossG: 0.404813\n",
      "[13: 105/1795] train lossD: -0.120416 lossG: 0.389726\n",
      "[13: 110/1795] train lossD: -0.100161 lossG: 0.374239\n",
      "[13: 115/1795] train lossD: -0.089925 lossG: 0.363534\n",
      "[13: 120/1795] train lossD: -0.110220 lossG: 0.473761\n",
      "[13: 125/1795] train lossD: -0.112652 lossG: 0.424714\n",
      "[13: 130/1795] train lossD: -0.144421 lossG: 0.443998\n",
      "[13: 135/1795] train lossD: -0.041646 lossG: 0.304720\n",
      "[13: 140/1795] train lossD: -0.124943 lossG: 0.409171\n",
      "[13: 145/1795] train lossD: -0.058837 lossG: 0.415185\n",
      "[13: 150/1795] train lossD: -0.061518 lossG: 0.669690\n",
      "[13: 155/1795] train lossD: -0.095445 lossG: 0.566722\n",
      "[13: 160/1795] train lossD: -0.088301 lossG: 0.560754\n",
      "[13: 165/1795] train lossD: -0.085244 lossG: 0.462261\n",
      "[13: 170/1795] train lossD: -0.088673 lossG: 0.394504\n",
      "[13: 175/1795] train lossD: -0.129786 lossG: 0.450579\n",
      "[13: 180/1795] train lossD: -0.110038 lossG: 0.446276\n",
      "[13: 185/1795] train lossD: -0.119451 lossG: 0.411642\n",
      "[13: 190/1795] train lossD: -0.084009 lossG: 0.428884\n",
      "[13: 195/1795] train lossD: -0.060669 lossG: 0.400795\n",
      "[13: 200/1795] train lossD: -0.006468 lossG: 0.345809\n",
      "[13: 205/1795] train lossD: -0.088055 lossG: 0.398364\n",
      "[13: 210/1795] train lossD: -0.141636 lossG: 0.465237\n",
      "[13: 215/1795] train lossD: -0.066109 lossG: 0.304784\n",
      "[13: 220/1795] train lossD: -0.029127 lossG: 0.443194\n",
      "[13: 225/1795] train lossD: -0.076783 lossG: 0.316855\n",
      "[13: 230/1795] train lossD: -0.062639 lossG: 0.335141\n",
      "[13: 235/1795] train lossD: -0.067762 lossG: 0.345591\n",
      "[13: 240/1795] train lossD: -0.044246 lossG: 0.279590\n",
      "[13: 245/1795] train lossD: 0.098851 lossG: 0.391935\n",
      "[13: 250/1795] train lossD: -0.131339 lossG: 0.373447\n",
      "[13: 255/1795] train lossD: -0.103680 lossG: 0.380219\n",
      "[13: 260/1795] train lossD: -0.079760 lossG: 0.471247\n",
      "[13: 265/1795] train lossD: -0.113719 lossG: 0.431866\n",
      "[13: 270/1795] train lossD: 0.032106 lossG: 0.339261\n",
      "[13: 275/1795] train lossD: -0.040274 lossG: 0.339578\n",
      "[13: 280/1795] train lossD: -0.111824 lossG: 0.346970\n",
      "[13: 285/1795] train lossD: -0.048107 lossG: 0.378631\n",
      "[13: 290/1795] train lossD: -0.070311 lossG: 0.319337\n",
      "[13: 295/1795] train lossD: -0.054946 lossG: 0.283460\n",
      "[13: 300/1795] train lossD: 0.058536 lossG: 0.354359\n",
      "[13: 305/1795] train lossD: -0.107699 lossG: 0.411880\n",
      "[13: 310/1795] train lossD: -0.118468 lossG: 0.405870\n",
      "[13: 315/1795] train lossD: -0.097019 lossG: 0.469478\n",
      "[13: 320/1795] train lossD: -0.091723 lossG: 0.412061\n",
      "[13: 325/1795] train lossD: -0.071931 lossG: 0.332394\n",
      "[13: 330/1795] train lossD: -0.195349 lossG: 0.472079\n",
      "[13: 335/1795] train lossD: -0.103379 lossG: 0.475696\n",
      "[13: 340/1795] train lossD: -0.104206 lossG: 0.325938\n",
      "[13: 345/1795] train lossD: -0.067461 lossG: 0.401618\n",
      "[13: 350/1795] train lossD: -0.035768 lossG: 0.299972\n",
      "[13: 355/1795] train lossD: -0.096268 lossG: 0.579294\n",
      "[13: 360/1795] train lossD: -0.044527 lossG: 0.375090\n",
      "[13: 365/1795] train lossD: -0.138419 lossG: 0.346949\n",
      "[13: 370/1795] train lossD: -0.064556 lossG: 0.392544\n",
      "[13: 375/1795] train lossD: -0.084713 lossG: 0.355331\n",
      "[13: 380/1795] train lossD: -0.041923 lossG: 0.426847\n",
      "[13: 385/1795] train lossD: -0.121302 lossG: 0.333641\n",
      "[13: 390/1795] train lossD: -0.146655 lossG: 0.571140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13: 395/1795] train lossD: -0.146324 lossG: 0.487935\n",
      "[13: 400/1795] train lossD: -0.104894 lossG: 0.446474\n",
      "[13: 405/1795] train lossD: -0.032748 lossG: 0.403173\n",
      "[13: 410/1795] train lossD: -0.085488 lossG: 0.403948\n",
      "[13: 415/1795] train lossD: -0.013853 lossG: 0.621051\n",
      "[13: 420/1795] train lossD: -0.041283 lossG: 0.390224\n",
      "[13: 425/1795] train lossD: -0.087177 lossG: 0.427529\n",
      "[13: 430/1795] train lossD: -0.074435 lossG: 0.396015\n",
      "[13: 435/1795] train lossD: -0.012387 lossG: 0.491427\n",
      "[13: 440/1795] train lossD: -0.082762 lossG: 0.301382\n",
      "[13: 445/1795] train lossD: -0.149831 lossG: 0.331476\n",
      "[13: 450/1795] train lossD: -0.098456 lossG: 0.457144\n",
      "[13: 455/1795] train lossD: -0.062060 lossG: 0.373008\n",
      "[13: 460/1795] train lossD: -0.101521 lossG: 0.319990\n",
      "[13: 465/1795] train lossD: -0.105820 lossG: 0.394742\n",
      "[13: 470/1795] train lossD: -0.058460 lossG: 0.393623\n",
      "[13: 475/1795] train lossD: -0.135215 lossG: 0.407690\n",
      "[13: 480/1795] train lossD: -0.095331 lossG: 0.304392\n",
      "[13: 485/1795] train lossD: -0.119875 lossG: 0.437274\n",
      "[13: 490/1795] train lossD: -0.133280 lossG: 0.355405\n",
      "[13: 495/1795] train lossD: -0.059223 lossG: 0.264967\n",
      "[13: 500/1795] train lossD: -0.107116 lossG: 0.320248\n",
      "[13: 505/1795] train lossD: 0.152111 lossG: 0.411049\n",
      "[13: 510/1795] train lossD: -0.074711 lossG: 0.425747\n",
      "[13: 515/1795] train lossD: -0.103318 lossG: 0.451153\n",
      "[13: 520/1795] train lossD: -0.126181 lossG: 0.389476\n",
      "[13: 525/1795] train lossD: -0.077307 lossG: 0.384110\n",
      "[13: 530/1795] train lossD: -0.066730 lossG: 0.439803\n",
      "[13: 535/1795] train lossD: -0.153189 lossG: 0.407565\n",
      "[13: 540/1795] train lossD: -0.199753 lossG: 0.452490\n",
      "[13: 545/1795] train lossD: -0.102707 lossG: 0.447875\n",
      "[13: 550/1795] train lossD: -0.100911 lossG: 0.319891\n",
      "[13: 555/1795] train lossD: -0.019475 lossG: 0.455879\n",
      "[13: 560/1795] train lossD: -0.074448 lossG: 0.292252\n",
      "[13: 565/1795] train lossD: -0.070727 lossG: 0.366721\n",
      "[13: 570/1795] train lossD: -0.128396 lossG: 0.378054\n",
      "[13: 575/1795] train lossD: -0.150804 lossG: 0.289430\n",
      "[13: 580/1795] train lossD: -0.139779 lossG: 0.311882\n",
      "[13: 585/1795] train lossD: -0.120470 lossG: 0.432367\n",
      "[13: 590/1795] train lossD: -0.227286 lossG: 0.312220\n",
      "[13: 595/1795] train lossD: -0.103814 lossG: 0.353432\n",
      "[13: 600/1795] train lossD: -0.108553 lossG: 0.284853\n",
      "[13: 605/1795] train lossD: 0.014241 lossG: 0.340731\n",
      "[13: 610/1795] train lossD: -0.138425 lossG: 0.368935\n",
      "[13: 615/1795] train lossD: -0.148589 lossG: 0.373136\n",
      "[13: 620/1795] train lossD: -0.103308 lossG: 0.303362\n",
      "[13: 625/1795] train lossD: -0.124105 lossG: 0.509372\n",
      "[13: 630/1795] train lossD: -0.074587 lossG: 0.355916\n",
      "[13: 635/1795] train lossD: -0.089621 lossG: 0.298712\n",
      "[13: 640/1795] train lossD: -0.114226 lossG: 0.393302\n",
      "[13: 645/1795] train lossD: -0.086880 lossG: 0.406253\n",
      "[13: 650/1795] train lossD: -0.097628 lossG: 0.370929\n",
      "[13: 655/1795] train lossD: -0.050308 lossG: 0.419443\n",
      "[13: 660/1795] train lossD: -0.099073 lossG: 0.345686\n",
      "[13: 665/1795] train lossD: -0.018175 lossG: 0.381520\n",
      "[13: 670/1795] train lossD: -0.063844 lossG: 0.302831\n",
      "[13: 675/1795] train lossD: -0.107489 lossG: 0.419181\n",
      "[13: 680/1795] train lossD: -0.015276 lossG: 0.439256\n",
      "[13: 685/1795] train lossD: -0.100423 lossG: 0.350746\n",
      "[13: 690/1795] train lossD: -0.094844 lossG: 0.270476\n",
      "[13: 695/1795] train lossD: -0.117397 lossG: 0.309758\n",
      "[13: 700/1795] train lossD: -0.076991 lossG: 0.377740\n",
      "[13: 705/1795] train lossD: -0.106206 lossG: 0.383071\n",
      "[13: 710/1795] train lossD: -0.127038 lossG: 0.493137\n",
      "[13: 715/1795] train lossD: -0.050179 lossG: 0.448080\n",
      "[13: 720/1795] train lossD: -0.098713 lossG: 0.397014\n",
      "[13: 725/1795] train lossD: -0.076216 lossG: 0.352586\n",
      "[13: 730/1795] train lossD: -0.123548 lossG: 0.609545\n",
      "[13: 735/1795] train lossD: -0.103863 lossG: 0.508502\n",
      "[13: 740/1795] train lossD: -0.119767 lossG: 0.362661\n",
      "[13: 745/1795] train lossD: -0.091544 lossG: 0.378808\n",
      "[13: 750/1795] train lossD: -0.140493 lossG: 0.479536\n",
      "[13: 755/1795] train lossD: -0.114437 lossG: 0.400553\n",
      "[13: 760/1795] train lossD: -0.146385 lossG: 0.375948\n",
      "[13: 765/1795] train lossD: -0.098640 lossG: 0.386383\n",
      "[13: 770/1795] train lossD: -0.079165 lossG: 0.399398\n",
      "[13: 775/1795] train lossD: -0.115624 lossG: 0.410168\n",
      "[13: 780/1795] train lossD: 0.000034 lossG: 0.511382\n",
      "[13: 785/1795] train lossD: -0.096442 lossG: 0.458055\n",
      "[13: 790/1795] train lossD: -0.120232 lossG: 0.452840\n",
      "[13: 795/1795] train lossD: -0.131991 lossG: 0.450891\n",
      "[13: 800/1795] train lossD: -0.075212 lossG: 0.491638\n",
      "[13: 805/1795] train lossD: -0.063387 lossG: 0.398288\n",
      "[13: 810/1795] train lossD: -0.068645 lossG: 0.412188\n",
      "[13: 815/1795] train lossD: 0.096227 lossG: 0.395218\n",
      "[13: 820/1795] train lossD: -0.080496 lossG: 0.346410\n",
      "[13: 825/1795] train lossD: -0.109365 lossG: 0.375741\n",
      "[13: 830/1795] train lossD: -0.128411 lossG: 0.395587\n",
      "[13: 835/1795] train lossD: -0.125839 lossG: 0.422818\n",
      "[13: 840/1795] train lossD: -0.043169 lossG: 0.409646\n",
      "[13: 845/1795] train lossD: -0.050482 lossG: 0.341898\n",
      "[13: 850/1795] train lossD: -0.080262 lossG: 0.356904\n",
      "[13: 855/1795] train lossD: -0.088998 lossG: 0.338061\n",
      "[13: 860/1795] train lossD: -0.123863 lossG: 0.312980\n",
      "[13: 865/1795] train lossD: -0.083949 lossG: 0.499076\n",
      "[13: 870/1795] train lossD: -0.114978 lossG: 0.308320\n",
      "[13: 875/1795] train lossD: -0.030824 lossG: 0.212570\n",
      "[13: 880/1795] train lossD: -0.112882 lossG: 0.297807\n",
      "[13: 885/1795] train lossD: -0.113871 lossG: 0.283910\n",
      "[13: 890/1795] train lossD: -0.146179 lossG: 0.447103\n",
      "[13: 895/1795] train lossD: -0.101952 lossG: 0.310467\n",
      "[13: 900/1795] train lossD: -0.097524 lossG: 0.383161\n",
      "[13: 905/1795] train lossD: -0.063520 lossG: 0.436356\n",
      "[13: 910/1795] train lossD: -0.157174 lossG: 0.425069\n",
      "[13: 915/1795] train lossD: -0.102273 lossG: 0.352052\n",
      "[13: 920/1795] train lossD: -0.051287 lossG: 0.411146\n",
      "[13: 925/1795] train lossD: -0.044062 lossG: 0.504180\n",
      "[13: 930/1795] train lossD: -0.127163 lossG: 0.396476\n",
      "[13: 935/1795] train lossD: -0.015305 lossG: 0.314337\n",
      "[13: 940/1795] train lossD: -0.143540 lossG: 0.260629\n",
      "[13: 945/1795] train lossD: -0.057900 lossG: 0.304275\n",
      "[13: 950/1795] train lossD: -0.025817 lossG: 0.272341\n",
      "[13: 955/1795] train lossD: -0.115400 lossG: 0.373000\n",
      "[13: 960/1795] train lossD: -0.035550 lossG: 0.339654\n",
      "[13: 965/1795] train lossD: -0.073139 lossG: 0.282465\n",
      "[13: 970/1795] train lossD: -0.070577 lossG: 0.354540\n",
      "[13: 975/1795] train lossD: -0.116341 lossG: 0.337029\n",
      "[13: 980/1795] train lossD: 0.134459 lossG: 0.430058\n",
      "[13: 985/1795] train lossD: -0.031783 lossG: 0.440199\n",
      "[13: 990/1795] train lossD: -0.120100 lossG: 0.341916\n",
      "[13: 995/1795] train lossD: -0.164965 lossG: 0.430718\n",
      "[13: 1000/1795] train lossD: -0.178444 lossG: 0.355525\n",
      "[13: 1005/1795] train lossD: -0.053576 lossG: 0.534652\n",
      "[13: 1010/1795] train lossD: -0.119220 lossG: 0.419334\n",
      "[13: 1015/1795] train lossD: -0.083918 lossG: 0.408488\n",
      "[13: 1020/1795] train lossD: -0.083944 lossG: 0.286177\n",
      "[13: 1025/1795] train lossD: -0.119839 lossG: 0.378187\n",
      "[13: 1030/1795] train lossD: 0.019132 lossG: 0.528270\n",
      "[13: 1035/1795] train lossD: -0.084655 lossG: 0.392303\n",
      "[13: 1040/1795] train lossD: -0.066911 lossG: 0.422869\n",
      "[13: 1045/1795] train lossD: -0.082505 lossG: 0.358466\n",
      "[13: 1050/1795] train lossD: -0.121292 lossG: 0.400614\n",
      "[13: 1055/1795] train lossD: -0.052370 lossG: 0.205718\n",
      "[13: 1060/1795] train lossD: -0.055430 lossG: 0.367128\n",
      "[13: 1065/1795] train lossD: -0.142555 lossG: 0.327252\n",
      "[13: 1070/1795] train lossD: -0.087872 lossG: 0.316708\n",
      "[13: 1075/1795] train lossD: -0.148197 lossG: 0.388268\n",
      "[13: 1080/1795] train lossD: -0.059034 lossG: 0.228772\n",
      "[13: 1085/1795] train lossD: -0.157627 lossG: 0.412376\n",
      "[13: 1090/1795] train lossD: -0.044765 lossG: 0.323841\n",
      "[13: 1095/1795] train lossD: -0.097419 lossG: 0.263327\n",
      "[13: 1100/1795] train lossD: -0.120728 lossG: 0.315127\n",
      "[13: 1105/1795] train lossD: -0.076830 lossG: 0.337532\n",
      "[13: 1110/1795] train lossD: -0.126193 lossG: 0.274445\n",
      "[13: 1115/1795] train lossD: -0.089833 lossG: 0.389650\n",
      "[13: 1120/1795] train lossD: -0.123724 lossG: 0.371094\n",
      "[13: 1125/1795] train lossD: -0.069529 lossG: 0.323572\n",
      "[13: 1130/1795] train lossD: -0.032820 lossG: 0.388150\n",
      "[13: 1135/1795] train lossD: -0.121364 lossG: 0.568169\n",
      "[13: 1140/1795] train lossD: -0.125148 lossG: 0.338619\n",
      "[13: 1145/1795] train lossD: -0.024717 lossG: 0.388834\n",
      "[13: 1150/1795] train lossD: -0.055996 lossG: 0.291499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13: 1155/1795] train lossD: -0.083148 lossG: 0.289533\n",
      "[13: 1160/1795] train lossD: -0.091862 lossG: 0.269774\n",
      "[13: 1165/1795] train lossD: -0.106380 lossG: 0.227915\n",
      "[13: 1170/1795] train lossD: -0.079031 lossG: 0.394598\n",
      "[13: 1175/1795] train lossD: -0.072360 lossG: 0.409915\n",
      "[13: 1180/1795] train lossD: -0.071476 lossG: 0.323542\n",
      "[13: 1185/1795] train lossD: -0.105716 lossG: 0.366108\n",
      "[13: 1190/1795] train lossD: 0.210885 lossG: 0.438359\n",
      "[13: 1195/1795] train lossD: -0.069829 lossG: 0.367111\n",
      "[13: 1200/1795] train lossD: -0.088418 lossG: 0.343549\n",
      "[13: 1205/1795] train lossD: -0.155360 lossG: 0.366984\n",
      "[13: 1210/1795] train lossD: -0.124442 lossG: 0.365462\n",
      "[13: 1215/1795] train lossD: -0.067653 lossG: 0.325384\n",
      "[13: 1220/1795] train lossD: -0.075288 lossG: 0.418578\n",
      "[13: 1225/1795] train lossD: -0.077794 lossG: 0.317965\n",
      "[13: 1230/1795] train lossD: -0.086148 lossG: 0.331990\n",
      "[13: 1235/1795] train lossD: -0.078406 lossG: 0.348276\n",
      "[13: 1240/1795] train lossD: -0.061409 lossG: 0.552783\n",
      "[13: 1245/1795] train lossD: -0.050691 lossG: 0.428027\n",
      "[13: 1250/1795] train lossD: -0.068736 lossG: 0.386331\n",
      "[13: 1255/1795] train lossD: -0.144537 lossG: 0.392569\n",
      "[13: 1260/1795] train lossD: 0.021978 lossG: 0.382862\n",
      "[13: 1265/1795] train lossD: -0.130284 lossG: 0.358654\n",
      "[13: 1270/1795] train lossD: -0.092975 lossG: 0.294540\n",
      "[13: 1275/1795] train lossD: -0.104733 lossG: 0.439345\n",
      "[13: 1280/1795] train lossD: -0.132874 lossG: 0.410848\n",
      "[13: 1285/1795] train lossD: -0.140475 lossG: 0.276586\n",
      "[13: 1290/1795] train lossD: -0.115562 lossG: 0.440958\n",
      "[13: 1295/1795] train lossD: -0.055172 lossG: 0.365668\n",
      "[13: 1300/1795] train lossD: -0.067734 lossG: 0.388290\n",
      "[13: 1305/1795] train lossD: -0.144839 lossG: 0.375453\n",
      "[13: 1310/1795] train lossD: -0.044263 lossG: 0.454590\n",
      "[13: 1315/1795] train lossD: -0.079527 lossG: 0.303969\n",
      "[13: 1320/1795] train lossD: -0.061750 lossG: 0.376385\n",
      "[13: 1325/1795] train lossD: -0.022438 lossG: 0.264432\n",
      "[13: 1330/1795] train lossD: -0.087426 lossG: 0.322764\n",
      "[13: 1335/1795] train lossD: -0.077713 lossG: 0.260129\n",
      "[13: 1340/1795] train lossD: -0.102921 lossG: 0.374838\n",
      "[13: 1345/1795] train lossD: -0.097094 lossG: 0.337303\n",
      "[13: 1350/1795] train lossD: -0.073809 lossG: 0.400456\n",
      "[13: 1355/1795] train lossD: -0.141840 lossG: 0.330472\n",
      "[13: 1360/1795] train lossD: -0.039188 lossG: 0.240725\n",
      "[13: 1365/1795] train lossD: -0.196693 lossG: 0.266484\n",
      "[13: 1370/1795] train lossD: -0.133805 lossG: 0.176402\n",
      "[13: 1375/1795] train lossD: -0.076599 lossG: 0.439669\n",
      "[13: 1380/1795] train lossD: -0.107329 lossG: 0.371997\n",
      "[13: 1385/1795] train lossD: -0.127400 lossG: 0.399598\n",
      "[13: 1390/1795] train lossD: -0.112712 lossG: 0.342432\n",
      "[13: 1395/1795] train lossD: -0.087549 lossG: 0.336191\n",
      "[13: 1400/1795] train lossD: -0.124968 lossG: 0.342464\n",
      "[13: 1405/1795] train lossD: -0.133038 lossG: 0.435839\n",
      "[13: 1410/1795] train lossD: 0.023190 lossG: 0.392550\n",
      "[13: 1415/1795] train lossD: -0.117934 lossG: 0.331573\n",
      "[13: 1420/1795] train lossD: -0.061477 lossG: 0.331645\n",
      "[13: 1425/1795] train lossD: -0.090641 lossG: 0.388193\n",
      "[13: 1430/1795] train lossD: -0.103844 lossG: 0.349181\n",
      "[13: 1435/1795] train lossD: -0.132373 lossG: 0.304828\n",
      "[13: 1440/1795] train lossD: -0.043015 lossG: 0.325710\n",
      "[13: 1445/1795] train lossD: -0.102912 lossG: 0.319531\n",
      "[13: 1450/1795] train lossD: -0.120252 lossG: 0.337865\n",
      "[13: 1455/1795] train lossD: -0.090800 lossG: 0.251858\n",
      "[13: 1460/1795] train lossD: -0.091539 lossG: 0.332910\n",
      "[13: 1465/1795] train lossD: 0.006885 lossG: 0.414159\n",
      "[13: 1470/1795] train lossD: -0.046094 lossG: 0.353845\n",
      "[13: 1475/1795] train lossD: -0.078818 lossG: 0.331069\n",
      "[13: 1480/1795] train lossD: -0.101423 lossG: 0.285776\n",
      "[13: 1485/1795] train lossD: -0.088286 lossG: 0.323044\n",
      "[13: 1490/1795] train lossD: -0.082445 lossG: 0.313815\n",
      "[13: 1495/1795] train lossD: -0.088322 lossG: 0.227986\n",
      "[13: 1500/1795] train lossD: -0.078043 lossG: 0.317486\n",
      "[13: 1505/1795] train lossD: -0.100593 lossG: 0.266551\n",
      "[13: 1510/1795] train lossD: -0.149606 lossG: 0.272752\n",
      "[13: 1515/1795] train lossD: -0.077886 lossG: 0.298276\n",
      "[13: 1520/1795] train lossD: -0.056216 lossG: 0.227777\n",
      "[13: 1525/1795] train lossD: -0.088456 lossG: 0.297322\n",
      "[13: 1530/1795] train lossD: -0.108966 lossG: 0.284984\n",
      "[13: 1535/1795] train lossD: -0.063719 lossG: 0.262848\n",
      "[13: 1540/1795] train lossD: -0.088763 lossG: 0.371523\n",
      "[13: 1545/1795] train lossD: -0.194322 lossG: 0.295729\n",
      "[13: 1550/1795] train lossD: -0.111400 lossG: 0.363113\n",
      "[13: 1555/1795] train lossD: -0.052745 lossG: 0.399824\n",
      "[13: 1560/1795] train lossD: -0.100442 lossG: 0.375983\n",
      "[13: 1565/1795] train lossD: -0.151756 lossG: 0.259258\n",
      "[13: 1570/1795] train lossD: -0.059232 lossG: 0.420168\n",
      "[13: 1575/1795] train lossD: -0.039525 lossG: 0.331563\n",
      "[13: 1580/1795] train lossD: -0.076944 lossG: 0.437281\n",
      "[13: 1585/1795] train lossD: -0.153082 lossG: 0.322538\n",
      "[13: 1590/1795] train lossD: -0.109771 lossG: 0.380429\n",
      "[13: 1595/1795] train lossD: -0.021116 lossG: 0.284351\n",
      "[13: 1600/1795] train lossD: -0.091097 lossG: 0.359635\n",
      "[13: 1605/1795] train lossD: -0.080237 lossG: 0.292458\n",
      "[13: 1610/1795] train lossD: -0.109265 lossG: 0.344967\n",
      "[13: 1615/1795] train lossD: -0.080876 lossG: 0.262517\n",
      "[13: 1620/1795] train lossD: -0.104972 lossG: 0.312490\n",
      "[13: 1625/1795] train lossD: -0.098966 lossG: 0.328410\n",
      "[13: 1630/1795] train lossD: -0.111854 lossG: 0.314624\n",
      "[13: 1635/1795] train lossD: -0.093713 lossG: 0.346248\n",
      "[13: 1640/1795] train lossD: -0.017778 lossG: 0.312076\n",
      "[13: 1645/1795] train lossD: -0.113721 lossG: 0.317022\n",
      "[13: 1650/1795] train lossD: -0.027912 lossG: 0.319238\n",
      "[13: 1655/1795] train lossD: 0.024934 lossG: 0.445934\n",
      "[13: 1660/1795] train lossD: -0.080008 lossG: 0.354890\n",
      "[13: 1665/1795] train lossD: -0.106632 lossG: 0.284657\n",
      "[13: 1670/1795] train lossD: -0.117632 lossG: 0.280550\n",
      "[13: 1675/1795] train lossD: -0.085609 lossG: 0.290201\n",
      "[13: 1680/1795] train lossD: 0.197831 lossG: 0.335039\n",
      "[13: 1685/1795] train lossD: -0.155185 lossG: 0.299584\n",
      "[13: 1690/1795] train lossD: -0.111421 lossG: 0.296207\n",
      "[13: 1695/1795] train lossD: -0.134837 lossG: 0.295672\n",
      "[13: 1700/1795] train lossD: -0.081201 lossG: 0.383277\n",
      "[13: 1705/1795] train lossD: -0.137584 lossG: 0.358374\n",
      "[13: 1710/1795] train lossD: -0.054884 lossG: 0.353239\n",
      "[13: 1715/1795] train lossD: -0.181930 lossG: 0.426722\n",
      "[13: 1720/1795] train lossD: 0.018641 lossG: 0.409870\n",
      "[13: 1725/1795] train lossD: -0.131488 lossG: 0.494482\n",
      "[13: 1730/1795] train lossD: -0.086054 lossG: 0.269494\n",
      "[13: 1735/1795] train lossD: -0.126983 lossG: 0.408732\n",
      "[13: 1740/1795] train lossD: -0.017821 lossG: 0.406662\n",
      "[13: 1745/1795] train lossD: -0.105891 lossG: 0.415796\n",
      "[13: 1750/1795] train lossD: -0.060587 lossG: 0.439171\n",
      "[13: 1755/1795] train lossD: -0.120325 lossG: 0.392573\n",
      "[13: 1760/1795] train lossD: -0.079373 lossG: 0.391525\n",
      "[13: 1765/1795] train lossD: -0.065235 lossG: 0.359454\n",
      "[13: 1770/1795] train lossD: -0.055492 lossG: 0.443716\n",
      "[13: 1775/1795] train lossD: -0.049317 lossG: 0.387028\n",
      "[13: 1780/1795] train lossD: -0.087525 lossG: 0.477450\n",
      "[13: 1785/1795] train lossD: -0.046115 lossG: 0.423818\n",
      "[13: 1790/1795] train lossD: -0.106971 lossG: 0.343855\n",
      "0.04444083571434021\n",
      "[14: 0/1795] train lossD: -0.191336 lossG: 0.344844\n",
      "[14: 5/1795] train lossD: -0.048510 lossG: 0.362834\n",
      "[14: 10/1795] train lossD: -0.103621 lossG: 0.307080\n",
      "[14: 15/1795] train lossD: 0.012875 lossG: 0.403188\n",
      "[14: 20/1795] train lossD: -0.119248 lossG: 0.362133\n",
      "[14: 25/1795] train lossD: -0.085642 lossG: 0.292163\n",
      "[14: 30/1795] train lossD: -0.059926 lossG: 0.328948\n",
      "[14: 35/1795] train lossD: -0.162588 lossG: 0.360935\n",
      "[14: 40/1795] train lossD: -0.196103 lossG: 0.494900\n",
      "[14: 45/1795] train lossD: -0.127049 lossG: 0.450202\n",
      "[14: 50/1795] train lossD: -0.063613 lossG: 0.423497\n",
      "[14: 55/1795] train lossD: -0.127475 lossG: 0.463950\n",
      "[14: 60/1795] train lossD: -0.046522 lossG: 0.218184\n",
      "[14: 65/1795] train lossD: -0.120242 lossG: 0.444200\n",
      "[14: 70/1795] train lossD: -0.167805 lossG: 0.387892\n",
      "[14: 75/1795] train lossD: -0.145131 lossG: 0.302169\n",
      "[14: 80/1795] train lossD: -0.054478 lossG: 0.333692\n",
      "[14: 85/1795] train lossD: -0.069496 lossG: 0.327336\n",
      "[14: 90/1795] train lossD: -0.092380 lossG: 0.237927\n",
      "[14: 95/1795] train lossD: -0.036403 lossG: 0.255855\n",
      "[14: 100/1795] train lossD: -0.049312 lossG: 0.249851\n",
      "[14: 105/1795] train lossD: -0.135450 lossG: 0.388305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14: 110/1795] train lossD: -0.122847 lossG: 0.336433\n",
      "[14: 115/1795] train lossD: -0.045417 lossG: 0.290805\n",
      "[14: 120/1795] train lossD: -0.017392 lossG: 0.304138\n",
      "[14: 125/1795] train lossD: -0.095371 lossG: 0.275918\n",
      "[14: 130/1795] train lossD: -0.092279 lossG: 0.300500\n",
      "[14: 135/1795] train lossD: -0.068797 lossG: 0.318352\n",
      "[14: 140/1795] train lossD: -0.168407 lossG: 0.253227\n",
      "[14: 145/1795] train lossD: 0.015915 lossG: 0.383042\n",
      "[14: 150/1795] train lossD: -0.107401 lossG: 0.333871\n",
      "[14: 155/1795] train lossD: -0.076502 lossG: 0.271494\n",
      "[14: 160/1795] train lossD: -0.086983 lossG: 0.310858\n",
      "[14: 165/1795] train lossD: -0.086066 lossG: 0.288820\n",
      "[14: 170/1795] train lossD: -0.088991 lossG: 0.546227\n",
      "[14: 175/1795] train lossD: -0.087400 lossG: 0.203212\n",
      "[14: 180/1795] train lossD: -0.106521 lossG: 0.308785\n",
      "[14: 185/1795] train lossD: -0.052347 lossG: 0.335033\n",
      "[14: 190/1795] train lossD: -0.079620 lossG: 0.340842\n",
      "[14: 195/1795] train lossD: -0.077509 lossG: 0.340828\n",
      "[14: 200/1795] train lossD: -0.105116 lossG: 0.328842\n",
      "[14: 205/1795] train lossD: -0.087998 lossG: 0.255925\n",
      "[14: 210/1795] train lossD: -0.124490 lossG: 0.279948\n",
      "[14: 215/1795] train lossD: -0.090712 lossG: 0.370393\n",
      "[14: 220/1795] train lossD: -0.091427 lossG: 0.311812\n",
      "[14: 225/1795] train lossD: -0.121701 lossG: 0.305084\n",
      "[14: 230/1795] train lossD: -0.078406 lossG: 0.359529\n",
      "[14: 235/1795] train lossD: -0.057926 lossG: 0.303913\n",
      "[14: 240/1795] train lossD: -0.108682 lossG: 0.349536\n",
      "[14: 245/1795] train lossD: -0.053402 lossG: 0.311395\n",
      "[14: 250/1795] train lossD: -0.152124 lossG: 0.379337\n",
      "[14: 255/1795] train lossD: -0.063920 lossG: 0.420801\n",
      "[14: 260/1795] train lossD: -0.120413 lossG: 0.404562\n",
      "[14: 265/1795] train lossD: -0.046271 lossG: 0.245149\n",
      "[14: 270/1795] train lossD: -0.089622 lossG: 0.448938\n",
      "[14: 275/1795] train lossD: -0.047165 lossG: 0.458852\n",
      "[14: 280/1795] train lossD: -0.130559 lossG: 0.520468\n",
      "[14: 285/1795] train lossD: 0.035346 lossG: 0.226667\n",
      "[14: 290/1795] train lossD: -0.067611 lossG: 0.273743\n",
      "[14: 295/1795] train lossD: -0.090499 lossG: 0.319199\n",
      "[14: 300/1795] train lossD: -0.079626 lossG: 0.363255\n",
      "[14: 305/1795] train lossD: -0.060323 lossG: 0.315875\n",
      "[14: 310/1795] train lossD: -0.087945 lossG: 0.291595\n",
      "[14: 315/1795] train lossD: -0.038184 lossG: 0.306329\n",
      "[14: 320/1795] train lossD: -0.128949 lossG: 0.323868\n",
      "[14: 325/1795] train lossD: -0.121924 lossG: 0.391722\n",
      "[14: 330/1795] train lossD: -0.072225 lossG: 0.246448\n",
      "[14: 335/1795] train lossD: -0.070023 lossG: 0.396364\n",
      "[14: 340/1795] train lossD: -0.100776 lossG: 0.345050\n",
      "[14: 345/1795] train lossD: -0.087375 lossG: 0.368287\n",
      "[14: 350/1795] train lossD: -0.126056 lossG: 0.403422\n",
      "[14: 355/1795] train lossD: 0.004912 lossG: 0.396059\n",
      "[14: 360/1795] train lossD: -0.129152 lossG: 0.445227\n",
      "[14: 365/1795] train lossD: -0.079433 lossG: 0.322741\n",
      "[14: 370/1795] train lossD: -0.120300 lossG: 0.254597\n",
      "[14: 375/1795] train lossD: -0.113409 lossG: 0.370249\n",
      "[14: 380/1795] train lossD: -0.098625 lossG: 0.369377\n",
      "[14: 385/1795] train lossD: -0.075725 lossG: 0.409183\n",
      "[14: 390/1795] train lossD: -0.066384 lossG: 0.447097\n",
      "[14: 395/1795] train lossD: -0.105707 lossG: 0.372071\n",
      "[14: 400/1795] train lossD: -0.091717 lossG: 0.360010\n",
      "[14: 405/1795] train lossD: -0.132378 lossG: 0.363648\n",
      "[14: 410/1795] train lossD: -0.007970 lossG: 0.249125\n",
      "[14: 415/1795] train lossD: -0.104272 lossG: 0.356313\n",
      "[14: 420/1795] train lossD: -0.101662 lossG: 0.393944\n",
      "[14: 425/1795] train lossD: -0.110818 lossG: 0.441788\n",
      "[14: 430/1795] train lossD: -0.106868 lossG: 0.349344\n",
      "[14: 435/1795] train lossD: -0.077148 lossG: 0.253535\n",
      "[14: 440/1795] train lossD: -0.109741 lossG: 0.335362\n",
      "[14: 445/1795] train lossD: -0.114553 lossG: 0.343354\n",
      "[14: 450/1795] train lossD: 0.089126 lossG: 0.293648\n",
      "[14: 455/1795] train lossD: -0.124484 lossG: 0.405465\n",
      "[14: 460/1795] train lossD: -0.053422 lossG: 0.228830\n",
      "[14: 465/1795] train lossD: -0.133437 lossG: 0.210311\n",
      "[14: 470/1795] train lossD: -0.125859 lossG: 0.297408\n",
      "[14: 475/1795] train lossD: -0.144570 lossG: 0.407318\n",
      "[14: 480/1795] train lossD: -0.073896 lossG: 0.454209\n",
      "[14: 485/1795] train lossD: -0.141743 lossG: 0.322604\n",
      "[14: 490/1795] train lossD: -0.069045 lossG: 0.294623\n",
      "[14: 495/1795] train lossD: 0.156199 lossG: 0.391519\n",
      "[14: 500/1795] train lossD: -0.123826 lossG: 0.446295\n",
      "[14: 505/1795] train lossD: -0.095303 lossG: 0.352567\n",
      "[14: 510/1795] train lossD: -0.095059 lossG: 0.352707\n",
      "[14: 515/1795] train lossD: -0.071859 lossG: 0.337008\n",
      "[14: 520/1795] train lossD: -0.094687 lossG: 0.371919\n",
      "[14: 525/1795] train lossD: 0.074051 lossG: 0.342056\n",
      "[14: 530/1795] train lossD: -0.069330 lossG: 0.329175\n",
      "[14: 535/1795] train lossD: -0.062624 lossG: 0.336260\n",
      "[14: 540/1795] train lossD: -0.020742 lossG: 0.348882\n",
      "[14: 545/1795] train lossD: -0.120906 lossG: 0.480063\n",
      "[14: 550/1795] train lossD: -0.151770 lossG: 0.371171\n",
      "[14: 555/1795] train lossD: -0.181202 lossG: 0.440605\n",
      "[14: 560/1795] train lossD: -0.157492 lossG: 0.360191\n",
      "[14: 565/1795] train lossD: -0.094777 lossG: 0.344204\n",
      "[14: 570/1795] train lossD: -0.059656 lossG: 0.431534\n",
      "[14: 575/1795] train lossD: -0.082868 lossG: 0.341812\n",
      "[14: 580/1795] train lossD: -0.113111 lossG: 0.272068\n",
      "[14: 585/1795] train lossD: -0.031110 lossG: 0.540983\n",
      "[14: 590/1795] train lossD: -0.068307 lossG: 0.426327\n",
      "[14: 595/1795] train lossD: -0.127198 lossG: 0.306714\n",
      "[14: 600/1795] train lossD: -0.070475 lossG: 0.345427\n",
      "[14: 605/1795] train lossD: -0.110526 lossG: 0.292992\n",
      "[14: 610/1795] train lossD: -0.081248 lossG: 0.255476\n",
      "[14: 615/1795] train lossD: -0.056198 lossG: 0.316307\n",
      "[14: 620/1795] train lossD: -0.097566 lossG: 0.420700\n",
      "[14: 625/1795] train lossD: -0.008234 lossG: 0.443531\n",
      "[14: 630/1795] train lossD: -0.033639 lossG: 0.430085\n",
      "[14: 635/1795] train lossD: -0.055549 lossG: 0.324384\n",
      "[14: 640/1795] train lossD: -0.097213 lossG: 0.355593\n",
      "[14: 645/1795] train lossD: -0.122043 lossG: 0.306689\n",
      "[14: 650/1795] train lossD: -0.133300 lossG: 0.332750\n",
      "[14: 655/1795] train lossD: -0.116108 lossG: 0.254598\n",
      "[14: 660/1795] train lossD: -0.129264 lossG: 0.218882\n",
      "[14: 665/1795] train lossD: -0.086457 lossG: 0.287383\n",
      "[14: 670/1795] train lossD: -0.064167 lossG: 0.313240\n",
      "[14: 675/1795] train lossD: -0.148119 lossG: 0.301910\n",
      "[14: 680/1795] train lossD: 0.016591 lossG: 0.405913\n",
      "[14: 685/1795] train lossD: -0.081425 lossG: 0.287819\n",
      "[14: 690/1795] train lossD: -0.030698 lossG: 0.456204\n",
      "[14: 695/1795] train lossD: -0.117523 lossG: 0.457550\n",
      "[14: 700/1795] train lossD: -0.055390 lossG: 0.366525\n",
      "[14: 705/1795] train lossD: -0.068904 lossG: 0.335314\n",
      "[14: 710/1795] train lossD: -0.130372 lossG: 0.334208\n",
      "[14: 715/1795] train lossD: -0.104156 lossG: 0.224004\n",
      "[14: 720/1795] train lossD: -0.139140 lossG: 0.371638\n",
      "[14: 725/1795] train lossD: -0.095276 lossG: 0.292364\n",
      "[14: 730/1795] train lossD: -0.091118 lossG: 0.320526\n",
      "[14: 735/1795] train lossD: -0.109762 lossG: 0.469144\n",
      "[14: 740/1795] train lossD: -0.097057 lossG: 0.424781\n",
      "[14: 745/1795] train lossD: -0.029036 lossG: 0.335104\n",
      "[14: 750/1795] train lossD: -0.096909 lossG: 0.345478\n",
      "[14: 755/1795] train lossD: -0.087894 lossG: 0.344032\n",
      "[14: 760/1795] train lossD: -0.085479 lossG: 0.352957\n",
      "[14: 765/1795] train lossD: -0.065590 lossG: 0.541937\n",
      "[14: 770/1795] train lossD: -0.118539 lossG: 0.408853\n",
      "[14: 775/1795] train lossD: -0.081596 lossG: 0.336359\n",
      "[14: 780/1795] train lossD: -0.079359 lossG: 0.374976\n",
      "[14: 785/1795] train lossD: -0.143434 lossG: 0.358184\n",
      "[14: 790/1795] train lossD: -0.202529 lossG: 0.360132\n",
      "[14: 795/1795] train lossD: -0.085929 lossG: 0.344760\n",
      "[14: 800/1795] train lossD: -0.124870 lossG: 0.357196\n",
      "[14: 805/1795] train lossD: -0.082714 lossG: 0.433477\n",
      "[14: 810/1795] train lossD: -0.108327 lossG: 0.456303\n",
      "[14: 815/1795] train lossD: -0.093678 lossG: 0.397468\n",
      "[14: 820/1795] train lossD: -0.076680 lossG: 0.373207\n",
      "[14: 825/1795] train lossD: -0.172018 lossG: 0.408336\n",
      "[14: 830/1795] train lossD: -0.133082 lossG: 0.353262\n",
      "[14: 835/1795] train lossD: -0.097588 lossG: 0.333831\n",
      "[14: 840/1795] train lossD: -0.076088 lossG: 0.398790\n",
      "[14: 845/1795] train lossD: -0.010489 lossG: 0.373920\n",
      "[14: 850/1795] train lossD: -0.019892 lossG: 0.355682\n",
      "[14: 855/1795] train lossD: -0.098659 lossG: 0.297725\n",
      "[14: 860/1795] train lossD: -0.083329 lossG: 0.354404\n",
      "[14: 865/1795] train lossD: -0.132776 lossG: 0.309398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14: 870/1795] train lossD: -0.102882 lossG: 0.316520\n",
      "[14: 875/1795] train lossD: -0.086784 lossG: 0.361771\n",
      "[14: 880/1795] train lossD: -0.126775 lossG: 0.478539\n",
      "[14: 885/1795] train lossD: -0.087620 lossG: 0.294946\n",
      "[14: 890/1795] train lossD: -0.107674 lossG: 0.276928\n",
      "[14: 895/1795] train lossD: -0.103999 lossG: 0.504612\n",
      "[14: 900/1795] train lossD: -0.102259 lossG: 0.314395\n",
      "[14: 905/1795] train lossD: -0.050361 lossG: 0.254870\n",
      "[14: 910/1795] train lossD: -0.106664 lossG: 0.341899\n",
      "[14: 915/1795] train lossD: -0.103804 lossG: 0.359263\n",
      "[14: 920/1795] train lossD: -0.021295 lossG: 0.289343\n",
      "[14: 925/1795] train lossD: -0.125495 lossG: 0.288801\n",
      "[14: 930/1795] train lossD: -0.104097 lossG: 0.303209\n",
      "[14: 935/1795] train lossD: -0.062822 lossG: 0.352587\n",
      "[14: 940/1795] train lossD: -0.104159 lossG: 0.331356\n",
      "[14: 945/1795] train lossD: -0.082141 lossG: 0.459315\n",
      "[14: 950/1795] train lossD: -0.143333 lossG: 0.376956\n",
      "[14: 955/1795] train lossD: -0.070116 lossG: 0.244317\n",
      "[14: 960/1795] train lossD: -0.090135 lossG: 0.327939\n",
      "[14: 965/1795] train lossD: -0.032797 lossG: 0.415481\n",
      "[14: 970/1795] train lossD: -0.116492 lossG: 0.445055\n",
      "[14: 975/1795] train lossD: -0.157721 lossG: 0.279185\n",
      "[14: 980/1795] train lossD: -0.024643 lossG: 0.527663\n",
      "[14: 985/1795] train lossD: -0.090027 lossG: 0.410050\n",
      "[14: 990/1795] train lossD: -0.122985 lossG: 0.459869\n",
      "[14: 995/1795] train lossD: -0.127508 lossG: 0.355033\n",
      "[14: 1000/1795] train lossD: -0.152527 lossG: 0.438905\n",
      "[14: 1005/1795] train lossD: -0.125112 lossG: 0.376725\n",
      "[14: 1010/1795] train lossD: -0.122953 lossG: 0.303214\n",
      "[14: 1015/1795] train lossD: 0.041765 lossG: 0.305122\n",
      "[14: 1020/1795] train lossD: -0.095243 lossG: 0.346719\n",
      "[14: 1025/1795] train lossD: -0.067462 lossG: 0.331027\n",
      "[14: 1030/1795] train lossD: -0.095046 lossG: 0.356642\n",
      "[14: 1035/1795] train lossD: -0.052726 lossG: 0.190770\n",
      "[14: 1040/1795] train lossD: -0.054611 lossG: 0.267708\n",
      "[14: 1045/1795] train lossD: -0.113297 lossG: 0.320101\n",
      "[14: 1050/1795] train lossD: -0.114277 lossG: 0.378415\n",
      "[14: 1055/1795] train lossD: -0.124747 lossG: 0.315713\n",
      "[14: 1060/1795] train lossD: -0.105979 lossG: 0.354731\n",
      "[14: 1065/1795] train lossD: -0.093304 lossG: 0.283105\n",
      "[14: 1070/1795] train lossD: -0.079731 lossG: 0.190718\n",
      "[14: 1075/1795] train lossD: -0.118583 lossG: 0.383353\n",
      "[14: 1080/1795] train lossD: -0.038044 lossG: 0.267283\n",
      "[14: 1085/1795] train lossD: -0.085179 lossG: 0.297400\n",
      "[14: 1090/1795] train lossD: -0.101657 lossG: 0.281960\n",
      "[14: 1095/1795] train lossD: -0.136766 lossG: 0.467119\n",
      "[14: 1100/1795] train lossD: -0.135829 lossG: 0.303342\n",
      "[14: 1105/1795] train lossD: -0.111332 lossG: 0.505144\n",
      "[14: 1110/1795] train lossD: -0.044480 lossG: 0.449014\n",
      "[14: 1115/1795] train lossD: -0.137021 lossG: 0.312259\n",
      "[14: 1120/1795] train lossD: -0.060081 lossG: 0.420623\n",
      "[14: 1125/1795] train lossD: -0.041354 lossG: 0.389685\n",
      "[14: 1130/1795] train lossD: -0.095902 lossG: 0.400748\n",
      "[14: 1135/1795] train lossD: -0.061621 lossG: 0.382957\n",
      "[14: 1140/1795] train lossD: -0.173663 lossG: 0.281215\n",
      "[14: 1145/1795] train lossD: -0.069943 lossG: 0.476192\n",
      "[14: 1150/1795] train lossD: -0.051539 lossG: 0.445018\n",
      "[14: 1155/1795] train lossD: -0.106365 lossG: 0.442050\n",
      "[14: 1160/1795] train lossD: -0.078221 lossG: 0.405321\n",
      "[14: 1165/1795] train lossD: -0.128443 lossG: 0.358031\n",
      "[14: 1170/1795] train lossD: -0.199275 lossG: 0.364067\n",
      "[14: 1175/1795] train lossD: -0.114820 lossG: 0.469017\n",
      "[14: 1180/1795] train lossD: -0.111686 lossG: 0.401921\n",
      "[14: 1185/1795] train lossD: -0.074284 lossG: 0.395259\n",
      "[14: 1190/1795] train lossD: -0.099475 lossG: 0.383766\n",
      "[14: 1195/1795] train lossD: -0.121765 lossG: 0.376927\n",
      "[14: 1200/1795] train lossD: -0.104670 lossG: 0.296734\n",
      "[14: 1205/1795] train lossD: -0.090746 lossG: 0.329159\n",
      "[14: 1210/1795] train lossD: -0.092722 lossG: 0.211234\n",
      "[14: 1215/1795] train lossD: -0.114783 lossG: 0.275636\n",
      "[14: 1220/1795] train lossD: -0.107324 lossG: 0.218486\n",
      "[14: 1225/1795] train lossD: -0.156144 lossG: 0.421289\n",
      "[14: 1230/1795] train lossD: -0.147618 lossG: 0.279215\n",
      "[14: 1235/1795] train lossD: -0.095466 lossG: 0.402677\n",
      "[14: 1240/1795] train lossD: -0.014755 lossG: 0.246569\n",
      "[14: 1245/1795] train lossD: -0.090279 lossG: 0.262917\n",
      "[14: 1250/1795] train lossD: 0.092667 lossG: 0.575151\n",
      "[14: 1255/1795] train lossD: -0.068580 lossG: 0.461231\n",
      "[14: 1260/1795] train lossD: -0.138953 lossG: 0.374675\n",
      "[14: 1265/1795] train lossD: -0.132204 lossG: 0.297643\n",
      "[14: 1270/1795] train lossD: -0.112735 lossG: 0.323464\n",
      "[14: 1275/1795] train lossD: -0.045434 lossG: 0.268579\n",
      "[14: 1280/1795] train lossD: -0.152614 lossG: 0.406427\n",
      "[14: 1285/1795] train lossD: 0.025331 lossG: 0.348644\n",
      "[14: 1290/1795] train lossD: -0.071140 lossG: 0.403130\n",
      "[14: 1295/1795] train lossD: -0.052716 lossG: 0.253313\n",
      "[14: 1300/1795] train lossD: -0.127500 lossG: 0.323854\n",
      "[14: 1305/1795] train lossD: -0.156154 lossG: 0.314795\n",
      "[14: 1310/1795] train lossD: -0.089771 lossG: 0.304672\n",
      "[14: 1315/1795] train lossD: -0.075900 lossG: 0.295843\n",
      "[14: 1320/1795] train lossD: -0.024577 lossG: 0.344555\n",
      "[14: 1325/1795] train lossD: -0.044190 lossG: 0.301913\n",
      "[14: 1330/1795] train lossD: -0.139357 lossG: 0.371940\n",
      "[14: 1335/1795] train lossD: -0.123716 lossG: 0.374459\n",
      "[14: 1340/1795] train lossD: -0.167020 lossG: 0.359167\n",
      "[14: 1345/1795] train lossD: -0.087078 lossG: 0.290608\n",
      "[14: 1350/1795] train lossD: -0.106829 lossG: 0.235392\n",
      "[14: 1355/1795] train lossD: -0.066870 lossG: 0.461302\n",
      "[14: 1360/1795] train lossD: -0.049568 lossG: 0.329786\n",
      "[14: 1365/1795] train lossD: -0.129854 lossG: 0.425787\n",
      "[14: 1370/1795] train lossD: -0.059737 lossG: 0.387577\n",
      "[14: 1375/1795] train lossD: -0.236918 lossG: 0.342109\n",
      "[14: 1380/1795] train lossD: -0.115033 lossG: 0.308041\n",
      "[14: 1385/1795] train lossD: 0.253369 lossG: 0.234009\n",
      "[14: 1390/1795] train lossD: -0.109175 lossG: 0.294210\n",
      "[14: 1395/1795] train lossD: -0.102703 lossG: 0.304110\n",
      "[14: 1400/1795] train lossD: -0.104780 lossG: 0.500621\n",
      "[14: 1405/1795] train lossD: -0.107116 lossG: 0.323522\n",
      "[14: 1410/1795] train lossD: -0.115055 lossG: 0.313177\n",
      "[14: 1415/1795] train lossD: -0.133713 lossG: 0.434139\n",
      "[14: 1420/1795] train lossD: -0.105590 lossG: 0.350139\n",
      "[14: 1425/1795] train lossD: -0.089614 lossG: 0.331729\n",
      "[14: 1430/1795] train lossD: -0.057448 lossG: 0.317981\n",
      "[14: 1435/1795] train lossD: -0.115806 lossG: 0.404048\n",
      "[14: 1440/1795] train lossD: -0.064309 lossG: 0.359935\n",
      "[14: 1445/1795] train lossD: -0.033904 lossG: 0.279770\n",
      "[14: 1450/1795] train lossD: -0.072729 lossG: 0.324132\n",
      "[14: 1455/1795] train lossD: -0.163553 lossG: 0.399164\n",
      "[14: 1460/1795] train lossD: -0.162094 lossG: 0.419825\n",
      "[14: 1465/1795] train lossD: -0.123862 lossG: 0.462773\n",
      "[14: 1470/1795] train lossD: -0.158219 lossG: 0.316125\n",
      "[14: 1475/1795] train lossD: -0.084616 lossG: 0.323987\n",
      "[14: 1480/1795] train lossD: -0.071837 lossG: 0.325697\n",
      "[14: 1485/1795] train lossD: -0.149436 lossG: 0.394821\n",
      "[14: 1490/1795] train lossD: -0.083179 lossG: 0.392361\n",
      "[14: 1495/1795] train lossD: -0.102090 lossG: 0.409643\n",
      "[14: 1500/1795] train lossD: -0.106193 lossG: 0.321818\n",
      "[14: 1505/1795] train lossD: 0.011888 lossG: 0.403211\n",
      "[14: 1510/1795] train lossD: -0.101371 lossG: 0.315370\n",
      "[14: 1515/1795] train lossD: -0.052311 lossG: 0.306344\n",
      "[14: 1520/1795] train lossD: -0.076816 lossG: 0.302991\n",
      "[14: 1525/1795] train lossD: -0.069794 lossG: 0.249789\n",
      "[14: 1530/1795] train lossD: -0.068418 lossG: 0.321502\n",
      "[14: 1535/1795] train lossD: -0.061639 lossG: 0.378160\n",
      "[14: 1540/1795] train lossD: -0.105760 lossG: 0.326320\n",
      "[14: 1545/1795] train lossD: -0.054815 lossG: 0.254414\n",
      "[14: 1550/1795] train lossD: -0.119981 lossG: 0.230471\n",
      "[14: 1555/1795] train lossD: -0.070648 lossG: 0.206292\n",
      "[14: 1560/1795] train lossD: 0.151898 lossG: 0.343403\n",
      "[14: 1565/1795] train lossD: -0.088467 lossG: 0.423890\n",
      "[14: 1570/1795] train lossD: -0.113250 lossG: 0.312865\n",
      "[14: 1575/1795] train lossD: -0.128202 lossG: 0.271155\n",
      "[14: 1580/1795] train lossD: -0.060517 lossG: 0.379082\n",
      "[14: 1585/1795] train lossD: -0.028830 lossG: 0.424826\n",
      "[14: 1590/1795] train lossD: -0.175496 lossG: 0.482939\n",
      "[14: 1595/1795] train lossD: -0.047894 lossG: 0.402766\n",
      "[14: 1600/1795] train lossD: -0.099181 lossG: 0.273779\n",
      "[14: 1605/1795] train lossD: -0.114031 lossG: 0.383556\n",
      "[14: 1610/1795] train lossD: -0.139622 lossG: 0.310036\n",
      "[14: 1615/1795] train lossD: -0.133052 lossG: 0.413021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14: 1620/1795] train lossD: -0.110780 lossG: 0.333514\n",
      "[14: 1625/1795] train lossD: -0.073787 lossG: 0.249462\n",
      "[14: 1630/1795] train lossD: -0.042414 lossG: 0.264292\n",
      "[14: 1635/1795] train lossD: -0.054840 lossG: 0.289745\n",
      "[14: 1640/1795] train lossD: -0.075405 lossG: 0.261486\n",
      "[14: 1645/1795] train lossD: -0.136344 lossG: 0.348482\n",
      "[14: 1650/1795] train lossD: -0.097239 lossG: 0.192804\n",
      "[14: 1655/1795] train lossD: -0.078257 lossG: 0.358176\n",
      "[14: 1660/1795] train lossD: -0.129736 lossG: 0.313374\n",
      "[14: 1665/1795] train lossD: -0.048446 lossG: 0.387424\n",
      "[14: 1670/1795] train lossD: -0.147545 lossG: 0.390828\n",
      "[14: 1675/1795] train lossD: -0.125127 lossG: 0.321861\n",
      "[14: 1680/1795] train lossD: -0.050712 lossG: 0.364646\n",
      "[14: 1685/1795] train lossD: -0.168766 lossG: 0.386137\n",
      "[14: 1690/1795] train lossD: -0.081204 lossG: 0.389975\n",
      "[14: 1695/1795] train lossD: -0.038811 lossG: 0.289909\n",
      "[14: 1700/1795] train lossD: -0.078125 lossG: 0.352642\n",
      "[14: 1705/1795] train lossD: -0.135460 lossG: 0.370364\n",
      "[14: 1710/1795] train lossD: -0.097935 lossG: 0.488981\n",
      "[14: 1715/1795] train lossD: -0.127058 lossG: 0.559892\n",
      "[14: 1720/1795] train lossD: -0.141138 lossG: 0.312621\n",
      "[14: 1725/1795] train lossD: -0.102903 lossG: 0.349684\n",
      "[14: 1730/1795] train lossD: -0.114908 lossG: 0.559658\n",
      "[14: 1735/1795] train lossD: -0.119988 lossG: 0.462957\n",
      "[14: 1740/1795] train lossD: -0.144401 lossG: 0.442630\n",
      "[14: 1745/1795] train lossD: -0.105939 lossG: 0.390880\n",
      "[14: 1750/1795] train lossD: -0.098968 lossG: 0.409770\n",
      "[14: 1755/1795] train lossD: -0.162354 lossG: 0.356527\n",
      "[14: 1760/1795] train lossD: -0.048923 lossG: 0.447748\n",
      "[14: 1765/1795] train lossD: -0.158340 lossG: 0.368906\n",
      "[14: 1770/1795] train lossD: -0.090802 lossG: 0.368451\n",
      "[14: 1775/1795] train lossD: -0.003241 lossG: 0.331455\n",
      "[14: 1780/1795] train lossD: -0.053330 lossG: 0.341659\n",
      "[14: 1785/1795] train lossD: -0.177158 lossG: 0.324964\n",
      "[14: 1790/1795] train lossD: -0.054650 lossG: 0.409048\n",
      "0.035055823624134064\n",
      "[15: 0/1795] train lossD: 0.049473 lossG: 0.292418\n",
      "[15: 5/1795] train lossD: -0.172763 lossG: 0.394934\n",
      "[15: 10/1795] train lossD: -0.088600 lossG: 0.411720\n",
      "[15: 15/1795] train lossD: -0.104356 lossG: 0.381700\n",
      "[15: 20/1795] train lossD: -0.110226 lossG: 0.325331\n",
      "[15: 25/1795] train lossD: -0.083875 lossG: 0.353919\n",
      "[15: 30/1795] train lossD: -0.086455 lossG: 0.364436\n",
      "[15: 35/1795] train lossD: -0.114201 lossG: 0.370675\n",
      "[15: 40/1795] train lossD: -0.089060 lossG: 0.299845\n",
      "[15: 45/1795] train lossD: -0.090511 lossG: 0.321010\n",
      "[15: 50/1795] train lossD: -0.007532 lossG: 0.372501\n",
      "[15: 55/1795] train lossD: 0.086003 lossG: 0.266716\n",
      "[15: 60/1795] train lossD: -0.175779 lossG: 0.274775\n",
      "[15: 65/1795] train lossD: -0.034491 lossG: 0.310579\n",
      "[15: 70/1795] train lossD: 0.087352 lossG: 0.259452\n",
      "[15: 75/1795] train lossD: -0.152574 lossG: 0.294439\n",
      "[15: 80/1795] train lossD: -0.117720 lossG: 0.325639\n",
      "[15: 85/1795] train lossD: -0.101209 lossG: 0.266887\n",
      "[15: 90/1795] train lossD: -0.092533 lossG: 0.314342\n",
      "[15: 95/1795] train lossD: -0.083409 lossG: 0.261847\n",
      "[15: 100/1795] train lossD: -0.069239 lossG: 0.293158\n",
      "[15: 105/1795] train lossD: 0.000658 lossG: 0.303112\n",
      "[15: 110/1795] train lossD: -0.077066 lossG: 0.245952\n",
      "[15: 115/1795] train lossD: -0.089390 lossG: 0.296492\n",
      "[15: 120/1795] train lossD: -0.205186 lossG: 0.212875\n",
      "[15: 125/1795] train lossD: -0.018486 lossG: 0.370017\n",
      "[15: 130/1795] train lossD: -0.101412 lossG: 0.323863\n",
      "[15: 135/1795] train lossD: -0.122382 lossG: 0.319394\n",
      "[15: 140/1795] train lossD: 0.073800 lossG: 0.243989\n",
      "[15: 145/1795] train lossD: -0.047248 lossG: 0.290473\n",
      "[15: 150/1795] train lossD: -0.069127 lossG: 0.263026\n",
      "[15: 155/1795] train lossD: -0.122704 lossG: 0.255508\n",
      "[15: 160/1795] train lossD: -0.128704 lossG: 0.326517\n",
      "[15: 165/1795] train lossD: -0.087103 lossG: 0.303202\n",
      "[15: 170/1795] train lossD: -0.083498 lossG: 0.230941\n",
      "[15: 175/1795] train lossD: -0.014692 lossG: 0.388333\n",
      "[15: 180/1795] train lossD: -0.101479 lossG: 0.331317\n",
      "[15: 185/1795] train lossD: -0.122810 lossG: 0.321433\n",
      "[15: 190/1795] train lossD: -0.087124 lossG: 0.353082\n",
      "[15: 195/1795] train lossD: -0.187108 lossG: 0.179048\n",
      "[15: 200/1795] train lossD: -0.030717 lossG: 0.273286\n",
      "[15: 205/1795] train lossD: -0.064348 lossG: 0.290782\n",
      "[15: 210/1795] train lossD: -0.087590 lossG: 0.222066\n",
      "[15: 215/1795] train lossD: -0.080157 lossG: 0.327097\n",
      "[15: 220/1795] train lossD: -0.095481 lossG: 0.292412\n",
      "[15: 225/1795] train lossD: -0.056766 lossG: 0.328859\n",
      "[15: 230/1795] train lossD: -0.095339 lossG: 0.392744\n",
      "[15: 235/1795] train lossD: -0.148971 lossG: 0.298459\n",
      "[15: 240/1795] train lossD: -0.122440 lossG: 0.459484\n",
      "[15: 245/1795] train lossD: -0.000589 lossG: 0.339925\n",
      "[15: 250/1795] train lossD: -0.083422 lossG: 0.258979\n",
      "[15: 255/1795] train lossD: -0.150906 lossG: 0.338494\n",
      "[15: 260/1795] train lossD: -0.080574 lossG: 0.291402\n",
      "[15: 265/1795] train lossD: -0.148685 lossG: 0.431531\n",
      "[15: 270/1795] train lossD: -0.123443 lossG: 0.272184\n",
      "[15: 275/1795] train lossD: -0.092007 lossG: 0.274630\n",
      "[15: 280/1795] train lossD: -0.072307 lossG: 0.375445\n",
      "[15: 285/1795] train lossD: -0.025029 lossG: 0.352387\n",
      "[15: 290/1795] train lossD: -0.074091 lossG: 0.425304\n",
      "[15: 295/1795] train lossD: -0.016689 lossG: 0.304159\n",
      "[15: 300/1795] train lossD: -0.133368 lossG: 0.432281\n",
      "[15: 305/1795] train lossD: -0.040660 lossG: 0.367200\n",
      "[15: 310/1795] train lossD: -0.050543 lossG: 0.379534\n",
      "[15: 315/1795] train lossD: -0.132310 lossG: 0.366632\n",
      "[15: 320/1795] train lossD: -0.114825 lossG: 0.268954\n",
      "[15: 325/1795] train lossD: -0.171152 lossG: 0.291411\n",
      "[15: 330/1795] train lossD: -0.031962 lossG: 0.542064\n",
      "[15: 335/1795] train lossD: -0.124114 lossG: 0.387095\n",
      "[15: 340/1795] train lossD: -0.063456 lossG: 0.314974\n",
      "[15: 345/1795] train lossD: -0.084505 lossG: 0.407555\n",
      "[15: 350/1795] train lossD: -0.113865 lossG: 0.308200\n",
      "[15: 355/1795] train lossD: -0.099418 lossG: 0.325853\n",
      "[15: 360/1795] train lossD: -0.180123 lossG: 0.309676\n",
      "[15: 365/1795] train lossD: -0.052598 lossG: 0.364669\n",
      "[15: 370/1795] train lossD: -0.095519 lossG: 0.330500\n",
      "[15: 375/1795] train lossD: -0.108938 lossG: 0.358057\n",
      "[15: 380/1795] train lossD: -0.179502 lossG: 0.424728\n",
      "[15: 385/1795] train lossD: -0.060611 lossG: 0.354854\n",
      "[15: 390/1795] train lossD: -0.127379 lossG: 0.302345\n",
      "[15: 395/1795] train lossD: -0.170460 lossG: 0.410025\n",
      "[15: 400/1795] train lossD: -0.044502 lossG: 0.399325\n",
      "[15: 405/1795] train lossD: -0.105766 lossG: 0.415753\n",
      "[15: 410/1795] train lossD: -0.104797 lossG: 0.553460\n",
      "[15: 415/1795] train lossD: -0.120127 lossG: 0.294710\n",
      "[15: 420/1795] train lossD: 0.194747 lossG: 0.473577\n",
      "[15: 425/1795] train lossD: -0.115561 lossG: 0.482320\n",
      "[15: 430/1795] train lossD: -0.114579 lossG: 0.377533\n",
      "[15: 435/1795] train lossD: -0.083565 lossG: 0.361615\n",
      "[15: 440/1795] train lossD: -0.097117 lossG: 0.423097\n",
      "[15: 445/1795] train lossD: -0.000238 lossG: 0.390327\n",
      "[15: 450/1795] train lossD: -0.118780 lossG: 0.347796\n",
      "[15: 455/1795] train lossD: -0.030614 lossG: 0.514672\n",
      "[15: 460/1795] train lossD: -0.062262 lossG: 0.446436\n",
      "[15: 465/1795] train lossD: -0.079550 lossG: 0.397665\n",
      "[15: 470/1795] train lossD: -0.072187 lossG: 0.461255\n",
      "[15: 475/1795] train lossD: -0.119110 lossG: 0.453317\n",
      "[15: 480/1795] train lossD: -0.096049 lossG: 0.404503\n",
      "[15: 485/1795] train lossD: -0.049714 lossG: 0.364354\n",
      "[15: 490/1795] train lossD: -0.116948 lossG: 0.378102\n",
      "[15: 495/1795] train lossD: 0.060398 lossG: 0.466339\n",
      "[15: 500/1795] train lossD: -0.048189 lossG: 0.330600\n",
      "[15: 505/1795] train lossD: 0.005744 lossG: 0.355544\n",
      "[15: 510/1795] train lossD: 0.044163 lossG: 0.300231\n",
      "[15: 515/1795] train lossD: -0.211760 lossG: 0.321994\n",
      "[15: 520/1795] train lossD: -0.074449 lossG: 0.338618\n",
      "[15: 525/1795] train lossD: -0.037240 lossG: 0.388770\n",
      "[15: 530/1795] train lossD: -0.156314 lossG: 0.446718\n",
      "[15: 535/1795] train lossD: -0.120178 lossG: 0.373633\n",
      "[15: 540/1795] train lossD: -0.156480 lossG: 0.324344\n",
      "[15: 545/1795] train lossD: -0.075579 lossG: 0.410949\n",
      "[15: 550/1795] train lossD: -0.212013 lossG: 0.508977\n",
      "[15: 555/1795] train lossD: -0.030011 lossG: 0.406211\n",
      "[15: 560/1795] train lossD: -0.085576 lossG: 0.405205\n",
      "[15: 565/1795] train lossD: -0.105360 lossG: 0.286570\n",
      "[15: 570/1795] train lossD: -0.005177 lossG: 0.340845\n",
      "[15: 575/1795] train lossD: -0.092987 lossG: 0.377872\n",
      "[15: 580/1795] train lossD: -0.187485 lossG: 0.431355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15: 585/1795] train lossD: -0.081895 lossG: 0.332304\n",
      "[15: 590/1795] train lossD: -0.109123 lossG: 0.274413\n",
      "[15: 595/1795] train lossD: -0.020077 lossG: 0.360716\n",
      "[15: 600/1795] train lossD: -0.077757 lossG: 0.348970\n",
      "[15: 605/1795] train lossD: -0.085812 lossG: 0.293818\n",
      "[15: 610/1795] train lossD: -0.207525 lossG: 0.402922\n",
      "[15: 615/1795] train lossD: 0.003161 lossG: 0.397149\n",
      "[15: 620/1795] train lossD: -0.092391 lossG: 0.223262\n",
      "[15: 625/1795] train lossD: 0.003487 lossG: 0.386814\n",
      "[15: 630/1795] train lossD: -0.117283 lossG: 0.387398\n",
      "[15: 635/1795] train lossD: -0.115547 lossG: 0.376021\n",
      "[15: 640/1795] train lossD: -0.135563 lossG: 0.309871\n",
      "[15: 645/1795] train lossD: -0.020874 lossG: 0.326631\n",
      "[15: 650/1795] train lossD: -0.123775 lossG: 0.365477\n",
      "[15: 655/1795] train lossD: -0.101141 lossG: 0.305537\n",
      "[15: 660/1795] train lossD: 0.003507 lossG: 0.523652\n",
      "[15: 665/1795] train lossD: -0.078542 lossG: 0.473627\n",
      "[15: 670/1795] train lossD: -0.096041 lossG: 0.375821\n",
      "[15: 675/1795] train lossD: -0.087741 lossG: 0.357968\n",
      "[15: 680/1795] train lossD: -0.122319 lossG: 0.319902\n",
      "[15: 685/1795] train lossD: -0.066193 lossG: 0.381677\n",
      "[15: 690/1795] train lossD: -0.061432 lossG: 0.325235\n",
      "[15: 695/1795] train lossD: -0.089548 lossG: 0.370174\n",
      "[15: 700/1795] train lossD: -0.127025 lossG: 0.381254\n",
      "[15: 705/1795] train lossD: -0.133869 lossG: 0.231305\n",
      "[15: 710/1795] train lossD: -0.144728 lossG: 0.376072\n",
      "[15: 715/1795] train lossD: -0.177731 lossG: 0.345174\n",
      "[15: 720/1795] train lossD: -0.136354 lossG: 0.260534\n",
      "[15: 725/1795] train lossD: -0.043428 lossG: 0.295539\n",
      "[15: 730/1795] train lossD: -0.045265 lossG: 0.466769\n",
      "[15: 735/1795] train lossD: -0.102377 lossG: 0.395557\n",
      "[15: 740/1795] train lossD: -0.173043 lossG: 0.342253\n",
      "[15: 745/1795] train lossD: -0.214005 lossG: 0.263087\n",
      "[15: 750/1795] train lossD: -0.100106 lossG: 0.471601\n",
      "[15: 755/1795] train lossD: -0.043964 lossG: 0.386621\n",
      "[15: 760/1795] train lossD: -0.142223 lossG: 0.428397\n",
      "[15: 765/1795] train lossD: -0.139930 lossG: 0.463048\n",
      "[15: 770/1795] train lossD: -0.066056 lossG: 0.434651\n",
      "[15: 775/1795] train lossD: -0.131521 lossG: 0.385664\n",
      "[15: 780/1795] train lossD: -0.208224 lossG: 0.447380\n",
      "[15: 785/1795] train lossD: -0.121575 lossG: 0.456827\n",
      "[15: 790/1795] train lossD: -0.089265 lossG: 0.299238\n",
      "[15: 795/1795] train lossD: 0.179151 lossG: 0.526325\n",
      "[15: 800/1795] train lossD: -0.150129 lossG: 0.422583\n",
      "[15: 805/1795] train lossD: -0.117661 lossG: 0.364454\n",
      "[15: 810/1795] train lossD: -0.141836 lossG: 0.544391\n",
      "[15: 815/1795] train lossD: -0.077672 lossG: 0.372592\n",
      "[15: 820/1795] train lossD: -0.082858 lossG: 0.509075\n",
      "[15: 825/1795] train lossD: -0.147139 lossG: 0.518060\n",
      "[15: 830/1795] train lossD: -0.101045 lossG: 0.365686\n",
      "[15: 835/1795] train lossD: -0.215198 lossG: 0.351048\n",
      "[15: 840/1795] train lossD: -0.069735 lossG: 0.595650\n",
      "[15: 845/1795] train lossD: -0.107575 lossG: 0.484438\n",
      "[15: 850/1795] train lossD: -0.057366 lossG: 0.453833\n",
      "[15: 855/1795] train lossD: -0.161035 lossG: 0.506715\n",
      "[15: 860/1795] train lossD: -0.092299 lossG: 0.499886\n",
      "[15: 865/1795] train lossD: -0.130350 lossG: 0.507845\n",
      "[15: 870/1795] train lossD: -0.253597 lossG: 0.433017\n",
      "[15: 875/1795] train lossD: -0.047326 lossG: 0.383255\n",
      "[15: 880/1795] train lossD: -0.067586 lossG: 0.276123\n",
      "[15: 885/1795] train lossD: -0.137467 lossG: 0.373266\n",
      "[15: 890/1795] train lossD: -0.066900 lossG: 0.346892\n",
      "[15: 895/1795] train lossD: -0.146363 lossG: 0.494074\n",
      "[15: 900/1795] train lossD: -0.133618 lossG: 0.303234\n",
      "[15: 905/1795] train lossD: -0.061056 lossG: 0.440611\n",
      "[15: 910/1795] train lossD: -0.116480 lossG: 0.448705\n",
      "[15: 915/1795] train lossD: -0.165004 lossG: 0.367087\n",
      "[15: 920/1795] train lossD: -0.246979 lossG: 0.410105\n",
      "[15: 925/1795] train lossD: -0.128665 lossG: 0.370195\n",
      "[15: 930/1795] train lossD: 0.008099 lossG: 0.538568\n",
      "[15: 935/1795] train lossD: -0.088972 lossG: 0.515924\n",
      "[15: 940/1795] train lossD: -0.095876 lossG: 0.444308\n",
      "[15: 945/1795] train lossD: -0.154687 lossG: 0.526640\n",
      "[15: 950/1795] train lossD: 0.090867 lossG: 0.431945\n",
      "[15: 955/1795] train lossD: -0.108329 lossG: 0.359310\n",
      "[15: 960/1795] train lossD: -0.187091 lossG: 0.347224\n",
      "[15: 965/1795] train lossD: -0.107682 lossG: 0.508026\n",
      "[15: 970/1795] train lossD: -0.120753 lossG: 0.361760\n",
      "[15: 975/1795] train lossD: -0.066351 lossG: 0.236333\n",
      "[15: 980/1795] train lossD: -0.088991 lossG: 0.462063\n",
      "[15: 985/1795] train lossD: -0.095778 lossG: 0.446422\n",
      "[15: 990/1795] train lossD: -0.125374 lossG: 0.611972\n",
      "[15: 995/1795] train lossD: -0.073585 lossG: 0.354037\n",
      "[15: 1000/1795] train lossD: -0.089346 lossG: 0.356469\n",
      "[15: 1005/1795] train lossD: -0.133330 lossG: 0.463670\n",
      "[15: 1010/1795] train lossD: -0.232220 lossG: 0.481567\n",
      "[15: 1015/1795] train lossD: -0.017670 lossG: 0.395189\n",
      "[15: 1020/1795] train lossD: -0.062582 lossG: 0.387000\n",
      "[15: 1025/1795] train lossD: 0.023524 lossG: 0.535102\n",
      "[15: 1030/1795] train lossD: -0.143071 lossG: 0.469007\n",
      "[15: 1035/1795] train lossD: -0.098584 lossG: 0.368642\n",
      "[15: 1040/1795] train lossD: -0.089714 lossG: 0.342457\n",
      "[15: 1045/1795] train lossD: -0.108868 lossG: 0.295917\n",
      "[15: 1050/1795] train lossD: -0.093639 lossG: 0.484811\n",
      "[15: 1055/1795] train lossD: -0.069976 lossG: 0.403627\n",
      "[15: 1060/1795] train lossD: -0.166973 lossG: 0.424398\n",
      "[15: 1065/1795] train lossD: -0.107975 lossG: 0.252184\n",
      "[15: 1070/1795] train lossD: 0.019627 lossG: 0.617897\n",
      "[15: 1075/1795] train lossD: -0.185256 lossG: 0.315563\n",
      "[15: 1080/1795] train lossD: -0.101392 lossG: 0.300574\n",
      "[15: 1085/1795] train lossD: 0.106335 lossG: 0.355278\n",
      "[15: 1090/1795] train lossD: -0.219352 lossG: 0.522552\n",
      "[15: 1095/1795] train lossD: -0.086471 lossG: 0.315077\n",
      "[15: 1100/1795] train lossD: -0.109550 lossG: 0.289391\n",
      "[15: 1105/1795] train lossD: -0.101529 lossG: 0.481870\n",
      "[15: 1110/1795] train lossD: 0.083000 lossG: 0.371056\n",
      "[15: 1115/1795] train lossD: -0.098227 lossG: 0.411204\n",
      "[15: 1120/1795] train lossD: -0.168572 lossG: 0.256918\n",
      "[15: 1125/1795] train lossD: -0.062590 lossG: 0.368181\n",
      "[15: 1130/1795] train lossD: -0.105713 lossG: 0.232081\n",
      "[15: 1135/1795] train lossD: -0.147175 lossG: 0.289282\n",
      "[15: 1140/1795] train lossD: -0.029500 lossG: 0.320829\n",
      "[15: 1145/1795] train lossD: -0.076449 lossG: 0.299543\n",
      "[15: 1150/1795] train lossD: -0.134870 lossG: 0.330147\n",
      "[15: 1155/1795] train lossD: -0.152961 lossG: 0.368395\n",
      "[15: 1160/1795] train lossD: -0.079933 lossG: 0.285286\n",
      "[15: 1165/1795] train lossD: -0.013557 lossG: 0.345360\n",
      "[15: 1170/1795] train lossD: -0.097455 lossG: 0.582526\n",
      "[15: 1175/1795] train lossD: -0.112246 lossG: 0.305107\n",
      "[15: 1180/1795] train lossD: -0.143590 lossG: 0.358180\n",
      "[15: 1185/1795] train lossD: -0.142676 lossG: 0.294497\n",
      "[15: 1190/1795] train lossD: -0.114269 lossG: 0.358703\n",
      "[15: 1195/1795] train lossD: -0.060009 lossG: 0.339751\n",
      "[15: 1200/1795] train lossD: -0.071311 lossG: 0.383291\n",
      "[15: 1205/1795] train lossD: -0.125383 lossG: 0.417917\n",
      "[15: 1210/1795] train lossD: -0.032818 lossG: 0.233438\n",
      "[15: 1215/1795] train lossD: -0.135609 lossG: 0.334284\n",
      "[15: 1220/1795] train lossD: -0.012222 lossG: 0.163622\n",
      "[15: 1225/1795] train lossD: -0.067532 lossG: 0.239184\n",
      "[15: 1230/1795] train lossD: 0.092089 lossG: 0.252765\n",
      "[15: 1235/1795] train lossD: -0.166482 lossG: 0.369936\n",
      "[15: 1240/1795] train lossD: -0.065292 lossG: 0.095068\n",
      "[15: 1245/1795] train lossD: -0.018928 lossG: 0.364857\n",
      "[15: 1250/1795] train lossD: -0.085313 lossG: 0.417165\n",
      "[15: 1255/1795] train lossD: -0.085972 lossG: 0.350821\n",
      "[15: 1260/1795] train lossD: -0.120101 lossG: 0.370040\n",
      "[15: 1265/1795] train lossD: 0.026126 lossG: 0.476905\n",
      "[15: 1270/1795] train lossD: -0.141696 lossG: 0.395697\n",
      "[15: 1275/1795] train lossD: -0.153889 lossG: 0.323716\n",
      "[15: 1280/1795] train lossD: -0.116868 lossG: 0.515673\n",
      "[15: 1285/1795] train lossD: -0.033594 lossG: 0.359804\n",
      "[15: 1290/1795] train lossD: -0.107772 lossG: 0.364660\n",
      "[15: 1295/1795] train lossD: -0.071070 lossG: 0.444931\n",
      "[15: 1300/1795] train lossD: -0.113320 lossG: 0.450352\n",
      "[15: 1305/1795] train lossD: -0.070610 lossG: 0.484695\n",
      "[15: 1310/1795] train lossD: -0.122833 lossG: 0.331542\n",
      "[15: 1315/1795] train lossD: -0.092648 lossG: 0.353237\n",
      "[15: 1320/1795] train lossD: -0.032690 lossG: 0.378553\n",
      "[15: 1325/1795] train lossD: -0.135300 lossG: 0.429033\n",
      "[15: 1330/1795] train lossD: 0.051135 lossG: 0.337036\n",
      "[15: 1335/1795] train lossD: 0.026398 lossG: 0.401842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15: 1340/1795] train lossD: -0.162447 lossG: 0.422100\n",
      "[15: 1345/1795] train lossD: -0.110531 lossG: 0.384050\n",
      "[15: 1350/1795] train lossD: -0.077629 lossG: 0.188809\n",
      "[15: 1355/1795] train lossD: -0.095115 lossG: 0.341881\n",
      "[15: 1360/1795] train lossD: -0.107892 lossG: 0.528337\n",
      "[15: 1365/1795] train lossD: -0.118546 lossG: 0.321949\n",
      "[15: 1370/1795] train lossD: -0.161756 lossG: 0.409417\n",
      "[15: 1375/1795] train lossD: -0.097987 lossG: 0.381022\n",
      "[15: 1380/1795] train lossD: -0.047101 lossG: 0.376652\n",
      "[15: 1385/1795] train lossD: -0.134328 lossG: 0.456751\n",
      "[15: 1390/1795] train lossD: -0.054668 lossG: 0.493053\n",
      "[15: 1395/1795] train lossD: -0.097914 lossG: 0.401583\n",
      "[15: 1400/1795] train lossD: -0.097978 lossG: 0.413899\n",
      "[15: 1405/1795] train lossD: -0.013411 lossG: 0.301917\n",
      "[15: 1410/1795] train lossD: -0.148528 lossG: 0.433917\n",
      "[15: 1415/1795] train lossD: -0.184462 lossG: 0.469560\n",
      "[15: 1420/1795] train lossD: -0.242981 lossG: 0.304513\n",
      "[15: 1425/1795] train lossD: -0.131188 lossG: 0.280257\n",
      "[15: 1430/1795] train lossD: -0.108805 lossG: 0.330745\n",
      "[15: 1435/1795] train lossD: -0.101507 lossG: 0.385001\n",
      "[15: 1440/1795] train lossD: -0.111222 lossG: 0.462737\n",
      "[15: 1445/1795] train lossD: -0.160888 lossG: 0.339884\n",
      "[15: 1450/1795] train lossD: -0.264806 lossG: 0.342546\n",
      "[15: 1455/1795] train lossD: -0.025629 lossG: 0.168407\n",
      "[15: 1460/1795] train lossD: -0.034452 lossG: 0.312774\n",
      "[15: 1465/1795] train lossD: -0.129169 lossG: 0.409489\n",
      "[15: 1470/1795] train lossD: -0.087677 lossG: 0.362768\n",
      "[15: 1475/1795] train lossD: -0.073218 lossG: 0.397907\n",
      "[15: 1480/1795] train lossD: -0.036446 lossG: 0.338957\n",
      "[15: 1485/1795] train lossD: -0.084086 lossG: 0.292778\n",
      "[15: 1490/1795] train lossD: -0.184977 lossG: 0.399498\n",
      "[15: 1495/1795] train lossD: -0.191119 lossG: 0.207613\n",
      "[15: 1500/1795] train lossD: -0.101803 lossG: 0.468231\n",
      "[15: 1505/1795] train lossD: -0.044934 lossG: 0.350543\n",
      "[15: 1510/1795] train lossD: -0.089829 lossG: 0.641611\n",
      "[15: 1515/1795] train lossD: -0.158868 lossG: 0.358912\n",
      "[15: 1520/1795] train lossD: -0.004576 lossG: 0.438601\n",
      "[15: 1525/1795] train lossD: -0.175912 lossG: 0.196323\n",
      "[15: 1530/1795] train lossD: -0.113827 lossG: 0.329300\n",
      "[15: 1535/1795] train lossD: -0.108932 lossG: 0.301547\n",
      "[15: 1540/1795] train lossD: -0.119785 lossG: 0.340041\n",
      "[15: 1545/1795] train lossD: -0.138433 lossG: 0.464588\n",
      "[15: 1550/1795] train lossD: -0.114212 lossG: 0.366860\n",
      "[15: 1555/1795] train lossD: -0.134654 lossG: 0.316864\n",
      "[15: 1560/1795] train lossD: -0.055280 lossG: 0.313056\n",
      "[15: 1565/1795] train lossD: 0.090192 lossG: 0.451944\n",
      "[15: 1570/1795] train lossD: 0.011899 lossG: 0.471454\n",
      "[15: 1575/1795] train lossD: -0.171936 lossG: 0.443090\n",
      "[15: 1580/1795] train lossD: 0.027493 lossG: 0.601418\n",
      "[15: 1585/1795] train lossD: 0.056278 lossG: 0.417011\n",
      "[15: 1590/1795] train lossD: -0.128183 lossG: 0.324774\n",
      "[15: 1595/1795] train lossD: -0.061839 lossG: 0.454994\n",
      "[15: 1600/1795] train lossD: -0.125463 lossG: 0.444555\n",
      "[15: 1605/1795] train lossD: 0.175637 lossG: 0.469089\n",
      "[15: 1610/1795] train lossD: -0.133058 lossG: 0.417663\n",
      "[15: 1615/1795] train lossD: -0.073256 lossG: 0.282389\n",
      "[15: 1620/1795] train lossD: -0.055243 lossG: 0.434379\n",
      "[15: 1625/1795] train lossD: 0.544821 lossG: 0.321997\n",
      "[15: 1630/1795] train lossD: -0.033037 lossG: 0.352108\n",
      "[15: 1635/1795] train lossD: -0.113947 lossG: 0.386239\n",
      "[15: 1640/1795] train lossD: -0.102137 lossG: 0.327128\n",
      "[15: 1645/1795] train lossD: -0.138266 lossG: 0.375948\n",
      "[15: 1650/1795] train lossD: -0.146470 lossG: 0.298793\n",
      "[15: 1655/1795] train lossD: -0.003765 lossG: 0.391042\n",
      "[15: 1660/1795] train lossD: -0.229515 lossG: 0.404112\n",
      "[15: 1665/1795] train lossD: -0.046181 lossG: 0.415666\n",
      "[15: 1670/1795] train lossD: -0.036103 lossG: 0.519910\n",
      "[15: 1675/1795] train lossD: -0.142312 lossG: 0.443538\n",
      "[15: 1680/1795] train lossD: -0.113119 lossG: 0.359823\n",
      "[15: 1685/1795] train lossD: -0.078335 lossG: 0.410462\n",
      "[15: 1690/1795] train lossD: -0.073657 lossG: 0.260952\n",
      "[15: 1695/1795] train lossD: -0.037902 lossG: 0.301189\n",
      "[15: 1700/1795] train lossD: -0.050588 lossG: 0.270318\n",
      "[15: 1705/1795] train lossD: -0.151926 lossG: 0.400633\n",
      "[15: 1710/1795] train lossD: 0.022353 lossG: 0.320754\n",
      "[15: 1715/1795] train lossD: -0.116930 lossG: 0.262969\n",
      "[15: 1720/1795] train lossD: -0.091937 lossG: 0.380888\n",
      "[15: 1725/1795] train lossD: -0.055043 lossG: 0.339115\n",
      "[15: 1730/1795] train lossD: -0.143893 lossG: 0.366349\n",
      "[15: 1735/1795] train lossD: -0.077809 lossG: 0.381478\n",
      "[15: 1740/1795] train lossD: 0.047947 lossG: 0.459594\n",
      "[15: 1745/1795] train lossD: -0.035908 lossG: 0.492991\n",
      "[15: 1750/1795] train lossD: -0.095418 lossG: 0.424545\n",
      "[15: 1755/1795] train lossD: -0.085792 lossG: 0.435082\n",
      "[15: 1760/1795] train lossD: -0.132958 lossG: 0.439156\n",
      "[15: 1765/1795] train lossD: -0.153753 lossG: 0.332998\n",
      "[15: 1770/1795] train lossD: -0.154585 lossG: 0.325291\n",
      "[15: 1775/1795] train lossD: -0.030816 lossG: 0.590103\n",
      "[15: 1780/1795] train lossD: -0.081635 lossG: 0.506953\n",
      "[15: 1785/1795] train lossD: -0.081341 lossG: 0.343510\n",
      "[15: 1790/1795] train lossD: -0.083754 lossG: 0.333619\n",
      "0.05547195300459862\n",
      "[16: 0/1795] train lossD: 3.094754 lossG: 0.336056\n",
      "[16: 5/1795] train lossD: -0.031061 lossG: 0.436208\n",
      "[16: 10/1795] train lossD: -0.054562 lossG: 0.436193\n",
      "[16: 15/1795] train lossD: -0.060412 lossG: 0.492038\n",
      "[16: 20/1795] train lossD: -0.057499 lossG: 0.479837\n",
      "[16: 25/1795] train lossD: -0.194185 lossG: 0.419705\n",
      "[16: 30/1795] train lossD: -0.071154 lossG: 0.441387\n",
      "[16: 35/1795] train lossD: -0.070213 lossG: 0.343059\n",
      "[16: 40/1795] train lossD: -0.122034 lossG: 0.212672\n",
      "[16: 45/1795] train lossD: -0.118189 lossG: 0.159284\n",
      "[16: 50/1795] train lossD: 0.195287 lossG: 0.174668\n",
      "[16: 55/1795] train lossD: -0.064582 lossG: 0.244251\n",
      "[16: 60/1795] train lossD: -0.067169 lossG: 0.308129\n",
      "[16: 65/1795] train lossD: -0.099126 lossG: 0.302399\n",
      "[16: 70/1795] train lossD: -0.202914 lossG: 0.264774\n",
      "[16: 75/1795] train lossD: -0.041972 lossG: 0.361091\n",
      "[16: 80/1795] train lossD: -0.050219 lossG: 0.248157\n",
      "[16: 85/1795] train lossD: -0.071682 lossG: 0.282854\n",
      "[16: 90/1795] train lossD: -0.071802 lossG: 0.344866\n",
      "[16: 95/1795] train lossD: -0.052349 lossG: 0.421155\n",
      "[16: 100/1795] train lossD: -0.162492 lossG: 0.295497\n",
      "[16: 105/1795] train lossD: -0.027652 lossG: 0.272841\n",
      "[16: 110/1795] train lossD: -0.051624 lossG: 0.182398\n",
      "[16: 115/1795] train lossD: -0.126212 lossG: 0.357698\n",
      "[16: 120/1795] train lossD: -0.105543 lossG: 0.250982\n",
      "[16: 125/1795] train lossD: -0.125495 lossG: 0.181268\n",
      "[16: 130/1795] train lossD: -0.059583 lossG: 0.334661\n",
      "[16: 135/1795] train lossD: -0.036754 lossG: 0.427179\n",
      "[16: 140/1795] train lossD: -0.130506 lossG: 0.490417\n",
      "[16: 145/1795] train lossD: -0.066422 lossG: 0.307770\n",
      "[16: 150/1795] train lossD: -0.059418 lossG: 0.280106\n",
      "[16: 155/1795] train lossD: -0.098826 lossG: 0.317126\n",
      "[16: 160/1795] train lossD: -0.001422 lossG: 0.441351\n",
      "[16: 165/1795] train lossD: -0.102228 lossG: 0.467007\n",
      "[16: 170/1795] train lossD: -0.075458 lossG: 0.401976\n",
      "[16: 175/1795] train lossD: -0.007523 lossG: 0.432713\n",
      "[16: 180/1795] train lossD: -0.015490 lossG: 0.384900\n",
      "[16: 185/1795] train lossD: -0.057466 lossG: 0.378912\n",
      "[16: 190/1795] train lossD: -0.126983 lossG: 0.368216\n",
      "[16: 195/1795] train lossD: -0.092919 lossG: 0.520639\n",
      "[16: 200/1795] train lossD: -0.099464 lossG: 0.300308\n",
      "[16: 205/1795] train lossD: 0.080637 lossG: 0.421694\n",
      "[16: 210/1795] train lossD: -0.075335 lossG: 0.374395\n",
      "[16: 215/1795] train lossD: -0.104624 lossG: 0.328458\n",
      "[16: 220/1795] train lossD: -0.083650 lossG: 0.292695\n",
      "[16: 225/1795] train lossD: 0.100834 lossG: 0.562868\n",
      "[16: 230/1795] train lossD: -0.105526 lossG: 0.537388\n",
      "[16: 235/1795] train lossD: -0.096366 lossG: 0.524728\n",
      "[16: 240/1795] train lossD: -0.098878 lossG: 0.456041\n",
      "[16: 245/1795] train lossD: -0.074110 lossG: 0.445261\n",
      "[16: 250/1795] train lossD: -0.103899 lossG: 0.409203\n",
      "[16: 255/1795] train lossD: -0.100814 lossG: 0.447368\n",
      "[16: 260/1795] train lossD: -0.096729 lossG: 0.356335\n",
      "[16: 265/1795] train lossD: -0.065930 lossG: 0.248562\n",
      "[16: 270/1795] train lossD: -0.055040 lossG: 0.354555\n",
      "[16: 275/1795] train lossD: -0.087138 lossG: 0.346772\n",
      "[16: 280/1795] train lossD: -0.020780 lossG: 0.442185\n",
      "[16: 285/1795] train lossD: -0.047277 lossG: 0.232291\n",
      "[16: 290/1795] train lossD: -0.079475 lossG: 0.216923\n",
      "[16: 295/1795] train lossD: -0.202249 lossG: 0.354570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16: 300/1795] train lossD: -0.039939 lossG: 0.334696\n",
      "[16: 305/1795] train lossD: -0.126365 lossG: 0.468998\n",
      "[16: 310/1795] train lossD: -0.100519 lossG: 0.320835\n",
      "[16: 315/1795] train lossD: -0.159447 lossG: 0.238557\n",
      "[16: 320/1795] train lossD: -0.094285 lossG: 0.295213\n",
      "[16: 325/1795] train lossD: -0.037192 lossG: 0.505749\n",
      "[16: 330/1795] train lossD: -0.027410 lossG: 0.414166\n",
      "[16: 335/1795] train lossD: -0.063150 lossG: 0.380378\n",
      "[16: 340/1795] train lossD: -0.106016 lossG: 0.417258\n",
      "[16: 345/1795] train lossD: -0.043490 lossG: 0.390245\n",
      "[16: 350/1795] train lossD: -0.123373 lossG: 0.330037\n",
      "[16: 355/1795] train lossD: -0.096142 lossG: 0.409388\n",
      "[16: 360/1795] train lossD: -0.023007 lossG: 0.567067\n",
      "[16: 365/1795] train lossD: -0.048412 lossG: 0.402783\n",
      "[16: 370/1795] train lossD: -0.083136 lossG: 0.404730\n",
      "[16: 375/1795] train lossD: 0.034670 lossG: 0.431499\n",
      "[16: 380/1795] train lossD: -0.039461 lossG: 0.425097\n",
      "[16: 385/1795] train lossD: -0.073726 lossG: 0.301743\n",
      "[16: 390/1795] train lossD: -0.122044 lossG: 0.361053\n",
      "[16: 395/1795] train lossD: -0.088696 lossG: 0.284137\n",
      "[16: 400/1795] train lossD: -0.038550 lossG: 0.277896\n",
      "[16: 405/1795] train lossD: -0.032179 lossG: 0.235454\n",
      "[16: 410/1795] train lossD: -0.056936 lossG: 0.390892\n",
      "[16: 415/1795] train lossD: -0.060278 lossG: 0.316085\n",
      "[16: 420/1795] train lossD: -0.152673 lossG: 0.399772\n",
      "[16: 425/1795] train lossD: -0.136078 lossG: 0.278185\n",
      "[16: 430/1795] train lossD: 0.139363 lossG: 0.416269\n",
      "[16: 435/1795] train lossD: -0.109470 lossG: 0.489858\n",
      "[16: 440/1795] train lossD: -0.070709 lossG: 0.413826\n",
      "[16: 445/1795] train lossD: -0.072464 lossG: 0.448947\n",
      "[16: 450/1795] train lossD: -0.140778 lossG: 0.374335\n",
      "[16: 455/1795] train lossD: -0.049574 lossG: 0.332479\n",
      "[16: 460/1795] train lossD: -0.074231 lossG: 0.495231\n",
      "[16: 465/1795] train lossD: -0.190008 lossG: 0.499748\n",
      "[16: 470/1795] train lossD: -0.114842 lossG: 0.274596\n",
      "[16: 475/1795] train lossD: -0.062480 lossG: 0.341936\n",
      "[16: 480/1795] train lossD: -0.051866 lossG: 0.394412\n",
      "[16: 485/1795] train lossD: -0.118380 lossG: 0.332735\n",
      "[16: 490/1795] train lossD: -0.059099 lossG: 0.368381\n",
      "[16: 495/1795] train lossD: -0.110310 lossG: 0.386603\n",
      "[16: 500/1795] train lossD: -0.058658 lossG: 0.397423\n",
      "[16: 505/1795] train lossD: -0.096529 lossG: 0.327363\n",
      "[16: 510/1795] train lossD: -0.090602 lossG: 0.342807\n",
      "[16: 515/1795] train lossD: -0.105458 lossG: 0.323377\n",
      "[16: 520/1795] train lossD: -0.119916 lossG: 0.229721\n",
      "[16: 525/1795] train lossD: -0.051295 lossG: 0.312840\n",
      "[16: 530/1795] train lossD: -0.066639 lossG: 0.270283\n",
      "[16: 535/1795] train lossD: -0.149072 lossG: 0.402269\n",
      "[16: 540/1795] train lossD: -0.195119 lossG: 0.396767\n",
      "[16: 545/1795] train lossD: -0.202568 lossG: 0.308096\n",
      "[16: 550/1795] train lossD: -0.114179 lossG: 0.273867\n",
      "[16: 555/1795] train lossD: 0.019110 lossG: 0.346667\n",
      "[16: 560/1795] train lossD: -0.109247 lossG: 0.575856\n",
      "[16: 565/1795] train lossD: -0.124983 lossG: 0.341699\n",
      "[16: 570/1795] train lossD: -0.196166 lossG: 0.521235\n",
      "[16: 575/1795] train lossD: -0.095949 lossG: 0.367379\n",
      "[16: 580/1795] train lossD: -0.125499 lossG: 0.536248\n",
      "[16: 585/1795] train lossD: -0.165554 lossG: 0.419853\n",
      "[16: 590/1795] train lossD: -0.080848 lossG: 0.372871\n",
      "[16: 595/1795] train lossD: -0.064449 lossG: 0.282722\n",
      "[16: 600/1795] train lossD: 0.015189 lossG: 0.372442\n",
      "[16: 605/1795] train lossD: -0.088795 lossG: 0.488529\n",
      "[16: 610/1795] train lossD: -0.071628 lossG: 0.392122\n",
      "[16: 615/1795] train lossD: -0.088041 lossG: 0.378512\n",
      "[16: 620/1795] train lossD: -0.141761 lossG: 0.423141\n",
      "[16: 625/1795] train lossD: 0.242796 lossG: 0.311176\n",
      "[16: 630/1795] train lossD: -0.072401 lossG: 0.346375\n",
      "[16: 635/1795] train lossD: -0.031272 lossG: 0.453973\n",
      "[16: 640/1795] train lossD: -0.103399 lossG: 0.320430\n",
      "[16: 645/1795] train lossD: -0.034895 lossG: 0.341649\n",
      "[16: 650/1795] train lossD: 0.085763 lossG: 0.489766\n",
      "[16: 655/1795] train lossD: -0.093143 lossG: 0.426099\n",
      "[16: 660/1795] train lossD: -0.023002 lossG: 0.306622\n",
      "[16: 665/1795] train lossD: -0.121206 lossG: 0.419610\n",
      "[16: 670/1795] train lossD: -0.128953 lossG: 0.331628\n",
      "[16: 675/1795] train lossD: -0.077705 lossG: 0.435841\n",
      "[16: 680/1795] train lossD: -0.070439 lossG: 0.440011\n",
      "[16: 685/1795] train lossD: -0.136275 lossG: 0.401556\n",
      "[16: 690/1795] train lossD: -0.174460 lossG: 0.590287\n",
      "[16: 695/1795] train lossD: 0.061411 lossG: 0.405556\n",
      "[16: 700/1795] train lossD: -0.077288 lossG: 0.243782\n",
      "[16: 705/1795] train lossD: -0.154389 lossG: 0.529328\n",
      "[16: 710/1795] train lossD: 0.618375 lossG: 0.366029\n",
      "[16: 715/1795] train lossD: -0.067096 lossG: 0.433564\n",
      "[16: 720/1795] train lossD: -0.037710 lossG: 0.402281\n",
      "[16: 725/1795] train lossD: -0.078154 lossG: 0.383761\n",
      "[16: 730/1795] train lossD: -0.073386 lossG: 0.321536\n",
      "[16: 735/1795] train lossD: -0.089081 lossG: 0.281800\n",
      "[16: 740/1795] train lossD: 0.236159 lossG: 0.564964\n",
      "[16: 745/1795] train lossD: -0.151723 lossG: 0.598489\n",
      "[16: 750/1795] train lossD: -0.023878 lossG: 0.524559\n",
      "[16: 755/1795] train lossD: -0.030749 lossG: 0.468033\n",
      "[16: 760/1795] train lossD: -0.117858 lossG: 0.420564\n",
      "[16: 765/1795] train lossD: -0.027925 lossG: 0.511373\n",
      "[16: 770/1795] train lossD: -0.061488 lossG: 0.573582\n",
      "[16: 775/1795] train lossD: -0.203322 lossG: 0.591822\n",
      "[16: 780/1795] train lossD: -0.155750 lossG: 0.337933\n",
      "[16: 785/1795] train lossD: -0.025803 lossG: 0.435998\n",
      "[16: 790/1795] train lossD: -0.055494 lossG: 0.481847\n",
      "[16: 795/1795] train lossD: -0.116203 lossG: 0.438097\n",
      "[16: 800/1795] train lossD: -0.156247 lossG: 0.333973\n",
      "[16: 805/1795] train lossD: -0.079356 lossG: 0.275716\n",
      "[16: 810/1795] train lossD: -0.067316 lossG: 0.524878\n",
      "[16: 815/1795] train lossD: -0.080661 lossG: 0.513457\n",
      "[16: 820/1795] train lossD: -0.178535 lossG: 0.473886\n",
      "[16: 825/1795] train lossD: -0.021248 lossG: 0.289516\n",
      "[16: 830/1795] train lossD: -0.140085 lossG: 0.276822\n",
      "[16: 835/1795] train lossD: 0.120830 lossG: 0.442098\n",
      "[16: 840/1795] train lossD: -0.154226 lossG: 0.337521\n",
      "[16: 845/1795] train lossD: -0.121721 lossG: 0.343279\n",
      "[16: 850/1795] train lossD: -0.092788 lossG: 0.438687\n",
      "[16: 855/1795] train lossD: -0.272594 lossG: 0.332095\n",
      "[16: 860/1795] train lossD: -0.087412 lossG: 0.312561\n",
      "[16: 865/1795] train lossD: -0.023577 lossG: 0.553131\n",
      "[16: 870/1795] train lossD: -0.095469 lossG: 0.388548\n",
      "[16: 875/1795] train lossD: -0.098476 lossG: 0.354346\n",
      "[16: 880/1795] train lossD: -0.044925 lossG: 0.361878\n",
      "[16: 885/1795] train lossD: -0.203514 lossG: 0.383752\n",
      "[16: 890/1795] train lossD: -0.159210 lossG: 0.440967\n",
      "[16: 895/1795] train lossD: -0.132698 lossG: 0.271618\n",
      "[16: 900/1795] train lossD: -0.083316 lossG: 0.343887\n",
      "[16: 905/1795] train lossD: -0.066102 lossG: 0.176843\n",
      "[16: 910/1795] train lossD: -0.088698 lossG: 0.230282\n",
      "[16: 915/1795] train lossD: -0.053768 lossG: 0.275825\n",
      "[16: 920/1795] train lossD: -0.009919 lossG: 0.311060\n",
      "[16: 925/1795] train lossD: -0.188027 lossG: 0.257394\n",
      "[16: 930/1795] train lossD: 0.150182 lossG: 0.367792\n",
      "[16: 935/1795] train lossD: -0.007392 lossG: 0.197120\n",
      "[16: 940/1795] train lossD: -0.198045 lossG: 0.492141\n",
      "[16: 945/1795] train lossD: -0.179952 lossG: 0.321508\n",
      "[16: 950/1795] train lossD: -0.136571 lossG: 0.303856\n",
      "[16: 955/1795] train lossD: -0.119345 lossG: 0.488294\n",
      "[16: 960/1795] train lossD: -0.132025 lossG: 0.261689\n",
      "[16: 965/1795] train lossD: -0.211254 lossG: 0.481981\n",
      "[16: 970/1795] train lossD: -0.064674 lossG: 0.367985\n",
      "[16: 975/1795] train lossD: -0.053393 lossG: 0.314499\n",
      "[16: 980/1795] train lossD: -0.104975 lossG: 0.384625\n",
      "[16: 985/1795] train lossD: -0.182178 lossG: 0.428526\n",
      "[16: 990/1795] train lossD: -0.051601 lossG: 0.414849\n",
      "[16: 995/1795] train lossD: -0.141023 lossG: 0.210945\n",
      "[16: 1000/1795] train lossD: 0.030315 lossG: 0.449360\n",
      "[16: 1005/1795] train lossD: -0.129894 lossG: 0.315234\n",
      "[16: 1010/1795] train lossD: -0.164157 lossG: 0.484677\n",
      "[16: 1015/1795] train lossD: -0.069111 lossG: 0.397467\n",
      "[16: 1020/1795] train lossD: -0.075694 lossG: 0.576459\n",
      "[16: 1025/1795] train lossD: -0.291787 lossG: 0.418753\n",
      "[16: 1030/1795] train lossD: -0.125877 lossG: 0.420492\n",
      "[16: 1035/1795] train lossD: -0.104661 lossG: 0.393509\n",
      "[16: 1040/1795] train lossD: -0.102726 lossG: 0.481336\n",
      "[16: 1045/1795] train lossD: -0.071356 lossG: 0.165816\n",
      "[16: 1050/1795] train lossD: 0.030230 lossG: 0.196207\n",
      "[16: 1055/1795] train lossD: -0.046880 lossG: 0.225877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16: 1060/1795] train lossD: -0.011077 lossG: 0.280806\n",
      "[16: 1065/1795] train lossD: -0.067131 lossG: 0.329275\n",
      "[16: 1070/1795] train lossD: -0.081512 lossG: 0.322682\n",
      "[16: 1075/1795] train lossD: -0.088524 lossG: 0.296030\n",
      "[16: 1080/1795] train lossD: -0.096946 lossG: 0.364283\n",
      "[16: 1085/1795] train lossD: -0.099022 lossG: 0.334849\n",
      "[16: 1090/1795] train lossD: 0.022456 lossG: 0.427682\n",
      "[16: 1095/1795] train lossD: -0.031861 lossG: 0.400407\n",
      "[16: 1100/1795] train lossD: -0.121910 lossG: 0.563614\n",
      "[16: 1105/1795] train lossD: -0.081924 lossG: 0.439053\n",
      "[16: 1110/1795] train lossD: -0.195514 lossG: 0.470731\n",
      "[16: 1115/1795] train lossD: -0.176478 lossG: 0.343765\n",
      "[16: 1120/1795] train lossD: -0.144864 lossG: 0.266582\n",
      "[16: 1125/1795] train lossD: -0.214292 lossG: 0.196968\n",
      "[16: 1130/1795] train lossD: -0.074964 lossG: 0.430779\n",
      "[16: 1135/1795] train lossD: -0.112908 lossG: 0.339631\n",
      "[16: 1140/1795] train lossD: -0.104170 lossG: 0.486536\n",
      "[16: 1145/1795] train lossD: -0.089830 lossG: 0.333898\n",
      "[16: 1150/1795] train lossD: -0.081896 lossG: 0.405004\n",
      "[16: 1155/1795] train lossD: -0.175822 lossG: 0.323525\n",
      "[16: 1160/1795] train lossD: 0.004519 lossG: 0.361930\n",
      "[16: 1165/1795] train lossD: -0.272472 lossG: 0.380103\n",
      "[16: 1170/1795] train lossD: -0.065186 lossG: 0.311736\n",
      "[16: 1175/1795] train lossD: -0.036023 lossG: 0.429390\n",
      "[16: 1180/1795] train lossD: -0.046787 lossG: 0.377766\n",
      "[16: 1185/1795] train lossD: -0.150921 lossG: 0.348200\n",
      "[16: 1190/1795] train lossD: -0.103735 lossG: 0.502438\n",
      "[16: 1195/1795] train lossD: -0.092722 lossG: 0.308750\n",
      "[16: 1200/1795] train lossD: 0.109566 lossG: 0.258907\n",
      "[16: 1205/1795] train lossD: -0.110515 lossG: 0.368401\n",
      "[16: 1210/1795] train lossD: -0.066892 lossG: 0.373568\n",
      "[16: 1215/1795] train lossD: -0.109066 lossG: 0.379678\n",
      "[16: 1220/1795] train lossD: -0.065845 lossG: 0.453840\n",
      "[16: 1225/1795] train lossD: -0.094917 lossG: 0.330944\n",
      "[16: 1230/1795] train lossD: -0.090933 lossG: 0.338470\n",
      "[16: 1235/1795] train lossD: -0.140268 lossG: 0.307926\n",
      "[16: 1240/1795] train lossD: 0.099871 lossG: 0.364081\n",
      "[16: 1245/1795] train lossD: -0.076397 lossG: 0.413453\n",
      "[16: 1250/1795] train lossD: -0.090315 lossG: 0.368412\n",
      "[16: 1255/1795] train lossD: -0.113961 lossG: 0.437903\n",
      "[16: 1260/1795] train lossD: -0.102821 lossG: 0.392834\n",
      "[16: 1265/1795] train lossD: -0.207865 lossG: 0.477751\n",
      "[16: 1270/1795] train lossD: -0.055445 lossG: 0.296952\n",
      "[16: 1275/1795] train lossD: -0.052724 lossG: 0.495301\n",
      "[16: 1280/1795] train lossD: -0.186698 lossG: 0.378618\n",
      "[16: 1285/1795] train lossD: -0.163973 lossG: 0.452900\n",
      "[16: 1290/1795] train lossD: -0.146931 lossG: 0.319844\n",
      "[16: 1295/1795] train lossD: -0.106718 lossG: 0.326583\n",
      "[16: 1300/1795] train lossD: -0.139004 lossG: 0.373504\n",
      "[16: 1305/1795] train lossD: -0.148175 lossG: 0.436060\n",
      "[16: 1310/1795] train lossD: 0.047555 lossG: 0.182251\n",
      "[16: 1315/1795] train lossD: -0.111275 lossG: 0.226891\n",
      "[16: 1320/1795] train lossD: -0.162698 lossG: 0.335118\n",
      "[16: 1325/1795] train lossD: -0.052049 lossG: 0.162331\n",
      "[16: 1330/1795] train lossD: -0.137040 lossG: 0.301685\n",
      "[16: 1335/1795] train lossD: -0.206687 lossG: 0.248744\n",
      "[16: 1340/1795] train lossD: -0.136683 lossG: 0.382886\n",
      "[16: 1345/1795] train lossD: -0.078497 lossG: 0.239455\n",
      "[16: 1350/1795] train lossD: -0.010443 lossG: 0.462311\n",
      "[16: 1355/1795] train lossD: -0.032153 lossG: 0.440035\n",
      "[16: 1360/1795] train lossD: -0.070137 lossG: 0.492619\n",
      "[16: 1365/1795] train lossD: -0.074796 lossG: 0.366215\n",
      "[16: 1370/1795] train lossD: -0.241285 lossG: 0.395439\n",
      "[16: 1375/1795] train lossD: -0.015165 lossG: 0.351407\n",
      "[16: 1380/1795] train lossD: -0.184785 lossG: 0.428442\n",
      "[16: 1385/1795] train lossD: -0.047291 lossG: 0.336375\n",
      "[16: 1390/1795] train lossD: -0.149596 lossG: 0.354871\n",
      "[16: 1395/1795] train lossD: -0.141027 lossG: 0.290069\n",
      "[16: 1400/1795] train lossD: -0.207370 lossG: 0.375886\n",
      "[16: 1405/1795] train lossD: -0.345534 lossG: 0.283450\n",
      "[16: 1410/1795] train lossD: -0.174918 lossG: 0.176357\n",
      "[16: 1415/1795] train lossD: 0.016322 lossG: 0.362249\n",
      "[16: 1420/1795] train lossD: -0.003228 lossG: 0.388378\n",
      "[16: 1425/1795] train lossD: -0.129194 lossG: 0.393310\n",
      "[16: 1430/1795] train lossD: -0.075166 lossG: 0.424946\n",
      "[16: 1435/1795] train lossD: -0.007653 lossG: 0.361204\n",
      "[16: 1440/1795] train lossD: -0.203406 lossG: 0.372420\n",
      "[16: 1445/1795] train lossD: -0.144259 lossG: 0.341528\n",
      "[16: 1450/1795] train lossD: -0.093855 lossG: 0.355000\n",
      "[16: 1455/1795] train lossD: -0.103017 lossG: 0.353239\n",
      "[16: 1460/1795] train lossD: -0.181317 lossG: 0.710296\n",
      "[16: 1465/1795] train lossD: -0.300171 lossG: 0.517224\n",
      "[16: 1470/1795] train lossD: -0.107416 lossG: 0.396615\n",
      "[16: 1475/1795] train lossD: -0.063328 lossG: 0.257403\n",
      "[16: 1480/1795] train lossD: -0.056317 lossG: 0.305016\n",
      "[16: 1485/1795] train lossD: -0.037736 lossG: 0.326045\n",
      "[16: 1490/1795] train lossD: -0.156065 lossG: 0.450008\n",
      "[16: 1495/1795] train lossD: -0.040277 lossG: 0.246387\n",
      "[16: 1500/1795] train lossD: -0.126395 lossG: 0.323388\n",
      "[16: 1505/1795] train lossD: -0.037925 lossG: 0.274639\n",
      "[16: 1510/1795] train lossD: 0.169083 lossG: 0.641737\n",
      "[16: 1515/1795] train lossD: -0.045900 lossG: 0.434425\n",
      "[16: 1520/1795] train lossD: -0.046425 lossG: 0.396316\n",
      "[16: 1525/1795] train lossD: -0.088135 lossG: 0.444450\n",
      "[16: 1530/1795] train lossD: -0.040504 lossG: 0.345123\n",
      "[16: 1535/1795] train lossD: -0.115095 lossG: 0.384364\n",
      "[16: 1540/1795] train lossD: -0.110932 lossG: 0.435681\n",
      "[16: 1545/1795] train lossD: -0.061767 lossG: 0.338314\n",
      "[16: 1550/1795] train lossD: -0.054578 lossG: 0.414896\n",
      "[16: 1555/1795] train lossD: -0.107054 lossG: 0.353979\n",
      "[16: 1560/1795] train lossD: -0.204611 lossG: 0.491543\n",
      "[16: 1565/1795] train lossD: -0.111199 lossG: 0.173869\n",
      "[16: 1570/1795] train lossD: -0.046324 lossG: 0.289106\n",
      "[16: 1575/1795] train lossD: -0.174675 lossG: 0.303337\n",
      "[16: 1580/1795] train lossD: -0.074512 lossG: 0.360475\n",
      "[16: 1585/1795] train lossD: -0.135500 lossG: 0.294039\n",
      "[16: 1590/1795] train lossD: -0.057895 lossG: 0.211598\n",
      "[16: 1595/1795] train lossD: -0.069813 lossG: 0.323172\n",
      "[16: 1600/1795] train lossD: -0.052170 lossG: 0.369638\n",
      "[16: 1605/1795] train lossD: -0.153288 lossG: 0.433839\n",
      "[16: 1610/1795] train lossD: -0.137854 lossG: 0.378612\n",
      "[16: 1615/1795] train lossD: -0.372381 lossG: 0.462569\n",
      "[16: 1620/1795] train lossD: -0.029406 lossG: 0.187673\n",
      "[16: 1625/1795] train lossD: -0.015617 lossG: 0.206311\n",
      "[16: 1630/1795] train lossD: -0.041482 lossG: 0.209759\n",
      "[16: 1635/1795] train lossD: -0.034620 lossG: 0.198376\n",
      "[16: 1640/1795] train lossD: -0.040048 lossG: 0.403435\n",
      "[16: 1645/1795] train lossD: -0.054548 lossG: 0.356392\n",
      "[16: 1650/1795] train lossD: -0.071560 lossG: 0.368387\n",
      "[16: 1655/1795] train lossD: -0.137121 lossG: 0.419580\n",
      "[16: 1660/1795] train lossD: -0.107366 lossG: 0.519027\n",
      "[16: 1665/1795] train lossD: -0.089004 lossG: 0.417312\n",
      "[16: 1670/1795] train lossD: -0.178504 lossG: 0.309869\n",
      "[16: 1675/1795] train lossD: 0.276876 lossG: 0.335729\n",
      "[16: 1680/1795] train lossD: -0.060119 lossG: 0.498923\n",
      "[16: 1685/1795] train lossD: -0.133789 lossG: 0.399093\n",
      "[16: 1690/1795] train lossD: -0.118280 lossG: 0.435309\n",
      "[16: 1695/1795] train lossD: -0.142250 lossG: 0.515347\n",
      "[16: 1700/1795] train lossD: -0.085831 lossG: 0.487324\n",
      "[16: 1705/1795] train lossD: -0.056692 lossG: 0.451751\n",
      "[16: 1710/1795] train lossD: -0.109401 lossG: 0.492306\n",
      "[16: 1715/1795] train lossD: -0.096217 lossG: 0.453922\n",
      "[16: 1720/1795] train lossD: -0.036599 lossG: 0.354946\n",
      "[16: 1725/1795] train lossD: -0.098104 lossG: 0.416005\n",
      "[16: 1730/1795] train lossD: -0.088020 lossG: 0.415265\n",
      "[16: 1735/1795] train lossD: -0.146264 lossG: 0.297808\n",
      "[16: 1740/1795] train lossD: -0.012999 lossG: 0.609650\n",
      "[16: 1745/1795] train lossD: -0.056111 lossG: 0.308968\n",
      "[16: 1750/1795] train lossD: -0.043181 lossG: 0.352178\n",
      "[16: 1755/1795] train lossD: 0.110049 lossG: 0.410439\n",
      "[16: 1760/1795] train lossD: -0.081700 lossG: 0.359549\n",
      "[16: 1765/1795] train lossD: -0.236098 lossG: 0.311730\n",
      "[16: 1770/1795] train lossD: -0.287899 lossG: 0.312736\n",
      "[16: 1775/1795] train lossD: -0.051938 lossG: 0.227656\n",
      "[16: 1780/1795] train lossD: 0.490518 lossG: 0.140530\n",
      "[16: 1785/1795] train lossD: 1.090146 lossG: 0.101100\n",
      "[16: 1790/1795] train lossD: -0.066380 lossG: 0.175855\n",
      "0.05058055743575096\n",
      "[17: 0/1795] train lossD: -0.038610 lossG: 0.219123\n",
      "[17: 5/1795] train lossD: -0.057717 lossG: 0.276355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17: 10/1795] train lossD: -0.089045 lossG: 0.242428\n",
      "[17: 15/1795] train lossD: -0.251678 lossG: 0.256791\n",
      "[17: 20/1795] train lossD: -0.080202 lossG: 0.400576\n",
      "[17: 25/1795] train lossD: -0.078314 lossG: 0.352758\n",
      "[17: 30/1795] train lossD: -0.195568 lossG: 0.361221\n",
      "[17: 35/1795] train lossD: -0.206895 lossG: 0.206466\n",
      "[17: 40/1795] train lossD: -0.125894 lossG: 0.444504\n",
      "[17: 45/1795] train lossD: -0.189456 lossG: 0.329319\n",
      "[17: 50/1795] train lossD: 1.845560 lossG: 0.377016\n",
      "[17: 55/1795] train lossD: -0.034652 lossG: 0.437524\n",
      "[17: 60/1795] train lossD: -0.084188 lossG: 0.470407\n",
      "[17: 65/1795] train lossD: -0.040239 lossG: 0.392629\n",
      "[17: 70/1795] train lossD: -0.107431 lossG: 0.409380\n",
      "[17: 75/1795] train lossD: -0.211915 lossG: 0.361828\n",
      "[17: 80/1795] train lossD: -0.203115 lossG: 0.379959\n",
      "[17: 85/1795] train lossD: -0.023343 lossG: 0.319608\n",
      "[17: 90/1795] train lossD: -0.214570 lossG: 0.380666\n",
      "[17: 95/1795] train lossD: -0.065826 lossG: 0.245362\n",
      "[17: 100/1795] train lossD: -0.115846 lossG: 0.215472\n",
      "[17: 105/1795] train lossD: -0.159452 lossG: 0.433344\n",
      "[17: 110/1795] train lossD: -0.087249 lossG: 0.183123\n",
      "[17: 115/1795] train lossD: 0.007793 lossG: 0.509266\n",
      "[17: 120/1795] train lossD: -0.192159 lossG: 0.338170\n",
      "[17: 125/1795] train lossD: -0.110096 lossG: 0.314113\n",
      "[17: 130/1795] train lossD: 0.029836 lossG: 0.388567\n",
      "[17: 135/1795] train lossD: -0.124044 lossG: 0.464462\n",
      "[17: 140/1795] train lossD: 0.041096 lossG: 0.358035\n",
      "[17: 145/1795] train lossD: -0.032092 lossG: 0.439744\n",
      "[17: 150/1795] train lossD: -0.148563 lossG: 0.385884\n",
      "[17: 155/1795] train lossD: -0.204495 lossG: 0.298086\n",
      "[17: 160/1795] train lossD: -0.102226 lossG: 0.299667\n",
      "[17: 165/1795] train lossD: 0.004464 lossG: 0.457186\n",
      "[17: 170/1795] train lossD: -0.111937 lossG: 0.507162\n",
      "[17: 175/1795] train lossD: -0.059675 lossG: 0.494941\n",
      "[17: 180/1795] train lossD: -0.093723 lossG: 0.522106\n",
      "[17: 185/1795] train lossD: -0.085809 lossG: 0.274942\n",
      "[17: 190/1795] train lossD: -0.083504 lossG: 0.369312\n",
      "[17: 195/1795] train lossD: -0.010607 lossG: 0.347598\n",
      "[17: 200/1795] train lossD: -0.049723 lossG: 0.289454\n",
      "[17: 205/1795] train lossD: -0.018892 lossG: 0.403827\n",
      "[17: 210/1795] train lossD: -0.178644 lossG: 0.507303\n",
      "[17: 215/1795] train lossD: -0.095560 lossG: 0.321923\n",
      "[17: 220/1795] train lossD: 0.449495 lossG: 0.366395\n",
      "[17: 225/1795] train lossD: -0.082298 lossG: 0.472886\n",
      "[17: 230/1795] train lossD: -0.028988 lossG: 0.413298\n",
      "[17: 235/1795] train lossD: -0.124790 lossG: 0.480579\n",
      "[17: 240/1795] train lossD: -0.121439 lossG: 0.546533\n",
      "[17: 245/1795] train lossD: 0.029763 lossG: 0.501913\n",
      "[17: 250/1795] train lossD: -0.052583 lossG: 0.566455\n",
      "[17: 255/1795] train lossD: -0.036981 lossG: 0.600155\n",
      "[17: 260/1795] train lossD: -0.067804 lossG: 0.563505\n",
      "[17: 265/1795] train lossD: -0.069855 lossG: 0.461736\n",
      "[17: 270/1795] train lossD: -0.049029 lossG: 0.395954\n",
      "[17: 275/1795] train lossD: -0.109678 lossG: 0.315504\n",
      "[17: 280/1795] train lossD: -0.123220 lossG: 0.362058\n",
      "[17: 285/1795] train lossD: -0.080180 lossG: 0.553418\n",
      "[17: 290/1795] train lossD: -0.100147 lossG: 0.571353\n",
      "[17: 295/1795] train lossD: -0.126432 lossG: 0.521875\n",
      "[17: 300/1795] train lossD: -0.203814 lossG: 0.535084\n",
      "[17: 305/1795] train lossD: -0.049725 lossG: 0.418190\n",
      "[17: 310/1795] train lossD: -0.176256 lossG: 0.324174\n",
      "[17: 315/1795] train lossD: -0.074005 lossG: 0.525466\n",
      "[17: 320/1795] train lossD: -0.066287 lossG: 0.233098\n",
      "[17: 325/1795] train lossD: -0.246113 lossG: 0.405690\n",
      "[17: 330/1795] train lossD: -0.086975 lossG: 0.527773\n",
      "[17: 335/1795] train lossD: -0.088552 lossG: 0.487119\n",
      "[17: 340/1795] train lossD: -0.033014 lossG: 0.394079\n",
      "[17: 345/1795] train lossD: -0.093885 lossG: 0.417488\n",
      "[17: 350/1795] train lossD: -0.180017 lossG: 0.258282\n",
      "[17: 355/1795] train lossD: -0.153604 lossG: 0.270423\n",
      "[17: 360/1795] train lossD: -0.064838 lossG: 0.390653\n",
      "[17: 365/1795] train lossD: -0.186369 lossG: 0.344458\n",
      "[17: 370/1795] train lossD: 0.022705 lossG: 0.339219\n",
      "[17: 375/1795] train lossD: -0.126540 lossG: 0.391512\n",
      "[17: 380/1795] train lossD: -0.043175 lossG: 0.371759\n",
      "[17: 385/1795] train lossD: -0.093137 lossG: 0.432230\n",
      "[17: 390/1795] train lossD: -0.028296 lossG: 0.321621\n",
      "[17: 395/1795] train lossD: 0.024534 lossG: 0.467311\n",
      "[17: 400/1795] train lossD: -0.099831 lossG: 0.488757\n",
      "[17: 405/1795] train lossD: -0.110815 lossG: 0.526789\n",
      "[17: 410/1795] train lossD: -0.228630 lossG: 0.380632\n",
      "[17: 415/1795] train lossD: -0.247631 lossG: 0.313586\n",
      "[17: 420/1795] train lossD: -0.035250 lossG: 0.326752\n",
      "[17: 425/1795] train lossD: -0.220902 lossG: 0.221343\n",
      "[17: 430/1795] train lossD: -0.020870 lossG: 0.316257\n",
      "[17: 435/1795] train lossD: -0.357024 lossG: 0.352209\n",
      "[17: 440/1795] train lossD: -0.102751 lossG: 0.184405\n",
      "[17: 445/1795] train lossD: -0.130619 lossG: 0.176721\n",
      "[17: 450/1795] train lossD: 0.110567 lossG: 0.449781\n",
      "[17: 455/1795] train lossD: -0.073544 lossG: 0.552553\n",
      "[17: 460/1795] train lossD: -0.083588 lossG: 0.564479\n",
      "[17: 465/1795] train lossD: -0.059064 lossG: 0.510988\n",
      "[17: 470/1795] train lossD: -0.049096 lossG: 0.529508\n",
      "[17: 475/1795] train lossD: -0.026785 lossG: 0.447127\n",
      "[17: 480/1795] train lossD: -0.128800 lossG: 0.469624\n",
      "[17: 485/1795] train lossD: -0.097342 lossG: 0.432042\n",
      "[17: 490/1795] train lossD: -0.038456 lossG: 0.311008\n",
      "[17: 495/1795] train lossD: -0.120859 lossG: 0.531642\n",
      "[17: 500/1795] train lossD: -0.031645 lossG: 0.488808\n",
      "[17: 505/1795] train lossD: -0.202752 lossG: 0.460914\n",
      "[17: 510/1795] train lossD: -0.252182 lossG: 0.432008\n",
      "[17: 515/1795] train lossD: 2.411755 lossG: 0.347257\n",
      "[17: 520/1795] train lossD: -0.013346 lossG: 0.444469\n",
      "[17: 525/1795] train lossD: 0.429345 lossG: 0.591409\n",
      "[17: 530/1795] train lossD: -0.000576 lossG: 0.578782\n",
      "[17: 535/1795] train lossD: -0.061635 lossG: 0.529222\n",
      "[17: 540/1795] train lossD: -0.049809 lossG: 0.453453\n",
      "[17: 545/1795] train lossD: -0.067252 lossG: 0.417447\n",
      "[17: 550/1795] train lossD: -0.134433 lossG: 0.432583\n",
      "[17: 555/1795] train lossD: -0.047271 lossG: 0.337852\n",
      "[17: 560/1795] train lossD: -0.137065 lossG: 0.378381\n",
      "[17: 565/1795] train lossD: -0.247473 lossG: 0.361851\n",
      "[17: 570/1795] train lossD: -0.342910 lossG: 0.545243\n",
      "[17: 575/1795] train lossD: 0.242919 lossG: 0.392145\n",
      "[17: 580/1795] train lossD: -0.036637 lossG: 0.423644\n",
      "[17: 585/1795] train lossD: -0.075835 lossG: 0.386251\n",
      "[17: 590/1795] train lossD: -0.152960 lossG: 0.290124\n",
      "[17: 595/1795] train lossD: -0.174942 lossG: 0.495738\n",
      "[17: 600/1795] train lossD: -0.050451 lossG: 0.457550\n",
      "[17: 605/1795] train lossD: -0.113008 lossG: 0.511578\n",
      "[17: 610/1795] train lossD: -0.123083 lossG: 0.504777\n",
      "[17: 615/1795] train lossD: -0.224539 lossG: 0.396944\n",
      "[17: 620/1795] train lossD: -0.147556 lossG: 0.420765\n",
      "[17: 625/1795] train lossD: -0.095536 lossG: 0.333137\n",
      "[17: 630/1795] train lossD: -0.058061 lossG: 0.442732\n",
      "[17: 635/1795] train lossD: -0.035227 lossG: 0.454564\n",
      "[17: 640/1795] train lossD: -0.209302 lossG: 0.281908\n",
      "[17: 645/1795] train lossD: 2.244651 lossG: 0.334671\n",
      "[17: 650/1795] train lossD: -0.085596 lossG: 0.366832\n",
      "[17: 655/1795] train lossD: -0.061930 lossG: 0.431100\n",
      "[17: 660/1795] train lossD: -0.085766 lossG: 0.494995\n",
      "[17: 665/1795] train lossD: -0.049617 lossG: 0.429906\n",
      "[17: 670/1795] train lossD: -0.030395 lossG: 0.444995\n",
      "[17: 675/1795] train lossD: -0.060815 lossG: 0.391090\n",
      "[17: 680/1795] train lossD: 0.039761 lossG: 0.355503\n",
      "[17: 685/1795] train lossD: -0.164669 lossG: 0.409364\n",
      "[17: 690/1795] train lossD: 0.039601 lossG: 0.215958\n",
      "[17: 695/1795] train lossD: -0.118258 lossG: 0.342184\n",
      "[17: 700/1795] train lossD: -0.136806 lossG: 0.306521\n",
      "[17: 705/1795] train lossD: -0.064930 lossG: 0.249189\n",
      "[17: 710/1795] train lossD: -0.090597 lossG: 0.302343\n",
      "[17: 715/1795] train lossD: -0.133227 lossG: 0.350037\n",
      "[17: 720/1795] train lossD: -0.151031 lossG: 0.308454\n",
      "[17: 725/1795] train lossD: -0.227189 lossG: 0.292188\n",
      "[17: 730/1795] train lossD: -0.019643 lossG: 0.232436\n",
      "[17: 735/1795] train lossD: -0.062723 lossG: 0.188318\n",
      "[17: 740/1795] train lossD: -0.032676 lossG: 0.209442\n",
      "[17: 745/1795] train lossD: -0.151908 lossG: 0.456461\n",
      "[17: 750/1795] train lossD: -0.136038 lossG: 0.323924\n",
      "[17: 755/1795] train lossD: -0.139470 lossG: 0.390133\n",
      "[17: 760/1795] train lossD: 0.006923 lossG: 0.598941\n",
      "[17: 765/1795] train lossD: -0.040592 lossG: 0.598849\n",
      "[17: 770/1795] train lossD: -0.108281 lossG: 0.510868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17: 775/1795] train lossD: -0.013186 lossG: 0.455021\n",
      "[17: 780/1795] train lossD: -0.144587 lossG: 0.344790\n",
      "[17: 785/1795] train lossD: -0.148753 lossG: 0.365353\n",
      "[17: 790/1795] train lossD: -0.141330 lossG: 0.310246\n",
      "[17: 795/1795] train lossD: -0.058907 lossG: 0.404058\n",
      "[17: 800/1795] train lossD: -0.073195 lossG: 0.372760\n",
      "[17: 805/1795] train lossD: -0.064105 lossG: 0.362562\n",
      "[17: 810/1795] train lossD: -0.148960 lossG: 0.533101\n",
      "[17: 815/1795] train lossD: -0.158683 lossG: 0.329499\n",
      "[17: 820/1795] train lossD: -0.062317 lossG: 0.326578\n",
      "[17: 825/1795] train lossD: -0.067317 lossG: 0.201999\n",
      "[17: 830/1795] train lossD: -0.100625 lossG: 0.381475\n",
      "[17: 835/1795] train lossD: -0.210707 lossG: 0.419891\n",
      "[17: 840/1795] train lossD: -0.209586 lossG: 0.315252\n",
      "[17: 845/1795] train lossD: -0.009997 lossG: 0.276823\n",
      "[17: 850/1795] train lossD: -0.117592 lossG: 0.272448\n",
      "[17: 855/1795] train lossD: -0.085357 lossG: 0.200472\n",
      "[17: 860/1795] train lossD: -0.072363 lossG: 0.279284\n",
      "[17: 865/1795] train lossD: -0.160787 lossG: 0.273396\n",
      "[17: 870/1795] train lossD: -0.277070 lossG: 0.490993\n",
      "[17: 875/1795] train lossD: -0.091156 lossG: 0.392839\n",
      "[17: 880/1795] train lossD: -0.244995 lossG: 0.224799\n",
      "[17: 885/1795] train lossD: -0.083205 lossG: 0.083339\n",
      "[17: 890/1795] train lossD: -0.025245 lossG: 0.522232\n",
      "[17: 895/1795] train lossD: -0.088620 lossG: 0.511356\n",
      "[17: 900/1795] train lossD: -0.084300 lossG: 0.483182\n",
      "[17: 905/1795] train lossD: -0.087787 lossG: 0.436739\n",
      "[17: 910/1795] train lossD: -0.083422 lossG: 0.460140\n",
      "[17: 915/1795] train lossD: -0.174992 lossG: 0.448820\n",
      "[17: 920/1795] train lossD: -0.099840 lossG: 0.301397\n",
      "[17: 925/1795] train lossD: -0.126580 lossG: 0.320691\n",
      "[17: 930/1795] train lossD: -0.025362 lossG: 0.231887\n",
      "[17: 935/1795] train lossD: -0.163986 lossG: 0.444314\n",
      "[17: 940/1795] train lossD: -0.039597 lossG: 0.288560\n",
      "[17: 945/1795] train lossD: -0.109977 lossG: 0.345041\n",
      "[17: 950/1795] train lossD: -0.133197 lossG: 0.475136\n",
      "[17: 955/1795] train lossD: -0.111790 lossG: 0.394100\n",
      "[17: 960/1795] train lossD: -0.098557 lossG: 0.373888\n",
      "[17: 965/1795] train lossD: -0.186896 lossG: 0.354845\n",
      "[17: 970/1795] train lossD: -0.125213 lossG: 0.298840\n",
      "[17: 975/1795] train lossD: -0.283704 lossG: 0.366505\n",
      "[17: 980/1795] train lossD: -0.102706 lossG: 0.245100\n",
      "[17: 985/1795] train lossD: -0.025190 lossG: 0.253391\n",
      "[17: 990/1795] train lossD: -0.281694 lossG: 0.431701\n",
      "[17: 995/1795] train lossD: -0.012418 lossG: 0.048009\n",
      "[17: 1000/1795] train lossD: -0.044003 lossG: 0.107084\n",
      "[17: 1005/1795] train lossD: 0.045931 lossG: 0.276638\n",
      "[17: 1010/1795] train lossD: -0.056407 lossG: 0.354627\n",
      "[17: 1015/1795] train lossD: -0.240985 lossG: 0.392814\n",
      "[17: 1020/1795] train lossD: -0.127727 lossG: 0.218203\n",
      "[17: 1025/1795] train lossD: -0.253949 lossG: 0.468791\n",
      "[17: 1030/1795] train lossD: -0.163259 lossG: 0.113932\n",
      "[17: 1035/1795] train lossD: -0.161825 lossG: 0.427512\n",
      "[17: 1040/1795] train lossD: -0.065333 lossG: 0.431519\n",
      "[17: 1045/1795] train lossD: -0.018762 lossG: 0.297316\n",
      "[17: 1050/1795] train lossD: -0.200517 lossG: 0.364063\n",
      "[17: 1055/1795] train lossD: -0.065007 lossG: 0.311163\n",
      "[17: 1060/1795] train lossD: 0.030605 lossG: 0.213574\n",
      "[17: 1065/1795] train lossD: -0.029730 lossG: 0.244707\n",
      "[17: 1070/1795] train lossD: -0.041935 lossG: 0.243734\n",
      "[17: 1075/1795] train lossD: -0.049423 lossG: 0.270633\n",
      "[17: 1080/1795] train lossD: -0.108225 lossG: 0.301690\n",
      "[17: 1085/1795] train lossD: 0.880609 lossG: 0.100654\n",
      "[17: 1090/1795] train lossD: -0.057459 lossG: 0.087186\n",
      "[17: 1095/1795] train lossD: -0.007480 lossG: 0.182120\n",
      "[17: 1100/1795] train lossD: -0.095914 lossG: 0.172022\n",
      "[17: 1105/1795] train lossD: -0.162080 lossG: 0.222272\n",
      "[17: 1110/1795] train lossD: -0.241768 lossG: 0.279384\n",
      "[17: 1115/1795] train lossD: -0.259180 lossG: 0.262075\n",
      "[17: 1120/1795] train lossD: -0.132565 lossG: 0.382513\n",
      "[17: 1125/1795] train lossD: -0.159365 lossG: 0.217703\n",
      "[17: 1130/1795] train lossD: -0.089156 lossG: 0.358038\n",
      "[17: 1135/1795] train lossD: -0.174362 lossG: 0.292193\n",
      "[17: 1140/1795] train lossD: -0.181752 lossG: 0.226250\n",
      "[17: 1145/1795] train lossD: -0.011900 lossG: 0.510682\n",
      "[17: 1150/1795] train lossD: -0.037603 lossG: 0.403658\n",
      "[17: 1155/1795] train lossD: -0.114467 lossG: 0.405060\n",
      "[17: 1160/1795] train lossD: -0.093283 lossG: 0.364113\n",
      "[17: 1165/1795] train lossD: -0.328077 lossG: 0.430576\n",
      "[17: 1170/1795] train lossD: -0.189930 lossG: 0.191098\n",
      "[17: 1175/1795] train lossD: -0.141692 lossG: 0.463352\n",
      "[17: 1180/1795] train lossD: -0.174788 lossG: 0.169525\n",
      "[17: 1185/1795] train lossD: -0.131781 lossG: 0.454773\n",
      "[17: 1190/1795] train lossD: -0.087721 lossG: 0.210336\n",
      "[17: 1195/1795] train lossD: -0.205326 lossG: 0.296613\n",
      "[17: 1200/1795] train lossD: -0.242277 lossG: 0.233794\n",
      "[17: 1205/1795] train lossD: -0.021431 lossG: 0.298236\n",
      "[17: 1210/1795] train lossD: -0.101732 lossG: 0.210257\n",
      "[17: 1215/1795] train lossD: -0.058350 lossG: 0.404479\n",
      "[17: 1220/1795] train lossD: -0.022427 lossG: 0.345900\n",
      "[17: 1225/1795] train lossD: -0.143431 lossG: 0.449682\n",
      "[17: 1230/1795] train lossD: -0.104688 lossG: 0.402674\n",
      "[17: 1235/1795] train lossD: -0.131232 lossG: 0.330445\n",
      "[17: 1240/1795] train lossD: -0.037235 lossG: 0.290281\n",
      "[17: 1245/1795] train lossD: -0.097514 lossG: 0.321322\n",
      "[17: 1250/1795] train lossD: 0.003206 lossG: 0.487630\n",
      "[17: 1255/1795] train lossD: -0.063606 lossG: 0.490359\n",
      "[17: 1260/1795] train lossD: -0.066385 lossG: 0.410834\n",
      "[17: 1265/1795] train lossD: -0.277249 lossG: 0.359563\n",
      "[17: 1270/1795] train lossD: 0.440015 lossG: 0.102817\n",
      "[17: 1275/1795] train lossD: -0.051099 lossG: 0.216743\n",
      "[17: 1280/1795] train lossD: -0.122047 lossG: 0.225318\n",
      "[17: 1285/1795] train lossD: -0.190168 lossG: 0.342569\n",
      "[17: 1290/1795] train lossD: -0.108325 lossG: 0.487984\n",
      "[17: 1295/1795] train lossD: -0.042565 lossG: 0.200496\n",
      "[17: 1300/1795] train lossD: -0.362272 lossG: 0.271644\n",
      "[17: 1305/1795] train lossD: -0.091173 lossG: 0.267433\n",
      "[17: 1310/1795] train lossD: 0.426644 lossG: 0.091443\n",
      "[17: 1315/1795] train lossD: -0.028659 lossG: 0.152229\n",
      "[17: 1320/1795] train lossD: 0.000099 lossG: 0.205524\n",
      "[17: 1325/1795] train lossD: -0.070894 lossG: 0.222349\n",
      "[17: 1330/1795] train lossD: 0.019655 lossG: 0.254046\n",
      "[17: 1335/1795] train lossD: -0.068313 lossG: 0.229116\n",
      "[17: 1340/1795] train lossD: -0.115631 lossG: 0.200914\n",
      "[17: 1345/1795] train lossD: -0.195591 lossG: 0.497800\n",
      "[17: 1350/1795] train lossD: -0.045677 lossG: 0.099857\n",
      "[17: 1355/1795] train lossD: -0.061743 lossG: 0.301966\n",
      "[17: 1360/1795] train lossD: -0.101292 lossG: 0.287974\n",
      "[17: 1365/1795] train lossD: -0.103210 lossG: 0.249113\n",
      "[17: 1370/1795] train lossD: -0.026606 lossG: 0.104164\n",
      "[17: 1375/1795] train lossD: -0.061958 lossG: 0.144010\n",
      "[17: 1380/1795] train lossD: 0.036547 lossG: 0.216815\n",
      "[17: 1385/1795] train lossD: -0.245608 lossG: 0.233325\n",
      "[17: 1390/1795] train lossD: -0.124147 lossG: 0.189117\n",
      "[17: 1395/1795] train lossD: 0.063447 lossG: 0.249060\n",
      "[17: 1400/1795] train lossD: -0.063077 lossG: 0.317087\n",
      "[17: 1405/1795] train lossD: -0.210857 lossG: 0.543122\n",
      "[17: 1410/1795] train lossD: -0.169766 lossG: 0.097119\n",
      "[17: 1415/1795] train lossD: -0.094355 lossG: 0.245642\n",
      "[17: 1420/1795] train lossD: -0.158760 lossG: 0.317587\n",
      "[17: 1425/1795] train lossD: -0.062429 lossG: 0.400623\n",
      "[17: 1430/1795] train lossD: -0.029541 lossG: 0.394023\n",
      "[17: 1435/1795] train lossD: -0.195039 lossG: 0.319187\n",
      "[17: 1440/1795] train lossD: -0.122147 lossG: 0.271178\n",
      "[17: 1445/1795] train lossD: -0.123122 lossG: 0.310847\n",
      "[17: 1450/1795] train lossD: -0.057020 lossG: 0.203983\n",
      "[17: 1455/1795] train lossD: -0.082780 lossG: 0.249964\n",
      "[17: 1460/1795] train lossD: -0.034761 lossG: 0.291655\n",
      "[17: 1465/1795] train lossD: -0.327889 lossG: 0.379815\n",
      "[17: 1470/1795] train lossD: -0.100671 lossG: 0.104924\n",
      "[17: 1475/1795] train lossD: -0.097627 lossG: 0.349933\n",
      "[17: 1480/1795] train lossD: -0.086881 lossG: 0.385692\n",
      "[17: 1485/1795] train lossD: -0.049171 lossG: 0.423546\n",
      "[17: 1490/1795] train lossD: -0.073700 lossG: 0.381145\n",
      "[17: 1495/1795] train lossD: -0.061833 lossG: 0.307126\n",
      "[17: 1500/1795] train lossD: -0.120901 lossG: 0.347008\n",
      "[17: 1505/1795] train lossD: -0.305136 lossG: 0.281126\n",
      "[17: 1510/1795] train lossD: -0.101382 lossG: 0.244699\n",
      "[17: 1515/1795] train lossD: 0.016809 lossG: 0.221227\n",
      "[17: 1520/1795] train lossD: -0.159476 lossG: 0.250119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17: 1525/1795] train lossD: 0.052567 lossG: 0.423733\n",
      "[17: 1530/1795] train lossD: -0.039212 lossG: 0.466098\n",
      "[17: 1535/1795] train lossD: -0.010547 lossG: 0.452719\n",
      "[17: 1540/1795] train lossD: -0.045656 lossG: 0.414618\n",
      "[17: 1545/1795] train lossD: 0.153334 lossG: 0.369215\n",
      "[17: 1550/1795] train lossD: -0.034955 lossG: 0.421984\n",
      "[17: 1555/1795] train lossD: -0.214864 lossG: 0.317095\n",
      "[17: 1560/1795] train lossD: -0.064569 lossG: 0.352819\n",
      "[17: 1565/1795] train lossD: -0.149587 lossG: 0.270172\n",
      "[17: 1570/1795] train lossD: -0.052278 lossG: 0.300921\n",
      "[17: 1575/1795] train lossD: 0.094232 lossG: 0.271824\n",
      "[17: 1580/1795] train lossD: -0.069709 lossG: 0.214244\n",
      "[17: 1585/1795] train lossD: -0.201789 lossG: 0.489701\n",
      "[17: 1590/1795] train lossD: -0.199037 lossG: 0.210609\n",
      "[17: 1595/1795] train lossD: -0.149809 lossG: 0.217632\n",
      "[17: 1600/1795] train lossD: -0.040141 lossG: 0.378477\n",
      "[17: 1605/1795] train lossD: -0.249402 lossG: 0.353292\n",
      "[17: 1610/1795] train lossD: -0.306514 lossG: 0.279604\n",
      "[17: 1615/1795] train lossD: -0.021445 lossG: 0.265898\n",
      "[17: 1620/1795] train lossD: -0.042803 lossG: 0.249562\n",
      "[17: 1625/1795] train lossD: -0.121756 lossG: 0.302967\n",
      "[17: 1630/1795] train lossD: -0.070746 lossG: 0.296482\n",
      "[17: 1635/1795] train lossD: -0.138588 lossG: 0.377698\n",
      "[17: 1640/1795] train lossD: -0.087329 lossG: 0.247643\n",
      "[17: 1645/1795] train lossD: -0.038405 lossG: 0.244664\n",
      "[17: 1650/1795] train lossD: -0.036709 lossG: 0.259920\n",
      "[17: 1655/1795] train lossD: -0.128782 lossG: 0.217318\n",
      "[17: 1660/1795] train lossD: -0.060621 lossG: 0.274225\n",
      "[17: 1665/1795] train lossD: 0.205684 lossG: 0.410747\n",
      "[17: 1670/1795] train lossD: -0.026163 lossG: 0.514272\n",
      "[17: 1675/1795] train lossD: -0.074643 lossG: 0.518549\n",
      "[17: 1680/1795] train lossD: -0.050404 lossG: 0.406430\n",
      "[17: 1685/1795] train lossD: -0.131517 lossG: 0.368747\n",
      "[17: 1690/1795] train lossD: -0.384370 lossG: 0.196732\n",
      "[17: 1695/1795] train lossD: -0.046921 lossG: 0.253108\n",
      "[17: 1700/1795] train lossD: -0.026100 lossG: 0.254209\n",
      "[17: 1705/1795] train lossD: -0.134572 lossG: 0.460110\n",
      "[17: 1710/1795] train lossD: -0.147839 lossG: 0.317006\n",
      "[17: 1715/1795] train lossD: -0.173078 lossG: 0.278938\n",
      "[17: 1720/1795] train lossD: 0.017874 lossG: 0.173415\n",
      "[17: 1725/1795] train lossD: -0.160750 lossG: 0.430818\n",
      "[17: 1730/1795] train lossD: -0.509984 lossG: 0.269551\n",
      "[17: 1735/1795] train lossD: -0.373971 lossG: 0.449659\n",
      "[17: 1740/1795] train lossD: 0.001244 lossG: 0.221345\n",
      "[17: 1745/1795] train lossD: 0.023262 lossG: 0.247619\n",
      "[17: 1750/1795] train lossD: -0.107409 lossG: 0.393362\n",
      "[17: 1755/1795] train lossD: -0.444363 lossG: 0.352516\n",
      "[17: 1760/1795] train lossD: -0.377702 lossG: 0.241916\n",
      "[17: 1765/1795] train lossD: -0.245225 lossG: 0.291582\n",
      "[17: 1770/1795] train lossD: -0.263593 lossG: 0.256299\n",
      "[17: 1775/1795] train lossD: -0.264302 lossG: 0.345611\n",
      "[17: 1780/1795] train lossD: -0.026553 lossG: 0.180626\n",
      "[17: 1785/1795] train lossD: -0.044458 lossG: 0.215474\n",
      "[17: 1790/1795] train lossD: -0.084683 lossG: 0.188839\n",
      "0.044261276721954346\n",
      "[18: 0/1795] train lossD: -0.075365 lossG: 0.391618\n",
      "[18: 5/1795] train lossD: 0.693001 lossG: 0.464512\n",
      "[18: 10/1795] train lossD: -0.064249 lossG: 0.545787\n",
      "[18: 15/1795] train lossD: -0.252980 lossG: 0.462308\n",
      "[18: 20/1795] train lossD: 0.438757 lossG: 0.414597\n",
      "[18: 25/1795] train lossD: -0.112658 lossG: 0.536867\n",
      "[18: 30/1795] train lossD: -0.088939 lossG: 0.428785\n",
      "[18: 35/1795] train lossD: -0.258393 lossG: 0.209436\n",
      "[18: 40/1795] train lossD: -0.080840 lossG: 0.331513\n",
      "[18: 45/1795] train lossD: -0.147591 lossG: 0.207014\n",
      "[18: 50/1795] train lossD: -0.104544 lossG: 0.301374\n",
      "[18: 55/1795] train lossD: -0.198760 lossG: 0.131051\n",
      "[18: 60/1795] train lossD: 0.074300 lossG: 0.381794\n",
      "[18: 65/1795] train lossD: -0.104373 lossG: 0.291053\n",
      "[18: 70/1795] train lossD: -0.034479 lossG: 0.337319\n",
      "[18: 75/1795] train lossD: -0.234870 lossG: 0.114902\n",
      "[18: 80/1795] train lossD: 0.015374 lossG: 0.038574\n",
      "[18: 85/1795] train lossD: -0.231977 lossG: 0.363360\n",
      "[18: 90/1795] train lossD: -0.469708 lossG: 0.388843\n",
      "[18: 95/1795] train lossD: -0.213406 lossG: 0.231516\n",
      "[18: 100/1795] train lossD: -0.229802 lossG: 0.171889\n",
      "[18: 105/1795] train lossD: -0.130771 lossG: 0.262340\n",
      "[18: 110/1795] train lossD: -0.161852 lossG: 0.264003\n",
      "[18: 115/1795] train lossD: -0.072826 lossG: 0.219782\n",
      "[18: 120/1795] train lossD: -0.066421 lossG: 0.234630\n",
      "[18: 125/1795] train lossD: -0.074597 lossG: 0.267673\n",
      "[18: 130/1795] train lossD: -0.051005 lossG: 0.248989\n",
      "[18: 135/1795] train lossD: -0.001827 lossG: 0.230095\n",
      "[18: 140/1795] train lossD: -0.091619 lossG: 0.248153\n",
      "[18: 145/1795] train lossD: -0.045508 lossG: 0.420663\n",
      "[18: 150/1795] train lossD: -0.043645 lossG: 0.405987\n",
      "[18: 155/1795] train lossD: -0.092847 lossG: 0.403241\n",
      "[18: 160/1795] train lossD: -0.040806 lossG: 0.337139\n",
      "[18: 165/1795] train lossD: -0.224424 lossG: 0.498770\n",
      "[18: 170/1795] train lossD: -0.091050 lossG: 0.224473\n",
      "[18: 175/1795] train lossD: -0.147853 lossG: 0.205396\n",
      "[18: 180/1795] train lossD: -0.316634 lossG: 0.416208\n",
      "[18: 185/1795] train lossD: -0.082810 lossG: 0.192963\n",
      "[18: 190/1795] train lossD: -0.000112 lossG: 0.514798\n",
      "[18: 195/1795] train lossD: -0.031203 lossG: 0.535891\n",
      "[18: 200/1795] train lossD: -0.042578 lossG: 0.485416\n",
      "[18: 205/1795] train lossD: -0.115814 lossG: 0.396137\n",
      "[18: 210/1795] train lossD: -0.138564 lossG: 0.350400\n",
      "[18: 215/1795] train lossD: -0.233370 lossG: 0.195404\n",
      "[18: 220/1795] train lossD: 0.034134 lossG: 0.299975\n",
      "[18: 225/1795] train lossD: -0.049913 lossG: 0.418029\n",
      "[18: 230/1795] train lossD: -0.043577 lossG: 0.480549\n",
      "[18: 235/1795] train lossD: -0.057046 lossG: 0.437434\n",
      "[18: 240/1795] train lossD: -0.174859 lossG: 0.483010\n",
      "[18: 245/1795] train lossD: -0.239192 lossG: 0.450382\n",
      "[18: 250/1795] train lossD: -0.083896 lossG: 0.353520\n",
      "[18: 255/1795] train lossD: -0.331636 lossG: 0.261768\n",
      "[18: 260/1795] train lossD: -0.266146 lossG: 0.314478\n",
      "[18: 265/1795] train lossD: -0.117319 lossG: 0.099521\n",
      "[18: 270/1795] train lossD: -0.158720 lossG: 0.263387\n",
      "[18: 275/1795] train lossD: -0.178273 lossG: 0.193356\n",
      "[18: 280/1795] train lossD: 0.021489 lossG: 0.091593\n",
      "[18: 285/1795] train lossD: -0.130345 lossG: 0.089752\n",
      "[18: 290/1795] train lossD: -0.018744 lossG: 0.321420\n",
      "[18: 295/1795] train lossD: -0.169794 lossG: 0.374970\n",
      "[18: 300/1795] train lossD: -0.268407 lossG: 0.272566\n",
      "[18: 305/1795] train lossD: 0.003850 lossG: 0.536198\n",
      "[18: 310/1795] train lossD: -0.307727 lossG: 0.238194\n",
      "[18: 315/1795] train lossD: 0.083010 lossG: 0.143053\n",
      "[18: 320/1795] train lossD: 0.048414 lossG: 0.123444\n",
      "[18: 325/1795] train lossD: -0.056941 lossG: 0.463150\n",
      "[18: 330/1795] train lossD: -0.078842 lossG: 0.503971\n",
      "[18: 335/1795] train lossD: -0.085177 lossG: 0.504115\n",
      "[18: 340/1795] train lossD: -0.118075 lossG: 0.437711\n",
      "[18: 345/1795] train lossD: -0.123122 lossG: 0.398644\n",
      "[18: 350/1795] train lossD: -0.212367 lossG: 0.302019\n",
      "[18: 355/1795] train lossD: -0.072696 lossG: 0.236753\n",
      "[18: 360/1795] train lossD: -0.223848 lossG: 0.347492\n",
      "[18: 365/1795] train lossD: 0.061230 lossG: 0.172924\n",
      "[18: 370/1795] train lossD: -0.105809 lossG: 0.142787\n",
      "[18: 375/1795] train lossD: -0.036726 lossG: 0.401317\n",
      "[18: 380/1795] train lossD: 1.874998 lossG: 0.070323\n",
      "[18: 385/1795] train lossD: 0.039766 lossG: 0.105252\n",
      "[18: 390/1795] train lossD: -0.002725 lossG: 0.128403\n",
      "[18: 395/1795] train lossD: -0.016114 lossG: 0.168821\n",
      "[18: 400/1795] train lossD: -0.007220 lossG: 0.183668\n",
      "[18: 405/1795] train lossD: -0.055215 lossG: 0.229006\n",
      "[18: 410/1795] train lossD: -0.055476 lossG: 0.211853\n",
      "[18: 415/1795] train lossD: -0.129701 lossG: 0.312558\n",
      "[18: 420/1795] train lossD: -0.091273 lossG: 0.186214\n",
      "[18: 425/1795] train lossD: -0.216040 lossG: 0.429254\n",
      "[18: 430/1795] train lossD: 0.023715 lossG: 0.083247\n",
      "[18: 435/1795] train lossD: -0.018143 lossG: 0.242215\n",
      "[18: 440/1795] train lossD: -0.076400 lossG: 0.258890\n",
      "[18: 445/1795] train lossD: -0.515133 lossG: 0.241178\n",
      "[18: 450/1795] train lossD: -0.200800 lossG: 0.178799\n",
      "[18: 455/1795] train lossD: -0.004995 lossG: 0.231257\n",
      "[18: 460/1795] train lossD: -0.074858 lossG: 0.316883\n",
      "[18: 465/1795] train lossD: -0.016467 lossG: 0.331913\n",
      "[18: 470/1795] train lossD: -0.078113 lossG: 0.294803\n",
      "[18: 475/1795] train lossD: -0.060015 lossG: 0.263927\n",
      "[18: 480/1795] train lossD: -0.037967 lossG: 0.328130\n",
      "[18: 485/1795] train lossD: -0.024090 lossG: 0.250658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18: 490/1795] train lossD: -0.019292 lossG: 0.230492\n",
      "[18: 495/1795] train lossD: -0.045127 lossG: 0.249728\n",
      "[18: 500/1795] train lossD: -0.179139 lossG: 0.278860\n",
      "[18: 505/1795] train lossD: -0.064570 lossG: 0.369058\n",
      "[18: 510/1795] train lossD: -0.179615 lossG: 0.378618\n",
      "[18: 515/1795] train lossD: -0.451042 lossG: 0.320763\n",
      "[18: 520/1795] train lossD: -0.318421 lossG: 0.129147\n",
      "[18: 525/1795] train lossD: -0.124276 lossG: 0.118754\n",
      "[18: 530/1795] train lossD: 1.182385 lossG: 0.147849\n",
      "[18: 535/1795] train lossD: -0.009624 lossG: 0.210843\n",
      "[18: 540/1795] train lossD: 0.012322 lossG: 0.218553\n",
      "[18: 545/1795] train lossD: -0.050400 lossG: 0.304565\n",
      "[18: 550/1795] train lossD: -0.043008 lossG: 0.323625\n",
      "[18: 555/1795] train lossD: -0.008599 lossG: 0.079105\n",
      "[18: 560/1795] train lossD: -0.455587 lossG: 0.070634\n",
      "[18: 565/1795] train lossD: -0.035474 lossG: 0.344808\n",
      "[18: 570/1795] train lossD: -0.107507 lossG: 0.076485\n",
      "[18: 575/1795] train lossD: 0.014154 lossG: 0.267030\n",
      "[18: 580/1795] train lossD: -0.104656 lossG: 0.482180\n",
      "[18: 585/1795] train lossD: -0.219717 lossG: 0.536740\n",
      "[18: 590/1795] train lossD: -0.035453 lossG: 0.333636\n",
      "[18: 595/1795] train lossD: -0.066342 lossG: 0.139299\n",
      "[18: 600/1795] train lossD: -0.009924 lossG: 0.070127\n",
      "[18: 605/1795] train lossD: -0.110159 lossG: 0.443966\n",
      "[18: 610/1795] train lossD: -0.386005 lossG: 0.106236\n",
      "[18: 615/1795] train lossD: -0.114280 lossG: 0.190457\n",
      "[18: 620/1795] train lossD: 0.024202 lossG: 0.045187\n",
      "[18: 625/1795] train lossD: -0.263743 lossG: -0.034662\n",
      "[18: 630/1795] train lossD: -0.334226 lossG: 0.051069\n",
      "[18: 635/1795] train lossD: -0.185984 lossG: 0.562508\n",
      "[18: 640/1795] train lossD: -0.134384 lossG: 0.120912\n",
      "[18: 645/1795] train lossD: 0.084080 lossG: 0.266901\n",
      "[18: 650/1795] train lossD: -0.132139 lossG: 0.585543\n",
      "[18: 655/1795] train lossD: 0.004034 lossG: 0.159969\n",
      "[18: 660/1795] train lossD: -0.174673 lossG: 0.253685\n",
      "[18: 665/1795] train lossD: -0.174103 lossG: 0.111217\n",
      "[18: 670/1795] train lossD: 0.083643 lossG: 0.152412\n",
      "[18: 675/1795] train lossD: -0.233795 lossG: 0.322679\n",
      "[18: 680/1795] train lossD: -0.100323 lossG: 0.256769\n",
      "[18: 685/1795] train lossD: -0.089902 lossG: 0.325470\n",
      "[18: 690/1795] train lossD: -0.012109 lossG: 0.060750\n",
      "[18: 695/1795] train lossD: -0.092557 lossG: 0.107126\n",
      "[18: 700/1795] train lossD: -0.174016 lossG: 0.112944\n",
      "[18: 705/1795] train lossD: -0.157738 lossG: 0.251932\n",
      "[18: 710/1795] train lossD: -0.119887 lossG: 0.248706\n",
      "[18: 715/1795] train lossD: -0.113080 lossG: 0.211845\n",
      "[18: 720/1795] train lossD: 0.080721 lossG: 0.262034\n",
      "[18: 725/1795] train lossD: -0.026785 lossG: 0.324881\n",
      "[18: 730/1795] train lossD: 0.042083 lossG: 0.303218\n",
      "[18: 735/1795] train lossD: -0.073016 lossG: 0.393619\n",
      "[18: 740/1795] train lossD: -0.032557 lossG: 0.398411\n",
      "[18: 745/1795] train lossD: -0.056956 lossG: 0.391490\n",
      "[18: 750/1795] train lossD: -0.133707 lossG: 0.378136\n",
      "[18: 755/1795] train lossD: -0.136080 lossG: 0.306820\n",
      "[18: 760/1795] train lossD: -0.233601 lossG: 0.276061\n",
      "[18: 765/1795] train lossD: -0.220682 lossG: 0.175250\n",
      "[18: 770/1795] train lossD: -0.188679 lossG: 0.309593\n",
      "[18: 775/1795] train lossD: -0.211177 lossG: 0.161793\n",
      "[18: 780/1795] train lossD: -0.119476 lossG: 0.180238\n",
      "[18: 785/1795] train lossD: 0.050658 lossG: -0.026846\n",
      "[18: 790/1795] train lossD: 0.007838 lossG: -0.015675\n",
      "[18: 795/1795] train lossD: -0.001916 lossG: 0.034522\n",
      "[18: 800/1795] train lossD: -0.064401 lossG: 0.151755\n",
      "[18: 805/1795] train lossD: -0.075525 lossG: 0.217552\n",
      "[18: 810/1795] train lossD: -0.597973 lossG: 0.302567\n",
      "[18: 815/1795] train lossD: -0.264236 lossG: 0.143345\n",
      "[18: 820/1795] train lossD: -0.103694 lossG: 0.144766\n",
      "[18: 825/1795] train lossD: 0.037568 lossG: 0.421144\n",
      "[18: 830/1795] train lossD: -0.061271 lossG: 0.223299\n",
      "[18: 835/1795] train lossD: -0.200197 lossG: 0.360283\n",
      "[18: 840/1795] train lossD: 0.414797 lossG: 0.073239\n",
      "[18: 845/1795] train lossD: -0.188215 lossG: 0.005788\n",
      "[18: 850/1795] train lossD: -0.113870 lossG: 0.051011\n",
      "[18: 855/1795] train lossD: 0.000990 lossG: 0.133667\n",
      "[18: 860/1795] train lossD: -0.656212 lossG: 0.353906\n",
      "[18: 865/1795] train lossD: -0.161048 lossG: 0.204919\n",
      "[18: 870/1795] train lossD: -0.381955 lossG: 0.575848\n",
      "[18: 875/1795] train lossD: -0.027654 lossG: 0.447589\n",
      "[18: 880/1795] train lossD: -0.036533 lossG: 0.491007\n",
      "[18: 885/1795] train lossD: -0.014760 lossG: 0.514890\n",
      "[18: 890/1795] train lossD: -0.082694 lossG: 0.690277\n",
      "[18: 895/1795] train lossD: -0.081255 lossG: 0.527941\n",
      "[18: 900/1795] train lossD: -0.127863 lossG: 0.569487\n",
      "[18: 905/1795] train lossD: -0.056205 lossG: 0.409818\n",
      "[18: 910/1795] train lossD: -0.089844 lossG: 0.490618\n",
      "[18: 915/1795] train lossD: -0.032665 lossG: 0.397141\n",
      "[18: 920/1795] train lossD: -0.078236 lossG: 0.348065\n",
      "[18: 925/1795] train lossD: -0.015811 lossG: 0.213123\n",
      "[18: 930/1795] train lossD: -0.118635 lossG: 0.268493\n",
      "[18: 935/1795] train lossD: 0.322325 lossG: 0.245189\n",
      "[18: 940/1795] train lossD: -0.045624 lossG: 0.037315\n",
      "[18: 945/1795] train lossD: 0.064565 lossG: 0.211538\n",
      "[18: 950/1795] train lossD: -0.160147 lossG: 0.425683\n",
      "[18: 955/1795] train lossD: -0.173230 lossG: 0.184752\n",
      "[18: 960/1795] train lossD: -0.138832 lossG: 0.431864\n",
      "[18: 965/1795] train lossD: -0.004406 lossG: 0.193001\n",
      "[18: 970/1795] train lossD: 0.153779 lossG: 0.226110\n",
      "[18: 975/1795] train lossD: -0.124458 lossG: 0.305887\n",
      "[18: 980/1795] train lossD: -0.112616 lossG: 0.293377\n",
      "[18: 985/1795] train lossD: -0.026659 lossG: 0.450266\n",
      "[18: 990/1795] train lossD: -0.094833 lossG: 0.408998\n",
      "[18: 995/1795] train lossD: -0.168030 lossG: 0.249584\n",
      "[18: 1000/1795] train lossD: -0.035849 lossG: 0.389339\n",
      "[18: 1005/1795] train lossD: -0.134925 lossG: 0.348011\n",
      "[18: 1010/1795] train lossD: -0.380496 lossG: 0.464848\n",
      "[18: 1015/1795] train lossD: -0.017297 lossG: 0.120885\n",
      "[18: 1020/1795] train lossD: -0.170524 lossG: 0.142469\n",
      "[18: 1025/1795] train lossD: -0.170936 lossG: 0.118403\n",
      "[18: 1030/1795] train lossD: -0.170654 lossG: 0.090820\n",
      "[18: 1035/1795] train lossD: -0.191407 lossG: -0.008292\n",
      "[18: 1040/1795] train lossD: -0.038291 lossG: 0.034106\n",
      "[18: 1045/1795] train lossD: -0.037515 lossG: 0.118909\n",
      "[18: 1050/1795] train lossD: -0.117879 lossG: 0.223481\n",
      "[18: 1055/1795] train lossD: -0.082734 lossG: 0.204114\n",
      "[18: 1060/1795] train lossD: -0.117487 lossG: 0.240525\n",
      "[18: 1065/1795] train lossD: -0.527675 lossG: 0.273364\n",
      "[18: 1070/1795] train lossD: -0.089358 lossG: 0.070855\n",
      "[18: 1075/1795] train lossD: -0.086444 lossG: 0.229117\n",
      "[18: 1080/1795] train lossD: -0.005677 lossG: 0.263791\n",
      "[18: 1085/1795] train lossD: -0.013178 lossG: 0.319358\n",
      "[18: 1090/1795] train lossD: -0.060254 lossG: 0.376387\n",
      "[18: 1095/1795] train lossD: -0.110721 lossG: 0.369478\n",
      "[18: 1100/1795] train lossD: -0.086073 lossG: 0.079422\n",
      "[18: 1105/1795] train lossD: -0.113706 lossG: 0.001227\n",
      "[18: 1110/1795] train lossD: 0.108150 lossG: 0.044067\n",
      "[18: 1115/1795] train lossD: -0.038868 lossG: 0.076266\n",
      "[18: 1120/1795] train lossD: -0.003738 lossG: 0.245994\n",
      "[18: 1125/1795] train lossD: -0.032357 lossG: 0.230013\n",
      "[18: 1130/1795] train lossD: -0.046595 lossG: 0.253622\n",
      "[18: 1135/1795] train lossD: -0.091091 lossG: 0.245636\n",
      "[18: 1140/1795] train lossD: -0.125328 lossG: 0.171568\n",
      "[18: 1145/1795] train lossD: -0.250146 lossG: 0.152903\n",
      "[18: 1150/1795] train lossD: 0.001285 lossG: 0.176840\n",
      "[18: 1155/1795] train lossD: -0.176087 lossG: 0.161641\n",
      "[18: 1160/1795] train lossD: 0.022288 lossG: 0.189744\n",
      "[18: 1165/1795] train lossD: 0.316828 lossG: 0.038340\n",
      "[18: 1170/1795] train lossD: 0.273108 lossG: 0.104197\n",
      "[18: 1175/1795] train lossD: -0.367794 lossG: 0.353727\n",
      "[18: 1180/1795] train lossD: -0.019918 lossG: 0.083384\n",
      "[18: 1185/1795] train lossD: -0.062254 lossG: 0.239486\n",
      "[18: 1190/1795] train lossD: -0.162137 lossG: 0.101285\n",
      "[18: 1195/1795] train lossD: -0.196263 lossG: 0.052924\n",
      "[18: 1200/1795] train lossD: -0.207502 lossG: 0.467648\n",
      "[18: 1205/1795] train lossD: -0.215154 lossG: 0.623133\n",
      "[18: 1210/1795] train lossD: -0.193422 lossG: 0.449137\n",
      "[18: 1215/1795] train lossD: 0.030529 lossG: 0.072306\n",
      "[18: 1220/1795] train lossD: -0.059397 lossG: 0.157454\n",
      "[18: 1225/1795] train lossD: -0.158928 lossG: 0.232025\n",
      "[18: 1230/1795] train lossD: 0.407907 lossG: 0.126543\n",
      "[18: 1235/1795] train lossD: -0.074170 lossG: 0.283704\n",
      "[18: 1240/1795] train lossD: -0.113408 lossG: 0.396408\n",
      "[18: 1245/1795] train lossD: -0.036708 lossG: 0.289563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18: 1250/1795] train lossD: -0.226373 lossG: 0.252055\n",
      "[18: 1255/1795] train lossD: -0.504007 lossG: 0.275468\n",
      "[18: 1260/1795] train lossD: -0.176210 lossG: 0.265269\n",
      "[18: 1265/1795] train lossD: -0.214342 lossG: 0.030674\n",
      "[18: 1270/1795] train lossD: -0.081049 lossG: 0.306308\n",
      "[18: 1275/1795] train lossD: -0.716286 lossG: 0.555692\n",
      "[18: 1280/1795] train lossD: -0.157814 lossG: 0.220224\n",
      "[18: 1285/1795] train lossD: -0.213651 lossG: 0.354557\n",
      "[18: 1290/1795] train lossD: -0.024037 lossG: 0.300944\n",
      "[18: 1295/1795] train lossD: -0.254009 lossG: 0.164366\n",
      "[18: 1300/1795] train lossD: -0.297053 lossG: 0.054292\n",
      "[18: 1305/1795] train lossD: -0.252699 lossG: 0.012360\n",
      "[18: 1310/1795] train lossD: 0.016942 lossG: 0.266159\n",
      "[18: 1315/1795] train lossD: -0.512041 lossG: 0.311844\n",
      "[18: 1320/1795] train lossD: -0.300134 lossG: 0.062590\n",
      "[18: 1325/1795] train lossD: -0.101879 lossG: 0.039655\n",
      "[18: 1330/1795] train lossD: 0.031284 lossG: 0.115179\n",
      "[18: 1335/1795] train lossD: -0.009826 lossG: 0.108769\n",
      "[18: 1340/1795] train lossD: -0.020923 lossG: 0.052234\n",
      "[18: 1345/1795] train lossD: -0.035833 lossG: 0.129995\n",
      "[18: 1350/1795] train lossD: -0.025197 lossG: 0.288339\n",
      "[18: 1355/1795] train lossD: -0.207967 lossG: 0.242491\n",
      "[18: 1360/1795] train lossD: -0.417170 lossG: 0.280603\n",
      "[18: 1365/1795] train lossD: 0.059041 lossG: 0.227222\n",
      "[18: 1370/1795] train lossD: 0.067909 lossG: 0.255063\n",
      "[18: 1375/1795] train lossD: 0.027746 lossG: 0.306494\n",
      "[18: 1380/1795] train lossD: 0.014516 lossG: 0.339031\n",
      "[18: 1385/1795] train lossD: -0.001041 lossG: 0.312210\n",
      "[18: 1390/1795] train lossD: 0.013076 lossG: 0.337550\n",
      "[18: 1395/1795] train lossD: 0.018264 lossG: 0.319956\n",
      "[18: 1400/1795] train lossD: -0.025687 lossG: 0.362293\n",
      "[18: 1405/1795] train lossD: -0.038943 lossG: 0.385743\n",
      "[18: 1410/1795] train lossD: -0.037715 lossG: 0.316159\n",
      "[18: 1415/1795] train lossD: -0.079238 lossG: 0.355700\n",
      "[18: 1420/1795] train lossD: -0.005857 lossG: 0.337760\n",
      "[18: 1425/1795] train lossD: -0.023289 lossG: 0.266986\n",
      "[18: 1430/1795] train lossD: -0.031866 lossG: 0.301503\n",
      "[18: 1435/1795] train lossD: 0.038557 lossG: 0.177833\n",
      "[18: 1440/1795] train lossD: -0.291863 lossG: 0.415212\n",
      "[18: 1445/1795] train lossD: -0.424976 lossG: 0.141235\n",
      "[18: 1450/1795] train lossD: -0.131633 lossG: 0.061046\n",
      "[18: 1455/1795] train lossD: -0.180794 lossG: 0.089984\n",
      "[18: 1460/1795] train lossD: 0.179829 lossG: 0.471835\n",
      "[18: 1465/1795] train lossD: 0.022535 lossG: 0.489619\n",
      "[18: 1470/1795] train lossD: -0.034824 lossG: 0.580062\n",
      "[18: 1475/1795] train lossD: -0.043316 lossG: 0.468029\n",
      "[18: 1480/1795] train lossD: -0.145001 lossG: 0.350064\n",
      "[18: 1485/1795] train lossD: -0.127120 lossG: 0.134003\n",
      "[18: 1490/1795] train lossD: -0.322151 lossG: 0.586010\n",
      "[18: 1495/1795] train lossD: 0.047673 lossG: 0.468258\n",
      "[18: 1500/1795] train lossD: -0.115793 lossG: 0.402182\n",
      "[18: 1505/1795] train lossD: -0.260076 lossG: 0.271974\n",
      "[18: 1510/1795] train lossD: -0.320237 lossG: 0.246891\n",
      "[18: 1515/1795] train lossD: -0.050858 lossG: 0.217780\n",
      "[18: 1520/1795] train lossD: 1.347977 lossG: 0.146362\n",
      "[18: 1525/1795] train lossD: -0.019197 lossG: 0.206816\n",
      "[18: 1530/1795] train lossD: -0.048411 lossG: 0.253104\n",
      "[18: 1535/1795] train lossD: -0.099794 lossG: 0.284950\n",
      "[18: 1540/1795] train lossD: -0.132940 lossG: 0.314321\n",
      "[18: 1545/1795] train lossD: -0.373395 lossG: 0.138865\n",
      "[18: 1550/1795] train lossD: -0.358069 lossG: 0.070804\n",
      "[18: 1555/1795] train lossD: -0.006742 lossG: 0.197870\n",
      "[18: 1560/1795] train lossD: -0.003374 lossG: 0.247077\n",
      "[18: 1565/1795] train lossD: 0.029292 lossG: 0.248289\n",
      "[18: 1570/1795] train lossD: 0.016645 lossG: 0.227212\n",
      "[18: 1575/1795] train lossD: -0.041414 lossG: 0.280965\n",
      "[18: 1580/1795] train lossD: -0.014623 lossG: 0.364218\n",
      "[18: 1585/1795] train lossD: 0.077738 lossG: 0.284493\n",
      "[18: 1590/1795] train lossD: -0.041535 lossG: 0.349619\n",
      "[18: 1595/1795] train lossD: -0.045031 lossG: 0.368947\n",
      "[18: 1600/1795] train lossD: -0.047164 lossG: 0.311004\n",
      "[18: 1605/1795] train lossD: -0.445556 lossG: 0.406965\n",
      "[18: 1610/1795] train lossD: -0.088012 lossG: 0.215033\n",
      "[18: 1615/1795] train lossD: 0.002058 lossG: 0.251355\n",
      "[18: 1620/1795] train lossD: -0.212806 lossG: 0.085944\n",
      "[18: 1625/1795] train lossD: -0.022201 lossG: -0.098123\n",
      "[18: 1630/1795] train lossD: -0.320552 lossG: -0.153192\n",
      "[18: 1635/1795] train lossD: -0.366007 lossG: -0.122891\n",
      "[18: 1640/1795] train lossD: -0.229022 lossG: 0.355626\n",
      "[18: 1645/1795] train lossD: -0.054273 lossG: 0.259626\n",
      "[18: 1650/1795] train lossD: 3.142906 lossG: 0.211416\n",
      "[18: 1655/1795] train lossD: 0.019166 lossG: 0.247833\n",
      "[18: 1660/1795] train lossD: -0.008975 lossG: 0.291305\n",
      "[18: 1665/1795] train lossD: 0.009252 lossG: 0.262166\n",
      "[18: 1670/1795] train lossD: 0.011436 lossG: 0.260528\n",
      "[18: 1675/1795] train lossD: -0.055316 lossG: 0.300846\n",
      "[18: 1680/1795] train lossD: -0.035729 lossG: 0.525529\n",
      "[18: 1685/1795] train lossD: -0.051284 lossG: 0.440126\n",
      "[18: 1690/1795] train lossD: -0.024601 lossG: 0.408487\n",
      "[18: 1695/1795] train lossD: -0.326995 lossG: 0.378837\n",
      "[18: 1700/1795] train lossD: -0.319960 lossG: 0.197967\n",
      "[18: 1705/1795] train lossD: -0.331174 lossG: 0.577367\n",
      "[18: 1710/1795] train lossD: 0.034097 lossG: 0.130526\n",
      "[18: 1715/1795] train lossD: 0.041918 lossG: 0.201909\n",
      "[18: 1720/1795] train lossD: -0.056164 lossG: 0.600091\n",
      "[18: 1725/1795] train lossD: -0.098315 lossG: 0.377082\n",
      "[18: 1730/1795] train lossD: -0.098643 lossG: 0.361441\n",
      "[18: 1735/1795] train lossD: -0.055667 lossG: 0.451243\n",
      "[18: 1740/1795] train lossD: -0.251195 lossG: 0.191806\n",
      "[18: 1745/1795] train lossD: -0.124588 lossG: 0.028900\n",
      "[18: 1750/1795] train lossD: 0.057246 lossG: 0.027800\n",
      "[18: 1755/1795] train lossD: -0.024830 lossG: 0.119596\n",
      "[18: 1760/1795] train lossD: -0.045028 lossG: 0.307512\n",
      "[18: 1765/1795] train lossD: -0.381101 lossG: 0.404415\n",
      "[18: 1770/1795] train lossD: -0.094315 lossG: 0.273629\n",
      "[18: 1775/1795] train lossD: -0.233697 lossG: 0.323539\n",
      "[18: 1780/1795] train lossD: -0.111153 lossG: -0.141547\n",
      "[18: 1785/1795] train lossD: -0.137663 lossG: 0.000347\n",
      "[18: 1790/1795] train lossD: -0.280520 lossG: 0.321367\n",
      "0.04403220862150192\n",
      "[19: 0/1795] train lossD: -0.002086 lossG: 0.090737\n",
      "[19: 5/1795] train lossD: 0.048616 lossG: 0.121492\n",
      "[19: 10/1795] train lossD: -0.149849 lossG: 0.132155\n",
      "[19: 15/1795] train lossD: -0.148540 lossG: 0.183515\n",
      "[19: 20/1795] train lossD: -0.320154 lossG: 0.240449\n",
      "[19: 25/1795] train lossD: -0.275184 lossG: 0.314869\n",
      "[19: 30/1795] train lossD: -0.613790 lossG: 0.133828\n",
      "[19: 35/1795] train lossD: -0.280916 lossG: 0.047430\n",
      "[19: 40/1795] train lossD: 1.678098 lossG: -0.017460\n",
      "[19: 45/1795] train lossD: 0.061314 lossG: 0.044318\n",
      "[19: 50/1795] train lossD: -0.039903 lossG: 0.104776\n",
      "[19: 55/1795] train lossD: -0.088538 lossG: 0.215593\n",
      "[19: 60/1795] train lossD: -0.049172 lossG: 0.235127\n",
      "[19: 65/1795] train lossD: -0.355679 lossG: 0.422674\n",
      "[19: 70/1795] train lossD: -0.182843 lossG: 0.399296\n",
      "[19: 75/1795] train lossD: -0.327170 lossG: 0.185517\n",
      "[19: 80/1795] train lossD: -0.056550 lossG: 0.194654\n",
      "[19: 85/1795] train lossD: -0.346855 lossG: -0.074116\n",
      "[19: 90/1795] train lossD: 0.032645 lossG: 0.232193\n",
      "[19: 95/1795] train lossD: -0.038100 lossG: 0.274169\n",
      "[19: 100/1795] train lossD: -0.211238 lossG: 0.325647\n",
      "[19: 105/1795] train lossD: 0.012941 lossG: 0.301007\n",
      "[19: 110/1795] train lossD: -0.027190 lossG: 0.309338\n",
      "[19: 115/1795] train lossD: -0.082134 lossG: 0.293171\n",
      "[19: 120/1795] train lossD: -0.403338 lossG: 0.183420\n",
      "[19: 125/1795] train lossD: -0.268680 lossG: 0.113912\n",
      "[19: 130/1795] train lossD: -0.173515 lossG: -0.092275\n",
      "[19: 135/1795] train lossD: -0.004567 lossG: -0.034897\n",
      "[19: 140/1795] train lossD: -0.373671 lossG: 0.058329\n",
      "[19: 145/1795] train lossD: 0.027822 lossG: 0.003716\n",
      "[19: 150/1795] train lossD: -0.546343 lossG: 0.472651\n",
      "[19: 155/1795] train lossD: -0.000245 lossG: 0.028521\n",
      "[19: 160/1795] train lossD: 0.065784 lossG: 0.243018\n",
      "[19: 165/1795] train lossD: -0.044236 lossG: 0.421635\n",
      "[19: 170/1795] train lossD: -0.324186 lossG: 0.641390\n",
      "[19: 175/1795] train lossD: -0.404871 lossG: 0.216424\n",
      "[19: 180/1795] train lossD: -0.226395 lossG: 0.151688\n",
      "[19: 185/1795] train lossD: -0.029662 lossG: 0.139592\n",
      "[19: 190/1795] train lossD: -0.127768 lossG: 0.229100\n",
      "[19: 195/1795] train lossD: -0.504836 lossG: 0.353904\n",
      "[19: 200/1795] train lossD: -0.217915 lossG: 0.040604\n",
      "[19: 205/1795] train lossD: -0.314113 lossG: 0.367966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19: 210/1795] train lossD: 0.075079 lossG: 0.150382\n",
      "[19: 215/1795] train lossD: 0.012937 lossG: 0.160229\n",
      "[19: 220/1795] train lossD: -0.029031 lossG: 0.171518\n",
      "[19: 225/1795] train lossD: 0.016086 lossG: 0.171617\n",
      "[19: 230/1795] train lossD: 0.039522 lossG: 0.283885\n",
      "[19: 235/1795] train lossD: -0.148192 lossG: 0.325738\n",
      "[19: 240/1795] train lossD: -0.058076 lossG: 0.336484\n",
      "[19: 245/1795] train lossD: -0.200399 lossG: 0.330786\n",
      "[19: 250/1795] train lossD: -0.005916 lossG: 0.300910\n",
      "[19: 255/1795] train lossD: -0.145583 lossG: 0.332196\n",
      "[19: 260/1795] train lossD: -0.301015 lossG: 0.237780\n",
      "[19: 265/1795] train lossD: -0.595175 lossG: 0.511293\n",
      "[19: 270/1795] train lossD: -0.522157 lossG: 0.020864\n",
      "[19: 275/1795] train lossD: -0.363248 lossG: -0.079840\n",
      "[19: 280/1795] train lossD: -0.031556 lossG: -0.006619\n",
      "[19: 285/1795] train lossD: -0.167612 lossG: 0.261544\n",
      "[19: 290/1795] train lossD: -0.464223 lossG: 0.023124\n",
      "[19: 295/1795] train lossD: 0.183814 lossG: 0.268479\n",
      "[19: 300/1795] train lossD: -0.057467 lossG: 0.219644\n",
      "[19: 305/1795] train lossD: -0.128879 lossG: 0.265068\n",
      "[19: 310/1795] train lossD: -0.263828 lossG: 0.153988\n",
      "[19: 315/1795] train lossD: -0.206441 lossG: 0.210658\n",
      "[19: 320/1795] train lossD: -0.115729 lossG: 0.256536\n",
      "[19: 325/1795] train lossD: -0.158589 lossG: 0.058998\n",
      "[19: 330/1795] train lossD: 0.108068 lossG: -0.069540\n",
      "[19: 335/1795] train lossD: -0.020584 lossG: -0.013627\n",
      "[19: 340/1795] train lossD: -0.014157 lossG: 0.104231\n",
      "[19: 345/1795] train lossD: -0.226793 lossG: 0.312685\n",
      "[19: 350/1795] train lossD: -0.340465 lossG: 0.069150\n",
      "[19: 355/1795] train lossD: -0.119970 lossG: 0.231487\n",
      "[19: 360/1795] train lossD: -0.613446 lossG: -0.016502\n",
      "[19: 365/1795] train lossD: -0.048946 lossG: 0.027456\n",
      "[19: 370/1795] train lossD: 0.073364 lossG: 0.104845\n",
      "[19: 375/1795] train lossD: -0.112817 lossG: 0.225856\n",
      "[19: 380/1795] train lossD: -0.083711 lossG: 0.294502\n",
      "[19: 385/1795] train lossD: -0.120438 lossG: 0.399503\n",
      "[19: 390/1795] train lossD: -0.158650 lossG: 0.521865\n",
      "[19: 395/1795] train lossD: -0.461846 lossG: -0.087303\n",
      "[19: 400/1795] train lossD: -0.136942 lossG: 0.211664\n",
      "[19: 405/1795] train lossD: -0.097092 lossG: 0.291225\n",
      "[19: 410/1795] train lossD: -0.242291 lossG: 0.172836\n",
      "[19: 415/1795] train lossD: -0.219302 lossG: 0.218320\n",
      "[19: 420/1795] train lossD: -0.184165 lossG: 0.360543\n",
      "[19: 425/1795] train lossD: -0.472950 lossG: 0.405962\n",
      "[19: 430/1795] train lossD: -0.053924 lossG: 0.174689\n",
      "[19: 435/1795] train lossD: -0.318720 lossG: 0.070103\n",
      "[19: 440/1795] train lossD: -0.598403 lossG: 0.022464\n",
      "[19: 445/1795] train lossD: -0.519137 lossG: -0.000563\n",
      "[19: 450/1795] train lossD: -0.139461 lossG: 0.026955\n",
      "[19: 455/1795] train lossD: -0.292844 lossG: 0.057150\n",
      "[19: 460/1795] train lossD: -0.504114 lossG: -0.061349\n",
      "[19: 465/1795] train lossD: -0.196026 lossG: -0.124601\n",
      "[19: 470/1795] train lossD: 0.329614 lossG: 0.261801\n",
      "[19: 475/1795] train lossD: -0.067702 lossG: 0.031348\n",
      "[19: 480/1795] train lossD: -0.087599 lossG: 0.125494\n",
      "[19: 485/1795] train lossD: 0.020664 lossG: 0.264280\n",
      "[19: 490/1795] train lossD: -0.012502 lossG: 0.327107\n",
      "[19: 495/1795] train lossD: -0.072852 lossG: 0.338715\n",
      "[19: 500/1795] train lossD: 0.008185 lossG: 0.265073\n",
      "[19: 505/1795] train lossD: -0.019156 lossG: 0.382718\n",
      "[19: 510/1795] train lossD: -0.063402 lossG: 0.394736\n",
      "[19: 515/1795] train lossD: -0.049001 lossG: 0.393488\n",
      "[19: 520/1795] train lossD: -0.158839 lossG: 0.369415\n",
      "[19: 525/1795] train lossD: -0.064699 lossG: 0.376783\n",
      "[19: 530/1795] train lossD: -0.534703 lossG: -0.084436\n",
      "[19: 535/1795] train lossD: 0.031276 lossG: 0.118109\n",
      "[19: 540/1795] train lossD: -0.249328 lossG: 0.055825\n",
      "[19: 545/1795] train lossD: -0.447876 lossG: -0.073073\n",
      "[19: 550/1795] train lossD: 0.845686 lossG: -0.001063\n",
      "[19: 555/1795] train lossD: -0.750092 lossG: 0.406830\n",
      "[19: 560/1795] train lossD: -0.195849 lossG: 0.382139\n",
      "[19: 565/1795] train lossD: 0.417782 lossG: 0.460629\n",
      "[19: 570/1795] train lossD: 0.056342 lossG: 0.081976\n",
      "[19: 575/1795] train lossD: -0.062655 lossG: 0.268223\n",
      "[19: 580/1795] train lossD: -0.075211 lossG: 0.274462\n",
      "[19: 585/1795] train lossD: 0.112679 lossG: 0.146849\n",
      "[19: 590/1795] train lossD: -0.038411 lossG: 0.221956\n",
      "[19: 595/1795] train lossD: -0.037840 lossG: 0.174511\n",
      "[19: 600/1795] train lossD: -0.052034 lossG: 0.208059\n",
      "[19: 605/1795] train lossD: -0.102232 lossG: 0.135759\n",
      "[19: 610/1795] train lossD: 0.143117 lossG: 0.357531\n",
      "[19: 615/1795] train lossD: -0.282902 lossG: 0.166688\n",
      "[19: 620/1795] train lossD: -0.003820 lossG: 0.394340\n",
      "[19: 625/1795] train lossD: -0.315184 lossG: -0.019445\n",
      "[19: 630/1795] train lossD: 0.087538 lossG: -0.137567\n",
      "[19: 635/1795] train lossD: -0.179506 lossG: -0.100832\n",
      "[19: 640/1795] train lossD: -0.440425 lossG: -0.089297\n",
      "[19: 645/1795] train lossD: -0.036925 lossG: -0.082675\n",
      "[19: 650/1795] train lossD: -0.097313 lossG: 0.076875\n",
      "[19: 655/1795] train lossD: -0.107977 lossG: 0.090458\n",
      "[19: 660/1795] train lossD: 0.304381 lossG: 0.044831\n",
      "[19: 665/1795] train lossD: -0.128268 lossG: -0.041150\n",
      "[19: 670/1795] train lossD: -0.089993 lossG: 0.097733\n",
      "[19: 675/1795] train lossD: -0.390358 lossG: 0.033699\n",
      "[19: 680/1795] train lossD: -0.570867 lossG: -0.094010\n",
      "[19: 685/1795] train lossD: -0.218134 lossG: -0.095394\n",
      "[19: 690/1795] train lossD: -0.172243 lossG: 0.007097\n",
      "[19: 695/1795] train lossD: -0.310168 lossG: -0.069997\n",
      "[19: 700/1795] train lossD: -0.127610 lossG: -0.102619\n",
      "[19: 705/1795] train lossD: -0.210882 lossG: 0.268725\n",
      "[19: 710/1795] train lossD: -0.284675 lossG: 0.082402\n",
      "[19: 715/1795] train lossD: 0.030022 lossG: 0.150696\n",
      "[19: 720/1795] train lossD: -0.701727 lossG: 0.228186\n",
      "[19: 725/1795] train lossD: -0.597035 lossG: 0.283225\n",
      "[19: 730/1795] train lossD: 0.007768 lossG: -0.123582\n",
      "[19: 735/1795] train lossD: 0.070782 lossG: -0.089569\n",
      "[19: 740/1795] train lossD: -0.221538 lossG: 0.017657\n",
      "[19: 745/1795] train lossD: -0.187395 lossG: 0.136611\n",
      "[19: 750/1795] train lossD: 0.071986 lossG: 0.059287\n",
      "[19: 755/1795] train lossD: -0.240816 lossG: -0.038223\n",
      "[19: 760/1795] train lossD: -0.350379 lossG: 0.110370\n",
      "[19: 765/1795] train lossD: -0.281844 lossG: -0.044612\n",
      "[19: 770/1795] train lossD: -0.418303 lossG: -0.216947\n",
      "[19: 775/1795] train lossD: -1.155099 lossG: 0.419580\n",
      "[19: 780/1795] train lossD: -0.236282 lossG: -0.056157\n",
      "[19: 785/1795] train lossD: -0.161778 lossG: 0.105891\n",
      "[19: 790/1795] train lossD: -0.659329 lossG: 0.243195\n",
      "[19: 795/1795] train lossD: -0.229784 lossG: 0.250509\n",
      "[19: 800/1795] train lossD: -0.167765 lossG: -0.246719\n",
      "[19: 805/1795] train lossD: -0.099690 lossG: 0.578303\n",
      "[19: 810/1795] train lossD: -0.610105 lossG: 0.558758\n",
      "[19: 815/1795] train lossD: -0.426437 lossG: 0.325812\n",
      "[19: 820/1795] train lossD: 0.042245 lossG: 0.228798\n",
      "[19: 825/1795] train lossD: 0.000273 lossG: 0.270557\n",
      "[19: 830/1795] train lossD: 0.039984 lossG: 0.290202\n",
      "[19: 835/1795] train lossD: -0.008490 lossG: 0.299513\n",
      "[19: 840/1795] train lossD: 0.033124 lossG: 0.396113\n",
      "[19: 845/1795] train lossD: -0.039818 lossG: 0.334515\n",
      "[19: 850/1795] train lossD: -0.064057 lossG: 0.354396\n",
      "[19: 855/1795] train lossD: 0.012894 lossG: 0.271371\n",
      "[19: 860/1795] train lossD: -0.033171 lossG: 0.315668\n",
      "[19: 865/1795] train lossD: -0.088981 lossG: 0.279332\n",
      "[19: 870/1795] train lossD: -0.139734 lossG: 0.304264\n",
      "[19: 875/1795] train lossD: -0.095601 lossG: 0.147815\n",
      "[19: 880/1795] train lossD: -0.124128 lossG: 0.234330\n",
      "[19: 885/1795] train lossD: -0.627835 lossG: 0.074003\n",
      "[19: 890/1795] train lossD: -0.457081 lossG: -0.307416\n",
      "[19: 895/1795] train lossD: -0.290479 lossG: 0.399026\n",
      "[19: 900/1795] train lossD: -0.202142 lossG: 0.047341\n",
      "[19: 905/1795] train lossD: -0.199028 lossG: -0.216844\n",
      "[19: 910/1795] train lossD: 0.035290 lossG: -0.098596\n",
      "[19: 915/1795] train lossD: -0.079794 lossG: 0.027514\n",
      "[19: 920/1795] train lossD: -0.030277 lossG: 0.126787\n",
      "[19: 925/1795] train lossD: 0.041391 lossG: 0.186934\n",
      "[19: 930/1795] train lossD: -0.083342 lossG: 0.207856\n",
      "[19: 935/1795] train lossD: -0.178591 lossG: -0.013443\n",
      "[19: 940/1795] train lossD: -0.324451 lossG: 0.258775\n",
      "[19: 945/1795] train lossD: 0.013709 lossG: 0.295883\n",
      "[19: 950/1795] train lossD: -0.592343 lossG: 0.091074\n",
      "[19: 955/1795] train lossD: -0.464471 lossG: -0.294992\n",
      "[19: 960/1795] train lossD: 0.195544 lossG: 0.055285\n",
      "[19: 965/1795] train lossD: -0.069638 lossG: 0.185767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19: 970/1795] train lossD: -0.054069 lossG: 0.468485\n",
      "[19: 975/1795] train lossD: -0.350327 lossG: 0.488957\n",
      "[19: 980/1795] train lossD: -0.115645 lossG: 0.099650\n",
      "[19: 985/1795] train lossD: -0.834662 lossG: 0.349625\n",
      "[19: 990/1795] train lossD: -0.525920 lossG: 0.069366\n",
      "[19: 995/1795] train lossD: -0.074321 lossG: 0.072561\n",
      "[19: 1000/1795] train lossD: 0.328111 lossG: 0.148121\n",
      "[19: 1005/1795] train lossD: 0.029044 lossG: 0.221511\n",
      "[19: 1010/1795] train lossD: 0.014032 lossG: 0.251582\n",
      "[19: 1015/1795] train lossD: 0.026670 lossG: 0.301332\n",
      "[19: 1020/1795] train lossD: 0.039980 lossG: 0.252594\n",
      "[19: 1025/1795] train lossD: -0.066065 lossG: 0.296454\n",
      "[19: 1030/1795] train lossD: -0.047593 lossG: 0.365610\n",
      "[19: 1035/1795] train lossD: -0.142934 lossG: 0.292907\n",
      "[19: 1040/1795] train lossD: -0.026234 lossG: 0.244143\n",
      "[19: 1045/1795] train lossD: -0.077374 lossG: 0.267684\n",
      "[19: 1050/1795] train lossD: -0.618631 lossG: 0.121913\n",
      "[19: 1055/1795] train lossD: -0.102498 lossG: 0.140343\n",
      "[19: 1060/1795] train lossD: -0.171312 lossG: 0.586094\n",
      "[19: 1065/1795] train lossD: -0.255229 lossG: 0.405342\n",
      "[19: 1070/1795] train lossD: -0.523901 lossG: 0.174590\n",
      "[19: 1075/1795] train lossD: -0.708095 lossG: -0.029609\n",
      "[19: 1080/1795] train lossD: -0.323935 lossG: -0.039166\n",
      "[19: 1085/1795] train lossD: -0.182144 lossG: 0.132178\n",
      "[19: 1090/1795] train lossD: -0.377151 lossG: 0.623617\n",
      "[19: 1095/1795] train lossD: -0.197062 lossG: 0.583223\n",
      "[19: 1100/1795] train lossD: -0.521395 lossG: 0.624251\n",
      "[19: 1105/1795] train lossD: -0.849630 lossG: 0.542003\n",
      "[19: 1110/1795] train lossD: -0.167946 lossG: 0.711267\n",
      "[19: 1115/1795] train lossD: -0.497072 lossG: 0.306073\n",
      "[19: 1120/1795] train lossD: -0.092444 lossG: 0.143808\n",
      "[19: 1125/1795] train lossD: -0.625619 lossG: 0.710925\n",
      "[19: 1130/1795] train lossD: -0.020628 lossG: -0.126541\n",
      "[19: 1135/1795] train lossD: -0.013035 lossG: -0.174723\n",
      "[19: 1140/1795] train lossD: 0.025784 lossG: -0.096446\n",
      "[19: 1145/1795] train lossD: -0.083481 lossG: -0.032044\n",
      "[19: 1150/1795] train lossD: -0.437942 lossG: 0.056285\n",
      "[19: 1155/1795] train lossD: 0.001011 lossG: -0.204076\n",
      "[19: 1160/1795] train lossD: 0.047029 lossG: -0.148838\n",
      "[19: 1165/1795] train lossD: -0.102518 lossG: 0.024078\n",
      "[19: 1170/1795] train lossD: 0.052811 lossG: 0.207113\n",
      "[19: 1175/1795] train lossD: -0.448972 lossG: 0.289817\n",
      "[19: 1180/1795] train lossD: -0.272892 lossG: -0.158520\n",
      "[19: 1185/1795] train lossD: 0.117937 lossG: 0.364719\n",
      "[19: 1190/1795] train lossD: -0.092565 lossG: 0.161851\n",
      "[19: 1195/1795] train lossD: -0.159752 lossG: -0.032957\n",
      "[19: 1200/1795] train lossD: -0.181959 lossG: -0.031133\n",
      "[19: 1205/1795] train lossD: -0.468473 lossG: 0.517865\n",
      "[19: 1210/1795] train lossD: 0.398805 lossG: 0.182611\n",
      "[19: 1215/1795] train lossD: -0.372687 lossG: -0.098873\n",
      "[19: 1220/1795] train lossD: -0.299822 lossG: 0.320673\n",
      "[19: 1225/1795] train lossD: -0.253765 lossG: -0.154350\n",
      "[19: 1230/1795] train lossD: 0.273419 lossG: 0.100018\n",
      "[19: 1235/1795] train lossD: -0.210610 lossG: 0.132571\n",
      "[19: 1240/1795] train lossD: -1.189317 lossG: 0.728240\n",
      "[19: 1245/1795] train lossD: -0.226980 lossG: 0.027625\n",
      "[19: 1250/1795] train lossD: -0.352373 lossG: -0.269279\n",
      "[19: 1255/1795] train lossD: -0.411803 lossG: 0.239553\n",
      "[19: 1260/1795] train lossD: 1.063586 lossG: 0.328376\n",
      "[19: 1265/1795] train lossD: -0.031482 lossG: 0.428576\n",
      "[19: 1270/1795] train lossD: 0.006240 lossG: 0.429277\n",
      "[19: 1275/1795] train lossD: -0.143612 lossG: 0.414709\n",
      "[19: 1280/1795] train lossD: -0.217188 lossG: 0.164421\n",
      "[19: 1285/1795] train lossD: -0.511642 lossG: 0.018822\n",
      "[19: 1290/1795] train lossD: -0.025582 lossG: 0.132073\n",
      "[19: 1295/1795] train lossD: -0.148446 lossG: -0.117780\n",
      "[19: 1300/1795] train lossD: -0.213419 lossG: -0.131978\n",
      "[19: 1305/1795] train lossD: -0.244770 lossG: -0.107798\n",
      "[19: 1310/1795] train lossD: 0.012348 lossG: 0.043520\n",
      "[19: 1315/1795] train lossD: -0.017393 lossG: 0.035302\n",
      "[19: 1320/1795] train lossD: -0.149612 lossG: 0.053320\n",
      "[19: 1325/1795] train lossD: 0.111802 lossG: 0.154671\n",
      "[19: 1330/1795] train lossD: 0.023858 lossG: 0.227963\n",
      "[19: 1335/1795] train lossD: -0.056491 lossG: 0.259896\n",
      "[19: 1340/1795] train lossD: -0.044056 lossG: 0.266141\n",
      "[19: 1345/1795] train lossD: -0.087324 lossG: 0.238944\n",
      "[19: 1350/1795] train lossD: -0.302366 lossG: 0.025489\n",
      "[19: 1355/1795] train lossD: -0.006380 lossG: 0.477341\n",
      "[19: 1360/1795] train lossD: -0.121618 lossG: 0.707378\n",
      "[19: 1365/1795] train lossD: -0.982500 lossG: 0.491759\n",
      "[19: 1370/1795] train lossD: 0.030881 lossG: 0.305232\n",
      "[19: 1375/1795] train lossD: -0.089555 lossG: 0.338977\n",
      "[19: 1380/1795] train lossD: -0.316127 lossG: 0.220622\n",
      "[19: 1385/1795] train lossD: -0.936847 lossG: 0.201784\n",
      "[19: 1390/1795] train lossD: -0.471662 lossG: 0.144151\n",
      "[19: 1395/1795] train lossD: -0.361003 lossG: -0.083647\n",
      "[19: 1400/1795] train lossD: -0.553100 lossG: 0.168999\n",
      "[19: 1405/1795] train lossD: -0.196636 lossG: 0.091574\n",
      "[19: 1410/1795] train lossD: -0.228605 lossG: 0.368452\n",
      "[19: 1415/1795] train lossD: -0.189246 lossG: 0.692340\n",
      "[19: 1420/1795] train lossD: 0.128115 lossG: -0.078684\n",
      "[19: 1425/1795] train lossD: 0.066126 lossG: -0.059416\n",
      "[19: 1430/1795] train lossD: 0.018124 lossG: -0.077066\n",
      "[19: 1435/1795] train lossD: 0.026012 lossG: 0.008037\n",
      "[19: 1440/1795] train lossD: -0.037023 lossG: 0.060074\n",
      "[19: 1445/1795] train lossD: -0.078631 lossG: 0.134511\n",
      "[19: 1450/1795] train lossD: -0.065288 lossG: 0.349224\n",
      "[19: 1455/1795] train lossD: -0.018720 lossG: 0.392899\n",
      "[19: 1460/1795] train lossD: 0.220884 lossG: -0.044774\n",
      "[19: 1465/1795] train lossD: 0.734277 lossG: 0.087210\n",
      "[19: 1470/1795] train lossD: -0.003252 lossG: 0.156211\n",
      "[19: 1475/1795] train lossD: -0.469589 lossG: -0.154080\n",
      "[19: 1480/1795] train lossD: 0.053073 lossG: -0.232700\n",
      "[19: 1485/1795] train lossD: 0.032790 lossG: -0.168203\n",
      "[19: 1490/1795] train lossD: -0.046040 lossG: -0.057044\n",
      "[19: 1495/1795] train lossD: -0.413096 lossG: 0.368442\n",
      "[19: 1500/1795] train lossD: -0.229391 lossG: 0.258440\n",
      "[19: 1505/1795] train lossD: -0.849863 lossG: 0.093761\n",
      "[19: 1510/1795] train lossD: -0.258957 lossG: 0.220424\n",
      "[19: 1515/1795] train lossD: -0.209094 lossG: -0.195341\n",
      "[19: 1520/1795] train lossD: 0.014010 lossG: -0.170145\n",
      "[19: 1525/1795] train lossD: -0.518662 lossG: 0.004295\n",
      "[19: 1530/1795] train lossD: -0.058416 lossG: 0.042824\n",
      "[19: 1535/1795] train lossD: 1.543526 lossG: 0.142284\n",
      "[19: 1540/1795] train lossD: 0.022445 lossG: 0.278142\n",
      "[19: 1545/1795] train lossD: 0.028180 lossG: 0.244527\n",
      "[19: 1550/1795] train lossD: -0.033758 lossG: 0.266771\n",
      "[19: 1555/1795] train lossD: -0.013032 lossG: 0.191855\n",
      "[19: 1560/1795] train lossD: -0.211459 lossG: 0.138801\n",
      "[19: 1565/1795] train lossD: 0.251318 lossG: 0.173269\n",
      "[19: 1570/1795] train lossD: -0.076352 lossG: 0.291136\n",
      "[19: 1575/1795] train lossD: -0.019567 lossG: 0.446095\n",
      "[19: 1580/1795] train lossD: -0.089629 lossG: 0.334134\n",
      "[19: 1585/1795] train lossD: 0.006368 lossG: 0.281023\n",
      "[19: 1590/1795] train lossD: -0.165497 lossG: 0.097395\n",
      "[19: 1595/1795] train lossD: -0.631268 lossG: 0.426870\n",
      "[19: 1600/1795] train lossD: -0.745260 lossG: 0.543372\n",
      "[19: 1605/1795] train lossD: 0.083678 lossG: 0.750215\n",
      "[19: 1610/1795] train lossD: 0.095458 lossG: 0.477605\n",
      "[19: 1615/1795] train lossD: -0.060306 lossG: 0.455649\n",
      "[19: 1620/1795] train lossD: -0.008780 lossG: 0.490128\n",
      "[19: 1625/1795] train lossD: 0.052924 lossG: 0.380278\n",
      "[19: 1630/1795] train lossD: -0.124144 lossG: 0.412300\n",
      "[19: 1635/1795] train lossD: 0.003555 lossG: 0.126344\n",
      "[19: 1640/1795] train lossD: -0.144134 lossG: -0.150130\n",
      "[19: 1645/1795] train lossD: -0.328194 lossG: 0.617552\n",
      "[19: 1650/1795] train lossD: 0.028430 lossG: 0.185771\n",
      "[19: 1655/1795] train lossD: -0.084796 lossG: 0.339377\n",
      "[19: 1660/1795] train lossD: -0.060929 lossG: 0.367320\n",
      "[19: 1665/1795] train lossD: -0.379702 lossG: 0.753840\n",
      "[19: 1670/1795] train lossD: -0.377878 lossG: 0.193304\n",
      "[19: 1675/1795] train lossD: -0.520034 lossG: -0.467448\n",
      "[19: 1680/1795] train lossD: 0.070256 lossG: 0.432238\n",
      "[19: 1685/1795] train lossD: -0.008243 lossG: 0.492272\n",
      "[19: 1690/1795] train lossD: 0.005020 lossG: 0.448391\n",
      "[19: 1695/1795] train lossD: -0.095951 lossG: 0.504233\n",
      "[19: 1700/1795] train lossD: -0.023223 lossG: 0.429933\n",
      "[19: 1705/1795] train lossD: -0.064550 lossG: 0.471002\n",
      "[19: 1710/1795] train lossD: -0.050675 lossG: 0.426877\n",
      "[19: 1715/1795] train lossD: -0.080090 lossG: 0.306223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19: 1720/1795] train lossD: -0.132802 lossG: 0.286624\n",
      "[19: 1725/1795] train lossD: -0.296394 lossG: 0.411649\n",
      "[19: 1730/1795] train lossD: -0.046704 lossG: 0.486944\n",
      "[19: 1735/1795] train lossD: -0.324580 lossG: 0.033480\n",
      "[19: 1740/1795] train lossD: -0.200020 lossG: -0.249516\n",
      "[19: 1745/1795] train lossD: -0.295603 lossG: 0.263623\n",
      "[19: 1750/1795] train lossD: -0.828268 lossG: 0.346242\n",
      "[19: 1755/1795] train lossD: -0.293528 lossG: 0.278897\n",
      "[19: 1760/1795] train lossD: -0.410679 lossG: 0.446373\n",
      "[19: 1765/1795] train lossD: -0.065221 lossG: 0.111475\n",
      "[19: 1770/1795] train lossD: -0.656395 lossG: 0.343412\n",
      "[19: 1775/1795] train lossD: 0.367184 lossG: 0.431312\n",
      "[19: 1780/1795] train lossD: -0.016714 lossG: 0.444727\n",
      "[19: 1785/1795] train lossD: 0.075902 lossG: 0.410235\n",
      "[19: 1790/1795] train lossD: -0.620729 lossG: 0.068872\n",
      "0.04144319146871567\n"
     ]
    }
   ],
   "source": [
    "lambda_gp = 10\n",
    "n_critic = 5\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "num_batch = len(dataset)/32\n",
    "\n",
    "generator.cuda()\n",
    "discriminator.cuda()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "Tensor = torch.cuda.FloatTensor \n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lambda epoch: 0.98**epoch)\n",
    "lr_scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lambda epoch: 0.98**epoch)\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    #print(D)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    #print('grad_out', fake.shape)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.contiguous().view(gradients.size(0), -1) #.contiguous()\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "loss_metric = []\n",
    "evaluate = []\n",
    "for epoch in tqdm(range(20)):\n",
    "    loss_epoch = []\n",
    "    for i, (imgs) in enumerate(train_loader):\n",
    "\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "        optimizer_D.zero_grad()\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (32, 128))))\n",
    "        fake_imgs = generator(z)\n",
    "        real_validity = discriminator(real_imgs)\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "       # print()\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "\n",
    "        if i % n_critic == 0:\n",
    "\n",
    "            fake_imgs = generator(z)\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake_imgs)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            loss_epoch.append(g_loss.item())\n",
    "            print('[%d: %d/%d] train lossD: %f lossG: %f' %(epoch, i, num_batch, d_loss.item(), g_loss.item()))\n",
    "    \n",
    "    loss_metric.append(np.mean(loss_epoch))\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D.step()\n",
    "  \n",
    "\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs) in enumerate(train_loader):\n",
    "            real_imgs = Variable(imgs.type(Tensor))\n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (32, 128))))\n",
    "            fake_imgs = generator(z)\n",
    "            metric = evaluate_chamfer(real_imgs, fake_imgs)\n",
    "            print(metric.item())\n",
    "            break\n",
    "        evaluate.append(metric.item())\n",
    "        generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acb1737a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04706810414791107,\n",
       " 0.04150030016899109,\n",
       " 0.050314679741859436,\n",
       " 0.04303291440010071,\n",
       " 0.03097650408744812,\n",
       " 0.037385858595371246,\n",
       " 0.04351937025785446,\n",
       " 0.038115449249744415,\n",
       " 0.03754439949989319,\n",
       " 0.03710556402802467,\n",
       " 0.05840221047401428,\n",
       " 0.04416750371456146,\n",
       " 0.04391780495643616,\n",
       " 0.04444083571434021,\n",
       " 0.035055823624134064,\n",
       " 0.05547195300459862,\n",
       " 0.05058055743575096,\n",
       " 0.044261276721954346,\n",
       " 0.04403220862150192,\n",
       " 0.04144319146871567]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3acc0f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4323050262287134,\n",
       " 0.9222088059343003,\n",
       " 0.7767139810207494,\n",
       " 0.7275533637960642,\n",
       " 0.6970954487582767,\n",
       " 0.6279972803293828,\n",
       " 0.506528032440329,\n",
       " 0.45121871902085947,\n",
       " 0.45607200335493325,\n",
       " 0.44971108478091887,\n",
       " 0.4427383228264811,\n",
       " 0.4037037217019328,\n",
       " 0.37972715563428766,\n",
       " 0.37237212041128315,\n",
       " 0.3517938849819736,\n",
       " 0.37264720304845766,\n",
       " 0.37103379194035835,\n",
       " 0.3482412675546072,\n",
       " 0.26491313311984777,\n",
       " 0.18868337146040248]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203da94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (imgs) in enumerate(train_loader):\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (32, 128))))\n",
    "        fake_imgs = generator(z)\n",
    "        break\n",
    "    metric = evaluate_chamfer(real_imgs, fake_imgs)\n",
    "    #generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00add261",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    z = Variable(Tensor(np.random.normal(0, 1, (32, 128))))\n",
    "    generated_pcd = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "179071b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = generated_pcd[16]\n",
    "points = pcd.permute(1,0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1752e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "points = o3d.utility.Vector3dVector(points) \n",
    "pcd.points = points\n",
    "# Visualize the point cloud within open3d\n",
    "o3d.visualization.draw_geometries([pcd]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c656b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {'D': discriminator.state_dict(), 'D_O': optimizer_D.state_dict(), 'G': generator.state_dict(), 'G_O': optimizer_G.state_dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3128be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_dict, 'PGAN_20.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11b481b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (fc4): Linear(in_features=1024, out_features=6144, bias=True)\n",
       "  (th): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1843b0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf8153e39c74ffebdd645feed1e2d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20: 0/1795] train lossD: -0.807587 lossG: 0.481738\n",
      "[20: 5/1795] train lossD: -0.748141 lossG: 0.297474\n",
      "[20: 10/1795] train lossD: -0.106421 lossG: 0.207815\n",
      "[20: 15/1795] train lossD: -0.424177 lossG: -0.409612\n",
      "[20: 20/1795] train lossD: -0.578078 lossG: -0.003368\n",
      "[20: 25/1795] train lossD: -0.028709 lossG: -0.018827\n",
      "[20: 30/1795] train lossD: 0.097778 lossG: -0.069648\n",
      "[20: 35/1795] train lossD: -0.024229 lossG: -0.041482\n",
      "[20: 40/1795] train lossD: -0.114464 lossG: 0.117094\n",
      "[20: 45/1795] train lossD: -0.177651 lossG: -0.154578\n",
      "[20: 50/1795] train lossD: -0.610722 lossG: 0.155119\n",
      "[20: 55/1795] train lossD: 0.169039 lossG: 0.147169\n",
      "[20: 60/1795] train lossD: -0.046874 lossG: -0.091843\n",
      "[20: 65/1795] train lossD: -0.246674 lossG: 0.185377\n",
      "[20: 70/1795] train lossD: -0.892875 lossG: 0.282319\n",
      "[20: 75/1795] train lossD: 0.109280 lossG: 0.042113\n",
      "[20: 80/1795] train lossD: 0.047861 lossG: 0.057616\n",
      "[20: 85/1795] train lossD: 0.031247 lossG: 0.027552\n",
      "[20: 90/1795] train lossD: 0.008372 lossG: 0.086300\n",
      "[20: 95/1795] train lossD: -0.013386 lossG: 0.174444\n",
      "[20: 100/1795] train lossD: 0.005376 lossG: 0.089434\n",
      "[20: 105/1795] train lossD: -0.187663 lossG: 0.044787\n",
      "[20: 110/1795] train lossD: -0.380502 lossG: 0.181061\n",
      "[20: 115/1795] train lossD: -0.444518 lossG: 0.007644\n",
      "[20: 120/1795] train lossD: -0.859410 lossG: 0.157088\n",
      "[20: 125/1795] train lossD: -0.498701 lossG: -0.180150\n",
      "[20: 130/1795] train lossD: 0.278118 lossG: 0.175898\n",
      "[20: 135/1795] train lossD: 0.012309 lossG: 0.278472\n",
      "[20: 140/1795] train lossD: 0.024947 lossG: 0.315355\n",
      "[20: 145/1795] train lossD: -0.028204 lossG: 0.276344\n",
      "[20: 150/1795] train lossD: -0.023013 lossG: 0.240575\n",
      "[20: 155/1795] train lossD: -0.006085 lossG: 0.208665\n",
      "[20: 160/1795] train lossD: -0.013035 lossG: 0.209594\n",
      "[20: 165/1795] train lossD: 0.146211 lossG: 0.064918\n",
      "[20: 170/1795] train lossD: -0.033838 lossG: 0.135204\n",
      "[20: 175/1795] train lossD: 0.001315 lossG: 0.271591\n",
      "[20: 180/1795] train lossD: -0.033215 lossG: 0.133616\n",
      "[20: 185/1795] train lossD: -0.087590 lossG: 0.230757\n",
      "[20: 190/1795] train lossD: -0.919869 lossG: -0.242406\n",
      "[20: 195/1795] train lossD: -0.912464 lossG: 0.013804\n",
      "[20: 200/1795] train lossD: -0.382591 lossG: -0.124079\n",
      "[20: 205/1795] train lossD: 0.006431 lossG: 0.619896\n",
      "[20: 210/1795] train lossD: -0.534091 lossG: -0.305057\n",
      "[20: 215/1795] train lossD: -0.549336 lossG: -0.069199\n",
      "[20: 220/1795] train lossD: 0.076219 lossG: 0.042801\n",
      "[20: 225/1795] train lossD: -0.170527 lossG: 0.142160\n",
      "[20: 230/1795] train lossD: -0.931352 lossG: -0.125798\n",
      "[20: 235/1795] train lossD: 0.023191 lossG: -0.271436\n",
      "[20: 240/1795] train lossD: 0.060854 lossG: -0.221442\n",
      "[20: 245/1795] train lossD: 0.160679 lossG: 0.015052\n",
      "[20: 250/1795] train lossD: -0.207009 lossG: 0.224652\n",
      "[20: 255/1795] train lossD: -1.430190 lossG: 0.052587\n",
      "[20: 260/1795] train lossD: 0.046041 lossG: 0.104809\n",
      "[20: 265/1795] train lossD: -0.489883 lossG: 0.155767\n",
      "[20: 270/1795] train lossD: -0.252032 lossG: -0.216352\n",
      "[20: 275/1795] train lossD: -0.313021 lossG: -0.044640\n",
      "[20: 280/1795] train lossD: -0.035912 lossG: 0.330884\n",
      "[20: 285/1795] train lossD: -0.323498 lossG: 0.386082\n",
      "[20: 290/1795] train lossD: -0.046770 lossG: -0.036978\n",
      "[20: 295/1795] train lossD: 0.023422 lossG: 0.076425\n",
      "[20: 300/1795] train lossD: -0.379900 lossG: 0.349806\n",
      "[20: 305/1795] train lossD: -0.589713 lossG: -0.106853\n",
      "[20: 310/1795] train lossD: -0.893169 lossG: -0.075584\n",
      "[20: 315/1795] train lossD: 0.105304 lossG: 0.366089\n",
      "[20: 320/1795] train lossD: -0.114512 lossG: 0.263404\n",
      "[20: 325/1795] train lossD: -0.134442 lossG: 0.251859\n",
      "[20: 330/1795] train lossD: -0.215944 lossG: 0.110337\n",
      "[20: 335/1795] train lossD: -0.634669 lossG: -0.058422\n",
      "[20: 340/1795] train lossD: -0.543568 lossG: -0.037819\n",
      "[20: 345/1795] train lossD: -0.070610 lossG: 0.306620\n",
      "[20: 350/1795] train lossD: -0.187852 lossG: 0.022671\n",
      "[20: 355/1795] train lossD: -0.463909 lossG: -0.253425\n",
      "[20: 360/1795] train lossD: -0.109385 lossG: 0.419994\n",
      "[20: 365/1795] train lossD: -0.396323 lossG: 0.261727\n",
      "[20: 370/1795] train lossD: -0.484326 lossG: -0.119579\n",
      "[20: 375/1795] train lossD: -0.000642 lossG: 0.359209\n",
      "[20: 380/1795] train lossD: -0.310993 lossG: -0.279736\n",
      "[20: 385/1795] train lossD: -0.333472 lossG: 0.388290\n",
      "[20: 390/1795] train lossD: -0.742730 lossG: 0.082183\n",
      "[20: 395/1795] train lossD: 0.001496 lossG: -0.195157\n",
      "[20: 400/1795] train lossD: 0.014768 lossG: -0.208196\n",
      "[20: 405/1795] train lossD: -0.076634 lossG: -0.089903\n",
      "[20: 410/1795] train lossD: -0.100987 lossG: -0.251654\n",
      "[20: 415/1795] train lossD: -1.359524 lossG: 0.597223\n",
      "[20: 420/1795] train lossD: 0.038701 lossG: 0.499050\n",
      "[20: 425/1795] train lossD: 0.000664 lossG: 0.523540\n",
      "[20: 430/1795] train lossD: -0.013566 lossG: 0.556451\n",
      "[20: 435/1795] train lossD: -0.032306 lossG: 0.560124\n",
      "[20: 440/1795] train lossD: 0.029960 lossG: 0.500325\n",
      "[20: 445/1795] train lossD: 0.059289 lossG: 0.364924\n",
      "[20: 450/1795] train lossD: 0.068534 lossG: 0.236305\n",
      "[20: 455/1795] train lossD: -0.063989 lossG: 0.336480\n",
      "[20: 460/1795] train lossD: 0.003352 lossG: 0.204668\n",
      "[20: 465/1795] train lossD: -0.041492 lossG: 0.304551\n",
      "[20: 470/1795] train lossD: -0.114914 lossG: 0.221100\n",
      "[20: 475/1795] train lossD: -0.114295 lossG: 0.306657\n",
      "[20: 480/1795] train lossD: -1.204404 lossG: 0.111831\n",
      "[20: 485/1795] train lossD: -0.269658 lossG: -0.181484\n",
      "[20: 490/1795] train lossD: 0.054059 lossG: -0.128090\n",
      "[20: 495/1795] train lossD: 0.046735 lossG: -0.186661\n",
      "[20: 500/1795] train lossD: 0.003015 lossG: -0.264635\n",
      "[20: 505/1795] train lossD: 0.057282 lossG: -0.295609\n",
      "[20: 510/1795] train lossD: -0.052834 lossG: -0.215692\n",
      "[20: 515/1795] train lossD: -0.068459 lossG: -0.187939\n",
      "[20: 520/1795] train lossD: 0.085623 lossG: -0.223433\n",
      "[20: 525/1795] train lossD: -0.065165 lossG: -0.185170\n",
      "[20: 530/1795] train lossD: -0.026431 lossG: -0.218337\n",
      "[20: 535/1795] train lossD: -0.075160 lossG: -0.209034\n",
      "[20: 540/1795] train lossD: -0.106948 lossG: -0.061011\n",
      "[20: 545/1795] train lossD: -0.039981 lossG: -0.109846\n",
      "[20: 550/1795] train lossD: -0.016213 lossG: 0.037654\n",
      "[20: 555/1795] train lossD: -0.019546 lossG: 0.100382\n",
      "[20: 560/1795] train lossD: -0.647086 lossG: -0.178889\n",
      "[20: 565/1795] train lossD: -0.523299 lossG: -0.119483\n",
      "[20: 570/1795] train lossD: -0.841494 lossG: 0.101947\n",
      "[20: 575/1795] train lossD: -0.806097 lossG: -0.260440\n",
      "[20: 580/1795] train lossD: 0.002630 lossG: -0.134937\n",
      "[20: 585/1795] train lossD: 0.071286 lossG: -0.081216\n",
      "[20: 590/1795] train lossD: 0.025604 lossG: -0.086826\n",
      "[20: 595/1795] train lossD: -0.059437 lossG: -0.029921\n",
      "[20: 600/1795] train lossD: 0.027039 lossG: -0.031130\n",
      "[20: 605/1795] train lossD: -0.021595 lossG: -0.002462\n",
      "[20: 610/1795] train lossD: -0.041299 lossG: 0.069454\n",
      "[20: 615/1795] train lossD: -0.033523 lossG: 0.124839\n",
      "[20: 620/1795] train lossD: -0.054584 lossG: 0.111678\n",
      "[20: 625/1795] train lossD: -0.651245 lossG: -0.184779\n",
      "[20: 630/1795] train lossD: -1.253532 lossG: 0.164944\n",
      "[20: 635/1795] train lossD: -0.326611 lossG: -0.052325\n",
      "[20: 640/1795] train lossD: -1.170769 lossG: 0.319920\n",
      "[20: 645/1795] train lossD: -1.269625 lossG: 0.170677\n",
      "[20: 650/1795] train lossD: -0.917566 lossG: 0.193582\n",
      "[20: 655/1795] train lossD: -0.820259 lossG: -0.205287\n",
      "[20: 660/1795] train lossD: -0.008917 lossG: 0.189443\n",
      "[20: 665/1795] train lossD: 0.047237 lossG: 0.063642\n",
      "[20: 670/1795] train lossD: -0.622547 lossG: -0.635172\n",
      "[20: 675/1795] train lossD: -0.032214 lossG: 0.060558\n",
      "[20: 680/1795] train lossD: -0.909122 lossG: -0.224909\n",
      "[20: 685/1795] train lossD: 0.081969 lossG: -0.244046\n",
      "[20: 690/1795] train lossD: -0.251636 lossG: 0.159392\n",
      "[20: 695/1795] train lossD: 0.213101 lossG: 0.132340\n",
      "[20: 700/1795] train lossD: -0.413053 lossG: -0.265081\n",
      "[20: 705/1795] train lossD: -1.148232 lossG: -0.073639\n",
      "[20: 710/1795] train lossD: -0.354104 lossG: 0.049599\n",
      "[20: 715/1795] train lossD: 0.031098 lossG: -0.467472\n",
      "[20: 720/1795] train lossD: 0.027177 lossG: -0.457257\n",
      "[20: 725/1795] train lossD: -0.231084 lossG: -0.475390\n",
      "[20: 730/1795] train lossD: 0.063558 lossG: 0.220432\n",
      "[20: 735/1795] train lossD: -0.773491 lossG: -0.929847\n",
      "[20: 740/1795] train lossD: -0.568351 lossG: 0.024572\n",
      "[20: 745/1795] train lossD: -1.122656 lossG: -0.160633\n",
      "[20: 750/1795] train lossD: -0.834603 lossG: -0.230337\n",
      "[20: 755/1795] train lossD: -0.533190 lossG: -0.153097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20: 760/1795] train lossD: 0.020829 lossG: -0.284100\n",
      "[20: 765/1795] train lossD: -0.789840 lossG: -0.411486\n",
      "[20: 770/1795] train lossD: -1.427090 lossG: -0.806479\n",
      "[20: 775/1795] train lossD: 0.034753 lossG: 0.189283\n",
      "[20: 780/1795] train lossD: 0.153099 lossG: 0.264034\n",
      "[20: 785/1795] train lossD: 0.049522 lossG: 0.330557\n",
      "[20: 790/1795] train lossD: 0.031899 lossG: 0.396909\n",
      "[20: 795/1795] train lossD: -0.034588 lossG: 0.316733\n",
      "[20: 800/1795] train lossD: 0.037472 lossG: 0.208986\n",
      "[20: 805/1795] train lossD: -0.022307 lossG: 0.046562\n",
      "[20: 810/1795] train lossD: -0.040782 lossG: 0.061139\n",
      "[20: 815/1795] train lossD: -0.042128 lossG: 0.148480\n",
      "[20: 820/1795] train lossD: -0.003080 lossG: 0.080112\n",
      "[20: 825/1795] train lossD: 0.056688 lossG: -0.140723\n",
      "[20: 830/1795] train lossD: -0.177413 lossG: -0.128567\n",
      "[20: 835/1795] train lossD: -0.345335 lossG: -0.409033\n",
      "[20: 840/1795] train lossD: -0.352528 lossG: -0.186890\n",
      "[20: 845/1795] train lossD: -0.672054 lossG: -0.019124\n",
      "[20: 850/1795] train lossD: -1.573697 lossG: 0.131487\n",
      "[20: 855/1795] train lossD: -0.387875 lossG: -0.457825\n",
      "[20: 860/1795] train lossD: 0.030165 lossG: 0.603421\n",
      "[20: 865/1795] train lossD: -0.000096 lossG: 0.534039\n",
      "[20: 870/1795] train lossD: -0.057394 lossG: 0.514747\n",
      "[20: 875/1795] train lossD: -0.017952 lossG: 0.496819\n",
      "[20: 880/1795] train lossD: -0.086530 lossG: 0.385918\n",
      "[20: 885/1795] train lossD: -0.084702 lossG: 0.415418\n",
      "[20: 890/1795] train lossD: 0.492106 lossG: -0.097655\n",
      "[20: 895/1795] train lossD: -0.243278 lossG: -0.051980\n",
      "[20: 900/1795] train lossD: -1.595096 lossG: 0.420280\n",
      "[20: 905/1795] train lossD: -0.374106 lossG: -0.156305\n",
      "[20: 910/1795] train lossD: -0.643271 lossG: -0.761061\n",
      "[20: 915/1795] train lossD: -0.610206 lossG: 0.498709\n",
      "[20: 920/1795] train lossD: -0.094114 lossG: 0.297681\n",
      "[20: 925/1795] train lossD: -0.251368 lossG: 0.233801\n",
      "[20: 930/1795] train lossD: -0.196140 lossG: -0.158488\n",
      "[20: 935/1795] train lossD: -0.203157 lossG: 0.323802\n",
      "[20: 940/1795] train lossD: -0.515961 lossG: 0.440552\n",
      "[20: 945/1795] train lossD: 0.093551 lossG: -0.244813\n",
      "[20: 950/1795] train lossD: -0.041262 lossG: -0.239101\n",
      "[20: 955/1795] train lossD: 0.049562 lossG: -0.247070\n",
      "[20: 960/1795] train lossD: -0.010864 lossG: -0.207136\n",
      "[20: 965/1795] train lossD: -0.053741 lossG: -0.136645\n",
      "[20: 970/1795] train lossD: -0.009647 lossG: -0.104625\n",
      "[20: 975/1795] train lossD: -0.050605 lossG: -0.085108\n",
      "[20: 980/1795] train lossD: 0.092029 lossG: 0.017595\n",
      "[20: 985/1795] train lossD: 0.095891 lossG: 0.139802\n",
      "[20: 990/1795] train lossD: -0.199412 lossG: -0.248840\n",
      "[20: 995/1795] train lossD: -0.761188 lossG: -0.659211\n",
      "[20: 1000/1795] train lossD: 0.009110 lossG: 0.011184\n",
      "[20: 1005/1795] train lossD: 0.106388 lossG: 0.109663\n",
      "[20: 1010/1795] train lossD: 0.056154 lossG: 0.125078\n",
      "[20: 1015/1795] train lossD: -0.025181 lossG: 0.145217\n",
      "[20: 1020/1795] train lossD: -0.208141 lossG: -0.311206\n",
      "[20: 1025/1795] train lossD: -0.074595 lossG: 0.284250\n",
      "[20: 1030/1795] train lossD: -0.329328 lossG: 0.414519\n",
      "[20: 1035/1795] train lossD: -0.273064 lossG: 0.083313\n",
      "[20: 1040/1795] train lossD: 0.162743 lossG: -0.177352\n",
      "[20: 1045/1795] train lossD: -0.173498 lossG: -0.161416\n",
      "[20: 1050/1795] train lossD: 0.121078 lossG: -0.163741\n",
      "[20: 1055/1795] train lossD: -0.282673 lossG: -0.071562\n",
      "[20: 1060/1795] train lossD: -1.130322 lossG: 0.027855\n",
      "[20: 1065/1795] train lossD: -0.282896 lossG: -0.330094\n",
      "[20: 1070/1795] train lossD: 0.145873 lossG: 0.389436\n",
      "[20: 1075/1795] train lossD: 0.008304 lossG: 0.175442\n",
      "[20: 1080/1795] train lossD: -0.130903 lossG: 0.010556\n",
      "[20: 1085/1795] train lossD: -0.159057 lossG: 0.254800\n",
      "[20: 1090/1795] train lossD: -1.190004 lossG: 0.109561\n",
      "[20: 1095/1795] train lossD: -1.418924 lossG: -0.191107\n",
      "[20: 1100/1795] train lossD: -0.583822 lossG: 0.251149\n",
      "[20: 1105/1795] train lossD: -0.405888 lossG: 0.745081\n",
      "[20: 1110/1795] train lossD: -0.018055 lossG: -0.168440\n",
      "[20: 1115/1795] train lossD: 0.088004 lossG: -0.026101\n",
      "[20: 1120/1795] train lossD: -0.166936 lossG: -0.076446\n",
      "[20: 1125/1795] train lossD: -1.042427 lossG: -0.032630\n",
      "[20: 1130/1795] train lossD: 0.076140 lossG: 0.271416\n",
      "[20: 1135/1795] train lossD: 0.038677 lossG: 0.318888\n",
      "[20: 1140/1795] train lossD: 0.036057 lossG: 0.322372\n",
      "[20: 1145/1795] train lossD: -0.058494 lossG: 0.271211\n",
      "[20: 1150/1795] train lossD: -0.018230 lossG: 0.373573\n",
      "[20: 1155/1795] train lossD: -0.104484 lossG: 0.120761\n",
      "[20: 1160/1795] train lossD: -0.459958 lossG: -0.527422\n",
      "[20: 1165/1795] train lossD: -0.592942 lossG: 0.335185\n",
      "[20: 1170/1795] train lossD: -0.356705 lossG: -0.100088\n",
      "[20: 1175/1795] train lossD: 0.388454 lossG: -0.079920\n",
      "[20: 1180/1795] train lossD: -0.041626 lossG: 0.113754\n",
      "[20: 1185/1795] train lossD: -0.596455 lossG: -0.179577\n",
      "[20: 1190/1795] train lossD: -1.367679 lossG: 0.424284\n",
      "[20: 1195/1795] train lossD: -0.450465 lossG: -0.370069\n",
      "[20: 1200/1795] train lossD: -0.486709 lossG: 0.240447\n",
      "[20: 1205/1795] train lossD: -0.836039 lossG: 0.186004\n",
      "[20: 1210/1795] train lossD: 0.740618 lossG: -0.138033\n",
      "[20: 1215/1795] train lossD: 0.037540 lossG: -0.080269\n",
      "[20: 1220/1795] train lossD: -0.058175 lossG: -0.734195\n",
      "[20: 1225/1795] train lossD: 0.088203 lossG: 0.353658\n",
      "[20: 1230/1795] train lossD: -0.076899 lossG: 0.528886\n",
      "[20: 1235/1795] train lossD: -0.224372 lossG: 0.523736\n",
      "[20: 1240/1795] train lossD: -0.172688 lossG: 0.411688\n",
      "[20: 1245/1795] train lossD: -0.737203 lossG: 0.126199\n",
      "[20: 1250/1795] train lossD: 0.039550 lossG: -0.180488\n",
      "[20: 1255/1795] train lossD: 0.061155 lossG: -0.139006\n",
      "[20: 1260/1795] train lossD: 0.014247 lossG: -0.087703\n",
      "[20: 1265/1795] train lossD: -0.021203 lossG: -0.027567\n",
      "[20: 1270/1795] train lossD: -0.045295 lossG: 0.104084\n",
      "[20: 1275/1795] train lossD: -0.420238 lossG: -0.167190\n",
      "[20: 1280/1795] train lossD: -0.894154 lossG: 0.211006\n",
      "[20: 1285/1795] train lossD: -1.004651 lossG: -0.642932\n",
      "[20: 1290/1795] train lossD: 0.054346 lossG: -0.056793\n",
      "[20: 1295/1795] train lossD: -0.132549 lossG: 0.275833\n",
      "[20: 1300/1795] train lossD: -0.410433 lossG: 0.040278\n",
      "[20: 1305/1795] train lossD: -0.188809 lossG: 0.588548\n",
      "[20: 1310/1795] train lossD: -0.708273 lossG: -0.413891\n",
      "[20: 1315/1795] train lossD: -0.022035 lossG: -0.176147\n",
      "[20: 1320/1795] train lossD: 0.121784 lossG: -0.068703\n",
      "[20: 1325/1795] train lossD: -0.228457 lossG: 0.137033\n",
      "[20: 1330/1795] train lossD: -0.697467 lossG: 0.115320\n",
      "[20: 1335/1795] train lossD: -0.283058 lossG: -0.251801\n",
      "[20: 1340/1795] train lossD: -1.273391 lossG: -0.138380\n",
      "[20: 1345/1795] train lossD: -1.022472 lossG: -0.259041\n",
      "[20: 1350/1795] train lossD: -0.078812 lossG: 0.054045\n",
      "[20: 1355/1795] train lossD: -0.096743 lossG: -0.014101\n",
      "[20: 1360/1795] train lossD: -0.503420 lossG: -0.352670\n",
      "[20: 1365/1795] train lossD: -1.368006 lossG: -0.614828\n",
      "[20: 1370/1795] train lossD: 0.008734 lossG: -0.227098\n",
      "[20: 1375/1795] train lossD: 0.024375 lossG: -0.201348\n",
      "[20: 1380/1795] train lossD: 0.008696 lossG: -0.081810\n",
      "[20: 1385/1795] train lossD: 0.023095 lossG: -0.041010\n",
      "[20: 1390/1795] train lossD: 0.014548 lossG: -0.060015\n",
      "[20: 1395/1795] train lossD: -0.608387 lossG: 0.580764\n",
      "[20: 1400/1795] train lossD: -1.365919 lossG: 0.261724\n",
      "[20: 1405/1795] train lossD: -0.028236 lossG: -0.408566\n",
      "[20: 1410/1795] train lossD: -0.180287 lossG: -0.247066\n",
      "[20: 1415/1795] train lossD: -0.638374 lossG: -0.440467\n",
      "[20: 1420/1795] train lossD: 1.832069 lossG: 0.188014\n",
      "[20: 1425/1795] train lossD: 0.061077 lossG: 0.235175\n",
      "[20: 1430/1795] train lossD: 0.015644 lossG: 0.092458\n",
      "[20: 1435/1795] train lossD: 0.068836 lossG: 0.156915\n",
      "[20: 1440/1795] train lossD: -0.003309 lossG: 0.216793\n",
      "[20: 1445/1795] train lossD: -0.420555 lossG: 0.101466\n",
      "[20: 1450/1795] train lossD: -0.888127 lossG: -0.030473\n",
      "[20: 1455/1795] train lossD: -1.285379 lossG: 0.108813\n",
      "[20: 1460/1795] train lossD: -0.164411 lossG: -0.328638\n",
      "[20: 1465/1795] train lossD: -1.382609 lossG: -0.155921\n",
      "[20: 1470/1795] train lossD: -1.481295 lossG: -0.152617\n",
      "[20: 1475/1795] train lossD: -1.527132 lossG: -0.186229\n",
      "[20: 1480/1795] train lossD: 0.067648 lossG: -0.410063\n",
      "[20: 1485/1795] train lossD: -0.357967 lossG: -0.407433\n",
      "[20: 1490/1795] train lossD: -0.841118 lossG: -0.496757\n",
      "[20: 1495/1795] train lossD: -0.645105 lossG: -0.483247\n",
      "[20: 1500/1795] train lossD: 0.001136 lossG: -0.146183\n",
      "[20: 1505/1795] train lossD: -0.981523 lossG: -0.983211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20: 1510/1795] train lossD: 0.229047 lossG: 0.067796\n",
      "[20: 1515/1795] train lossD: 0.056498 lossG: 0.135144\n",
      "[20: 1520/1795] train lossD: -0.092086 lossG: 0.177526\n",
      "[20: 1525/1795] train lossD: 0.003877 lossG: 0.209724\n",
      "[20: 1530/1795] train lossD: 0.037385 lossG: 0.279255\n",
      "[20: 1535/1795] train lossD: 0.096546 lossG: 0.262552\n",
      "[20: 1540/1795] train lossD: 0.015448 lossG: 0.236089\n",
      "[20: 1545/1795] train lossD: -0.007470 lossG: 0.200547\n",
      "[20: 1550/1795] train lossD: -0.042142 lossG: 0.244105\n",
      "[20: 1555/1795] train lossD: -0.069728 lossG: 0.286821\n",
      "[20: 1560/1795] train lossD: -0.061560 lossG: 0.193381\n",
      "[20: 1565/1795] train lossD: -0.036469 lossG: 0.228478\n",
      "[20: 1570/1795] train lossD: -0.069730 lossG: 0.123842\n",
      "[20: 1575/1795] train lossD: -0.305970 lossG: 0.097855\n",
      "[20: 1580/1795] train lossD: -0.621070 lossG: -0.116850\n",
      "[20: 1585/1795] train lossD: -0.390693 lossG: -0.334977\n",
      "[20: 1590/1795] train lossD: -0.790113 lossG: -0.420916\n",
      "[20: 1595/1795] train lossD: -1.118239 lossG: 0.110824\n",
      "[20: 1600/1795] train lossD: 0.130178 lossG: 0.412462\n",
      "[20: 1605/1795] train lossD: -0.027721 lossG: 0.470126\n",
      "[20: 1610/1795] train lossD: -0.042901 lossG: 0.495624\n",
      "[20: 1615/1795] train lossD: -0.046997 lossG: 0.455450\n",
      "[20: 1620/1795] train lossD: -0.017588 lossG: 0.391136\n",
      "[20: 1625/1795] train lossD: -0.029242 lossG: 0.387126\n",
      "[20: 1630/1795] train lossD: -0.020403 lossG: 0.432291\n",
      "[20: 1635/1795] train lossD: -0.023945 lossG: 0.232228\n",
      "[20: 1640/1795] train lossD: -0.514210 lossG: -0.118269\n",
      "[20: 1645/1795] train lossD: -0.520317 lossG: -0.191414\n",
      "[20: 1650/1795] train lossD: -0.409492 lossG: -0.464290\n",
      "[20: 1655/1795] train lossD: -0.195588 lossG: -0.597101\n",
      "[20: 1660/1795] train lossD: 0.150907 lossG: -0.020810\n",
      "[20: 1665/1795] train lossD: 0.189178 lossG: 0.305649\n",
      "[20: 1670/1795] train lossD: -0.047684 lossG: 0.197306\n",
      "[20: 1675/1795] train lossD: -0.210292 lossG: 0.313698\n",
      "[20: 1680/1795] train lossD: -1.037862 lossG: 0.166404\n",
      "[20: 1685/1795] train lossD: -0.386606 lossG: -0.229864\n",
      "[20: 1690/1795] train lossD: -0.619281 lossG: -0.061352\n",
      "[20: 1695/1795] train lossD: -0.773468 lossG: -0.147735\n",
      "[20: 1700/1795] train lossD: 0.129039 lossG: -0.532071\n",
      "[20: 1705/1795] train lossD: 0.225162 lossG: -0.509578\n",
      "[20: 1710/1795] train lossD: 0.029129 lossG: -0.248157\n",
      "[20: 1715/1795] train lossD: -0.175675 lossG: -0.201661\n",
      "[20: 1720/1795] train lossD: -0.172786 lossG: 0.198278\n",
      "[20: 1725/1795] train lossD: -0.155666 lossG: 0.364280\n",
      "[20: 1730/1795] train lossD: -1.440030 lossG: 0.220596\n",
      "[20: 1735/1795] train lossD: -0.445904 lossG: -0.384098\n",
      "[20: 1740/1795] train lossD: -1.095450 lossG: 0.329582\n",
      "[20: 1745/1795] train lossD: -0.449942 lossG: 0.021164\n",
      "[20: 1750/1795] train lossD: -1.808198 lossG: 0.340015\n",
      "[20: 1755/1795] train lossD: -0.774397 lossG: -0.144327\n",
      "[20: 1760/1795] train lossD: -1.477347 lossG: 0.113127\n",
      "[20: 1765/1795] train lossD: -0.386455 lossG: -0.660108\n",
      "[20: 1770/1795] train lossD: -0.252910 lossG: 0.315952\n",
      "[20: 1775/1795] train lossD: -0.223221 lossG: 0.431740\n",
      "[20: 1780/1795] train lossD: -0.773719 lossG: 0.267499\n",
      "[20: 1785/1795] train lossD: -1.124232 lossG: 0.075385\n",
      "[20: 1790/1795] train lossD: -0.249126 lossG: 0.133971\n",
      "0.038034774363040924\n",
      "[21: 0/1795] train lossD: -0.413842 lossG: -0.113441\n",
      "[21: 5/1795] train lossD: -0.386533 lossG: 0.109523\n",
      "[21: 10/1795] train lossD: -0.462510 lossG: 0.111163\n",
      "[21: 15/1795] train lossD: -0.502173 lossG: -0.327909\n",
      "[21: 20/1795] train lossD: -0.716671 lossG: 0.005790\n",
      "[21: 25/1795] train lossD: -1.200065 lossG: 0.369389\n",
      "[21: 30/1795] train lossD: -0.653467 lossG: -0.146618\n",
      "[21: 35/1795] train lossD: 0.126288 lossG: 0.131558\n",
      "[21: 40/1795] train lossD: -1.248598 lossG: 0.366204\n",
      "[21: 45/1795] train lossD: -0.804776 lossG: 0.342573\n",
      "[21: 50/1795] train lossD: -1.830267 lossG: 0.227929\n",
      "[21: 55/1795] train lossD: -2.361920 lossG: 0.439894\n",
      "[21: 60/1795] train lossD: -0.000633 lossG: -0.041675\n",
      "[21: 65/1795] train lossD: -0.169278 lossG: -0.581780\n",
      "[21: 70/1795] train lossD: -0.680924 lossG: 0.110998\n",
      "[21: 75/1795] train lossD: -1.113784 lossG: 0.139747\n",
      "[21: 80/1795] train lossD: 0.106165 lossG: -0.673007\n",
      "[21: 85/1795] train lossD: 0.076784 lossG: -0.448548\n",
      "[21: 90/1795] train lossD: -0.012636 lossG: -0.281180\n",
      "[21: 95/1795] train lossD: -0.003891 lossG: -0.151291\n",
      "[21: 100/1795] train lossD: -0.556039 lossG: -0.399225\n",
      "[21: 105/1795] train lossD: -1.155838 lossG: 0.327899\n",
      "[21: 110/1795] train lossD: -1.180706 lossG: 0.250856\n",
      "[21: 115/1795] train lossD: -0.875849 lossG: -0.823240\n",
      "[21: 120/1795] train lossD: 0.084022 lossG: -0.661766\n",
      "[21: 125/1795] train lossD: 0.056914 lossG: -0.685599\n",
      "[21: 130/1795] train lossD: 0.017116 lossG: -0.671814\n",
      "[21: 135/1795] train lossD: 0.068622 lossG: -0.633071\n",
      "[21: 140/1795] train lossD: -0.016194 lossG: -0.539706\n",
      "[21: 145/1795] train lossD: 0.010967 lossG: -0.427165\n",
      "[21: 150/1795] train lossD: 0.047945 lossG: -0.401875\n",
      "[21: 155/1795] train lossD: -0.138743 lossG: -0.305740\n",
      "[21: 160/1795] train lossD: -0.688364 lossG: 0.021253\n",
      "[21: 165/1795] train lossD: -0.003073 lossG: 0.305890\n",
      "[21: 170/1795] train lossD: -0.900783 lossG: -0.483579\n",
      "[21: 175/1795] train lossD: 9.642150 lossG: 0.090257\n",
      "[21: 180/1795] train lossD: 0.145535 lossG: 0.207923\n",
      "[21: 185/1795] train lossD: 0.007086 lossG: 0.269127\n",
      "[21: 190/1795] train lossD: -0.065315 lossG: 0.245028\n",
      "[21: 195/1795] train lossD: 0.007789 lossG: 0.245939\n",
      "[21: 200/1795] train lossD: -0.021446 lossG: 0.172858\n",
      "[21: 205/1795] train lossD: 0.055134 lossG: 0.150414\n",
      "[21: 210/1795] train lossD: 0.000482 lossG: 0.152392\n",
      "[21: 215/1795] train lossD: -0.450609 lossG: -0.302126\n",
      "[21: 220/1795] train lossD: -1.006910 lossG: -0.296446\n",
      "[21: 225/1795] train lossD: -0.077850 lossG: -0.182410\n",
      "[21: 230/1795] train lossD: -0.894070 lossG: 0.002070\n",
      "[21: 235/1795] train lossD: -1.101716 lossG: -0.129247\n",
      "[21: 240/1795] train lossD: -0.027035 lossG: -0.385590\n",
      "[21: 245/1795] train lossD: 0.075168 lossG: -0.027136\n",
      "[21: 250/1795] train lossD: -0.442192 lossG: -0.522962\n",
      "[21: 255/1795] train lossD: 7.567089 lossG: 0.143040\n",
      "[21: 260/1795] train lossD: -0.035653 lossG: 0.309123\n",
      "[21: 265/1795] train lossD: 0.067755 lossG: 0.286276\n",
      "[21: 270/1795] train lossD: 0.069312 lossG: 0.173468\n",
      "[21: 275/1795] train lossD: -0.004530 lossG: 0.217551\n",
      "[21: 280/1795] train lossD: -0.020166 lossG: 0.236456\n",
      "[21: 285/1795] train lossD: -0.097768 lossG: 0.186448\n",
      "[21: 290/1795] train lossD: -0.060130 lossG: 0.182366\n",
      "[21: 295/1795] train lossD: -0.748506 lossG: -0.279674\n",
      "[21: 300/1795] train lossD: -1.665706 lossG: -0.311983\n",
      "[21: 305/1795] train lossD: 0.033007 lossG: -0.617520\n",
      "[21: 310/1795] train lossD: 0.078043 lossG: -0.540596\n",
      "[21: 315/1795] train lossD: 0.065385 lossG: -0.540494\n",
      "[21: 320/1795] train lossD: 0.299068 lossG: -0.414774\n",
      "[21: 325/1795] train lossD: 0.042226 lossG: -0.364036\n",
      "[21: 330/1795] train lossD: 0.032264 lossG: -0.379389\n",
      "[21: 335/1795] train lossD: -0.037994 lossG: -0.227115\n",
      "[21: 340/1795] train lossD: -0.057987 lossG: -0.102358\n",
      "[21: 345/1795] train lossD: -0.146549 lossG: -0.082190\n",
      "[21: 350/1795] train lossD: -0.559390 lossG: -0.445175\n",
      "[21: 355/1795] train lossD: -1.534245 lossG: -0.165957\n",
      "[21: 360/1795] train lossD: -0.292134 lossG: -0.249968\n",
      "[21: 365/1795] train lossD: -1.095255 lossG: 0.020894\n",
      "[21: 370/1795] train lossD: -1.449807 lossG: 0.022641\n",
      "[21: 375/1795] train lossD: -1.590098 lossG: 0.521832\n",
      "[21: 380/1795] train lossD: -0.308591 lossG: -0.105182\n",
      "[21: 385/1795] train lossD: 4.672815 lossG: 0.102879\n",
      "[21: 390/1795] train lossD: 0.036665 lossG: 0.190006\n",
      "[21: 395/1795] train lossD: 0.021542 lossG: 0.180949\n",
      "[21: 400/1795] train lossD: 0.019557 lossG: 0.119020\n",
      "[21: 405/1795] train lossD: 0.045812 lossG: 0.060220\n",
      "[21: 410/1795] train lossD: -0.018117 lossG: 0.162286\n",
      "[21: 415/1795] train lossD: -0.047334 lossG: 0.041347\n",
      "[21: 420/1795] train lossD: -0.014827 lossG: 0.044577\n",
      "[21: 425/1795] train lossD: -0.301617 lossG: -0.056380\n",
      "[21: 430/1795] train lossD: -0.143658 lossG: 0.461458\n",
      "[21: 435/1795] train lossD: 0.350897 lossG: 0.450139\n",
      "[21: 440/1795] train lossD: 0.070185 lossG: 0.494870\n",
      "[21: 445/1795] train lossD: -0.024024 lossG: 0.587018\n",
      "[21: 450/1795] train lossD: 0.037168 lossG: 0.475105\n",
      "[21: 455/1795] train lossD: -0.001936 lossG: 0.271505\n",
      "[21: 460/1795] train lossD: -0.297495 lossG: 0.362424\n",
      "[21: 465/1795] train lossD: -1.215928 lossG: -1.318200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21: 470/1795] train lossD: -0.144023 lossG: 0.447918\n",
      "[21: 475/1795] train lossD: -0.544629 lossG: 0.181151\n",
      "[21: 480/1795] train lossD: -0.814790 lossG: 0.239695\n",
      "[21: 485/1795] train lossD: -1.380573 lossG: -0.017210\n",
      "[21: 490/1795] train lossD: -0.084046 lossG: 0.112156\n",
      "[21: 495/1795] train lossD: -0.946914 lossG: -0.136392\n",
      "[21: 500/1795] train lossD: -0.774300 lossG: 0.082123\n",
      "[21: 505/1795] train lossD: 0.062043 lossG: 0.143084\n",
      "[21: 510/1795] train lossD: 0.009030 lossG: 0.228548\n",
      "[21: 515/1795] train lossD: -0.052567 lossG: 0.393810\n",
      "[21: 520/1795] train lossD: 0.071534 lossG: 0.359392\n",
      "[21: 525/1795] train lossD: 0.000448 lossG: 0.364192\n",
      "[21: 530/1795] train lossD: 0.031893 lossG: 0.278142\n",
      "[21: 535/1795] train lossD: -0.145217 lossG: 0.049643\n",
      "[21: 540/1795] train lossD: -0.006338 lossG: 0.262318\n",
      "[21: 545/1795] train lossD: -0.256832 lossG: 0.048698\n",
      "[21: 550/1795] train lossD: -0.952073 lossG: 0.513741\n",
      "[21: 555/1795] train lossD: -0.115281 lossG: -0.000642\n",
      "[21: 560/1795] train lossD: -0.898537 lossG: 0.434183\n",
      "[21: 565/1795] train lossD: 0.029907 lossG: 0.456728\n",
      "[21: 570/1795] train lossD: 0.121637 lossG: 0.501355\n",
      "[21: 575/1795] train lossD: 0.089884 lossG: 0.503163\n",
      "[21: 580/1795] train lossD: 0.025975 lossG: 0.519140\n",
      "[21: 585/1795] train lossD: 0.056032 lossG: 0.490766\n",
      "[21: 590/1795] train lossD: -0.006658 lossG: 0.559136\n",
      "[21: 595/1795] train lossD: 0.062837 lossG: 0.461838\n",
      "[21: 600/1795] train lossD: 0.060616 lossG: 0.371404\n",
      "[21: 605/1795] train lossD: -0.032428 lossG: 0.433651\n",
      "[21: 610/1795] train lossD: 0.160682 lossG: 0.216904\n",
      "[21: 615/1795] train lossD: -0.002028 lossG: 0.184414\n",
      "[21: 620/1795] train lossD: -0.038446 lossG: 0.207865\n",
      "[21: 625/1795] train lossD: -0.029434 lossG: 0.197541\n",
      "[21: 630/1795] train lossD: -0.803794 lossG: -0.026618\n",
      "[21: 635/1795] train lossD: -0.809566 lossG: 0.270641\n",
      "[21: 640/1795] train lossD: 0.031532 lossG: 0.334367\n",
      "[21: 645/1795] train lossD: -0.086325 lossG: 0.598377\n",
      "[21: 650/1795] train lossD: -0.043575 lossG: 0.307353\n",
      "[21: 655/1795] train lossD: -0.477610 lossG: -0.165166\n",
      "[21: 660/1795] train lossD: -1.165044 lossG: 0.357439\n",
      "[21: 665/1795] train lossD: -0.314145 lossG: 0.723534\n",
      "[21: 670/1795] train lossD: -0.630692 lossG: -0.531803\n",
      "[21: 675/1795] train lossD: -1.483520 lossG: -0.552245\n",
      "[21: 680/1795] train lossD: -0.329293 lossG: -0.259125\n",
      "[21: 685/1795] train lossD: -0.024898 lossG: 0.262139\n",
      "[21: 690/1795] train lossD: -1.816210 lossG: -0.068672\n",
      "[21: 695/1795] train lossD: -1.321250 lossG: -1.017357\n",
      "[21: 700/1795] train lossD: -0.072138 lossG: -0.218112\n",
      "[21: 705/1795] train lossD: -0.076115 lossG: -0.027453\n",
      "[21: 710/1795] train lossD: -0.668392 lossG: 0.395669\n",
      "[21: 715/1795] train lossD: -0.112362 lossG: 0.784841\n",
      "[21: 720/1795] train lossD: -0.067768 lossG: 0.576744\n",
      "[21: 725/1795] train lossD: -2.101113 lossG: 0.760735\n",
      "[21: 730/1795] train lossD: -1.410835 lossG: 0.259551\n",
      "[21: 735/1795] train lossD: -0.218263 lossG: 0.252354\n",
      "[21: 740/1795] train lossD: 0.016438 lossG: 0.309696\n",
      "[21: 745/1795] train lossD: -1.332537 lossG: -0.191404\n",
      "[21: 750/1795] train lossD: -1.295785 lossG: -0.161944\n",
      "[21: 755/1795] train lossD: -0.171946 lossG: -0.043417\n",
      "[21: 760/1795] train lossD: -1.204672 lossG: 0.253981\n",
      "[21: 765/1795] train lossD: -0.113448 lossG: 0.425759\n",
      "[21: 770/1795] train lossD: -0.007636 lossG: 0.374124\n",
      "[21: 775/1795] train lossD: 0.028927 lossG: 0.321333\n",
      "[21: 780/1795] train lossD: -0.070874 lossG: 0.184788\n",
      "[21: 785/1795] train lossD: -0.263689 lossG: 0.250605\n",
      "[21: 790/1795] train lossD: -1.200877 lossG: -0.805942\n",
      "[21: 795/1795] train lossD: -0.449647 lossG: -0.318991\n",
      "[21: 800/1795] train lossD: -1.663156 lossG: -0.164099\n",
      "[21: 805/1795] train lossD: -0.704071 lossG: -0.421338\n",
      "[21: 810/1795] train lossD: -1.685800 lossG: 0.059129\n",
      "[21: 815/1795] train lossD: -0.447625 lossG: -0.177971\n",
      "[21: 820/1795] train lossD: 0.126092 lossG: 0.159380\n",
      "[21: 825/1795] train lossD: -0.091379 lossG: -0.337181\n",
      "[21: 830/1795] train lossD: -0.138381 lossG: -0.104982\n",
      "[21: 835/1795] train lossD: -0.434941 lossG: -0.343598\n",
      "[21: 840/1795] train lossD: 0.349101 lossG: -0.500199\n",
      "[21: 845/1795] train lossD: -0.981037 lossG: -0.362808\n",
      "[21: 850/1795] train lossD: -2.101457 lossG: 0.190053\n",
      "[21: 855/1795] train lossD: -0.638955 lossG: -0.383848\n",
      "[21: 860/1795] train lossD: -0.982219 lossG: 0.092213\n",
      "[21: 865/1795] train lossD: -2.526280 lossG: -0.406548\n",
      "[21: 870/1795] train lossD: -0.125324 lossG: 0.423454\n",
      "[21: 875/1795] train lossD: -1.851633 lossG: -0.313137\n",
      "[21: 880/1795] train lossD: -0.045443 lossG: -0.056102\n",
      "[21: 885/1795] train lossD: 0.072272 lossG: -0.137662\n",
      "[21: 890/1795] train lossD: -0.221108 lossG: -0.156968\n",
      "[21: 895/1795] train lossD: -1.661566 lossG: 0.192162\n",
      "[21: 900/1795] train lossD: 6.187518 lossG: -0.362597\n",
      "[21: 905/1795] train lossD: 0.009545 lossG: -0.375215\n",
      "[21: 910/1795] train lossD: -0.054758 lossG: -0.327913\n",
      "[21: 915/1795] train lossD: -0.078628 lossG: -0.343762\n",
      "[21: 920/1795] train lossD: -1.066004 lossG: 0.016615\n",
      "[21: 925/1795] train lossD: -1.413806 lossG: 0.023642\n",
      "[21: 930/1795] train lossD: -0.551598 lossG: -0.136027\n",
      "[21: 935/1795] train lossD: -1.158713 lossG: 0.106407\n",
      "[21: 940/1795] train lossD: 16.559179 lossG: -0.584151\n",
      "[21: 945/1795] train lossD: 0.129873 lossG: -0.554946\n",
      "[21: 950/1795] train lossD: 0.087127 lossG: -0.559938\n",
      "[21: 955/1795] train lossD: 0.301007 lossG: -0.583658\n",
      "[21: 960/1795] train lossD: 0.084813 lossG: -0.478354\n",
      "[21: 965/1795] train lossD: -0.023598 lossG: -0.413742\n",
      "[21: 970/1795] train lossD: 0.000675 lossG: -0.352636\n",
      "[21: 975/1795] train lossD: -0.158343 lossG: -0.206684\n",
      "[21: 980/1795] train lossD: 0.045996 lossG: -0.298435\n",
      "[21: 985/1795] train lossD: -0.016514 lossG: -0.078075\n",
      "[21: 990/1795] train lossD: -1.310402 lossG: -1.952309\n",
      "[21: 995/1795] train lossD: -0.313264 lossG: -0.585275\n",
      "[21: 1000/1795] train lossD: 0.070436 lossG: -0.952426\n",
      "[21: 1005/1795] train lossD: 0.304647 lossG: -0.958935\n",
      "[21: 1010/1795] train lossD: 0.087785 lossG: -0.889634\n",
      "[21: 1015/1795] train lossD: 0.120993 lossG: -0.890603\n",
      "[21: 1020/1795] train lossD: 0.042571 lossG: -0.882048\n",
      "[21: 1025/1795] train lossD: 0.038956 lossG: -0.862567\n",
      "[21: 1030/1795] train lossD: 0.092861 lossG: -0.879019\n",
      "[21: 1035/1795] train lossD: 0.069424 lossG: -0.832880\n",
      "[21: 1040/1795] train lossD: 0.040874 lossG: -0.818761\n",
      "[21: 1045/1795] train lossD: 0.005948 lossG: -0.775377\n",
      "[21: 1050/1795] train lossD: 0.027709 lossG: -0.720368\n",
      "[21: 1055/1795] train lossD: -0.024935 lossG: -0.658823\n",
      "[21: 1060/1795] train lossD: -0.093960 lossG: -0.656252\n",
      "[21: 1065/1795] train lossD: -0.009432 lossG: -0.618300\n",
      "[21: 1070/1795] train lossD: 0.035212 lossG: -0.558119\n",
      "[21: 1075/1795] train lossD: -0.044875 lossG: -0.478185\n",
      "[21: 1080/1795] train lossD: -0.055291 lossG: -0.355830\n",
      "[21: 1085/1795] train lossD: 0.046063 lossG: -0.343121\n",
      "[21: 1090/1795] train lossD: -0.395400 lossG: -0.338827\n",
      "[21: 1095/1795] train lossD: -1.208992 lossG: -0.747904\n",
      "[21: 1100/1795] train lossD: -0.350551 lossG: -0.517022\n",
      "[21: 1105/1795] train lossD: -0.463828 lossG: -1.155550\n",
      "[21: 1110/1795] train lossD: -0.820920 lossG: -0.391832\n",
      "[21: 1115/1795] train lossD: -1.124532 lossG: -0.569147\n",
      "[21: 1120/1795] train lossD: -1.572485 lossG: -1.147850\n",
      "[21: 1125/1795] train lossD: -0.614835 lossG: -0.278525\n",
      "[21: 1130/1795] train lossD: -2.733012 lossG: 0.309394\n",
      "[21: 1135/1795] train lossD: -0.225902 lossG: -0.749589\n",
      "[21: 1140/1795] train lossD: -0.972253 lossG: -0.386245\n",
      "[21: 1145/1795] train lossD: -0.009390 lossG: -0.303989\n",
      "[21: 1150/1795] train lossD: 0.018293 lossG: -0.278006\n",
      "[21: 1155/1795] train lossD: -0.021351 lossG: -0.256832\n",
      "[21: 1160/1795] train lossD: 0.007459 lossG: 0.171152\n",
      "[21: 1165/1795] train lossD: -0.769087 lossG: -0.921816\n",
      "[21: 1170/1795] train lossD: 0.754455 lossG: -0.391752\n",
      "[21: 1175/1795] train lossD: -1.024502 lossG: 0.239539\n",
      "[21: 1180/1795] train lossD: -1.199145 lossG: -1.354961\n",
      "[21: 1185/1795] train lossD: -1.607697 lossG: 0.216752\n",
      "[21: 1190/1795] train lossD: -0.551642 lossG: -0.638568\n",
      "[21: 1195/1795] train lossD: -1.813073 lossG: 0.087428\n",
      "[21: 1200/1795] train lossD: -1.489045 lossG: -0.282714\n",
      "[21: 1205/1795] train lossD: -0.615045 lossG: 0.169986\n",
      "[21: 1210/1795] train lossD: 0.142732 lossG: -0.335660\n",
      "[21: 1215/1795] train lossD: 0.086580 lossG: -0.258983\n",
      "[21: 1220/1795] train lossD: -0.005080 lossG: -0.259891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21: 1225/1795] train lossD: -0.118081 lossG: -0.230307\n",
      "[21: 1230/1795] train lossD: 0.071539 lossG: -0.158431\n",
      "[21: 1235/1795] train lossD: -1.776634 lossG: -0.155230\n",
      "[21: 1240/1795] train lossD: -0.281563 lossG: -0.288000\n",
      "[21: 1245/1795] train lossD: 0.008502 lossG: -0.173086\n",
      "[21: 1250/1795] train lossD: -0.552042 lossG: -0.149418\n",
      "[21: 1255/1795] train lossD: -0.744766 lossG: -0.182784\n",
      "[21: 1260/1795] train lossD: -1.565578 lossG: -0.612518\n",
      "[21: 1265/1795] train lossD: -1.000278 lossG: -1.011385\n",
      "[21: 1270/1795] train lossD: -2.179865 lossG: 0.119881\n",
      "[21: 1275/1795] train lossD: -1.793039 lossG: 0.149191\n",
      "[21: 1280/1795] train lossD: -1.951310 lossG: -0.795006\n",
      "[21: 1285/1795] train lossD: -1.966771 lossG: 0.054194\n",
      "[21: 1290/1795] train lossD: -1.478568 lossG: -0.791066\n",
      "[21: 1295/1795] train lossD: -1.162521 lossG: -0.566123\n",
      "[21: 1300/1795] train lossD: 0.066030 lossG: 0.317918\n",
      "[21: 1305/1795] train lossD: -1.404056 lossG: -0.211547\n",
      "[21: 1310/1795] train lossD: -1.278420 lossG: -0.442457\n",
      "[21: 1315/1795] train lossD: 0.179326 lossG: 0.065978\n",
      "[21: 1320/1795] train lossD: -1.757447 lossG: 0.141797\n",
      "[21: 1325/1795] train lossD: -0.099638 lossG: 0.670616\n",
      "[21: 1330/1795] train lossD: -0.290204 lossG: 0.383914\n",
      "[21: 1335/1795] train lossD: -2.487719 lossG: 0.441251\n",
      "[21: 1340/1795] train lossD: 0.009654 lossG: -0.206617\n",
      "[21: 1345/1795] train lossD: -0.170494 lossG: -0.237750\n",
      "[21: 1350/1795] train lossD: -0.786672 lossG: -0.535423\n",
      "[21: 1355/1795] train lossD: -0.715845 lossG: -0.063461\n",
      "[21: 1360/1795] train lossD: -2.241781 lossG: -0.429435\n",
      "[21: 1365/1795] train lossD: 0.115397 lossG: 0.426416\n",
      "[21: 1370/1795] train lossD: -0.186633 lossG: 0.303329\n",
      "[21: 1375/1795] train lossD: -0.726276 lossG: -0.097420\n",
      "[21: 1380/1795] train lossD: -2.127937 lossG: -0.785817\n",
      "[21: 1385/1795] train lossD: -0.761912 lossG: 0.540076\n",
      "[21: 1390/1795] train lossD: -1.836966 lossG: -0.934556\n",
      "[21: 1395/1795] train lossD: -0.555986 lossG: 0.485857\n",
      "[21: 1400/1795] train lossD: -0.360146 lossG: 0.437755\n",
      "[21: 1405/1795] train lossD: -1.636977 lossG: -0.647444\n",
      "[21: 1410/1795] train lossD: -0.220339 lossG: -0.644223\n",
      "[21: 1415/1795] train lossD: -0.099352 lossG: -0.651063\n",
      "[21: 1420/1795] train lossD: -0.392629 lossG: 0.303619\n",
      "[21: 1425/1795] train lossD: -2.254268 lossG: 0.477280\n",
      "[21: 1430/1795] train lossD: -0.588979 lossG: -0.271525\n",
      "[21: 1435/1795] train lossD: 8.434100 lossG: 0.197119\n",
      "[21: 1440/1795] train lossD: -0.016808 lossG: 0.344931\n",
      "[21: 1445/1795] train lossD: 0.065997 lossG: 0.503667\n",
      "[21: 1450/1795] train lossD: 0.024094 lossG: 0.508766\n",
      "[21: 1455/1795] train lossD: 0.017669 lossG: 0.232963\n",
      "[21: 1460/1795] train lossD: -0.013780 lossG: 0.244087\n",
      "[21: 1465/1795] train lossD: 0.213069 lossG: -0.039717\n",
      "[21: 1470/1795] train lossD: 0.046555 lossG: -0.171575\n",
      "[21: 1475/1795] train lossD: 0.035619 lossG: -0.060842\n",
      "[21: 1480/1795] train lossD: 0.007936 lossG: 0.173964\n",
      "[21: 1485/1795] train lossD: 0.061853 lossG: 0.039774\n",
      "[21: 1490/1795] train lossD: 0.102252 lossG: 0.104977\n",
      "[21: 1495/1795] train lossD: -0.044831 lossG: 0.338576\n",
      "[21: 1500/1795] train lossD: -0.055302 lossG: 0.270073\n",
      "[21: 1505/1795] train lossD: -0.033692 lossG: 0.350180\n",
      "[21: 1510/1795] train lossD: 0.016850 lossG: 0.212583\n",
      "[21: 1515/1795] train lossD: -0.029488 lossG: -0.631694\n",
      "[21: 1520/1795] train lossD: 0.035830 lossG: 0.369612\n",
      "[21: 1525/1795] train lossD: -0.946161 lossG: 0.452390\n",
      "[21: 1530/1795] train lossD: 2.248754 lossG: 0.211866\n",
      "[21: 1535/1795] train lossD: -0.442773 lossG: 0.154001\n",
      "[21: 1540/1795] train lossD: -1.034796 lossG: 0.510813\n",
      "[21: 1545/1795] train lossD: -0.521873 lossG: -0.526818\n",
      "[21: 1550/1795] train lossD: 0.207738 lossG: 0.638308\n",
      "[21: 1555/1795] train lossD: -0.044969 lossG: 0.862901\n",
      "[21: 1560/1795] train lossD: 0.112955 lossG: 0.668694\n",
      "[21: 1565/1795] train lossD: -0.075527 lossG: 0.770610\n",
      "[21: 1570/1795] train lossD: -0.047051 lossG: 0.643284\n",
      "[21: 1575/1795] train lossD: -0.081394 lossG: 0.647353\n",
      "[21: 1580/1795] train lossD: -0.269755 lossG: 0.808761\n",
      "[21: 1585/1795] train lossD: -1.749958 lossG: -0.354610\n",
      "[21: 1590/1795] train lossD: -0.242321 lossG: 0.817173\n",
      "[21: 1595/1795] train lossD: 2.842058 lossG: 0.033162\n",
      "[21: 1600/1795] train lossD: -0.159799 lossG: 0.573967\n",
      "[21: 1605/1795] train lossD: -0.530421 lossG: 0.397902\n",
      "[21: 1610/1795] train lossD: -0.365567 lossG: -0.645689\n",
      "[21: 1615/1795] train lossD: -0.682424 lossG: 0.569791\n",
      "[21: 1620/1795] train lossD: -0.357583 lossG: 0.945049\n",
      "[21: 1625/1795] train lossD: -1.344651 lossG: -0.679522\n",
      "[21: 1630/1795] train lossD: -0.135418 lossG: 0.629743\n",
      "[21: 1635/1795] train lossD: -0.054691 lossG: 0.099379\n",
      "[21: 1640/1795] train lossD: -1.568575 lossG: 0.858518\n",
      "[21: 1645/1795] train lossD: -0.742551 lossG: 0.489670\n",
      "[21: 1650/1795] train lossD: -2.733672 lossG: 0.338447\n",
      "[21: 1655/1795] train lossD: -1.327813 lossG: 0.001423\n",
      "[21: 1660/1795] train lossD: -0.018160 lossG: -0.113394\n",
      "[21: 1665/1795] train lossD: -1.798098 lossG: 0.472080\n",
      "[21: 1670/1795] train lossD: -1.513734 lossG: -0.155139\n",
      "[21: 1675/1795] train lossD: -2.003270 lossG: 0.380782\n",
      "[21: 1680/1795] train lossD: -0.997673 lossG: -0.195206\n",
      "[21: 1685/1795] train lossD: -1.160085 lossG: -0.538839\n",
      "[21: 1690/1795] train lossD: -0.707209 lossG: 0.521492\n",
      "[21: 1695/1795] train lossD: -2.555987 lossG: 0.450424\n",
      "[21: 1700/1795] train lossD: -2.526409 lossG: 0.416496\n",
      "[21: 1705/1795] train lossD: 0.022889 lossG: -0.587450\n",
      "[21: 1710/1795] train lossD: -0.307039 lossG: -0.725582\n",
      "[21: 1715/1795] train lossD: 0.173006 lossG: -0.657457\n",
      "[21: 1720/1795] train lossD: 0.650756 lossG: -0.274430\n",
      "[21: 1725/1795] train lossD: -0.349376 lossG: 0.173660\n",
      "[21: 1730/1795] train lossD: -2.228462 lossG: -0.063275\n",
      "[21: 1735/1795] train lossD: -3.406420 lossG: -0.000507\n",
      "[21: 1740/1795] train lossD: -0.611164 lossG: 0.143563\n",
      "[21: 1745/1795] train lossD: -2.507287 lossG: -0.283476\n",
      "[21: 1750/1795] train lossD: -1.284745 lossG: -0.656624\n",
      "[21: 1755/1795] train lossD: 12.730599 lossG: -0.517655\n",
      "[21: 1760/1795] train lossD: 0.149201 lossG: -0.542672\n",
      "[21: 1765/1795] train lossD: 0.157361 lossG: -0.546417\n",
      "[21: 1770/1795] train lossD: 0.102127 lossG: -0.520074\n",
      "[21: 1775/1795] train lossD: 0.037023 lossG: -0.466079\n",
      "[21: 1780/1795] train lossD: 0.082279 lossG: -0.512049\n",
      "[21: 1785/1795] train lossD: 0.005817 lossG: -0.380136\n",
      "[21: 1790/1795] train lossD: 0.137808 lossG: -0.278153\n",
      "0.03929232805967331\n",
      "[22: 0/1795] train lossD: 0.057501 lossG: -0.332282\n",
      "[22: 5/1795] train lossD: 0.084228 lossG: -0.177092\n",
      "[22: 10/1795] train lossD: -0.085443 lossG: -0.245261\n",
      "[22: 15/1795] train lossD: -2.130976 lossG: 0.061782\n",
      "[22: 20/1795] train lossD: -0.464188 lossG: 0.684975\n",
      "[22: 25/1795] train lossD: -0.097688 lossG: 0.487109\n",
      "[22: 30/1795] train lossD: -0.176547 lossG: 0.029668\n",
      "[22: 35/1795] train lossD: -0.839713 lossG: -0.333582\n",
      "[22: 40/1795] train lossD: -1.432831 lossG: -0.592067\n",
      "[22: 45/1795] train lossD: -2.909783 lossG: -0.211207\n",
      "[22: 50/1795] train lossD: 0.084124 lossG: -0.009968\n",
      "[22: 55/1795] train lossD: -0.179240 lossG: 0.145661\n",
      "[22: 60/1795] train lossD: -1.271655 lossG: -0.434084\n",
      "[22: 65/1795] train lossD: -1.488689 lossG: 0.126928\n",
      "[22: 70/1795] train lossD: -0.001149 lossG: -0.060063\n",
      "[22: 75/1795] train lossD: -0.791398 lossG: -0.360640\n",
      "[22: 80/1795] train lossD: -1.003868 lossG: 0.598539\n",
      "[22: 85/1795] train lossD: -2.765548 lossG: 0.283122\n",
      "[22: 90/1795] train lossD: 0.014831 lossG: -0.824689\n",
      "[22: 95/1795] train lossD: -3.001210 lossG: 0.121408\n",
      "[22: 100/1795] train lossD: -2.067616 lossG: -0.414823\n",
      "[22: 105/1795] train lossD: -0.088851 lossG: 0.315580\n",
      "[22: 110/1795] train lossD: -2.382559 lossG: -1.021542\n",
      "[22: 115/1795] train lossD: -0.759965 lossG: 0.013103\n",
      "[22: 120/1795] train lossD: -0.241017 lossG: -1.248138\n",
      "[22: 125/1795] train lossD: -1.156170 lossG: -0.402502\n",
      "[22: 130/1795] train lossD: -1.934111 lossG: -1.126514\n",
      "[22: 135/1795] train lossD: 0.177025 lossG: 0.151368\n",
      "[22: 140/1795] train lossD: 0.100928 lossG: 0.149526\n",
      "[22: 145/1795] train lossD: -1.022449 lossG: 0.815459\n",
      "[22: 150/1795] train lossD: -2.844329 lossG: -0.036801\n",
      "[22: 155/1795] train lossD: -2.213843 lossG: 0.081969\n",
      "[22: 160/1795] train lossD: 55.328300 lossG: 0.504552\n",
      "[22: 165/1795] train lossD: 0.097468 lossG: 0.519782\n",
      "[22: 170/1795] train lossD: 0.085769 lossG: 0.540453\n",
      "[22: 175/1795] train lossD: 0.113058 lossG: 0.519370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22: 180/1795] train lossD: 0.077196 lossG: 0.558143\n",
      "[22: 185/1795] train lossD: 0.056186 lossG: 0.438431\n",
      "[22: 190/1795] train lossD: -0.143726 lossG: 0.320166\n",
      "[22: 195/1795] train lossD: 0.139484 lossG: 0.074421\n",
      "[22: 200/1795] train lossD: 0.033016 lossG: -0.118782\n",
      "[22: 205/1795] train lossD: -0.038710 lossG: 0.040250\n",
      "[22: 210/1795] train lossD: -0.062952 lossG: 0.137940\n",
      "[22: 215/1795] train lossD: -2.552221 lossG: -0.603667\n",
      "[22: 220/1795] train lossD: -0.514019 lossG: -0.067721\n",
      "[22: 225/1795] train lossD: -2.902024 lossG: -0.958632\n",
      "[22: 230/1795] train lossD: -0.333109 lossG: -0.488606\n",
      "[22: 235/1795] train lossD: -0.986165 lossG: -0.614258\n",
      "[22: 240/1795] train lossD: -2.726863 lossG: -0.074289\n",
      "[22: 245/1795] train lossD: -0.627108 lossG: -0.734420\n",
      "[22: 250/1795] train lossD: -1.588332 lossG: -0.480407\n",
      "[22: 255/1795] train lossD: -2.439461 lossG: -1.110973\n",
      "[22: 260/1795] train lossD: 0.197035 lossG: -0.958413\n",
      "[22: 265/1795] train lossD: 0.225337 lossG: -0.853456\n",
      "[22: 270/1795] train lossD: 0.170078 lossG: -0.913790\n",
      "[22: 275/1795] train lossD: -0.026943 lossG: -0.596099\n",
      "[22: 280/1795] train lossD: -0.017752 lossG: -0.509922\n",
      "[22: 285/1795] train lossD: -0.139098 lossG: -0.197821\n",
      "[22: 290/1795] train lossD: -1.224611 lossG: -0.537678\n",
      "[22: 295/1795] train lossD: -0.895988 lossG: 0.154198\n",
      "[22: 300/1795] train lossD: -2.339815 lossG: 0.323364\n",
      "[22: 305/1795] train lossD: -2.639345 lossG: -0.153734\n",
      "[22: 310/1795] train lossD: -1.525837 lossG: -0.562593\n",
      "[22: 315/1795] train lossD: 0.319051 lossG: 0.063502\n",
      "[22: 320/1795] train lossD: -3.357637 lossG: -0.091286\n",
      "[22: 325/1795] train lossD: -1.152163 lossG: -0.130472\n",
      "[22: 330/1795] train lossD: -1.114196 lossG: -1.072437\n",
      "[22: 335/1795] train lossD: -4.400773 lossG: -0.190912\n",
      "[22: 340/1795] train lossD: 0.214847 lossG: 0.116375\n",
      "[22: 345/1795] train lossD: -1.605246 lossG: -0.785800\n",
      "[22: 350/1795] train lossD: -3.026891 lossG: -2.097034\n",
      "[22: 355/1795] train lossD: -0.969133 lossG: -1.863069\n",
      "[22: 360/1795] train lossD: -3.337993 lossG: -0.290813\n",
      "[22: 365/1795] train lossD: 0.092282 lossG: 0.557610\n",
      "[22: 370/1795] train lossD: -0.003326 lossG: 0.752452\n",
      "[22: 375/1795] train lossD: -1.631393 lossG: 1.022117\n",
      "[22: 380/1795] train lossD: -0.638067 lossG: 0.102366\n",
      "[22: 385/1795] train lossD: 2.965253 lossG: 0.217319\n",
      "[22: 390/1795] train lossD: -0.901035 lossG: 0.124442\n",
      "[22: 395/1795] train lossD: -2.134382 lossG: -1.231907\n",
      "[22: 400/1795] train lossD: 0.962118 lossG: 0.471527\n",
      "[22: 405/1795] train lossD: -2.268295 lossG: 0.595362\n",
      "[22: 410/1795] train lossD: -2.785089 lossG: 0.305946\n",
      "[22: 415/1795] train lossD: -0.696855 lossG: 0.913110\n",
      "[22: 420/1795] train lossD: 0.017019 lossG: 0.720978\n",
      "[22: 425/1795] train lossD: 0.083958 lossG: 0.648645\n",
      "[22: 430/1795] train lossD: 0.101924 lossG: 0.724628\n",
      "[22: 435/1795] train lossD: 1.805418 lossG: -0.030149\n",
      "[22: 440/1795] train lossD: 0.273919 lossG: 0.079245\n",
      "[22: 445/1795] train lossD: 0.065855 lossG: 0.050360\n",
      "[22: 450/1795] train lossD: 0.005035 lossG: 0.147652\n",
      "[22: 455/1795] train lossD: 0.028625 lossG: 0.149295\n",
      "[22: 460/1795] train lossD: -0.024943 lossG: 0.066633\n",
      "[22: 465/1795] train lossD: 0.037341 lossG: 0.180879\n",
      "[22: 470/1795] train lossD: 0.176650 lossG: 0.153778\n",
      "[22: 475/1795] train lossD: -2.756899 lossG: -0.113213\n",
      "[22: 480/1795] train lossD: -1.715301 lossG: -2.331903\n",
      "[22: 485/1795] train lossD: 0.071843 lossG: -0.017625\n",
      "[22: 490/1795] train lossD: -0.309893 lossG: -0.041352\n",
      "[22: 495/1795] train lossD: 0.035641 lossG: -0.085149\n",
      "[22: 500/1795] train lossD: -0.931336 lossG: -0.579285\n",
      "[22: 505/1795] train lossD: -2.436327 lossG: -0.283568\n",
      "[22: 510/1795] train lossD: -0.057774 lossG: -0.089271\n",
      "[22: 515/1795] train lossD: -1.090574 lossG: -0.264280\n",
      "[22: 520/1795] train lossD: -3.013897 lossG: -0.722813\n",
      "[22: 525/1795] train lossD: -2.940665 lossG: -0.580004\n",
      "[22: 530/1795] train lossD: -0.725912 lossG: -0.174653\n",
      "[22: 535/1795] train lossD: -1.743622 lossG: -0.650572\n",
      "[22: 540/1795] train lossD: -1.971533 lossG: -0.445536\n",
      "[22: 545/1795] train lossD: -3.586798 lossG: -0.317829\n",
      "[22: 550/1795] train lossD: 0.011814 lossG: -0.080334\n",
      "[22: 555/1795] train lossD: -0.344878 lossG: 0.128248\n",
      "[22: 560/1795] train lossD: -2.855987 lossG: -0.678916\n",
      "[22: 565/1795] train lossD: -2.295417 lossG: 0.446824\n",
      "[22: 570/1795] train lossD: -1.206986 lossG: -1.075361\n",
      "[22: 575/1795] train lossD: -1.976585 lossG: -0.918766\n",
      "[22: 580/1795] train lossD: -1.129374 lossG: 0.274591\n",
      "[22: 585/1795] train lossD: 1.877262 lossG: -1.172759\n",
      "[22: 590/1795] train lossD: 0.129203 lossG: -0.255270\n",
      "[22: 595/1795] train lossD: 0.071663 lossG: -0.403937\n",
      "[22: 600/1795] train lossD: -0.658758 lossG: 0.013137\n",
      "[22: 605/1795] train lossD: 1.597587 lossG: -0.866353\n",
      "[22: 610/1795] train lossD: -1.155174 lossG: -0.255714\n",
      "[22: 615/1795] train lossD: -0.024769 lossG: 0.453142\n",
      "[22: 620/1795] train lossD: -0.360706 lossG: 0.526682\n",
      "[22: 625/1795] train lossD: -0.262055 lossG: 0.715200\n",
      "[22: 630/1795] train lossD: -1.865356 lossG: -0.349990\n",
      "[22: 635/1795] train lossD: -1.238140 lossG: 0.208993\n",
      "[22: 640/1795] train lossD: 0.415826 lossG: 0.037666\n",
      "[22: 645/1795] train lossD: -3.083655 lossG: 0.482675\n",
      "[22: 650/1795] train lossD: -0.095325 lossG: 0.691937\n",
      "[22: 655/1795] train lossD: -2.686576 lossG: 1.352885\n",
      "[22: 660/1795] train lossD: -1.080108 lossG: -0.075296\n",
      "[22: 665/1795] train lossD: -3.145889 lossG: 0.914504\n",
      "[22: 670/1795] train lossD: -1.263585 lossG: -0.700227\n",
      "[22: 675/1795] train lossD: -3.597100 lossG: 0.620585\n",
      "[22: 680/1795] train lossD: -2.803253 lossG: 0.155451\n",
      "[22: 685/1795] train lossD: -3.901338 lossG: 0.180302\n",
      "[22: 690/1795] train lossD: -4.579631 lossG: -0.387114\n",
      "[22: 695/1795] train lossD: 0.310228 lossG: -0.507285\n",
      "[22: 700/1795] train lossD: -2.192504 lossG: -0.949600\n",
      "[22: 705/1795] train lossD: -1.487147 lossG: -1.762747\n",
      "[22: 710/1795] train lossD: -0.037853 lossG: -0.006437\n",
      "[22: 715/1795] train lossD: -1.907853 lossG: 0.855171\n",
      "[22: 720/1795] train lossD: -0.314387 lossG: 1.051529\n",
      "[22: 725/1795] train lossD: -2.684445 lossG: 0.996856\n",
      "[22: 730/1795] train lossD: 0.087181 lossG: 0.028102\n",
      "[22: 735/1795] train lossD: -3.048376 lossG: 0.694419\n",
      "[22: 740/1795] train lossD: -4.161299 lossG: -1.982271\n",
      "[22: 745/1795] train lossD: -3.631231 lossG: -0.096871\n",
      "[22: 750/1795] train lossD: -4.297086 lossG: -0.093594\n",
      "[22: 755/1795] train lossD: -1.588790 lossG: -0.892226\n",
      "[22: 760/1795] train lossD: -0.472190 lossG: -0.072066\n",
      "[22: 765/1795] train lossD: -0.109784 lossG: 0.251738\n",
      "[22: 770/1795] train lossD: 0.047540 lossG: 0.390008\n",
      "[22: 775/1795] train lossD: 0.086447 lossG: 0.263293\n",
      "[22: 780/1795] train lossD: 0.139462 lossG: 0.156683\n",
      "[22: 785/1795] train lossD: -1.090885 lossG: -0.218604\n",
      "[22: 790/1795] train lossD: -0.425548 lossG: -0.407230\n",
      "[22: 795/1795] train lossD: -2.001816 lossG: 0.199363\n",
      "[22: 800/1795] train lossD: -2.868171 lossG: -0.240877\n",
      "[22: 805/1795] train lossD: -2.080594 lossG: -1.468578\n",
      "[22: 810/1795] train lossD: 4.719621 lossG: -0.369642\n",
      "[22: 815/1795] train lossD: 0.206669 lossG: -0.421622\n",
      "[22: 820/1795] train lossD: 0.021854 lossG: -0.157363\n",
      "[22: 825/1795] train lossD: 0.071418 lossG: -0.096882\n",
      "[22: 830/1795] train lossD: 0.086204 lossG: -0.083170\n",
      "[22: 835/1795] train lossD: -0.088748 lossG: 0.291862\n",
      "[22: 840/1795] train lossD: -0.232646 lossG: -0.485940\n",
      "[22: 845/1795] train lossD: -4.529342 lossG: 0.418606\n",
      "[22: 850/1795] train lossD: 0.169170 lossG: -0.092956\n",
      "[22: 855/1795] train lossD: -0.176270 lossG: 0.307465\n",
      "[22: 860/1795] train lossD: -0.288736 lossG: 0.764685\n",
      "[22: 865/1795] train lossD: -1.566236 lossG: 1.036462\n",
      "[22: 870/1795] train lossD: 0.246839 lossG: -0.201366\n",
      "[22: 875/1795] train lossD: -4.339707 lossG: -0.479378\n",
      "[22: 880/1795] train lossD: -1.351463 lossG: -1.659206\n",
      "[22: 885/1795] train lossD: -0.971476 lossG: 0.044353\n",
      "[22: 890/1795] train lossD: -1.033544 lossG: 0.224677\n",
      "[22: 895/1795] train lossD: -2.044990 lossG: 0.539126\n",
      "[22: 900/1795] train lossD: -2.221309 lossG: -0.493286\n",
      "[22: 905/1795] train lossD: -2.068334 lossG: -0.022402\n",
      "[22: 910/1795] train lossD: -2.384143 lossG: -1.086004\n",
      "[22: 915/1795] train lossD: -2.914606 lossG: 0.400957\n",
      "[22: 920/1795] train lossD: -4.716659 lossG: -0.335839\n",
      "[22: 925/1795] train lossD: -3.129355 lossG: 0.645793\n",
      "[22: 930/1795] train lossD: -4.897891 lossG: 0.589447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22: 935/1795] train lossD: -2.277234 lossG: 0.194690\n",
      "[22: 940/1795] train lossD: -4.373433 lossG: -0.328410\n",
      "[22: 945/1795] train lossD: -4.226242 lossG: -2.640084\n",
      "[22: 950/1795] train lossD: 0.188488 lossG: -0.783332\n",
      "[22: 955/1795] train lossD: -0.347615 lossG: -0.648050\n",
      "[22: 960/1795] train lossD: 0.219503 lossG: -0.237329\n",
      "[22: 965/1795] train lossD: -3.024637 lossG: 0.272342\n",
      "[22: 970/1795] train lossD: -1.464966 lossG: -0.393275\n",
      "[22: 975/1795] train lossD: 0.147359 lossG: 0.248204\n",
      "[22: 980/1795] train lossD: -2.005623 lossG: 0.320067\n",
      "[22: 985/1795] train lossD: -3.112333 lossG: -0.643095\n",
      "[22: 990/1795] train lossD: -3.229557 lossG: 0.121072\n",
      "[22: 995/1795] train lossD: -0.444505 lossG: -0.953215\n",
      "[22: 1000/1795] train lossD: 0.046893 lossG: -0.808607\n",
      "[22: 1005/1795] train lossD: 0.108103 lossG: -0.031991\n",
      "[22: 1010/1795] train lossD: -2.405398 lossG: -0.817688\n",
      "[22: 1015/1795] train lossD: -2.387852 lossG: -0.204265\n",
      "[22: 1020/1795] train lossD: -2.030707 lossG: -0.993872\n",
      "[22: 1025/1795] train lossD: 16.797407 lossG: 0.308750\n",
      "[22: 1030/1795] train lossD: 0.378678 lossG: 0.357045\n",
      "[22: 1035/1795] train lossD: 1.038868 lossG: 0.162405\n",
      "[22: 1040/1795] train lossD: 0.951315 lossG: -0.020828\n",
      "[22: 1045/1795] train lossD: 0.186847 lossG: 0.016294\n",
      "[22: 1050/1795] train lossD: 0.082948 lossG: 0.069377\n",
      "[22: 1055/1795] train lossD: 0.066291 lossG: 0.086803\n",
      "[22: 1060/1795] train lossD: 0.075594 lossG: 0.401216\n",
      "[22: 1065/1795] train lossD: -2.361265 lossG: -1.261085\n",
      "[22: 1070/1795] train lossD: -1.222236 lossG: 0.781657\n",
      "[22: 1075/1795] train lossD: -2.272752 lossG: -0.470724\n",
      "[22: 1080/1795] train lossD: -3.345050 lossG: 0.455097\n",
      "[22: 1085/1795] train lossD: -1.822098 lossG: -1.741467\n",
      "[22: 1090/1795] train lossD: 43.749653 lossG: 0.050501\n",
      "[22: 1095/1795] train lossD: 0.327444 lossG: 0.129167\n",
      "[22: 1100/1795] train lossD: 0.216954 lossG: 0.060082\n",
      "[22: 1105/1795] train lossD: 0.336555 lossG: 0.005732\n",
      "[22: 1110/1795] train lossD: 0.167065 lossG: 0.151402\n",
      "[22: 1115/1795] train lossD: 0.238709 lossG: 0.130887\n",
      "[22: 1120/1795] train lossD: 0.311758 lossG: -0.035618\n",
      "[22: 1125/1795] train lossD: 0.110988 lossG: -0.139419\n",
      "[22: 1130/1795] train lossD: 0.081320 lossG: 0.032359\n",
      "[22: 1135/1795] train lossD: 0.142160 lossG: 0.358632\n",
      "[22: 1140/1795] train lossD: 0.066025 lossG: 0.021686\n",
      "[22: 1145/1795] train lossD: 0.025757 lossG: 0.362849\n",
      "[22: 1150/1795] train lossD: -0.030240 lossG: 0.284632\n",
      "[22: 1155/1795] train lossD: 0.017504 lossG: 0.078742\n",
      "[22: 1160/1795] train lossD: 0.033077 lossG: 0.200228\n",
      "[22: 1165/1795] train lossD: -0.039905 lossG: 0.416766\n",
      "[22: 1170/1795] train lossD: -0.006941 lossG: 0.267676\n",
      "[22: 1175/1795] train lossD: -0.040624 lossG: 0.520963\n",
      "[22: 1180/1795] train lossD: -0.068261 lossG: 0.307521\n",
      "[22: 1185/1795] train lossD: -0.089034 lossG: 0.433465\n",
      "[22: 1190/1795] train lossD: -0.040237 lossG: 0.374204\n",
      "[22: 1195/1795] train lossD: -0.009633 lossG: 0.217714\n",
      "[22: 1200/1795] train lossD: -0.065206 lossG: 0.363973\n",
      "[22: 1205/1795] train lossD: 0.151841 lossG: 0.302360\n",
      "[22: 1210/1795] train lossD: -0.043002 lossG: 0.511109\n",
      "[22: 1215/1795] train lossD: -0.090236 lossG: 0.436753\n",
      "[22: 1220/1795] train lossD: -0.037274 lossG: 0.535192\n",
      "[22: 1225/1795] train lossD: -0.071341 lossG: 0.634944\n",
      "[22: 1230/1795] train lossD: -0.115530 lossG: 0.820901\n",
      "[22: 1235/1795] train lossD: 0.133126 lossG: 0.490414\n",
      "[22: 1240/1795] train lossD: 0.150660 lossG: 0.208793\n",
      "[22: 1245/1795] train lossD: -0.161738 lossG: 0.568804\n",
      "[22: 1250/1795] train lossD: -0.092186 lossG: 0.617050\n",
      "[22: 1255/1795] train lossD: -0.037740 lossG: 0.753862\n",
      "[22: 1260/1795] train lossD: -0.114982 lossG: 0.641844\n",
      "[22: 1265/1795] train lossD: -0.018707 lossG: 0.459937\n",
      "[22: 1270/1795] train lossD: -0.089721 lossG: 0.436885\n",
      "[22: 1275/1795] train lossD: -0.184903 lossG: 0.937341\n",
      "[22: 1280/1795] train lossD: 0.046223 lossG: 0.457906\n",
      "[22: 1285/1795] train lossD: 0.061433 lossG: 0.704364\n",
      "[22: 1290/1795] train lossD: 0.059378 lossG: 0.437185\n",
      "[22: 1295/1795] train lossD: -0.061856 lossG: 0.483075\n",
      "[22: 1300/1795] train lossD: -0.043468 lossG: 0.801778\n",
      "[22: 1305/1795] train lossD: -0.045924 lossG: 0.546679\n",
      "[22: 1310/1795] train lossD: -0.010849 lossG: 0.581279\n",
      "[22: 1315/1795] train lossD: -0.109208 lossG: 0.656881\n",
      "[22: 1320/1795] train lossD: -0.143284 lossG: 0.787771\n",
      "[22: 1325/1795] train lossD: -0.136827 lossG: 0.704441\n",
      "[22: 1330/1795] train lossD: -0.074268 lossG: 0.580100\n",
      "[22: 1335/1795] train lossD: -0.019878 lossG: 0.662817\n",
      "[22: 1340/1795] train lossD: -0.046170 lossG: 0.807375\n",
      "[22: 1345/1795] train lossD: -0.066911 lossG: 0.517778\n",
      "[22: 1350/1795] train lossD: -0.048774 lossG: 0.561559\n",
      "[22: 1355/1795] train lossD: -0.085358 lossG: 0.596571\n",
      "[22: 1360/1795] train lossD: 0.064492 lossG: 0.545016\n",
      "[22: 1365/1795] train lossD: -0.022171 lossG: 0.599095\n",
      "[22: 1370/1795] train lossD: -0.071390 lossG: 0.844611\n",
      "[22: 1375/1795] train lossD: -0.009548 lossG: 0.661112\n",
      "[22: 1380/1795] train lossD: -0.126769 lossG: 0.779403\n",
      "[22: 1385/1795] train lossD: 0.040730 lossG: 0.630104\n",
      "[22: 1390/1795] train lossD: -0.021025 lossG: 0.834622\n",
      "[22: 1395/1795] train lossD: -0.036785 lossG: 0.570349\n",
      "[22: 1400/1795] train lossD: -0.003666 lossG: 0.741815\n",
      "[22: 1405/1795] train lossD: -0.054523 lossG: 0.960352\n",
      "[22: 1410/1795] train lossD: -0.052188 lossG: 0.683886\n",
      "[22: 1415/1795] train lossD: 0.035765 lossG: 0.623487\n",
      "[22: 1420/1795] train lossD: 0.003324 lossG: 0.867761\n",
      "[22: 1425/1795] train lossD: 0.001184 lossG: 0.551716\n",
      "[22: 1430/1795] train lossD: 0.003706 lossG: 0.432903\n",
      "[22: 1435/1795] train lossD: -0.125927 lossG: 1.137415\n",
      "[22: 1440/1795] train lossD: -0.063928 lossG: 0.619301\n",
      "[22: 1445/1795] train lossD: -0.027584 lossG: 0.616867\n",
      "[22: 1450/1795] train lossD: -0.042940 lossG: 0.388903\n",
      "[22: 1455/1795] train lossD: -0.035111 lossG: 0.764473\n",
      "[22: 1460/1795] train lossD: -0.075753 lossG: 0.679066\n",
      "[22: 1465/1795] train lossD: -0.014656 lossG: 0.920006\n",
      "[22: 1470/1795] train lossD: -0.020059 lossG: 0.984016\n",
      "[22: 1475/1795] train lossD: -0.038772 lossG: 0.871120\n",
      "[22: 1480/1795] train lossD: -0.025903 lossG: 0.753139\n",
      "[22: 1485/1795] train lossD: 0.008389 lossG: 0.409114\n",
      "[22: 1490/1795] train lossD: 0.000143 lossG: 0.541348\n",
      "[22: 1495/1795] train lossD: 0.012037 lossG: 0.587614\n",
      "[22: 1500/1795] train lossD: -0.040951 lossG: 0.688699\n",
      "[22: 1505/1795] train lossD: -0.050899 lossG: 0.563993\n",
      "[22: 1510/1795] train lossD: 0.012602 lossG: 0.879823\n",
      "[22: 1515/1795] train lossD: 0.066881 lossG: 0.584725\n",
      "[22: 1520/1795] train lossD: 0.033145 lossG: 0.754363\n",
      "[22: 1525/1795] train lossD: -0.021094 lossG: 0.773810\n",
      "[22: 1530/1795] train lossD: -0.005379 lossG: 0.818215\n",
      "[22: 1535/1795] train lossD: -0.040002 lossG: 0.864258\n",
      "[22: 1540/1795] train lossD: 0.081613 lossG: 0.621036\n",
      "[22: 1545/1795] train lossD: 0.053413 lossG: 0.939484\n",
      "[22: 1550/1795] train lossD: 0.038499 lossG: 0.574824\n",
      "[22: 1555/1795] train lossD: 0.030364 lossG: 0.700759\n",
      "[22: 1560/1795] train lossD: -0.029219 lossG: 0.746593\n",
      "[22: 1565/1795] train lossD: 0.002753 lossG: 0.764949\n",
      "[22: 1570/1795] train lossD: -0.059321 lossG: 0.858753\n",
      "[22: 1575/1795] train lossD: -0.030243 lossG: 0.523058\n",
      "[22: 1580/1795] train lossD: -0.086129 lossG: 0.893833\n",
      "[22: 1585/1795] train lossD: 0.017679 lossG: 0.741983\n",
      "[22: 1590/1795] train lossD: -0.002792 lossG: 0.966596\n",
      "[22: 1595/1795] train lossD: -0.061428 lossG: 0.704764\n",
      "[22: 1600/1795] train lossD: -0.027955 lossG: 0.460993\n",
      "[22: 1605/1795] train lossD: -0.014543 lossG: 0.942910\n",
      "[22: 1610/1795] train lossD: 0.019423 lossG: 0.767339\n",
      "[22: 1615/1795] train lossD: 0.044550 lossG: 0.604398\n",
      "[22: 1620/1795] train lossD: -0.028644 lossG: 0.851871\n",
      "[22: 1625/1795] train lossD: 0.031789 lossG: 0.782799\n",
      "[22: 1630/1795] train lossD: -0.052783 lossG: 0.529279\n",
      "[22: 1635/1795] train lossD: 0.030767 lossG: 0.732549\n",
      "[22: 1640/1795] train lossD: -0.030282 lossG: 0.811627\n",
      "[22: 1645/1795] train lossD: 0.021727 lossG: 0.557410\n",
      "[22: 1650/1795] train lossD: -0.026070 lossG: 0.580460\n",
      "[22: 1655/1795] train lossD: -0.003075 lossG: 0.627904\n",
      "[22: 1660/1795] train lossD: -0.029249 lossG: 0.802923\n",
      "[22: 1665/1795] train lossD: -0.017848 lossG: 0.801765\n",
      "[22: 1670/1795] train lossD: -0.029405 lossG: 0.903807\n",
      "[22: 1675/1795] train lossD: 0.028607 lossG: 0.750644\n",
      "[22: 1680/1795] train lossD: -0.041950 lossG: 1.023344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22: 1685/1795] train lossD: 0.026760 lossG: 0.893418\n",
      "[22: 1690/1795] train lossD: -0.021671 lossG: 0.959390\n",
      "[22: 1695/1795] train lossD: -0.019966 lossG: 1.201048\n",
      "[22: 1700/1795] train lossD: -0.002713 lossG: 1.047190\n",
      "[22: 1705/1795] train lossD: -0.004307 lossG: 0.689066\n",
      "[22: 1710/1795] train lossD: -0.011577 lossG: 0.843962\n",
      "[22: 1715/1795] train lossD: -0.042102 lossG: 0.802724\n",
      "[22: 1720/1795] train lossD: -0.047714 lossG: 0.794172\n",
      "[22: 1725/1795] train lossD: -0.061460 lossG: 1.045196\n",
      "[22: 1730/1795] train lossD: 0.002746 lossG: 0.616806\n",
      "[22: 1735/1795] train lossD: -0.009513 lossG: 0.963340\n",
      "[22: 1740/1795] train lossD: 0.062758 lossG: 0.713113\n",
      "[22: 1745/1795] train lossD: 0.021991 lossG: 0.828444\n",
      "[22: 1750/1795] train lossD: 0.102557 lossG: 0.800525\n",
      "[22: 1755/1795] train lossD: 0.037065 lossG: 0.682270\n",
      "[22: 1760/1795] train lossD: -0.007404 lossG: 0.778201\n",
      "[22: 1765/1795] train lossD: 0.057545 lossG: 0.776756\n",
      "[22: 1770/1795] train lossD: -0.020070 lossG: 0.566608\n",
      "[22: 1775/1795] train lossD: -0.081402 lossG: 0.877505\n",
      "[22: 1780/1795] train lossD: -0.031777 lossG: 0.689595\n",
      "[22: 1785/1795] train lossD: 0.061301 lossG: 0.566042\n",
      "[22: 1790/1795] train lossD: 0.134135 lossG: 0.649105\n",
      "0.04248970001935959\n",
      "[23: 0/1795] train lossD: -0.048467 lossG: 0.811859\n",
      "[23: 5/1795] train lossD: -0.018953 lossG: 0.805494\n",
      "[23: 10/1795] train lossD: -0.027203 lossG: 0.661320\n",
      "[23: 15/1795] train lossD: 0.031096 lossG: 0.856850\n",
      "[23: 20/1795] train lossD: -0.007838 lossG: 0.741275\n",
      "[23: 25/1795] train lossD: -0.036870 lossG: 0.811538\n",
      "[23: 30/1795] train lossD: -0.047780 lossG: 1.026889\n",
      "[23: 35/1795] train lossD: -0.012502 lossG: 0.782679\n",
      "[23: 40/1795] train lossD: -0.034448 lossG: 0.831321\n",
      "[23: 45/1795] train lossD: -0.034189 lossG: 0.931196\n",
      "[23: 50/1795] train lossD: 0.079257 lossG: 0.892516\n",
      "[23: 55/1795] train lossD: -0.026515 lossG: 0.925980\n",
      "[23: 60/1795] train lossD: -0.085336 lossG: 0.942241\n",
      "[23: 65/1795] train lossD: -0.003593 lossG: 0.628637\n",
      "[23: 70/1795] train lossD: -0.070293 lossG: 0.454086\n",
      "[23: 75/1795] train lossD: -0.026335 lossG: 0.646579\n",
      "[23: 80/1795] train lossD: -0.008613 lossG: 0.453138\n",
      "[23: 85/1795] train lossD: -0.020006 lossG: 0.834017\n",
      "[23: 90/1795] train lossD: -0.033268 lossG: 0.901482\n",
      "[23: 95/1795] train lossD: 0.005214 lossG: 0.862207\n",
      "[23: 100/1795] train lossD: -0.039266 lossG: 0.729893\n",
      "[23: 105/1795] train lossD: -0.006348 lossG: 0.681354\n",
      "[23: 110/1795] train lossD: -0.045307 lossG: 1.229566\n",
      "[23: 115/1795] train lossD: 0.030613 lossG: 0.727301\n",
      "[23: 120/1795] train lossD: 0.022349 lossG: 1.018771\n",
      "[23: 125/1795] train lossD: 0.011585 lossG: 0.977446\n",
      "[23: 130/1795] train lossD: 0.037918 lossG: 0.759879\n",
      "[23: 135/1795] train lossD: -0.037432 lossG: 0.655107\n",
      "[23: 140/1795] train lossD: -0.086156 lossG: 0.809362\n",
      "[23: 145/1795] train lossD: -0.040229 lossG: 0.970624\n",
      "[23: 150/1795] train lossD: 0.111635 lossG: 1.167421\n",
      "[23: 155/1795] train lossD: -0.023139 lossG: 0.930542\n",
      "[23: 160/1795] train lossD: -0.051029 lossG: 0.747572\n",
      "[23: 165/1795] train lossD: -0.000005 lossG: 0.722932\n",
      "[23: 170/1795] train lossD: 0.122957 lossG: 0.441895\n",
      "[23: 175/1795] train lossD: -0.034012 lossG: 0.683576\n",
      "[23: 180/1795] train lossD: -0.000558 lossG: 0.887620\n",
      "[23: 185/1795] train lossD: 0.011949 lossG: 0.769479\n",
      "[23: 190/1795] train lossD: -0.070815 lossG: 0.613539\n",
      "[23: 195/1795] train lossD: 0.033465 lossG: 0.711088\n",
      "[23: 200/1795] train lossD: 0.034007 lossG: 0.884767\n",
      "[23: 205/1795] train lossD: 0.026228 lossG: 0.769013\n",
      "[23: 210/1795] train lossD: 0.082993 lossG: 0.785131\n",
      "[23: 215/1795] train lossD: -0.010005 lossG: 0.591102\n",
      "[23: 220/1795] train lossD: 0.007172 lossG: 0.628019\n",
      "[23: 225/1795] train lossD: 0.003512 lossG: 0.517357\n",
      "[23: 230/1795] train lossD: -0.019872 lossG: 0.338574\n",
      "[23: 235/1795] train lossD: -0.037293 lossG: 0.617638\n",
      "[23: 240/1795] train lossD: -0.005793 lossG: 0.570407\n",
      "[23: 245/1795] train lossD: -0.037230 lossG: 0.772591\n",
      "[23: 250/1795] train lossD: -0.017354 lossG: 0.458853\n",
      "[23: 255/1795] train lossD: -0.022993 lossG: 0.643545\n",
      "[23: 260/1795] train lossD: 0.015682 lossG: 0.679276\n",
      "[23: 265/1795] train lossD: -0.056218 lossG: 0.882998\n",
      "[23: 270/1795] train lossD: 0.007240 lossG: 0.797999\n",
      "[23: 275/1795] train lossD: -0.001310 lossG: 0.851905\n",
      "[23: 280/1795] train lossD: 0.039402 lossG: 0.831433\n",
      "[23: 285/1795] train lossD: 0.086955 lossG: 0.730907\n",
      "[23: 290/1795] train lossD: 0.109341 lossG: 0.759802\n",
      "[23: 295/1795] train lossD: -0.015708 lossG: 0.801181\n",
      "[23: 300/1795] train lossD: 0.002769 lossG: 0.730549\n",
      "[23: 305/1795] train lossD: -0.019804 lossG: 0.371509\n",
      "[23: 310/1795] train lossD: -0.075594 lossG: 0.537061\n",
      "[23: 315/1795] train lossD: 0.137580 lossG: 0.644139\n",
      "[23: 320/1795] train lossD: -0.054559 lossG: 0.706569\n",
      "[23: 325/1795] train lossD: -0.008098 lossG: 0.610353\n",
      "[23: 330/1795] train lossD: -0.030604 lossG: 0.600951\n",
      "[23: 335/1795] train lossD: 0.044791 lossG: 0.656294\n",
      "[23: 340/1795] train lossD: -0.015740 lossG: 0.549419\n",
      "[23: 345/1795] train lossD: -0.006841 lossG: 0.698949\n",
      "[23: 350/1795] train lossD: -0.035036 lossG: 0.627108\n",
      "[23: 355/1795] train lossD: -0.041613 lossG: 0.601717\n",
      "[23: 360/1795] train lossD: 0.052324 lossG: 0.577884\n",
      "[23: 365/1795] train lossD: -0.055569 lossG: 0.436714\n",
      "[23: 370/1795] train lossD: 0.011384 lossG: 0.523999\n",
      "[23: 375/1795] train lossD: -0.012000 lossG: 0.408402\n",
      "[23: 380/1795] train lossD: -0.006408 lossG: 0.802306\n",
      "[23: 385/1795] train lossD: -0.034677 lossG: 0.708467\n",
      "[23: 390/1795] train lossD: -0.012346 lossG: 0.888023\n",
      "[23: 395/1795] train lossD: -0.057525 lossG: 0.655424\n",
      "[23: 400/1795] train lossD: -0.040346 lossG: 0.692299\n",
      "[23: 405/1795] train lossD: -0.005612 lossG: 0.634944\n",
      "[23: 410/1795] train lossD: 0.013879 lossG: 0.674571\n",
      "[23: 415/1795] train lossD: 0.037118 lossG: 0.559176\n",
      "[23: 420/1795] train lossD: -0.003427 lossG: 0.656953\n",
      "[23: 425/1795] train lossD: 0.044069 lossG: 0.643995\n",
      "[23: 430/1795] train lossD: -0.055449 lossG: 0.468697\n",
      "[23: 435/1795] train lossD: -0.031558 lossG: 0.764464\n",
      "[23: 440/1795] train lossD: -0.042734 lossG: 0.678469\n",
      "[23: 445/1795] train lossD: 0.018881 lossG: 1.078743\n",
      "[23: 450/1795] train lossD: 0.007075 lossG: 0.604440\n",
      "[23: 455/1795] train lossD: 0.062488 lossG: 0.692552\n",
      "[23: 460/1795] train lossD: 0.019147 lossG: 0.726953\n",
      "[23: 465/1795] train lossD: -0.023252 lossG: 0.467392\n",
      "[23: 470/1795] train lossD: -0.019583 lossG: 0.618301\n",
      "[23: 475/1795] train lossD: -0.028520 lossG: 0.617624\n",
      "[23: 480/1795] train lossD: -0.019472 lossG: 0.453943\n",
      "[23: 485/1795] train lossD: 0.027731 lossG: 0.634267\n",
      "[23: 490/1795] train lossD: -0.007881 lossG: 0.748577\n",
      "[23: 495/1795] train lossD: 0.012383 lossG: 0.805090\n",
      "[23: 500/1795] train lossD: 0.060366 lossG: 0.801053\n",
      "[23: 505/1795] train lossD: 0.052655 lossG: 1.218868\n",
      "[23: 510/1795] train lossD: 0.036697 lossG: 0.936416\n",
      "[23: 515/1795] train lossD: -0.035655 lossG: 0.694829\n",
      "[23: 520/1795] train lossD: 0.129171 lossG: 0.669085\n",
      "[23: 525/1795] train lossD: -0.025621 lossG: 0.550926\n",
      "[23: 530/1795] train lossD: -0.020066 lossG: 0.696424\n",
      "[23: 535/1795] train lossD: -0.031745 lossG: 0.707525\n",
      "[23: 540/1795] train lossD: -0.010911 lossG: 0.828191\n",
      "[23: 545/1795] train lossD: -0.032403 lossG: 0.672268\n",
      "[23: 550/1795] train lossD: -0.032592 lossG: 0.928271\n",
      "[23: 555/1795] train lossD: 0.018011 lossG: 0.748600\n",
      "[23: 560/1795] train lossD: 0.007726 lossG: 0.698302\n",
      "[23: 565/1795] train lossD: -0.037532 lossG: 0.932534\n",
      "[23: 570/1795] train lossD: -0.049017 lossG: 0.787401\n",
      "[23: 575/1795] train lossD: -0.039231 lossG: 0.748973\n",
      "[23: 580/1795] train lossD: -0.087153 lossG: 0.775633\n",
      "[23: 585/1795] train lossD: -0.021026 lossG: 0.646722\n",
      "[23: 590/1795] train lossD: 0.007871 lossG: 0.953026\n",
      "[23: 595/1795] train lossD: 0.013959 lossG: 0.573700\n",
      "[23: 600/1795] train lossD: 0.002248 lossG: 0.699437\n",
      "[23: 605/1795] train lossD: 0.023856 lossG: 0.817805\n",
      "[23: 610/1795] train lossD: 0.033847 lossG: 0.559836\n",
      "[23: 615/1795] train lossD: 0.024536 lossG: 0.583240\n",
      "[23: 620/1795] train lossD: -0.028723 lossG: 0.631934\n",
      "[23: 625/1795] train lossD: 0.073572 lossG: 0.706619\n",
      "[23: 630/1795] train lossD: 0.013661 lossG: 0.668217\n",
      "[23: 635/1795] train lossD: -0.015357 lossG: 0.803469\n",
      "[23: 640/1795] train lossD: -0.044640 lossG: 0.775591\n",
      "[23: 645/1795] train lossD: -0.010286 lossG: 0.787010\n",
      "[23: 650/1795] train lossD: -0.034350 lossG: 0.726822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23: 655/1795] train lossD: -0.041486 lossG: 0.693704\n",
      "[23: 660/1795] train lossD: -0.030190 lossG: 0.641400\n",
      "[23: 665/1795] train lossD: 0.034435 lossG: 0.555689\n",
      "[23: 670/1795] train lossD: -0.022451 lossG: 0.369486\n",
      "[23: 675/1795] train lossD: 0.020929 lossG: 0.471013\n",
      "[23: 680/1795] train lossD: 0.065533 lossG: 0.633637\n",
      "[23: 685/1795] train lossD: 0.037023 lossG: 0.764571\n",
      "[23: 690/1795] train lossD: 0.004878 lossG: 0.637439\n",
      "[23: 695/1795] train lossD: -0.001991 lossG: 0.581428\n",
      "[23: 700/1795] train lossD: -0.010802 lossG: 0.529404\n",
      "[23: 705/1795] train lossD: -0.072509 lossG: 0.583291\n",
      "[23: 710/1795] train lossD: 0.102270 lossG: 0.562633\n",
      "[23: 715/1795] train lossD: -0.014514 lossG: 0.634814\n",
      "[23: 720/1795] train lossD: -0.027579 lossG: 0.505946\n",
      "[23: 725/1795] train lossD: 0.014114 lossG: 0.684113\n",
      "[23: 730/1795] train lossD: -0.006420 lossG: 0.537763\n",
      "[23: 735/1795] train lossD: 0.021273 lossG: 0.467461\n",
      "[23: 740/1795] train lossD: -0.035542 lossG: 0.871229\n",
      "[23: 745/1795] train lossD: -0.001639 lossG: 0.628769\n",
      "[23: 750/1795] train lossD: 0.026821 lossG: 0.732585\n",
      "[23: 755/1795] train lossD: 0.009510 lossG: 0.813214\n",
      "[23: 760/1795] train lossD: -0.049998 lossG: 0.671011\n",
      "[23: 765/1795] train lossD: 0.038714 lossG: 0.603240\n",
      "[23: 770/1795] train lossD: 0.038671 lossG: 0.515220\n",
      "[23: 775/1795] train lossD: 0.036201 lossG: 0.579146\n",
      "[23: 780/1795] train lossD: -0.045923 lossG: 0.579316\n",
      "[23: 785/1795] train lossD: -0.024361 lossG: 0.641163\n",
      "[23: 790/1795] train lossD: -0.004763 lossG: 0.611533\n",
      "[23: 795/1795] train lossD: -0.033230 lossG: 0.504162\n",
      "[23: 800/1795] train lossD: -0.047958 lossG: 0.549744\n",
      "[23: 805/1795] train lossD: 0.026895 lossG: 0.537828\n",
      "[23: 810/1795] train lossD: -0.002720 lossG: 0.502769\n",
      "[23: 815/1795] train lossD: -0.016480 lossG: 0.547225\n",
      "[23: 820/1795] train lossD: 0.002747 lossG: 0.674394\n",
      "[23: 825/1795] train lossD: -0.007957 lossG: 0.666978\n",
      "[23: 830/1795] train lossD: 0.006290 lossG: 0.774463\n",
      "[23: 835/1795] train lossD: -0.067902 lossG: 0.799416\n",
      "[23: 840/1795] train lossD: -0.057396 lossG: 0.924895\n",
      "[23: 845/1795] train lossD: -0.069804 lossG: 0.939225\n",
      "[23: 850/1795] train lossD: -0.003070 lossG: 0.706233\n",
      "[23: 855/1795] train lossD: -0.019459 lossG: 0.789947\n",
      "[23: 860/1795] train lossD: -0.037476 lossG: 0.705928\n",
      "[23: 865/1795] train lossD: -0.032343 lossG: 0.530133\n",
      "[23: 870/1795] train lossD: -0.027877 lossG: 0.587309\n",
      "[23: 875/1795] train lossD: -0.046302 lossG: 0.374374\n",
      "[23: 880/1795] train lossD: -0.066313 lossG: 0.558424\n",
      "[23: 885/1795] train lossD: 0.020440 lossG: 0.673601\n",
      "[23: 890/1795] train lossD: -0.008166 lossG: 0.761069\n",
      "[23: 895/1795] train lossD: -0.025829 lossG: 0.588837\n",
      "[23: 900/1795] train lossD: -0.003364 lossG: 0.781809\n",
      "[23: 905/1795] train lossD: -0.037286 lossG: 0.804257\n",
      "[23: 910/1795] train lossD: 0.015926 lossG: 0.524578\n",
      "[23: 915/1795] train lossD: -0.046006 lossG: 0.466832\n",
      "[23: 920/1795] train lossD: -0.021027 lossG: 0.612684\n",
      "[23: 925/1795] train lossD: 0.015042 lossG: 0.626650\n",
      "[23: 930/1795] train lossD: 0.010680 lossG: 0.758225\n",
      "[23: 935/1795] train lossD: 0.069370 lossG: 0.670862\n",
      "[23: 940/1795] train lossD: 0.012092 lossG: 0.493611\n",
      "[23: 945/1795] train lossD: -0.032254 lossG: 0.329390\n",
      "[23: 950/1795] train lossD: -0.011839 lossG: 0.459106\n",
      "[23: 955/1795] train lossD: -0.040093 lossG: 0.592215\n",
      "[23: 960/1795] train lossD: -0.027055 lossG: 0.788684\n",
      "[23: 965/1795] train lossD: -0.004467 lossG: 0.630551\n",
      "[23: 970/1795] train lossD: -0.050291 lossG: 0.667332\n",
      "[23: 975/1795] train lossD: -0.016137 lossG: 0.454102\n",
      "[23: 980/1795] train lossD: 0.024099 lossG: 0.588135\n",
      "[23: 985/1795] train lossD: 0.060110 lossG: 0.669529\n",
      "[23: 990/1795] train lossD: -0.025972 lossG: 0.493726\n",
      "[23: 995/1795] train lossD: 0.078556 lossG: 0.670635\n",
      "[23: 1000/1795] train lossD: 0.006950 lossG: 0.555670\n",
      "[23: 1005/1795] train lossD: 0.028097 lossG: 0.592066\n",
      "[23: 1010/1795] train lossD: -0.048982 lossG: 0.821285\n",
      "[23: 1015/1795] train lossD: -0.012860 lossG: 0.870185\n",
      "[23: 1020/1795] train lossD: -0.034037 lossG: 0.611922\n",
      "[23: 1025/1795] train lossD: 0.018112 lossG: 0.575304\n",
      "[23: 1030/1795] train lossD: -0.020734 lossG: 0.758951\n",
      "[23: 1035/1795] train lossD: -0.032269 lossG: 0.557013\n",
      "[23: 1040/1795] train lossD: 0.021597 lossG: 0.819679\n",
      "[23: 1045/1795] train lossD: -0.063331 lossG: 0.796054\n",
      "[23: 1050/1795] train lossD: -0.017251 lossG: 0.687476\n",
      "[23: 1055/1795] train lossD: 0.016413 lossG: 0.597130\n",
      "[23: 1060/1795] train lossD: 0.002392 lossG: 0.602067\n",
      "[23: 1065/1795] train lossD: -0.067790 lossG: 0.525616\n",
      "[23: 1070/1795] train lossD: 0.055659 lossG: 0.682416\n",
      "[23: 1075/1795] train lossD: -0.033282 lossG: 0.461325\n",
      "[23: 1080/1795] train lossD: 0.017968 lossG: 0.530999\n",
      "[23: 1085/1795] train lossD: -0.023548 lossG: 0.741778\n",
      "[23: 1090/1795] train lossD: -0.029994 lossG: 0.585154\n",
      "[23: 1095/1795] train lossD: -0.012571 lossG: 0.565408\n",
      "[23: 1100/1795] train lossD: 0.010634 lossG: 0.989869\n",
      "[23: 1105/1795] train lossD: 0.004250 lossG: 0.823682\n",
      "[23: 1110/1795] train lossD: 0.027681 lossG: 0.620634\n",
      "[23: 1115/1795] train lossD: 0.038060 lossG: 0.476591\n",
      "[23: 1120/1795] train lossD: -0.039518 lossG: 0.455929\n",
      "[23: 1125/1795] train lossD: 0.044806 lossG: 0.649780\n",
      "[23: 1130/1795] train lossD: -0.036974 lossG: 0.878424\n",
      "[23: 1135/1795] train lossD: -0.030330 lossG: 0.539455\n",
      "[23: 1140/1795] train lossD: -0.072574 lossG: 0.706672\n",
      "[23: 1145/1795] train lossD: 0.015001 lossG: 0.709186\n",
      "[23: 1150/1795] train lossD: -0.033951 lossG: 0.896756\n",
      "[23: 1155/1795] train lossD: 0.019331 lossG: 0.958719\n",
      "[23: 1160/1795] train lossD: -0.081765 lossG: 0.812334\n",
      "[23: 1165/1795] train lossD: -0.015410 lossG: 0.700182\n",
      "[23: 1170/1795] train lossD: 0.015096 lossG: 0.500081\n",
      "[23: 1175/1795] train lossD: -0.017459 lossG: 0.593628\n",
      "[23: 1180/1795] train lossD: -0.016312 lossG: 0.512761\n",
      "[23: 1185/1795] train lossD: 0.039396 lossG: 0.585587\n",
      "[23: 1190/1795] train lossD: 0.043678 lossG: 0.613784\n",
      "[23: 1195/1795] train lossD: -0.001251 lossG: 0.637308\n",
      "[23: 1200/1795] train lossD: -0.043722 lossG: 0.602324\n",
      "[23: 1205/1795] train lossD: -0.010919 lossG: 0.466772\n",
      "[23: 1210/1795] train lossD: -0.028336 lossG: 0.628435\n",
      "[23: 1215/1795] train lossD: -0.026232 lossG: 0.546212\n",
      "[23: 1220/1795] train lossD: -0.008328 lossG: 0.725736\n",
      "[23: 1225/1795] train lossD: -0.004342 lossG: 0.622217\n",
      "[23: 1230/1795] train lossD: -0.038077 lossG: 0.629344\n",
      "[23: 1235/1795] train lossD: 0.026762 lossG: 0.613361\n",
      "[23: 1240/1795] train lossD: 0.018763 lossG: 0.686233\n",
      "[23: 1245/1795] train lossD: -0.056622 lossG: 0.750374\n",
      "[23: 1250/1795] train lossD: -0.050408 lossG: 0.716893\n",
      "[23: 1255/1795] train lossD: -0.016506 lossG: 0.897892\n",
      "[23: 1260/1795] train lossD: -0.055050 lossG: 1.072094\n",
      "[23: 1265/1795] train lossD: -0.013206 lossG: 0.739858\n",
      "[23: 1270/1795] train lossD: 0.024185 lossG: 0.912875\n",
      "[23: 1275/1795] train lossD: -0.004037 lossG: 0.641278\n",
      "[23: 1280/1795] train lossD: -0.038089 lossG: 0.473394\n",
      "[23: 1285/1795] train lossD: -0.007334 lossG: 0.412802\n",
      "[23: 1290/1795] train lossD: -0.028939 lossG: 0.456753\n",
      "[23: 1295/1795] train lossD: 0.003003 lossG: 0.484598\n",
      "[23: 1300/1795] train lossD: 0.125910 lossG: 0.594169\n",
      "[23: 1305/1795] train lossD: -0.034424 lossG: 0.605230\n",
      "[23: 1310/1795] train lossD: -0.026850 lossG: 0.388534\n",
      "[23: 1315/1795] train lossD: 0.034597 lossG: 0.893215\n",
      "[23: 1320/1795] train lossD: -0.048160 lossG: 0.809308\n",
      "[23: 1325/1795] train lossD: -0.021864 lossG: 0.876162\n",
      "[23: 1330/1795] train lossD: -0.028674 lossG: 0.829336\n",
      "[23: 1335/1795] train lossD: -0.052723 lossG: 0.776851\n",
      "[23: 1340/1795] train lossD: -0.054758 lossG: 0.528723\n",
      "[23: 1345/1795] train lossD: -0.030931 lossG: 0.581809\n",
      "[23: 1350/1795] train lossD: 0.156753 lossG: 0.749874\n",
      "[23: 1355/1795] train lossD: -0.046904 lossG: 0.892054\n",
      "[23: 1360/1795] train lossD: -0.012409 lossG: 0.760949\n",
      "[23: 1365/1795] train lossD: -0.051295 lossG: 0.657224\n",
      "[23: 1370/1795] train lossD: -0.039225 lossG: 0.749106\n",
      "[23: 1375/1795] train lossD: 0.154070 lossG: 0.731099\n",
      "[23: 1380/1795] train lossD: 0.056948 lossG: 0.677362\n",
      "[23: 1385/1795] train lossD: -0.038829 lossG: 0.723529\n",
      "[23: 1390/1795] train lossD: 0.005535 lossG: 0.616531\n",
      "[23: 1395/1795] train lossD: -0.019315 lossG: 0.623947\n",
      "[23: 1400/1795] train lossD: 0.017322 lossG: 0.535854\n",
      "[23: 1405/1795] train lossD: -0.044968 lossG: 0.678054\n",
      "[23: 1410/1795] train lossD: -0.083547 lossG: 0.530951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23: 1415/1795] train lossD: -0.030075 lossG: 0.614282\n",
      "[23: 1420/1795] train lossD: -0.029404 lossG: 0.562451\n",
      "[23: 1425/1795] train lossD: -0.015623 lossG: 0.623366\n",
      "[23: 1430/1795] train lossD: 0.049975 lossG: 0.682234\n",
      "[23: 1435/1795] train lossD: 0.025468 lossG: 0.569912\n",
      "[23: 1440/1795] train lossD: 0.029078 lossG: 0.857175\n",
      "[23: 1445/1795] train lossD: -0.018987 lossG: 0.927381\n",
      "[23: 1450/1795] train lossD: -0.050103 lossG: 0.752743\n",
      "[23: 1455/1795] train lossD: 0.000009 lossG: 0.612747\n",
      "[23: 1460/1795] train lossD: 0.002191 lossG: 0.527504\n",
      "[23: 1465/1795] train lossD: 0.026099 lossG: 0.510259\n",
      "[23: 1470/1795] train lossD: 0.046992 lossG: 0.695779\n",
      "[23: 1475/1795] train lossD: -0.083367 lossG: 0.770289\n",
      "[23: 1480/1795] train lossD: 0.027028 lossG: 0.690043\n",
      "[23: 1485/1795] train lossD: -0.061947 lossG: 0.560369\n",
      "[23: 1490/1795] train lossD: 0.000285 lossG: 0.886157\n",
      "[23: 1495/1795] train lossD: -0.005792 lossG: 0.359368\n",
      "[23: 1500/1795] train lossD: 0.063194 lossG: 0.565400\n",
      "[23: 1505/1795] train lossD: -0.042096 lossG: 0.400844\n",
      "[23: 1510/1795] train lossD: -0.005325 lossG: 0.422445\n",
      "[23: 1515/1795] train lossD: 0.006179 lossG: 0.563905\n",
      "[23: 1520/1795] train lossD: -0.007177 lossG: 0.552554\n",
      "[23: 1525/1795] train lossD: -0.037857 lossG: 0.641083\n",
      "[23: 1530/1795] train lossD: -0.016627 lossG: 0.611683\n",
      "[23: 1535/1795] train lossD: -0.039851 lossG: 0.458866\n",
      "[23: 1540/1795] train lossD: -0.062973 lossG: 0.508109\n",
      "[23: 1545/1795] train lossD: 0.015373 lossG: 0.659931\n",
      "[23: 1550/1795] train lossD: -0.007613 lossG: 0.710233\n",
      "[23: 1555/1795] train lossD: 0.011052 lossG: 0.595667\n",
      "[23: 1560/1795] train lossD: -0.091313 lossG: 0.739578\n",
      "[23: 1565/1795] train lossD: 0.023153 lossG: 0.514614\n",
      "[23: 1570/1795] train lossD: -0.025113 lossG: 0.680635\n",
      "[23: 1575/1795] train lossD: -0.006027 lossG: 0.619551\n",
      "[23: 1580/1795] train lossD: -0.007308 lossG: 0.590684\n",
      "[23: 1585/1795] train lossD: -0.025886 lossG: 0.614460\n",
      "[23: 1590/1795] train lossD: -0.043393 lossG: 0.549546\n",
      "[23: 1595/1795] train lossD: -0.013399 lossG: 0.842223\n",
      "[23: 1600/1795] train lossD: -0.020841 lossG: 0.853487\n",
      "[23: 1605/1795] train lossD: 0.010687 lossG: 0.671560\n",
      "[23: 1610/1795] train lossD: 0.021964 lossG: 0.492357\n",
      "[23: 1615/1795] train lossD: -0.055565 lossG: 0.377535\n",
      "[23: 1620/1795] train lossD: -0.062183 lossG: 0.562343\n",
      "[23: 1625/1795] train lossD: -0.022279 lossG: 0.608162\n",
      "[23: 1630/1795] train lossD: -0.052289 lossG: 0.499018\n",
      "[23: 1635/1795] train lossD: -0.046579 lossG: 0.589683\n",
      "[23: 1640/1795] train lossD: -0.035037 lossG: 0.470228\n",
      "[23: 1645/1795] train lossD: -0.026033 lossG: 0.416369\n",
      "[23: 1650/1795] train lossD: -0.019653 lossG: 0.719700\n",
      "[23: 1655/1795] train lossD: -0.017345 lossG: 0.551613\n",
      "[23: 1660/1795] train lossD: -0.015018 lossG: 0.613424\n",
      "[23: 1665/1795] train lossD: -0.023254 lossG: 0.598439\n",
      "[23: 1670/1795] train lossD: 0.046069 lossG: 0.630961\n",
      "[23: 1675/1795] train lossD: -0.077240 lossG: 0.618411\n",
      "[23: 1680/1795] train lossD: -0.002392 lossG: 0.584014\n",
      "[23: 1685/1795] train lossD: -0.029525 lossG: 0.697678\n",
      "[23: 1690/1795] train lossD: 0.015595 lossG: 0.559999\n",
      "[23: 1695/1795] train lossD: -0.008980 lossG: 0.853964\n",
      "[23: 1700/1795] train lossD: 0.003836 lossG: 0.628180\n",
      "[23: 1705/1795] train lossD: -0.021982 lossG: 0.879156\n",
      "[23: 1710/1795] train lossD: -0.038699 lossG: 0.745139\n",
      "[23: 1715/1795] train lossD: -0.025706 lossG: 0.541486\n",
      "[23: 1720/1795] train lossD: -0.042012 lossG: 0.639758\n",
      "[23: 1725/1795] train lossD: -0.050902 lossG: 0.667986\n",
      "[23: 1730/1795] train lossD: -0.007127 lossG: 0.692313\n",
      "[23: 1735/1795] train lossD: -0.025284 lossG: 0.758928\n",
      "[23: 1740/1795] train lossD: -0.025431 lossG: 0.872591\n",
      "[23: 1745/1795] train lossD: -0.001820 lossG: 0.888014\n",
      "[23: 1750/1795] train lossD: -0.122640 lossG: 0.859922\n",
      "[23: 1755/1795] train lossD: -0.024669 lossG: 1.031259\n",
      "[23: 1760/1795] train lossD: -0.040277 lossG: 0.705127\n",
      "[23: 1765/1795] train lossD: -0.017928 lossG: 0.793161\n",
      "[23: 1770/1795] train lossD: -0.001819 lossG: 0.735279\n",
      "[23: 1775/1795] train lossD: 0.016755 lossG: 0.645303\n",
      "[23: 1780/1795] train lossD: 0.041379 lossG: 0.676019\n",
      "[23: 1785/1795] train lossD: -0.051980 lossG: 0.560527\n",
      "[23: 1790/1795] train lossD: -0.071620 lossG: 0.572437\n",
      "0.04734976589679718\n",
      "[24: 0/1795] train lossD: 0.006488 lossG: 0.706880\n",
      "[24: 5/1795] train lossD: -0.043251 lossG: 0.778006\n",
      "[24: 10/1795] train lossD: 0.000863 lossG: 0.713566\n",
      "[24: 15/1795] train lossD: 0.036785 lossG: 0.787020\n",
      "[24: 20/1795] train lossD: -0.044140 lossG: 0.843373\n",
      "[24: 25/1795] train lossD: -0.042016 lossG: 0.538354\n",
      "[24: 30/1795] train lossD: 0.011758 lossG: 0.612163\n",
      "[24: 35/1795] train lossD: 0.088177 lossG: 0.642125\n",
      "[24: 40/1795] train lossD: -0.055732 lossG: 0.495164\n",
      "[24: 45/1795] train lossD: -0.010820 lossG: 0.477316\n",
      "[24: 50/1795] train lossD: -0.036921 lossG: 0.609224\n",
      "[24: 55/1795] train lossD: -0.053443 lossG: 0.646365\n",
      "[24: 60/1795] train lossD: 0.001472 lossG: 0.597245\n",
      "[24: 65/1795] train lossD: -0.045782 lossG: 0.502580\n",
      "[24: 70/1795] train lossD: -0.050815 lossG: 0.512969\n",
      "[24: 75/1795] train lossD: -0.023682 lossG: 0.502533\n",
      "[24: 80/1795] train lossD: 0.037652 lossG: 0.757101\n",
      "[24: 85/1795] train lossD: -0.036286 lossG: 0.646418\n",
      "[24: 90/1795] train lossD: -0.069522 lossG: 0.629112\n",
      "[24: 95/1795] train lossD: -0.015862 lossG: 0.444105\n",
      "[24: 100/1795] train lossD: -0.048298 lossG: 0.461870\n",
      "[24: 105/1795] train lossD: -0.012510 lossG: 0.428444\n",
      "[24: 110/1795] train lossD: -0.040613 lossG: 0.767393\n",
      "[24: 115/1795] train lossD: 0.019073 lossG: 0.759576\n",
      "[24: 120/1795] train lossD: -0.005903 lossG: 0.598754\n",
      "[24: 125/1795] train lossD: -0.049936 lossG: 0.453414\n",
      "[24: 130/1795] train lossD: -0.006289 lossG: 0.313405\n",
      "[24: 135/1795] train lossD: -0.001770 lossG: 0.444650\n",
      "[24: 140/1795] train lossD: -0.058294 lossG: 0.300987\n",
      "[24: 145/1795] train lossD: -0.009189 lossG: 0.396203\n",
      "[24: 150/1795] train lossD: -0.066189 lossG: 0.394460\n",
      "[24: 155/1795] train lossD: -0.026465 lossG: 0.521666\n",
      "[24: 160/1795] train lossD: -0.007496 lossG: 0.742363\n",
      "[24: 165/1795] train lossD: -0.049449 lossG: 0.382512\n",
      "[24: 170/1795] train lossD: 0.003079 lossG: 0.683127\n",
      "[24: 175/1795] train lossD: -0.039447 lossG: 0.559428\n",
      "[24: 180/1795] train lossD: -0.045925 lossG: 0.502001\n",
      "[24: 185/1795] train lossD: -0.044933 lossG: 0.460059\n",
      "[24: 190/1795] train lossD: -0.013510 lossG: 0.499557\n",
      "[24: 195/1795] train lossD: 0.000179 lossG: 0.711748\n",
      "[24: 200/1795] train lossD: 0.001652 lossG: 0.679701\n",
      "[24: 205/1795] train lossD: -0.029817 lossG: 0.663034\n",
      "[24: 210/1795] train lossD: 0.009652 lossG: 0.668466\n",
      "[24: 215/1795] train lossD: 0.001962 lossG: 0.732971\n",
      "[24: 220/1795] train lossD: -0.018428 lossG: 0.610584\n",
      "[24: 225/1795] train lossD: -0.047544 lossG: 0.454242\n",
      "[24: 230/1795] train lossD: -0.052344 lossG: 0.590287\n",
      "[24: 235/1795] train lossD: -0.019218 lossG: 0.687906\n",
      "[24: 240/1795] train lossD: -0.024097 lossG: 0.657565\n",
      "[24: 245/1795] train lossD: -0.010934 lossG: 0.567009\n",
      "[24: 250/1795] train lossD: -0.049845 lossG: 0.574094\n",
      "[24: 255/1795] train lossD: -0.013457 lossG: 0.865253\n",
      "[24: 260/1795] train lossD: 0.017977 lossG: 0.800697\n",
      "[24: 265/1795] train lossD: -0.028630 lossG: 0.726531\n",
      "[24: 270/1795] train lossD: -0.021876 lossG: 0.607989\n",
      "[24: 275/1795] train lossD: -0.044474 lossG: 0.486620\n",
      "[24: 280/1795] train lossD: -0.047581 lossG: 0.691986\n",
      "[24: 285/1795] train lossD: -0.034529 lossG: 0.455651\n",
      "[24: 290/1795] train lossD: -0.010481 lossG: 0.648631\n",
      "[24: 295/1795] train lossD: -0.021107 lossG: 0.647911\n",
      "[24: 300/1795] train lossD: 0.017523 lossG: 0.622065\n",
      "[24: 305/1795] train lossD: -0.006616 lossG: 0.573410\n",
      "[24: 310/1795] train lossD: -0.007599 lossG: 0.605640\n",
      "[24: 315/1795] train lossD: -0.023196 lossG: 0.870406\n",
      "[24: 320/1795] train lossD: -0.082158 lossG: 0.965708\n",
      "[24: 325/1795] train lossD: -0.027854 lossG: 0.730621\n",
      "[24: 330/1795] train lossD: -0.034500 lossG: 0.731409\n",
      "[24: 335/1795] train lossD: -0.019162 lossG: 0.728621\n",
      "[24: 340/1795] train lossD: -0.019808 lossG: 0.590569\n",
      "[24: 345/1795] train lossD: -0.020272 lossG: 0.627472\n",
      "[24: 350/1795] train lossD: -0.033723 lossG: 0.805678\n",
      "[24: 355/1795] train lossD: -0.019140 lossG: 0.545887\n",
      "[24: 360/1795] train lossD: -0.029002 lossG: 0.727373\n",
      "[24: 365/1795] train lossD: 0.043817 lossG: 0.565484\n",
      "[24: 370/1795] train lossD: -0.031901 lossG: 0.621637\n",
      "[24: 375/1795] train lossD: -0.042183 lossG: 0.632656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24: 380/1795] train lossD: 0.048286 lossG: 0.534779\n",
      "[24: 385/1795] train lossD: -0.017165 lossG: 0.763685\n",
      "[24: 390/1795] train lossD: -0.076643 lossG: 0.818435\n",
      "[24: 395/1795] train lossD: -0.003623 lossG: 0.579384\n",
      "[24: 400/1795] train lossD: -0.050915 lossG: 0.562287\n",
      "[24: 405/1795] train lossD: 0.027955 lossG: 0.357725\n",
      "[24: 410/1795] train lossD: -0.074984 lossG: 0.500176\n",
      "[24: 415/1795] train lossD: -0.012506 lossG: 0.569767\n",
      "[24: 420/1795] train lossD: -0.057954 lossG: 0.625820\n",
      "[24: 425/1795] train lossD: 0.034777 lossG: 0.908251\n",
      "[24: 430/1795] train lossD: -0.020391 lossG: 0.689833\n",
      "[24: 435/1795] train lossD: 0.002782 lossG: 0.626090\n",
      "[24: 440/1795] train lossD: 0.056221 lossG: 0.719874\n",
      "[24: 445/1795] train lossD: -0.072248 lossG: 0.581377\n",
      "[24: 450/1795] train lossD: -0.025108 lossG: 0.622597\n",
      "[24: 455/1795] train lossD: -0.062275 lossG: 0.676312\n",
      "[24: 460/1795] train lossD: -0.003876 lossG: 0.568688\n",
      "[24: 465/1795] train lossD: -0.066050 lossG: 0.293823\n",
      "[24: 470/1795] train lossD: -0.001533 lossG: 0.556845\n",
      "[24: 475/1795] train lossD: -0.003115 lossG: 0.507693\n",
      "[24: 480/1795] train lossD: -0.018078 lossG: 0.537897\n",
      "[24: 485/1795] train lossD: -0.007914 lossG: 0.516417\n",
      "[24: 490/1795] train lossD: -0.011696 lossG: 0.731416\n",
      "[24: 495/1795] train lossD: -0.031013 lossG: 0.542251\n",
      "[24: 500/1795] train lossD: -0.032102 lossG: 0.614426\n",
      "[24: 505/1795] train lossD: -0.002487 lossG: 0.620630\n",
      "[24: 510/1795] train lossD: -0.044435 lossG: 0.503779\n",
      "[24: 515/1795] train lossD: -0.038890 lossG: 0.570098\n",
      "[24: 520/1795] train lossD: 0.029679 lossG: 0.429047\n",
      "[24: 525/1795] train lossD: -0.089051 lossG: 0.491279\n",
      "[24: 530/1795] train lossD: -0.035258 lossG: 0.640821\n",
      "[24: 535/1795] train lossD: -0.025599 lossG: 0.650393\n",
      "[24: 540/1795] train lossD: -0.064468 lossG: 0.760265\n",
      "[24: 545/1795] train lossD: -0.011662 lossG: 0.754766\n",
      "[24: 550/1795] train lossD: 0.036839 lossG: 0.739630\n",
      "[24: 555/1795] train lossD: -0.035031 lossG: 0.591566\n",
      "[24: 560/1795] train lossD: 0.033753 lossG: 0.739091\n",
      "[24: 565/1795] train lossD: -0.046552 lossG: 0.677693\n",
      "[24: 570/1795] train lossD: -0.061525 lossG: 0.736536\n",
      "[24: 575/1795] train lossD: -0.016442 lossG: 0.688865\n",
      "[24: 580/1795] train lossD: 0.002269 lossG: 0.660654\n",
      "[24: 585/1795] train lossD: 0.008791 lossG: 0.749189\n",
      "[24: 590/1795] train lossD: -0.047588 lossG: 1.012558\n",
      "[24: 595/1795] train lossD: 0.024636 lossG: 0.826713\n",
      "[24: 600/1795] train lossD: -0.054115 lossG: 0.840614\n",
      "[24: 605/1795] train lossD: -0.025067 lossG: 0.824662\n",
      "[24: 610/1795] train lossD: -0.008530 lossG: 1.006697\n",
      "[24: 615/1795] train lossD: -0.033510 lossG: 0.696715\n",
      "[24: 620/1795] train lossD: -0.044988 lossG: 0.748650\n",
      "[24: 625/1795] train lossD: -0.016119 lossG: 0.658953\n",
      "[24: 630/1795] train lossD: 0.008020 lossG: 0.577004\n",
      "[24: 635/1795] train lossD: -0.042256 lossG: 0.668555\n",
      "[24: 640/1795] train lossD: -0.011718 lossG: 0.660633\n",
      "[24: 645/1795] train lossD: -0.042927 lossG: 0.776944\n",
      "[24: 650/1795] train lossD: -0.003950 lossG: 0.546896\n",
      "[24: 655/1795] train lossD: -0.065531 lossG: 0.711228\n",
      "[24: 660/1795] train lossD: -0.028056 lossG: 0.714177\n",
      "[24: 665/1795] train lossD: -0.040860 lossG: 0.474253\n",
      "[24: 670/1795] train lossD: -0.042891 lossG: 0.592824\n",
      "[24: 675/1795] train lossD: -0.030673 lossG: 0.625414\n",
      "[24: 680/1795] train lossD: -0.024356 lossG: 0.686853\n",
      "[24: 685/1795] train lossD: 0.001305 lossG: 0.495335\n",
      "[24: 690/1795] train lossD: -0.032611 lossG: 0.343624\n",
      "[24: 695/1795] train lossD: 0.040699 lossG: 0.478983\n",
      "[24: 700/1795] train lossD: -0.052052 lossG: 0.584699\n",
      "[24: 705/1795] train lossD: -0.041894 lossG: 0.688793\n",
      "[24: 710/1795] train lossD: -0.043331 lossG: 0.484745\n",
      "[24: 715/1795] train lossD: 0.118040 lossG: 0.553866\n",
      "[24: 720/1795] train lossD: -0.015116 lossG: 0.632483\n",
      "[24: 725/1795] train lossD: -0.064226 lossG: 0.546052\n",
      "[24: 730/1795] train lossD: -0.091479 lossG: 0.614045\n",
      "[24: 735/1795] train lossD: -0.079000 lossG: 0.563125\n",
      "[24: 740/1795] train lossD: -0.015659 lossG: 0.486488\n",
      "[24: 745/1795] train lossD: -0.025934 lossG: 0.595392\n",
      "[24: 750/1795] train lossD: -0.074891 lossG: 0.626224\n",
      "[24: 755/1795] train lossD: -0.041915 lossG: 0.628056\n",
      "[24: 760/1795] train lossD: -0.023181 lossG: 0.577842\n",
      "[24: 765/1795] train lossD: -0.058324 lossG: 0.599492\n",
      "[24: 770/1795] train lossD: 0.027744 lossG: 0.499036\n",
      "[24: 775/1795] train lossD: -0.007446 lossG: 0.520634\n",
      "[24: 780/1795] train lossD: -0.009569 lossG: 0.634669\n",
      "[24: 785/1795] train lossD: 0.013109 lossG: 0.482318\n",
      "[24: 790/1795] train lossD: -0.026830 lossG: 0.695060\n",
      "[24: 795/1795] train lossD: -0.071619 lossG: 0.846098\n",
      "[24: 800/1795] train lossD: -0.058722 lossG: 0.916472\n",
      "[24: 805/1795] train lossD: -0.055262 lossG: 0.626257\n",
      "[24: 810/1795] train lossD: -0.008924 lossG: 0.465361\n",
      "[24: 815/1795] train lossD: -0.010613 lossG: 0.521558\n",
      "[24: 820/1795] train lossD: -0.049444 lossG: 0.485459\n",
      "[24: 825/1795] train lossD: -0.017511 lossG: 0.474620\n",
      "[24: 830/1795] train lossD: 0.074243 lossG: 0.501794\n",
      "[24: 835/1795] train lossD: -0.016771 lossG: 0.586877\n",
      "[24: 840/1795] train lossD: -0.060096 lossG: 0.753260\n",
      "[24: 845/1795] train lossD: -0.027545 lossG: 0.629002\n",
      "[24: 850/1795] train lossD: -0.051804 lossG: 0.487363\n",
      "[24: 855/1795] train lossD: 0.029214 lossG: 0.586203\n",
      "[24: 860/1795] train lossD: -0.027532 lossG: 0.622935\n",
      "[24: 865/1795] train lossD: 0.009614 lossG: 0.784544\n",
      "[24: 870/1795] train lossD: -0.009472 lossG: 0.917409\n",
      "[24: 875/1795] train lossD: -0.019138 lossG: 0.836854\n",
      "[24: 880/1795] train lossD: -0.011728 lossG: 0.791475\n",
      "[24: 885/1795] train lossD: -0.023508 lossG: 0.840355\n",
      "[24: 890/1795] train lossD: -0.020075 lossG: 0.711978\n",
      "[24: 895/1795] train lossD: -0.050525 lossG: 0.691741\n",
      "[24: 900/1795] train lossD: 0.012276 lossG: 0.720491\n",
      "[24: 905/1795] train lossD: -0.053740 lossG: 0.694657\n",
      "[24: 910/1795] train lossD: -0.034639 lossG: 0.573965\n",
      "[24: 915/1795] train lossD: -0.086293 lossG: 0.483221\n",
      "[24: 920/1795] train lossD: -0.002396 lossG: 0.520317\n",
      "[24: 925/1795] train lossD: 0.000477 lossG: 0.605147\n",
      "[24: 930/1795] train lossD: -0.043890 lossG: 0.545671\n",
      "[24: 935/1795] train lossD: -0.038793 lossG: 0.648385\n",
      "[24: 940/1795] train lossD: -0.023474 lossG: 0.770452\n",
      "[24: 945/1795] train lossD: -0.026896 lossG: 0.795270\n",
      "[24: 950/1795] train lossD: -0.008818 lossG: 0.501045\n",
      "[24: 955/1795] train lossD: -0.041252 lossG: 0.594654\n",
      "[24: 960/1795] train lossD: 0.001176 lossG: 0.711009\n",
      "[24: 965/1795] train lossD: 0.074378 lossG: 0.637173\n",
      "[24: 970/1795] train lossD: -0.000962 lossG: 0.788235\n",
      "[24: 975/1795] train lossD: 0.067573 lossG: 0.811145\n",
      "[24: 980/1795] train lossD: -0.060117 lossG: 0.766764\n",
      "[24: 985/1795] train lossD: -0.052652 lossG: 0.777966\n",
      "[24: 990/1795] train lossD: -0.028275 lossG: 0.598366\n",
      "[24: 995/1795] train lossD: -0.021377 lossG: 0.627432\n",
      "[24: 1000/1795] train lossD: 0.001631 lossG: 0.628711\n",
      "[24: 1005/1795] train lossD: -0.058260 lossG: 0.504817\n",
      "[24: 1010/1795] train lossD: -0.085126 lossG: 0.481983\n",
      "[24: 1015/1795] train lossD: -0.037286 lossG: 0.538032\n",
      "[24: 1020/1795] train lossD: -0.018883 lossG: 0.478826\n",
      "[24: 1025/1795] train lossD: 0.014939 lossG: 0.466070\n",
      "[24: 1030/1795] train lossD: -0.047244 lossG: 0.447532\n",
      "[24: 1035/1795] train lossD: -0.000178 lossG: 0.670826\n",
      "[24: 1040/1795] train lossD: 0.060867 lossG: 0.395853\n",
      "[24: 1045/1795] train lossD: -0.003189 lossG: 0.540982\n",
      "[24: 1050/1795] train lossD: -0.034723 lossG: 0.541590\n",
      "[24: 1055/1795] train lossD: -0.022738 lossG: 0.699451\n",
      "[24: 1060/1795] train lossD: 0.137459 lossG: 0.924263\n",
      "[24: 1065/1795] train lossD: 0.005221 lossG: 0.651241\n",
      "[24: 1070/1795] train lossD: -0.012619 lossG: 0.559133\n",
      "[24: 1075/1795] train lossD: -0.001821 lossG: 0.448063\n",
      "[24: 1080/1795] train lossD: -0.011266 lossG: 0.478544\n",
      "[24: 1085/1795] train lossD: -0.045537 lossG: 0.687982\n",
      "[24: 1090/1795] train lossD: -0.017668 lossG: 0.604880\n",
      "[24: 1095/1795] train lossD: -0.041706 lossG: 0.638617\n",
      "[24: 1100/1795] train lossD: -0.004005 lossG: 0.621787\n",
      "[24: 1105/1795] train lossD: -0.015787 lossG: 0.814728\n",
      "[24: 1110/1795] train lossD: -0.009977 lossG: 0.555268\n",
      "[24: 1115/1795] train lossD: -0.033309 lossG: 0.587509\n",
      "[24: 1120/1795] train lossD: -0.038172 lossG: 0.560309\n",
      "[24: 1125/1795] train lossD: -0.050299 lossG: 0.531804\n",
      "[24: 1130/1795] train lossD: 0.028875 lossG: 0.490226\n",
      "[24: 1135/1795] train lossD: -0.009726 lossG: 0.463570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24: 1140/1795] train lossD: -0.047378 lossG: 0.442398\n",
      "[24: 1145/1795] train lossD: 0.161400 lossG: 0.587057\n",
      "[24: 1150/1795] train lossD: -0.016481 lossG: 0.510579\n",
      "[24: 1155/1795] train lossD: 0.000552 lossG: 0.371833\n",
      "[24: 1160/1795] train lossD: -0.038442 lossG: 0.566155\n",
      "[24: 1165/1795] train lossD: -0.011579 lossG: 0.599923\n",
      "[24: 1170/1795] train lossD: 0.046690 lossG: 0.562368\n",
      "[24: 1175/1795] train lossD: -0.032666 lossG: 0.459613\n",
      "[24: 1180/1795] train lossD: -0.019387 lossG: 0.572353\n",
      "[24: 1185/1795] train lossD: -0.006324 lossG: 0.366825\n",
      "[24: 1190/1795] train lossD: -0.002424 lossG: 0.612709\n",
      "[24: 1195/1795] train lossD: -0.026215 lossG: 0.655681\n",
      "[24: 1200/1795] train lossD: -0.008696 lossG: 0.842791\n",
      "[24: 1205/1795] train lossD: -0.027382 lossG: 0.846359\n",
      "[24: 1210/1795] train lossD: -0.027362 lossG: 0.610460\n",
      "[24: 1215/1795] train lossD: -0.058974 lossG: 0.529806\n",
      "[24: 1220/1795] train lossD: -0.029447 lossG: 0.851089\n",
      "[24: 1225/1795] train lossD: -0.031772 lossG: 0.894101\n",
      "[24: 1230/1795] train lossD: -0.069926 lossG: 0.785151\n",
      "[24: 1235/1795] train lossD: -0.021867 lossG: 0.532167\n",
      "[24: 1240/1795] train lossD: -0.018309 lossG: 0.780373\n",
      "[24: 1245/1795] train lossD: 0.006339 lossG: 0.625731\n",
      "[24: 1250/1795] train lossD: -0.030968 lossG: 0.695704\n",
      "[24: 1255/1795] train lossD: -0.059013 lossG: 0.498998\n",
      "[24: 1260/1795] train lossD: 0.030030 lossG: 0.725512\n",
      "[24: 1265/1795] train lossD: -0.026180 lossG: 0.609946\n",
      "[24: 1270/1795] train lossD: -0.025763 lossG: 0.615161\n",
      "[24: 1275/1795] train lossD: -0.062848 lossG: 0.766345\n",
      "[24: 1280/1795] train lossD: -0.025737 lossG: 0.620576\n",
      "[24: 1285/1795] train lossD: -0.068094 lossG: 0.484755\n",
      "[24: 1290/1795] train lossD: 0.018043 lossG: 0.652661\n",
      "[24: 1295/1795] train lossD: -0.034264 lossG: 0.799412\n",
      "[24: 1300/1795] train lossD: -0.029790 lossG: 0.700659\n",
      "[24: 1305/1795] train lossD: -0.043420 lossG: 0.555478\n",
      "[24: 1310/1795] train lossD: -0.017182 lossG: 0.645332\n",
      "[24: 1315/1795] train lossD: -0.028376 lossG: 0.325677\n",
      "[24: 1320/1795] train lossD: -0.060046 lossG: 0.422934\n",
      "[24: 1325/1795] train lossD: -0.027332 lossG: 0.482668\n",
      "[24: 1330/1795] train lossD: -0.067587 lossG: 0.454624\n",
      "[24: 1335/1795] train lossD: 0.008686 lossG: 0.589974\n",
      "[24: 1340/1795] train lossD: -0.030127 lossG: 0.609637\n",
      "[24: 1345/1795] train lossD: -0.069939 lossG: 0.565848\n",
      "[24: 1350/1795] train lossD: -0.041635 lossG: 0.583862\n",
      "[24: 1355/1795] train lossD: -0.090474 lossG: 0.550550\n",
      "[24: 1360/1795] train lossD: -0.038819 lossG: 0.625492\n",
      "[24: 1365/1795] train lossD: -0.036089 lossG: 0.710975\n",
      "[24: 1370/1795] train lossD: -0.023987 lossG: 0.649189\n",
      "[24: 1375/1795] train lossD: -0.026757 lossG: 0.715417\n",
      "[24: 1380/1795] train lossD: -0.026804 lossG: 0.696941\n",
      "[24: 1385/1795] train lossD: 0.025819 lossG: 0.585305\n",
      "[24: 1390/1795] train lossD: -0.049197 lossG: 0.576907\n",
      "[24: 1395/1795] train lossD: -0.088453 lossG: 0.724538\n",
      "[24: 1400/1795] train lossD: -0.014882 lossG: 0.519902\n",
      "[24: 1405/1795] train lossD: 0.006795 lossG: 0.659026\n",
      "[24: 1410/1795] train lossD: -0.055920 lossG: 0.562208\n",
      "[24: 1415/1795] train lossD: -0.041102 lossG: 0.522171\n",
      "[24: 1420/1795] train lossD: -0.028803 lossG: 0.485289\n",
      "[24: 1425/1795] train lossD: 0.001616 lossG: 0.376951\n",
      "[24: 1430/1795] train lossD: -0.015736 lossG: 0.473761\n",
      "[24: 1435/1795] train lossD: -0.048852 lossG: 0.580373\n",
      "[24: 1440/1795] train lossD: 0.009896 lossG: 0.470703\n",
      "[24: 1445/1795] train lossD: -0.004113 lossG: 0.459779\n",
      "[24: 1450/1795] train lossD: -0.033149 lossG: 0.350180\n",
      "[24: 1455/1795] train lossD: -0.013107 lossG: 0.505122\n",
      "[24: 1460/1795] train lossD: -0.043018 lossG: 0.629998\n",
      "[24: 1465/1795] train lossD: 0.028705 lossG: 0.621281\n",
      "[24: 1470/1795] train lossD: -0.047653 lossG: 0.592732\n",
      "[24: 1475/1795] train lossD: -0.056118 lossG: 0.684623\n",
      "[24: 1480/1795] train lossD: -0.054511 lossG: 0.577728\n",
      "[24: 1485/1795] train lossD: -0.055188 lossG: 0.720188\n",
      "[24: 1490/1795] train lossD: -0.026420 lossG: 0.580054\n",
      "[24: 1495/1795] train lossD: 0.025110 lossG: 0.392331\n",
      "[24: 1500/1795] train lossD: 0.004431 lossG: 0.587497\n",
      "[24: 1505/1795] train lossD: -0.027678 lossG: 0.651506\n",
      "[24: 1510/1795] train lossD: -0.079468 lossG: 0.740776\n",
      "[24: 1515/1795] train lossD: -0.001043 lossG: 0.652543\n",
      "[24: 1520/1795] train lossD: 0.005184 lossG: 0.678358\n",
      "[24: 1525/1795] train lossD: -0.044557 lossG: 0.685888\n",
      "[24: 1530/1795] train lossD: -0.049773 lossG: 0.584081\n",
      "[24: 1535/1795] train lossD: -0.022448 lossG: 0.602157\n",
      "[24: 1540/1795] train lossD: -0.016340 lossG: 0.617528\n",
      "[24: 1545/1795] train lossD: -0.019598 lossG: 0.664370\n",
      "[24: 1550/1795] train lossD: 0.064684 lossG: 0.412697\n",
      "[24: 1555/1795] train lossD: -0.039210 lossG: 0.508032\n",
      "[24: 1560/1795] train lossD: -0.045834 lossG: 0.667011\n",
      "[24: 1565/1795] train lossD: 0.029663 lossG: 0.809902\n",
      "[24: 1570/1795] train lossD: -0.036232 lossG: 0.798344\n",
      "[24: 1575/1795] train lossD: -0.006163 lossG: 0.489589\n",
      "[24: 1580/1795] train lossD: -0.068595 lossG: 0.761611\n",
      "[24: 1585/1795] train lossD: -0.035863 lossG: 0.779751\n",
      "[24: 1590/1795] train lossD: -0.012149 lossG: 0.703032\n",
      "[24: 1595/1795] train lossD: -0.092248 lossG: 1.014241\n",
      "[24: 1600/1795] train lossD: -0.047204 lossG: 0.722697\n",
      "[24: 1605/1795] train lossD: -0.029606 lossG: 0.735815\n",
      "[24: 1610/1795] train lossD: 0.022380 lossG: 0.678059\n",
      "[24: 1615/1795] train lossD: -0.085554 lossG: 0.807707\n",
      "[24: 1620/1795] train lossD: -0.007605 lossG: 0.570833\n",
      "[24: 1625/1795] train lossD: -0.011185 lossG: 0.638262\n",
      "[24: 1630/1795] train lossD: -0.051966 lossG: 0.608228\n",
      "[24: 1635/1795] train lossD: -0.033834 lossG: 0.521530\n",
      "[24: 1640/1795] train lossD: -0.037328 lossG: 0.737318\n",
      "[24: 1645/1795] train lossD: -0.000414 lossG: 0.687338\n",
      "[24: 1650/1795] train lossD: 0.047830 lossG: 0.847477\n",
      "[24: 1655/1795] train lossD: -0.051587 lossG: 0.793780\n",
      "[24: 1660/1795] train lossD: -0.066039 lossG: 0.728992\n",
      "[24: 1665/1795] train lossD: -0.054917 lossG: 0.656954\n",
      "[24: 1670/1795] train lossD: -0.052032 lossG: 0.690401\n",
      "[24: 1675/1795] train lossD: -0.023389 lossG: 0.896114\n",
      "[24: 1680/1795] train lossD: -0.038920 lossG: 0.770758\n",
      "[24: 1685/1795] train lossD: -0.028493 lossG: 0.699037\n",
      "[24: 1690/1795] train lossD: 0.002641 lossG: 0.707110\n",
      "[24: 1695/1795] train lossD: -0.014511 lossG: 0.532142\n",
      "[24: 1700/1795] train lossD: 0.004953 lossG: 0.624298\n",
      "[24: 1705/1795] train lossD: -0.015719 lossG: 0.664464\n",
      "[24: 1710/1795] train lossD: -0.033898 lossG: 0.742315\n",
      "[24: 1715/1795] train lossD: -0.059566 lossG: 0.754978\n",
      "[24: 1720/1795] train lossD: -0.030524 lossG: 0.608427\n",
      "[24: 1725/1795] train lossD: -0.074384 lossG: 0.573362\n",
      "[24: 1730/1795] train lossD: -0.050180 lossG: 0.503587\n",
      "[24: 1735/1795] train lossD: -0.037356 lossG: 0.729143\n",
      "[24: 1740/1795] train lossD: -0.055498 lossG: 0.861462\n",
      "[24: 1745/1795] train lossD: -0.050678 lossG: 0.818790\n",
      "[24: 1750/1795] train lossD: -0.013532 lossG: 0.640527\n",
      "[24: 1755/1795] train lossD: 0.046494 lossG: 0.564960\n",
      "[24: 1760/1795] train lossD: -0.006254 lossG: 0.607303\n",
      "[24: 1765/1795] train lossD: -0.027755 lossG: 0.644482\n",
      "[24: 1770/1795] train lossD: -0.017500 lossG: 0.569061\n",
      "[24: 1775/1795] train lossD: 0.016482 lossG: 0.676297\n",
      "[24: 1780/1795] train lossD: -0.043475 lossG: 0.667546\n",
      "[24: 1785/1795] train lossD: -0.086690 lossG: 0.563338\n",
      "[24: 1790/1795] train lossD: -0.038587 lossG: 0.818991\n",
      "0.047086551785469055\n",
      "[25: 0/1795] train lossD: 0.008544 lossG: 0.505486\n",
      "[25: 5/1795] train lossD: -0.056732 lossG: 0.621590\n",
      "[25: 10/1795] train lossD: -0.046834 lossG: 0.507501\n",
      "[25: 15/1795] train lossD: -0.042381 lossG: 0.481804\n",
      "[25: 20/1795] train lossD: -0.024400 lossG: 0.563957\n",
      "[25: 25/1795] train lossD: 0.063650 lossG: 0.588923\n",
      "[25: 30/1795] train lossD: 0.030131 lossG: 0.488722\n",
      "[25: 35/1795] train lossD: -0.000741 lossG: 0.524909\n",
      "[25: 40/1795] train lossD: -0.042037 lossG: 0.575067\n",
      "[25: 45/1795] train lossD: -0.025892 lossG: 0.580390\n",
      "[25: 50/1795] train lossD: -0.047440 lossG: 0.658010\n",
      "[25: 55/1795] train lossD: -0.070192 lossG: 0.675936\n",
      "[25: 60/1795] train lossD: -0.031846 lossG: 0.521775\n",
      "[25: 65/1795] train lossD: -0.069018 lossG: 0.449727\n",
      "[25: 70/1795] train lossD: -0.017074 lossG: 0.588748\n",
      "[25: 75/1795] train lossD: -0.028575 lossG: 0.692538\n",
      "[25: 80/1795] train lossD: -0.012851 lossG: 0.668306\n",
      "[25: 85/1795] train lossD: -0.047016 lossG: 0.630321\n",
      "[25: 90/1795] train lossD: -0.014835 lossG: 0.636815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25: 95/1795] train lossD: -0.017916 lossG: 0.596038\n",
      "[25: 100/1795] train lossD: -0.052619 lossG: 0.555402\n",
      "[25: 105/1795] train lossD: -0.079200 lossG: 0.608518\n",
      "[25: 110/1795] train lossD: -0.041032 lossG: 0.773457\n",
      "[25: 115/1795] train lossD: 0.011747 lossG: 0.771187\n",
      "[25: 120/1795] train lossD: -0.014506 lossG: 0.724562\n",
      "[25: 125/1795] train lossD: -0.049497 lossG: 0.630640\n",
      "[25: 130/1795] train lossD: -0.055404 lossG: 0.629876\n",
      "[25: 135/1795] train lossD: 0.023601 lossG: 0.767068\n",
      "[25: 140/1795] train lossD: -0.017223 lossG: 0.790648\n",
      "[25: 145/1795] train lossD: -0.039491 lossG: 0.749467\n",
      "[25: 150/1795] train lossD: -0.104289 lossG: 0.827529\n",
      "[25: 155/1795] train lossD: -0.067043 lossG: 0.810660\n",
      "[25: 160/1795] train lossD: -0.033645 lossG: 0.570623\n",
      "[25: 165/1795] train lossD: 0.011079 lossG: 0.591089\n",
      "[25: 170/1795] train lossD: 0.038077 lossG: 0.666252\n",
      "[25: 175/1795] train lossD: -0.063745 lossG: 0.705949\n",
      "[25: 180/1795] train lossD: -0.038661 lossG: 0.606625\n",
      "[25: 185/1795] train lossD: -0.045610 lossG: 0.549526\n",
      "[25: 190/1795] train lossD: -0.041521 lossG: 0.572594\n",
      "[25: 195/1795] train lossD: -0.014263 lossG: 0.726756\n",
      "[25: 200/1795] train lossD: -0.033188 lossG: 0.620004\n",
      "[25: 205/1795] train lossD: -0.017240 lossG: 0.701804\n",
      "[25: 210/1795] train lossD: -0.060750 lossG: 0.592556\n",
      "[25: 215/1795] train lossD: -0.064306 lossG: 0.592703\n",
      "[25: 220/1795] train lossD: 0.032830 lossG: 0.673330\n",
      "[25: 225/1795] train lossD: -0.033809 lossG: 0.702999\n",
      "[25: 230/1795] train lossD: 0.002378 lossG: 0.696035\n",
      "[25: 235/1795] train lossD: -0.007660 lossG: 0.607678\n",
      "[25: 240/1795] train lossD: -0.022505 lossG: 0.706689\n",
      "[25: 245/1795] train lossD: -0.035784 lossG: 0.711030\n",
      "[25: 250/1795] train lossD: -0.039826 lossG: 0.638356\n",
      "[25: 255/1795] train lossD: 0.062037 lossG: 0.603830\n",
      "[25: 260/1795] train lossD: -0.050187 lossG: 0.528766\n",
      "[25: 265/1795] train lossD: -0.003491 lossG: 0.595723\n",
      "[25: 270/1795] train lossD: 0.004636 lossG: 0.486950\n",
      "[25: 275/1795] train lossD: -0.030003 lossG: 0.676019\n",
      "[25: 280/1795] train lossD: 0.000623 lossG: 0.703171\n",
      "[25: 285/1795] train lossD: -0.045886 lossG: 0.662883\n",
      "[25: 290/1795] train lossD: -0.006266 lossG: 0.584671\n",
      "[25: 295/1795] train lossD: -0.009381 lossG: 0.711681\n",
      "[25: 300/1795] train lossD: 0.034982 lossG: 0.552577\n",
      "[25: 305/1795] train lossD: -0.045568 lossG: 0.611131\n",
      "[25: 310/1795] train lossD: -0.021904 lossG: 0.793731\n",
      "[25: 315/1795] train lossD: -0.074248 lossG: 0.830264\n",
      "[25: 320/1795] train lossD: -0.000172 lossG: 0.666163\n",
      "[25: 325/1795] train lossD: 0.061458 lossG: 0.629482\n",
      "[25: 330/1795] train lossD: 0.021306 lossG: 0.551450\n",
      "[25: 335/1795] train lossD: -0.022541 lossG: 0.573694\n",
      "[25: 340/1795] train lossD: 0.015650 lossG: 0.647721\n",
      "[25: 345/1795] train lossD: -0.034189 lossG: 0.567368\n",
      "[25: 350/1795] train lossD: -0.077251 lossG: 0.550942\n",
      "[25: 355/1795] train lossD: -0.039507 lossG: 0.577807\n",
      "[25: 360/1795] train lossD: -0.065793 lossG: 0.663718\n",
      "[25: 365/1795] train lossD: -0.044187 lossG: 0.639155\n",
      "[25: 370/1795] train lossD: -0.000475 lossG: 0.733072\n",
      "[25: 375/1795] train lossD: -0.022297 lossG: 0.678291\n",
      "[25: 380/1795] train lossD: -0.015516 lossG: 0.657716\n",
      "[25: 385/1795] train lossD: -0.063946 lossG: 0.682001\n",
      "[25: 390/1795] train lossD: -0.000098 lossG: 0.617184\n",
      "[25: 395/1795] train lossD: -0.063312 lossG: 0.646858\n",
      "[25: 400/1795] train lossD: 0.051468 lossG: 0.701278\n",
      "[25: 405/1795] train lossD: -0.028176 lossG: 0.490386\n",
      "[25: 410/1795] train lossD: -0.035103 lossG: 0.609402\n",
      "[25: 415/1795] train lossD: 0.032543 lossG: 0.526175\n",
      "[25: 420/1795] train lossD: 0.019021 lossG: 0.596634\n",
      "[25: 425/1795] train lossD: -0.037992 lossG: 0.684749\n",
      "[25: 430/1795] train lossD: -0.038965 lossG: 0.804102\n",
      "[25: 435/1795] train lossD: -0.029357 lossG: 0.726452\n",
      "[25: 440/1795] train lossD: -0.000383 lossG: 0.865032\n",
      "[25: 445/1795] train lossD: 0.002486 lossG: 0.787280\n",
      "[25: 450/1795] train lossD: -0.026056 lossG: 0.655126\n",
      "[25: 455/1795] train lossD: -0.007666 lossG: 0.783602\n",
      "[25: 460/1795] train lossD: -0.047642 lossG: 0.587470\n",
      "[25: 465/1795] train lossD: -0.093760 lossG: 0.739626\n",
      "[25: 470/1795] train lossD: -0.022823 lossG: 0.532298\n",
      "[25: 475/1795] train lossD: -0.042162 lossG: 0.528499\n",
      "[25: 480/1795] train lossD: -0.035119 lossG: 0.642388\n",
      "[25: 485/1795] train lossD: -0.046923 lossG: 0.687810\n",
      "[25: 490/1795] train lossD: -0.013874 lossG: 0.502794\n",
      "[25: 495/1795] train lossD: -0.009758 lossG: 0.558214\n",
      "[25: 500/1795] train lossD: -0.015254 lossG: 0.797707\n",
      "[25: 505/1795] train lossD: -0.012112 lossG: 0.695728\n",
      "[25: 510/1795] train lossD: -0.026055 lossG: 0.416890\n",
      "[25: 515/1795] train lossD: -0.059091 lossG: 0.632124\n",
      "[25: 520/1795] train lossD: -0.019905 lossG: 0.666693\n",
      "[25: 525/1795] train lossD: -0.010740 lossG: 0.423991\n",
      "[25: 530/1795] train lossD: -0.014612 lossG: 0.536600\n",
      "[25: 535/1795] train lossD: -0.072297 lossG: 0.526366\n",
      "[25: 540/1795] train lossD: -0.003818 lossG: 0.485068\n",
      "[25: 545/1795] train lossD: -0.049159 lossG: 0.488566\n",
      "[25: 550/1795] train lossD: -0.033209 lossG: 0.557825\n",
      "[25: 555/1795] train lossD: -0.035401 lossG: 0.668785\n",
      "[25: 560/1795] train lossD: -0.001219 lossG: 0.672506\n",
      "[25: 565/1795] train lossD: 0.030793 lossG: 0.442543\n",
      "[25: 570/1795] train lossD: 0.015266 lossG: 0.321029\n",
      "[25: 575/1795] train lossD: -0.038439 lossG: 0.674994\n",
      "[25: 580/1795] train lossD: -0.031878 lossG: 0.622997\n",
      "[25: 585/1795] train lossD: -0.017660 lossG: 0.525531\n",
      "[25: 590/1795] train lossD: -0.035643 lossG: 0.598383\n",
      "[25: 595/1795] train lossD: 0.001385 lossG: 0.697890\n",
      "[25: 600/1795] train lossD: -0.034344 lossG: 0.660422\n",
      "[25: 605/1795] train lossD: 0.021054 lossG: 0.629430\n",
      "[25: 610/1795] train lossD: -0.052443 lossG: 0.647207\n",
      "[25: 615/1795] train lossD: -0.019224 lossG: 0.739609\n",
      "[25: 620/1795] train lossD: -0.021033 lossG: 0.774505\n",
      "[25: 625/1795] train lossD: -0.036766 lossG: 0.627740\n",
      "[25: 630/1795] train lossD: -0.062846 lossG: 0.659107\n",
      "[25: 635/1795] train lossD: -0.060891 lossG: 0.693981\n",
      "[25: 640/1795] train lossD: -0.056392 lossG: 0.603608\n",
      "[25: 645/1795] train lossD: -0.027931 lossG: 0.680709\n",
      "[25: 650/1795] train lossD: -0.051321 lossG: 0.676854\n",
      "[25: 655/1795] train lossD: -0.063683 lossG: 0.849404\n",
      "[25: 660/1795] train lossD: -0.016511 lossG: 0.695856\n",
      "[25: 665/1795] train lossD: 0.019730 lossG: 0.599698\n",
      "[25: 670/1795] train lossD: 0.075350 lossG: 0.698894\n",
      "[25: 675/1795] train lossD: -0.061107 lossG: 0.800388\n",
      "[25: 680/1795] train lossD: -0.014428 lossG: 0.912545\n",
      "[25: 685/1795] train lossD: -0.039871 lossG: 0.740321\n",
      "[25: 690/1795] train lossD: -0.042811 lossG: 0.715291\n",
      "[25: 695/1795] train lossD: -0.014605 lossG: 0.806194\n",
      "[25: 700/1795] train lossD: -0.018229 lossG: 0.717920\n",
      "[25: 705/1795] train lossD: 0.048992 lossG: 0.738668\n",
      "[25: 710/1795] train lossD: -0.014394 lossG: 0.713162\n",
      "[25: 715/1795] train lossD: -0.014541 lossG: 0.758337\n",
      "[25: 720/1795] train lossD: 0.013513 lossG: 0.841915\n",
      "[25: 725/1795] train lossD: -0.029278 lossG: 0.802576\n",
      "[25: 730/1795] train lossD: -0.032485 lossG: 0.730511\n",
      "[25: 735/1795] train lossD: 0.008073 lossG: 0.778763\n",
      "[25: 740/1795] train lossD: 0.035639 lossG: 0.609095\n",
      "[25: 745/1795] train lossD: -0.039122 lossG: 0.601580\n",
      "[25: 750/1795] train lossD: -0.032534 lossG: 0.639881\n",
      "[25: 755/1795] train lossD: -0.034219 lossG: 0.684901\n",
      "[25: 760/1795] train lossD: -0.045445 lossG: 0.506246\n",
      "[25: 765/1795] train lossD: -0.039603 lossG: 0.486802\n",
      "[25: 770/1795] train lossD: -0.063828 lossG: 0.541871\n",
      "[25: 775/1795] train lossD: -0.048286 lossG: 0.762175\n",
      "[25: 780/1795] train lossD: -0.020901 lossG: 0.558566\n",
      "[25: 785/1795] train lossD: -0.066180 lossG: 0.470892\n",
      "[25: 790/1795] train lossD: -0.025373 lossG: 0.498833\n",
      "[25: 795/1795] train lossD: -0.098633 lossG: 0.798233\n",
      "[25: 800/1795] train lossD: 0.055083 lossG: 0.655263\n",
      "[25: 805/1795] train lossD: 0.000530 lossG: 0.631222\n",
      "[25: 810/1795] train lossD: -0.010190 lossG: 0.656707\n",
      "[25: 815/1795] train lossD: 0.016302 lossG: 0.744986\n",
      "[25: 820/1795] train lossD: -0.038628 lossG: 0.633686\n",
      "[25: 825/1795] train lossD: -0.041645 lossG: 0.558878\n",
      "[25: 830/1795] train lossD: 0.000643 lossG: 0.581496\n",
      "[25: 835/1795] train lossD: 0.046631 lossG: 0.679676\n",
      "[25: 840/1795] train lossD: -0.085656 lossG: 0.580677\n",
      "[25: 845/1795] train lossD: 0.020802 lossG: 0.793859\n",
      "[25: 850/1795] train lossD: -0.031996 lossG: 0.705404\n",
      "[25: 855/1795] train lossD: -0.048003 lossG: 0.627710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25: 860/1795] train lossD: -0.014145 lossG: 0.554064\n",
      "[25: 865/1795] train lossD: -0.061039 lossG: 0.601704\n",
      "[25: 870/1795] train lossD: 0.026011 lossG: 0.548406\n",
      "[25: 875/1795] train lossD: -0.045608 lossG: 0.537866\n",
      "[25: 880/1795] train lossD: -0.033601 lossG: 0.587316\n",
      "[25: 885/1795] train lossD: -0.016932 lossG: 0.498578\n",
      "[25: 890/1795] train lossD: -0.070305 lossG: 0.610625\n",
      "[25: 895/1795] train lossD: -0.072076 lossG: 0.435399\n",
      "[25: 900/1795] train lossD: -0.060507 lossG: 0.539483\n",
      "[25: 905/1795] train lossD: -0.023480 lossG: 0.506332\n",
      "[25: 910/1795] train lossD: -0.056152 lossG: 0.572851\n",
      "[25: 915/1795] train lossD: -0.070793 lossG: 0.536055\n",
      "[25: 920/1795] train lossD: -0.043417 lossG: 0.565870\n",
      "[25: 925/1795] train lossD: -0.011197 lossG: 0.747764\n",
      "[25: 930/1795] train lossD: -0.027176 lossG: 0.725937\n",
      "[25: 935/1795] train lossD: -0.030038 lossG: 0.846273\n",
      "[25: 940/1795] train lossD: -0.032354 lossG: 0.773631\n",
      "[25: 945/1795] train lossD: -0.021378 lossG: 0.682542\n",
      "[25: 950/1795] train lossD: -0.008648 lossG: 0.653890\n",
      "[25: 955/1795] train lossD: -0.009112 lossG: 0.470097\n",
      "[25: 960/1795] train lossD: -0.014092 lossG: 0.562663\n",
      "[25: 965/1795] train lossD: -0.011104 lossG: 0.623326\n",
      "[25: 970/1795] train lossD: -0.069656 lossG: 0.648654\n",
      "[25: 975/1795] train lossD: -0.058606 lossG: 0.763525\n",
      "[25: 980/1795] train lossD: -0.060965 lossG: 0.665876\n",
      "[25: 985/1795] train lossD: -0.049904 lossG: 0.733329\n",
      "[25: 990/1795] train lossD: -0.045489 lossG: 0.556401\n",
      "[25: 995/1795] train lossD: 0.013984 lossG: 0.659036\n",
      "[25: 1000/1795] train lossD: -0.009384 lossG: 0.727443\n",
      "[25: 1005/1795] train lossD: -0.008875 lossG: 0.596397\n",
      "[25: 1010/1795] train lossD: 0.007951 lossG: 0.650656\n",
      "[25: 1015/1795] train lossD: -0.035946 lossG: 0.487758\n",
      "[25: 1020/1795] train lossD: -0.026125 lossG: 0.663994\n",
      "[25: 1025/1795] train lossD: -0.007468 lossG: 0.669402\n",
      "[25: 1030/1795] train lossD: -0.016450 lossG: 0.484697\n",
      "[25: 1035/1795] train lossD: -0.067967 lossG: 0.536663\n",
      "[25: 1040/1795] train lossD: -0.036945 lossG: 0.655782\n",
      "[25: 1045/1795] train lossD: -0.009846 lossG: 0.439943\n",
      "[25: 1050/1795] train lossD: -0.032708 lossG: 0.519947\n",
      "[25: 1055/1795] train lossD: -0.000512 lossG: 0.520671\n",
      "[25: 1060/1795] train lossD: 0.006715 lossG: 0.568430\n",
      "[25: 1065/1795] train lossD: -0.032930 lossG: 0.739667\n",
      "[25: 1070/1795] train lossD: -0.025781 lossG: 0.625550\n",
      "[25: 1075/1795] train lossD: -0.051256 lossG: 0.775666\n",
      "[25: 1080/1795] train lossD: 0.018367 lossG: 0.561209\n",
      "[25: 1085/1795] train lossD: -0.042146 lossG: 0.557430\n",
      "[25: 1090/1795] train lossD: -0.010614 lossG: 0.486439\n",
      "[25: 1095/1795] train lossD: 0.022374 lossG: 0.660719\n",
      "[25: 1100/1795] train lossD: -0.053786 lossG: 0.635946\n",
      "[25: 1105/1795] train lossD: -0.009025 lossG: 0.638076\n",
      "[25: 1110/1795] train lossD: -0.054908 lossG: 0.646100\n",
      "[25: 1115/1795] train lossD: -0.020794 lossG: 0.608371\n",
      "[25: 1120/1795] train lossD: -0.048315 lossG: 0.632794\n",
      "[25: 1125/1795] train lossD: 0.012744 lossG: 0.987589\n",
      "[25: 1130/1795] train lossD: -0.010749 lossG: 0.718018\n",
      "[25: 1135/1795] train lossD: -0.033748 lossG: 0.753821\n",
      "[25: 1140/1795] train lossD: 0.002198 lossG: 0.664025\n",
      "[25: 1145/1795] train lossD: -0.062496 lossG: 0.660660\n",
      "[25: 1150/1795] train lossD: 0.025081 lossG: 0.823806\n",
      "[25: 1155/1795] train lossD: -0.084091 lossG: 0.681194\n",
      "[25: 1160/1795] train lossD: -0.037025 lossG: 0.630329\n",
      "[25: 1165/1795] train lossD: 0.012891 lossG: 0.492752\n",
      "[25: 1170/1795] train lossD: -0.060373 lossG: 0.626645\n",
      "[25: 1175/1795] train lossD: -0.057510 lossG: 0.635594\n",
      "[25: 1180/1795] train lossD: -0.047338 lossG: 0.684071\n",
      "[25: 1185/1795] train lossD: -0.024568 lossG: 0.689083\n",
      "[25: 1190/1795] train lossD: -0.063661 lossG: 0.545403\n",
      "[25: 1195/1795] train lossD: -0.065211 lossG: 0.593728\n",
      "[25: 1200/1795] train lossD: -0.017810 lossG: 0.562128\n",
      "[25: 1205/1795] train lossD: -0.101065 lossG: 0.547027\n",
      "[25: 1210/1795] train lossD: 0.011162 lossG: 0.665632\n",
      "[25: 1215/1795] train lossD: -0.013766 lossG: 0.558822\n",
      "[25: 1220/1795] train lossD: -0.006196 lossG: 0.681679\n",
      "[25: 1225/1795] train lossD: -0.056426 lossG: 0.757446\n",
      "[25: 1230/1795] train lossD: -0.052162 lossG: 0.676969\n",
      "[25: 1235/1795] train lossD: -0.061823 lossG: 0.783474\n",
      "[25: 1240/1795] train lossD: 0.019257 lossG: 0.667198\n",
      "[25: 1245/1795] train lossD: -0.026446 lossG: 0.697628\n",
      "[25: 1250/1795] train lossD: -0.060795 lossG: 0.581661\n",
      "[25: 1255/1795] train lossD: -0.039262 lossG: 0.600915\n",
      "[25: 1260/1795] train lossD: -0.057571 lossG: 0.536341\n",
      "[25: 1265/1795] train lossD: -0.068910 lossG: 0.632029\n",
      "[25: 1270/1795] train lossD: -0.024158 lossG: 0.497475\n",
      "[25: 1275/1795] train lossD: -0.058849 lossG: 0.540320\n",
      "[25: 1280/1795] train lossD: 0.028509 lossG: 0.722114\n",
      "[25: 1285/1795] train lossD: -0.047670 lossG: 0.801136\n",
      "[25: 1290/1795] train lossD: -0.083542 lossG: 0.739397\n",
      "[25: 1295/1795] train lossD: -0.096719 lossG: 0.667346\n",
      "[25: 1300/1795] train lossD: -0.006045 lossG: 0.566295\n",
      "[25: 1305/1795] train lossD: -0.001719 lossG: 0.540583\n",
      "[25: 1310/1795] train lossD: -0.071663 lossG: 0.647536\n",
      "[25: 1315/1795] train lossD: -0.071831 lossG: 0.602196\n",
      "[25: 1320/1795] train lossD: -0.049295 lossG: 0.894744\n",
      "[25: 1325/1795] train lossD: -0.029742 lossG: 0.653944\n",
      "[25: 1330/1795] train lossD: -0.050114 lossG: 0.624727\n",
      "[25: 1335/1795] train lossD: -0.041794 lossG: 0.716739\n",
      "[25: 1340/1795] train lossD: -0.015019 lossG: 0.691275\n",
      "[25: 1345/1795] train lossD: -0.013303 lossG: 0.573281\n",
      "[25: 1350/1795] train lossD: 0.021913 lossG: 0.688840\n",
      "[25: 1355/1795] train lossD: -0.002870 lossG: 0.685445\n",
      "[25: 1360/1795] train lossD: -0.064978 lossG: 0.620896\n",
      "[25: 1365/1795] train lossD: 0.039791 lossG: 0.647389\n",
      "[25: 1370/1795] train lossD: -0.055288 lossG: 0.625341\n",
      "[25: 1375/1795] train lossD: -0.074228 lossG: 0.793781\n",
      "[25: 1380/1795] train lossD: 0.014198 lossG: 0.769490\n",
      "[25: 1385/1795] train lossD: -0.091716 lossG: 0.916547\n",
      "[25: 1390/1795] train lossD: -0.005598 lossG: 0.891616\n",
      "[25: 1395/1795] train lossD: -0.002308 lossG: 0.640078\n",
      "[25: 1400/1795] train lossD: -0.039109 lossG: 0.625443\n",
      "[25: 1405/1795] train lossD: -0.011137 lossG: 0.691391\n",
      "[25: 1410/1795] train lossD: -0.050823 lossG: 0.652731\n",
      "[25: 1415/1795] train lossD: -0.033090 lossG: 0.744117\n",
      "[25: 1420/1795] train lossD: -0.018209 lossG: 0.588821\n",
      "[25: 1425/1795] train lossD: -0.035668 lossG: 0.759308\n",
      "[25: 1430/1795] train lossD: -0.029652 lossG: 0.644375\n",
      "[25: 1435/1795] train lossD: -0.031621 lossG: 0.492552\n",
      "[25: 1440/1795] train lossD: 0.356128 lossG: 0.551768\n",
      "[25: 1445/1795] train lossD: -0.014563 lossG: 0.477955\n",
      "[25: 1450/1795] train lossD: -0.017152 lossG: 0.489136\n",
      "[25: 1455/1795] train lossD: -0.025587 lossG: 0.411767\n",
      "[25: 1460/1795] train lossD: -0.027200 lossG: 0.512419\n",
      "[25: 1465/1795] train lossD: -0.054996 lossG: 0.549982\n",
      "[25: 1470/1795] train lossD: -0.019993 lossG: 0.496663\n",
      "[25: 1475/1795] train lossD: -0.038593 lossG: 0.600599\n",
      "[25: 1480/1795] train lossD: -0.014731 lossG: 0.759462\n",
      "[25: 1485/1795] train lossD: -0.060111 lossG: 0.739379\n",
      "[25: 1490/1795] train lossD: 0.051752 lossG: 0.637508\n",
      "[25: 1495/1795] train lossD: -0.009135 lossG: 0.757584\n",
      "[25: 1500/1795] train lossD: -0.057369 lossG: 0.722513\n",
      "[25: 1505/1795] train lossD: 0.210116 lossG: 0.699262\n",
      "[25: 1510/1795] train lossD: -0.025926 lossG: 0.614743\n",
      "[25: 1515/1795] train lossD: -0.012270 lossG: 0.594920\n",
      "[25: 1520/1795] train lossD: 0.019906 lossG: 0.440762\n",
      "[25: 1525/1795] train lossD: -0.015280 lossG: 0.405235\n",
      "[25: 1530/1795] train lossD: 0.008759 lossG: 0.565733\n",
      "[25: 1535/1795] train lossD: -0.042767 lossG: 0.527576\n",
      "[25: 1540/1795] train lossD: -0.021194 lossG: 0.668642\n",
      "[25: 1545/1795] train lossD: 0.034351 lossG: 0.703258\n",
      "[25: 1550/1795] train lossD: -0.022385 lossG: 0.777418\n",
      "[25: 1555/1795] train lossD: -0.034297 lossG: 0.684798\n",
      "[25: 1560/1795] train lossD: -0.040899 lossG: 0.483457\n",
      "[25: 1565/1795] train lossD: -0.045559 lossG: 0.646053\n",
      "[25: 1570/1795] train lossD: -0.040454 lossG: 0.438045\n",
      "[25: 1575/1795] train lossD: -0.005402 lossG: 0.564379\n",
      "[25: 1580/1795] train lossD: -0.038306 lossG: 0.481583\n",
      "[25: 1585/1795] train lossD: -0.009914 lossG: 0.358562\n",
      "[25: 1590/1795] train lossD: 0.006708 lossG: 0.432661\n",
      "[25: 1595/1795] train lossD: -0.027688 lossG: 0.526372\n",
      "[25: 1600/1795] train lossD: 0.005138 lossG: 0.558872\n",
      "[25: 1605/1795] train lossD: 0.006593 lossG: 0.705165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25: 1610/1795] train lossD: -0.069925 lossG: 0.587025\n",
      "[25: 1615/1795] train lossD: -0.072702 lossG: 0.560598\n",
      "[25: 1620/1795] train lossD: -0.011635 lossG: 0.671609\n",
      "[25: 1625/1795] train lossD: -0.019106 lossG: 0.669218\n",
      "[25: 1630/1795] train lossD: -0.045137 lossG: 0.788028\n",
      "[25: 1635/1795] train lossD: -0.042479 lossG: 0.509106\n",
      "[25: 1640/1795] train lossD: -0.011782 lossG: 0.621658\n",
      "[25: 1645/1795] train lossD: -0.039922 lossG: 0.568688\n",
      "[25: 1650/1795] train lossD: -0.030977 lossG: 0.681755\n",
      "[25: 1655/1795] train lossD: -0.033529 lossG: 0.670031\n",
      "[25: 1660/1795] train lossD: -0.015562 lossG: 0.537791\n",
      "[25: 1665/1795] train lossD: -0.030793 lossG: 0.473881\n",
      "[25: 1670/1795] train lossD: -0.040979 lossG: 0.630012\n",
      "[25: 1675/1795] train lossD: -0.001880 lossG: 0.528828\n",
      "[25: 1680/1795] train lossD: -0.029880 lossG: 0.441280\n",
      "[25: 1685/1795] train lossD: -0.042608 lossG: 0.470146\n",
      "[25: 1690/1795] train lossD: 0.041257 lossG: 0.763211\n",
      "[25: 1695/1795] train lossD: -0.027875 lossG: 0.708083\n",
      "[25: 1700/1795] train lossD: -0.028881 lossG: 0.584692\n",
      "[25: 1705/1795] train lossD: -0.025392 lossG: 0.499828\n",
      "[25: 1710/1795] train lossD: -0.003270 lossG: 0.459852\n",
      "[25: 1715/1795] train lossD: 0.010761 lossG: 0.484938\n",
      "[25: 1720/1795] train lossD: -0.013917 lossG: 0.586003\n",
      "[25: 1725/1795] train lossD: -0.012544 lossG: 0.594647\n",
      "[25: 1730/1795] train lossD: -0.037938 lossG: 0.561713\n",
      "[25: 1735/1795] train lossD: -0.030894 lossG: 0.699962\n",
      "[25: 1740/1795] train lossD: -0.021255 lossG: 0.663176\n",
      "[25: 1745/1795] train lossD: -0.002776 lossG: 0.623899\n",
      "[25: 1750/1795] train lossD: -0.030800 lossG: 0.529580\n",
      "[25: 1755/1795] train lossD: -0.033353 lossG: 0.524214\n",
      "[25: 1760/1795] train lossD: -0.011328 lossG: 0.345752\n",
      "[25: 1765/1795] train lossD: 0.012976 lossG: 0.520542\n",
      "[25: 1770/1795] train lossD: -0.005935 lossG: 0.748443\n",
      "[25: 1775/1795] train lossD: 0.004943 lossG: 0.650066\n",
      "[25: 1780/1795] train lossD: -0.057693 lossG: 0.543500\n",
      "[25: 1785/1795] train lossD: -0.000446 lossG: 0.633333\n",
      "[25: 1790/1795] train lossD: -0.019914 lossG: 0.714680\n",
      "0.044641152024269104\n",
      "[26: 0/1795] train lossD: -0.070712 lossG: 0.725263\n",
      "[26: 5/1795] train lossD: 0.007573 lossG: 0.723011\n",
      "[26: 10/1795] train lossD: -0.047697 lossG: 0.673004\n",
      "[26: 15/1795] train lossD: -0.083128 lossG: 0.790832\n",
      "[26: 20/1795] train lossD: -0.042740 lossG: 0.573557\n",
      "[26: 25/1795] train lossD: -0.011218 lossG: 0.546898\n",
      "[26: 30/1795] train lossD: -0.022229 lossG: 0.617289\n",
      "[26: 35/1795] train lossD: 0.008430 lossG: 0.595174\n",
      "[26: 40/1795] train lossD: -0.013367 lossG: 0.552635\n",
      "[26: 45/1795] train lossD: -0.024466 lossG: 0.456376\n",
      "[26: 50/1795] train lossD: -0.085305 lossG: 0.625823\n",
      "[26: 55/1795] train lossD: 0.000978 lossG: 0.610781\n",
      "[26: 60/1795] train lossD: -0.002428 lossG: 0.696542\n",
      "[26: 65/1795] train lossD: -0.019270 lossG: 0.639154\n",
      "[26: 70/1795] train lossD: -0.031650 lossG: 0.684636\n",
      "[26: 75/1795] train lossD: -0.032476 lossG: 0.565322\n",
      "[26: 80/1795] train lossD: -0.042933 lossG: 0.621951\n",
      "[26: 85/1795] train lossD: 0.059289 lossG: 0.651715\n",
      "[26: 90/1795] train lossD: 0.019956 lossG: 0.645337\n",
      "[26: 95/1795] train lossD: -0.032558 lossG: 0.614454\n",
      "[26: 100/1795] train lossD: -0.028035 lossG: 0.521196\n",
      "[26: 105/1795] train lossD: -0.082565 lossG: 0.469220\n",
      "[26: 110/1795] train lossD: -0.031140 lossG: 0.630676\n",
      "[26: 115/1795] train lossD: -0.041867 lossG: 0.699131\n",
      "[26: 120/1795] train lossD: 0.006222 lossG: 0.519194\n",
      "[26: 125/1795] train lossD: -0.020008 lossG: 0.551931\n",
      "[26: 130/1795] train lossD: -0.037922 lossG: 0.564992\n",
      "[26: 135/1795] train lossD: -0.041924 lossG: 0.477507\n",
      "[26: 140/1795] train lossD: 0.012490 lossG: 0.499910\n",
      "[26: 145/1795] train lossD: -0.079292 lossG: 0.465995\n",
      "[26: 150/1795] train lossD: 0.011690 lossG: 0.507159\n",
      "[26: 155/1795] train lossD: 0.001641 lossG: 0.471992\n",
      "[26: 160/1795] train lossD: 0.062595 lossG: 0.746804\n",
      "[26: 165/1795] train lossD: -0.032113 lossG: 0.621937\n",
      "[26: 170/1795] train lossD: 0.041123 lossG: 0.775189\n",
      "[26: 175/1795] train lossD: -0.027282 lossG: 0.706901\n",
      "[26: 180/1795] train lossD: -0.025075 lossG: 0.806860\n",
      "[26: 185/1795] train lossD: 0.009449 lossG: 0.655078\n",
      "[26: 190/1795] train lossD: 0.055386 lossG: 0.671109\n",
      "[26: 195/1795] train lossD: 0.009681 lossG: 0.647178\n",
      "[26: 200/1795] train lossD: -0.030133 lossG: 0.576593\n",
      "[26: 205/1795] train lossD: -0.028272 lossG: 0.530671\n",
      "[26: 210/1795] train lossD: -0.035366 lossG: 0.439265\n",
      "[26: 215/1795] train lossD: -0.054767 lossG: 0.528032\n",
      "[26: 220/1795] train lossD: -0.040364 lossG: 0.672999\n",
      "[26: 225/1795] train lossD: -0.067208 lossG: 0.684398\n",
      "[26: 230/1795] train lossD: -0.027939 lossG: 0.616163\n",
      "[26: 235/1795] train lossD: 0.026473 lossG: 0.699154\n",
      "[26: 240/1795] train lossD: 0.010934 lossG: 0.693719\n",
      "[26: 245/1795] train lossD: -0.086267 lossG: 0.630462\n",
      "[26: 250/1795] train lossD: -0.019918 lossG: 0.552332\n",
      "[26: 255/1795] train lossD: -0.030394 lossG: 0.668718\n",
      "[26: 260/1795] train lossD: -0.010957 lossG: 0.540101\n",
      "[26: 265/1795] train lossD: -0.074407 lossG: 0.419037\n",
      "[26: 270/1795] train lossD: -0.029223 lossG: 0.474193\n",
      "[26: 275/1795] train lossD: 0.014025 lossG: 0.735907\n",
      "[26: 280/1795] train lossD: 0.021732 lossG: 0.683933\n",
      "[26: 285/1795] train lossD: -0.022401 lossG: 0.490990\n",
      "[26: 290/1795] train lossD: -0.022499 lossG: 0.702070\n",
      "[26: 295/1795] train lossD: 0.005011 lossG: 0.568052\n",
      "[26: 300/1795] train lossD: -0.038399 lossG: 0.523236\n",
      "[26: 305/1795] train lossD: -0.016397 lossG: 0.586531\n",
      "[26: 310/1795] train lossD: -0.060199 lossG: 0.398811\n",
      "[26: 315/1795] train lossD: -0.057355 lossG: 0.375118\n",
      "[26: 320/1795] train lossD: 0.001342 lossG: 0.607450\n",
      "[26: 325/1795] train lossD: -0.080578 lossG: 0.592008\n",
      "[26: 330/1795] train lossD: 0.111338 lossG: 0.621323\n",
      "[26: 335/1795] train lossD: 0.015949 lossG: 0.491423\n",
      "[26: 340/1795] train lossD: 0.025986 lossG: 0.640933\n",
      "[26: 345/1795] train lossD: -0.021914 lossG: 0.468371\n",
      "[26: 350/1795] train lossD: -0.078627 lossG: 0.530552\n",
      "[26: 355/1795] train lossD: -0.055679 lossG: 0.534931\n",
      "[26: 360/1795] train lossD: -0.016437 lossG: 0.763859\n",
      "[26: 365/1795] train lossD: -0.048206 lossG: 0.519001\n",
      "[26: 370/1795] train lossD: -0.074340 lossG: 0.724304\n",
      "[26: 375/1795] train lossD: -0.028634 lossG: 0.809927\n",
      "[26: 380/1795] train lossD: -0.034483 lossG: 0.718270\n",
      "[26: 385/1795] train lossD: -0.020021 lossG: 0.705465\n",
      "[26: 390/1795] train lossD: -0.043686 lossG: 0.678827\n",
      "[26: 395/1795] train lossD: -0.036702 lossG: 0.582478\n",
      "[26: 400/1795] train lossD: -0.011589 lossG: 0.615003\n",
      "[26: 405/1795] train lossD: 0.031291 lossG: 0.614330\n",
      "[26: 410/1795] train lossD: -0.022987 lossG: 0.583846\n",
      "[26: 415/1795] train lossD: -0.013661 lossG: 0.580747\n",
      "[26: 420/1795] train lossD: -0.007770 lossG: 0.710482\n",
      "[26: 425/1795] train lossD: -0.072316 lossG: 0.709687\n",
      "[26: 430/1795] train lossD: -0.026782 lossG: 0.828484\n",
      "[26: 435/1795] train lossD: -0.029869 lossG: 0.862423\n",
      "[26: 440/1795] train lossD: 0.016327 lossG: 0.924326\n",
      "[26: 445/1795] train lossD: -0.056881 lossG: 0.759566\n",
      "[26: 450/1795] train lossD: 0.005620 lossG: 0.657520\n",
      "[26: 455/1795] train lossD: -0.010948 lossG: 0.414122\n",
      "[26: 460/1795] train lossD: 0.052712 lossG: 0.603419\n",
      "[26: 465/1795] train lossD: -0.061129 lossG: 0.582189\n",
      "[26: 470/1795] train lossD: -0.068995 lossG: 0.683617\n",
      "[26: 475/1795] train lossD: -0.033513 lossG: 0.470018\n",
      "[26: 480/1795] train lossD: 0.012103 lossG: 0.512955\n",
      "[26: 485/1795] train lossD: 0.007325 lossG: 0.584116\n",
      "[26: 490/1795] train lossD: -0.046058 lossG: 0.658105\n",
      "[26: 495/1795] train lossD: 0.004723 lossG: 0.619885\n",
      "[26: 500/1795] train lossD: -0.024214 lossG: 0.612997\n",
      "[26: 505/1795] train lossD: -0.011175 lossG: 0.559323\n",
      "[26: 510/1795] train lossD: -0.051042 lossG: 0.666862\n",
      "[26: 515/1795] train lossD: 0.013476 lossG: 0.742919\n",
      "[26: 520/1795] train lossD: -0.040112 lossG: 0.627647\n",
      "[26: 525/1795] train lossD: -0.036110 lossG: 0.696278\n",
      "[26: 530/1795] train lossD: -0.019723 lossG: 0.760529\n",
      "[26: 535/1795] train lossD: -0.077756 lossG: 0.608673\n",
      "[26: 540/1795] train lossD: -0.055512 lossG: 0.662956\n",
      "[26: 545/1795] train lossD: 0.000259 lossG: 0.758429\n",
      "[26: 550/1795] train lossD: -0.009313 lossG: 0.805364\n",
      "[26: 555/1795] train lossD: -0.010743 lossG: 0.670651\n",
      "[26: 560/1795] train lossD: -0.026932 lossG: 0.709039\n",
      "[26: 565/1795] train lossD: -0.047514 lossG: 0.831674\n",
      "[26: 570/1795] train lossD: 0.011437 lossG: 0.652288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26: 575/1795] train lossD: -0.015769 lossG: 0.561049\n",
      "[26: 580/1795] train lossD: -0.000224 lossG: 0.600939\n",
      "[26: 585/1795] train lossD: -0.038789 lossG: 0.586257\n",
      "[26: 590/1795] train lossD: -0.030280 lossG: 0.413426\n",
      "[26: 595/1795] train lossD: -0.009728 lossG: 0.594769\n",
      "[26: 600/1795] train lossD: -0.073606 lossG: 0.703190\n",
      "[26: 605/1795] train lossD: -0.026073 lossG: 0.635158\n",
      "[26: 610/1795] train lossD: -0.039303 lossG: 0.539953\n",
      "[26: 615/1795] train lossD: -0.045919 lossG: 0.749634\n",
      "[26: 620/1795] train lossD: -0.015613 lossG: 0.595285\n",
      "[26: 625/1795] train lossD: -0.066011 lossG: 0.579058\n",
      "[26: 630/1795] train lossD: -0.001460 lossG: 0.741792\n",
      "[26: 635/1795] train lossD: -0.036512 lossG: 0.640753\n",
      "[26: 640/1795] train lossD: -0.008231 lossG: 0.800187\n",
      "[26: 645/1795] train lossD: -0.071464 lossG: 0.836307\n",
      "[26: 650/1795] train lossD: -0.055501 lossG: 0.855375\n",
      "[26: 655/1795] train lossD: -0.001398 lossG: 0.662033\n",
      "[26: 660/1795] train lossD: -0.029739 lossG: 0.578556\n",
      "[26: 665/1795] train lossD: -0.028498 lossG: 0.546421\n",
      "[26: 670/1795] train lossD: 0.024861 lossG: 0.686553\n",
      "[26: 675/1795] train lossD: -0.014274 lossG: 0.905939\n",
      "[26: 680/1795] train lossD: -0.039416 lossG: 0.616392\n",
      "[26: 685/1795] train lossD: -0.009413 lossG: 0.638268\n",
      "[26: 690/1795] train lossD: -0.028261 lossG: 0.577112\n",
      "[26: 695/1795] train lossD: -0.038392 lossG: 0.618998\n",
      "[26: 700/1795] train lossD: -0.016004 lossG: 0.491026\n",
      "[26: 705/1795] train lossD: -0.026267 lossG: 0.505671\n",
      "[26: 710/1795] train lossD: -0.002706 lossG: 0.524108\n",
      "[26: 715/1795] train lossD: -0.019908 lossG: 0.584489\n",
      "[26: 720/1795] train lossD: -0.015089 lossG: 0.555762\n",
      "[26: 725/1795] train lossD: -0.104055 lossG: 0.893446\n",
      "[26: 730/1795] train lossD: 0.020320 lossG: 0.696207\n",
      "[26: 735/1795] train lossD: -0.073222 lossG: 0.736429\n",
      "[26: 740/1795] train lossD: -0.054404 lossG: 0.596744\n",
      "[26: 745/1795] train lossD: 0.003238 lossG: 0.606924\n",
      "[26: 750/1795] train lossD: -0.000763 lossG: 0.698954\n",
      "[26: 755/1795] train lossD: 0.002384 lossG: 0.706802\n",
      "[26: 760/1795] train lossD: -0.050066 lossG: 0.583149\n",
      "[26: 765/1795] train lossD: -0.008127 lossG: 0.733364\n",
      "[26: 770/1795] train lossD: -0.010004 lossG: 0.679305\n",
      "[26: 775/1795] train lossD: -0.006120 lossG: 0.765508\n",
      "[26: 780/1795] train lossD: -0.032074 lossG: 0.690439\n",
      "[26: 785/1795] train lossD: -0.021686 lossG: 0.797572\n",
      "[26: 790/1795] train lossD: -0.012736 lossG: 0.746096\n",
      "[26: 795/1795] train lossD: 0.060871 lossG: 0.594068\n",
      "[26: 800/1795] train lossD: 0.000543 lossG: 0.518154\n",
      "[26: 805/1795] train lossD: 0.010962 lossG: 0.737627\n",
      "[26: 810/1795] train lossD: -0.018545 lossG: 0.600062\n",
      "[26: 815/1795] train lossD: -0.032337 lossG: 0.552088\n",
      "[26: 820/1795] train lossD: -0.046995 lossG: 0.629864\n",
      "[26: 825/1795] train lossD: -0.073875 lossG: 0.683840\n",
      "[26: 830/1795] train lossD: -0.031796 lossG: 0.631027\n",
      "[26: 835/1795] train lossD: -0.057997 lossG: 0.678768\n",
      "[26: 840/1795] train lossD: -0.014175 lossG: 0.671098\n",
      "[26: 845/1795] train lossD: -0.020640 lossG: 0.754911\n",
      "[26: 850/1795] train lossD: 0.000534 lossG: 0.811981\n",
      "[26: 855/1795] train lossD: -0.049868 lossG: 0.776426\n",
      "[26: 860/1795] train lossD: 0.020982 lossG: 0.474340\n",
      "[26: 865/1795] train lossD: -0.030136 lossG: 0.504367\n",
      "[26: 870/1795] train lossD: 0.010733 lossG: 0.443232\n",
      "[26: 875/1795] train lossD: 0.009202 lossG: 0.466540\n",
      "[26: 880/1795] train lossD: -0.017236 lossG: 0.668686\n",
      "[26: 885/1795] train lossD: -0.022172 lossG: 0.754351\n",
      "[26: 890/1795] train lossD: 0.007830 lossG: 0.654425\n",
      "[26: 895/1795] train lossD: -0.036507 lossG: 0.732159\n",
      "[26: 900/1795] train lossD: 0.011468 lossG: 0.757763\n",
      "[26: 905/1795] train lossD: -0.007644 lossG: 0.654876\n",
      "[26: 910/1795] train lossD: -0.030390 lossG: 0.598074\n",
      "[26: 915/1795] train lossD: -0.027639 lossG: 0.450716\n",
      "[26: 920/1795] train lossD: 0.059607 lossG: 0.651699\n",
      "[26: 925/1795] train lossD: -0.048026 lossG: 0.753207\n",
      "[26: 930/1795] train lossD: -0.002801 lossG: 0.710209\n",
      "[26: 935/1795] train lossD: -0.042404 lossG: 0.736745\n",
      "[26: 940/1795] train lossD: -0.028999 lossG: 0.611892\n",
      "[26: 945/1795] train lossD: -0.031177 lossG: 0.719048\n",
      "[26: 950/1795] train lossD: -0.021266 lossG: 0.596655\n",
      "[26: 955/1795] train lossD: -0.039736 lossG: 0.704918\n",
      "[26: 960/1795] train lossD: -0.031933 lossG: 0.643810\n",
      "[26: 965/1795] train lossD: -0.030223 lossG: 0.631930\n",
      "[26: 970/1795] train lossD: 0.007241 lossG: 0.628400\n",
      "[26: 975/1795] train lossD: -0.007759 lossG: 0.723882\n",
      "[26: 980/1795] train lossD: -0.030454 lossG: 0.648475\n",
      "[26: 985/1795] train lossD: -0.013436 lossG: 0.670078\n",
      "[26: 990/1795] train lossD: -0.034710 lossG: 0.617488\n",
      "[26: 995/1795] train lossD: -0.035289 lossG: 0.691321\n",
      "[26: 1000/1795] train lossD: -0.061261 lossG: 0.796397\n",
      "[26: 1005/1795] train lossD: -0.044214 lossG: 0.572722\n",
      "[26: 1010/1795] train lossD: -0.088506 lossG: 0.509382\n",
      "[26: 1015/1795] train lossD: -0.064218 lossG: 0.603211\n",
      "[26: 1020/1795] train lossD: 0.009535 lossG: 0.649802\n",
      "[26: 1025/1795] train lossD: -0.018442 lossG: 0.567391\n",
      "[26: 1030/1795] train lossD: -0.070212 lossG: 0.680245\n",
      "[26: 1035/1795] train lossD: 0.025655 lossG: 0.586030\n",
      "[26: 1040/1795] train lossD: -0.018409 lossG: 0.597580\n",
      "[26: 1045/1795] train lossD: -0.003975 lossG: 0.583179\n",
      "[26: 1050/1795] train lossD: 0.009958 lossG: 0.584804\n",
      "[26: 1055/1795] train lossD: -0.037492 lossG: 0.655406\n",
      "[26: 1060/1795] train lossD: -0.005842 lossG: 0.620139\n",
      "[26: 1065/1795] train lossD: -0.005318 lossG: 0.656267\n",
      "[26: 1070/1795] train lossD: -0.039373 lossG: 0.637896\n",
      "[26: 1075/1795] train lossD: 0.023850 lossG: 0.607560\n",
      "[26: 1080/1795] train lossD: -0.033443 lossG: 0.802937\n",
      "[26: 1085/1795] train lossD: -0.015598 lossG: 0.592884\n",
      "[26: 1090/1795] train lossD: -0.045795 lossG: 0.533165\n",
      "[26: 1095/1795] train lossD: -0.015206 lossG: 0.552369\n",
      "[26: 1100/1795] train lossD: 0.000531 lossG: 0.626570\n",
      "[26: 1105/1795] train lossD: -0.061881 lossG: 0.665471\n",
      "[26: 1110/1795] train lossD: -0.037187 lossG: 0.500898\n",
      "[26: 1115/1795] train lossD: -0.037365 lossG: 0.475195\n",
      "[26: 1120/1795] train lossD: 0.016705 lossG: 0.539825\n",
      "[26: 1125/1795] train lossD: -0.013294 lossG: 0.596105\n",
      "[26: 1130/1795] train lossD: -0.002428 lossG: 0.656292\n",
      "[26: 1135/1795] train lossD: -0.049277 lossG: 0.791046\n",
      "[26: 1140/1795] train lossD: -0.035525 lossG: 0.756554\n",
      "[26: 1145/1795] train lossD: 0.006639 lossG: 0.662801\n",
      "[26: 1150/1795] train lossD: -0.045648 lossG: 0.716848\n",
      "[26: 1155/1795] train lossD: -0.010808 lossG: 0.608862\n",
      "[26: 1160/1795] train lossD: -0.000166 lossG: 0.694443\n",
      "[26: 1165/1795] train lossD: -0.054418 lossG: 0.689190\n",
      "[26: 1170/1795] train lossD: -0.051776 lossG: 0.632765\n",
      "[26: 1175/1795] train lossD: -0.070728 lossG: 0.716089\n",
      "[26: 1180/1795] train lossD: 0.017395 lossG: 0.724351\n",
      "[26: 1185/1795] train lossD: -0.016156 lossG: 0.624731\n",
      "[26: 1190/1795] train lossD: 0.002561 lossG: 0.661467\n",
      "[26: 1195/1795] train lossD: -0.037421 lossG: 0.623863\n",
      "[26: 1200/1795] train lossD: -0.060119 lossG: 0.574305\n",
      "[26: 1205/1795] train lossD: 0.005192 lossG: 0.777959\n",
      "[26: 1210/1795] train lossD: -0.046188 lossG: 0.779422\n",
      "[26: 1215/1795] train lossD: -0.030106 lossG: 0.642335\n",
      "[26: 1220/1795] train lossD: -0.012477 lossG: 0.646407\n",
      "[26: 1225/1795] train lossD: -0.062072 lossG: 0.699638\n",
      "[26: 1230/1795] train lossD: 0.022736 lossG: 0.582982\n",
      "[26: 1235/1795] train lossD: -0.015365 lossG: 0.690504\n",
      "[26: 1240/1795] train lossD: -0.054484 lossG: 0.670916\n",
      "[26: 1245/1795] train lossD: -0.009919 lossG: 0.667511\n",
      "[26: 1250/1795] train lossD: -0.017895 lossG: 0.495294\n",
      "[26: 1255/1795] train lossD: -0.026924 lossG: 0.577907\n",
      "[26: 1260/1795] train lossD: -0.013238 lossG: 0.478646\n",
      "[26: 1265/1795] train lossD: -0.037602 lossG: 0.595212\n",
      "[26: 1270/1795] train lossD: -0.028215 lossG: 0.659547\n",
      "[26: 1275/1795] train lossD: -0.012487 lossG: 0.683744\n",
      "[26: 1280/1795] train lossD: -0.047512 lossG: 0.447775\n",
      "[26: 1285/1795] train lossD: 0.021352 lossG: 0.555007\n",
      "[26: 1290/1795] train lossD: -0.046190 lossG: 0.543181\n",
      "[26: 1295/1795] train lossD: -0.009063 lossG: 0.638602\n",
      "[26: 1300/1795] train lossD: -0.050862 lossG: 0.521014\n",
      "[26: 1305/1795] train lossD: 0.060195 lossG: 0.568503\n",
      "[26: 1310/1795] train lossD: -0.064988 lossG: 0.667827\n",
      "[26: 1315/1795] train lossD: -0.040844 lossG: 0.698336\n",
      "[26: 1320/1795] train lossD: -0.010428 lossG: 0.595821\n",
      "[26: 1325/1795] train lossD: 0.029649 lossG: 0.635742\n",
      "[26: 1330/1795] train lossD: -0.032350 lossG: 0.552986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26: 1335/1795] train lossD: -0.052468 lossG: 0.551497\n",
      "[26: 1340/1795] train lossD: -0.010631 lossG: 0.475438\n",
      "[26: 1345/1795] train lossD: 0.060877 lossG: 0.589327\n",
      "[26: 1350/1795] train lossD: -0.026056 lossG: 0.543093\n",
      "[26: 1355/1795] train lossD: -0.024906 lossG: 0.585757\n",
      "[26: 1360/1795] train lossD: 0.015048 lossG: 0.656135\n",
      "[26: 1365/1795] train lossD: -0.050251 lossG: 0.562566\n",
      "[26: 1370/1795] train lossD: 0.013392 lossG: 0.625402\n",
      "[26: 1375/1795] train lossD: -0.042373 lossG: 0.574003\n",
      "[26: 1380/1795] train lossD: -0.045329 lossG: 0.497967\n",
      "[26: 1385/1795] train lossD: -0.045032 lossG: 0.511558\n",
      "[26: 1390/1795] train lossD: -0.080596 lossG: 0.573291\n",
      "[26: 1395/1795] train lossD: -0.010618 lossG: 0.523444\n",
      "[26: 1400/1795] train lossD: -0.081982 lossG: 0.488469\n",
      "[26: 1405/1795] train lossD: -0.000613 lossG: 0.499387\n",
      "[26: 1410/1795] train lossD: -0.043461 lossG: 0.451302\n",
      "[26: 1415/1795] train lossD: -0.008070 lossG: 0.444575\n",
      "[26: 1420/1795] train lossD: -0.004259 lossG: 0.586682\n",
      "[26: 1425/1795] train lossD: -0.008587 lossG: 0.617513\n",
      "[26: 1430/1795] train lossD: -0.030943 lossG: 0.435883\n",
      "[26: 1435/1795] train lossD: -0.057350 lossG: 0.505593\n",
      "[26: 1440/1795] train lossD: 0.035459 lossG: 0.632083\n",
      "[26: 1445/1795] train lossD: -0.029281 lossG: 0.734596\n",
      "[26: 1450/1795] train lossD: -0.048023 lossG: 0.624927\n",
      "[26: 1455/1795] train lossD: -0.009135 lossG: 0.622268\n",
      "[26: 1460/1795] train lossD: -0.018218 lossG: 0.817861\n",
      "[26: 1465/1795] train lossD: -0.044017 lossG: 0.590733\n",
      "[26: 1470/1795] train lossD: -0.106350 lossG: 0.636982\n",
      "[26: 1475/1795] train lossD: -0.005632 lossG: 0.840920\n",
      "[26: 1480/1795] train lossD: -0.081036 lossG: 0.807311\n",
      "[26: 1485/1795] train lossD: 0.035717 lossG: 0.745088\n",
      "[26: 1490/1795] train lossD: -0.049371 lossG: 0.664986\n",
      "[26: 1495/1795] train lossD: -0.047318 lossG: 0.669515\n",
      "[26: 1500/1795] train lossD: -0.015927 lossG: 0.674486\n",
      "[26: 1505/1795] train lossD: -0.074241 lossG: 0.771992\n",
      "[26: 1510/1795] train lossD: -0.069216 lossG: 0.716940\n",
      "[26: 1515/1795] train lossD: -0.008140 lossG: 0.782309\n",
      "[26: 1520/1795] train lossD: -0.061515 lossG: 0.729385\n",
      "[26: 1525/1795] train lossD: -0.013490 lossG: 0.643248\n",
      "[26: 1530/1795] train lossD: 0.089389 lossG: 0.647304\n",
      "[26: 1535/1795] train lossD: -0.003596 lossG: 0.681312\n",
      "[26: 1540/1795] train lossD: -0.058794 lossG: 0.731680\n",
      "[26: 1545/1795] train lossD: 0.002637 lossG: 0.669955\n",
      "[26: 1550/1795] train lossD: -0.069138 lossG: 0.513108\n",
      "[26: 1555/1795] train lossD: -0.017560 lossG: 0.782214\n",
      "[26: 1560/1795] train lossD: -0.053187 lossG: 0.627297\n",
      "[26: 1565/1795] train lossD: -0.029435 lossG: 0.484848\n",
      "[26: 1570/1795] train lossD: 0.098385 lossG: 0.502741\n",
      "[26: 1575/1795] train lossD: -0.033178 lossG: 0.638548\n",
      "[26: 1580/1795] train lossD: 0.048257 lossG: 0.687289\n",
      "[26: 1585/1795] train lossD: -0.004806 lossG: 0.619322\n",
      "[26: 1590/1795] train lossD: -0.029360 lossG: 0.678887\n",
      "[26: 1595/1795] train lossD: -0.043235 lossG: 0.698904\n",
      "[26: 1600/1795] train lossD: -0.074293 lossG: 0.910325\n",
      "[26: 1605/1795] train lossD: -0.033824 lossG: 0.797436\n",
      "[26: 1610/1795] train lossD: -0.011700 lossG: 0.864018\n",
      "[26: 1615/1795] train lossD: 0.007155 lossG: 0.831212\n",
      "[26: 1620/1795] train lossD: -0.015116 lossG: 0.681205\n",
      "[26: 1625/1795] train lossD: -0.054120 lossG: 0.798411\n",
      "[26: 1630/1795] train lossD: 0.004397 lossG: 0.583261\n",
      "[26: 1635/1795] train lossD: 0.018294 lossG: 0.727113\n",
      "[26: 1640/1795] train lossD: 0.000979 lossG: 0.637772\n",
      "[26: 1645/1795] train lossD: -0.009983 lossG: 0.722978\n",
      "[26: 1650/1795] train lossD: -0.034605 lossG: 0.713504\n",
      "[26: 1655/1795] train lossD: -0.041700 lossG: 0.587160\n",
      "[26: 1660/1795] train lossD: -0.012265 lossG: 0.538471\n",
      "[26: 1665/1795] train lossD: -0.003865 lossG: 0.559908\n",
      "[26: 1670/1795] train lossD: -0.077054 lossG: 0.629971\n",
      "[26: 1675/1795] train lossD: 0.020275 lossG: 0.568946\n",
      "[26: 1680/1795] train lossD: -0.048632 lossG: 0.492845\n",
      "[26: 1685/1795] train lossD: -0.027157 lossG: 0.624536\n",
      "[26: 1690/1795] train lossD: -0.047829 lossG: 0.539745\n",
      "[26: 1695/1795] train lossD: -0.039064 lossG: 0.474779\n",
      "[26: 1700/1795] train lossD: -0.038292 lossG: 0.543002\n",
      "[26: 1705/1795] train lossD: -0.070101 lossG: 0.628573\n",
      "[26: 1710/1795] train lossD: -0.066851 lossG: 0.575112\n",
      "[26: 1715/1795] train lossD: -0.001840 lossG: 0.574009\n",
      "[26: 1720/1795] train lossD: 0.067456 lossG: 0.505493\n",
      "[26: 1725/1795] train lossD: 0.017344 lossG: 0.524621\n",
      "[26: 1730/1795] train lossD: -0.002719 lossG: 0.619587\n",
      "[26: 1735/1795] train lossD: -0.004338 lossG: 0.557315\n",
      "[26: 1740/1795] train lossD: -0.015428 lossG: 0.528817\n",
      "[26: 1745/1795] train lossD: -0.030587 lossG: 0.725446\n",
      "[26: 1750/1795] train lossD: -0.054305 lossG: 0.761506\n",
      "[26: 1755/1795] train lossD: -0.053463 lossG: 0.677002\n",
      "[26: 1760/1795] train lossD: -0.035578 lossG: 0.707752\n",
      "[26: 1765/1795] train lossD: -0.050170 lossG: 0.730873\n",
      "[26: 1770/1795] train lossD: -0.064926 lossG: 0.639400\n",
      "[26: 1775/1795] train lossD: -0.041725 lossG: 0.700477\n",
      "[26: 1780/1795] train lossD: 0.013814 lossG: 0.688329\n",
      "[26: 1785/1795] train lossD: -0.026269 lossG: 0.577908\n",
      "[26: 1790/1795] train lossD: -0.017534 lossG: 0.583473\n",
      "0.05280192196369171\n",
      "[27: 0/1795] train lossD: -0.018932 lossG: 0.501256\n",
      "[27: 5/1795] train lossD: 0.008574 lossG: 0.450136\n",
      "[27: 10/1795] train lossD: 0.035529 lossG: 0.485233\n",
      "[27: 15/1795] train lossD: -0.050340 lossG: 0.640640\n",
      "[27: 20/1795] train lossD: -0.022661 lossG: 0.541475\n",
      "[27: 25/1795] train lossD: 0.042002 lossG: 0.638336\n",
      "[27: 30/1795] train lossD: 0.026712 lossG: 0.701567\n",
      "[27: 35/1795] train lossD: -0.047401 lossG: 0.543536\n",
      "[27: 40/1795] train lossD: -0.010369 lossG: 0.605138\n",
      "[27: 45/1795] train lossD: -0.012831 lossG: 0.661633\n",
      "[27: 50/1795] train lossD: -0.042633 lossG: 0.549204\n",
      "[27: 55/1795] train lossD: -0.060607 lossG: 0.423725\n",
      "[27: 60/1795] train lossD: -0.019837 lossG: 0.477424\n",
      "[27: 65/1795] train lossD: -0.062366 lossG: 0.620268\n",
      "[27: 70/1795] train lossD: -0.049486 lossG: 0.577645\n",
      "[27: 75/1795] train lossD: -0.015625 lossG: 0.732539\n",
      "[27: 80/1795] train lossD: -0.051696 lossG: 0.661237\n",
      "[27: 85/1795] train lossD: -0.033131 lossG: 0.594149\n",
      "[27: 90/1795] train lossD: 0.048406 lossG: 0.613658\n",
      "[27: 95/1795] train lossD: -0.005027 lossG: 0.531288\n",
      "[27: 100/1795] train lossD: -0.030842 lossG: 0.526485\n",
      "[27: 105/1795] train lossD: -0.050138 lossG: 0.863762\n",
      "[27: 110/1795] train lossD: -0.013306 lossG: 0.779742\n",
      "[27: 115/1795] train lossD: -0.043589 lossG: 0.712867\n",
      "[27: 120/1795] train lossD: 0.058549 lossG: 0.770077\n",
      "[27: 125/1795] train lossD: -0.033396 lossG: 0.822665\n",
      "[27: 130/1795] train lossD: 0.001812 lossG: 0.622106\n",
      "[27: 135/1795] train lossD: -0.037148 lossG: 0.542917\n",
      "[27: 140/1795] train lossD: -0.059973 lossG: 0.563140\n",
      "[27: 145/1795] train lossD: 0.089464 lossG: 0.434605\n",
      "[27: 150/1795] train lossD: 0.002343 lossG: 0.627638\n",
      "[27: 155/1795] train lossD: -0.054522 lossG: 0.610654\n",
      "[27: 160/1795] train lossD: -0.007001 lossG: 0.480869\n",
      "[27: 165/1795] train lossD: -0.013116 lossG: 0.427903\n",
      "[27: 170/1795] train lossD: -0.007479 lossG: 0.715772\n",
      "[27: 175/1795] train lossD: -0.028011 lossG: 0.462945\n",
      "[27: 180/1795] train lossD: -0.046132 lossG: 0.601987\n",
      "[27: 185/1795] train lossD: -0.025922 lossG: 0.437080\n",
      "[27: 190/1795] train lossD: -0.034814 lossG: 0.473803\n",
      "[27: 195/1795] train lossD: -0.069297 lossG: 0.371817\n",
      "[27: 200/1795] train lossD: -0.033504 lossG: 0.455013\n",
      "[27: 205/1795] train lossD: -0.069691 lossG: 0.591831\n",
      "[27: 210/1795] train lossD: -0.086967 lossG: 0.650733\n",
      "[27: 215/1795] train lossD: -0.013257 lossG: 0.504887\n",
      "[27: 220/1795] train lossD: 0.028064 lossG: 0.507787\n",
      "[27: 225/1795] train lossD: 0.005421 lossG: 0.464562\n",
      "[27: 230/1795] train lossD: -0.012644 lossG: 0.544337\n",
      "[27: 235/1795] train lossD: -0.049071 lossG: 0.596412\n",
      "[27: 240/1795] train lossD: -0.050500 lossG: 0.624710\n",
      "[27: 245/1795] train lossD: -0.092218 lossG: 0.458079\n",
      "[27: 250/1795] train lossD: -0.034921 lossG: 0.618969\n",
      "[27: 255/1795] train lossD: -0.022815 lossG: 0.616781\n",
      "[27: 260/1795] train lossD: -0.020713 lossG: 0.615336\n",
      "[27: 265/1795] train lossD: -0.041276 lossG: 0.696076\n",
      "[27: 270/1795] train lossD: -0.035906 lossG: 0.600644\n",
      "[27: 275/1795] train lossD: -0.043874 lossG: 0.507728\n",
      "[27: 280/1795] train lossD: -0.032834 lossG: 0.420020\n",
      "[27: 285/1795] train lossD: 0.029326 lossG: 0.754409\n",
      "[27: 290/1795] train lossD: -0.020906 lossG: 0.654912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27: 295/1795] train lossD: -0.022437 lossG: 0.650739\n",
      "[27: 300/1795] train lossD: -0.030597 lossG: 0.767039\n",
      "[27: 305/1795] train lossD: 0.008266 lossG: 0.657745\n",
      "[27: 310/1795] train lossD: -0.009905 lossG: 0.755410\n",
      "[27: 315/1795] train lossD: -0.018546 lossG: 0.750191\n",
      "[27: 320/1795] train lossD: -0.038682 lossG: 0.505293\n",
      "[27: 325/1795] train lossD: 0.020609 lossG: 0.733140\n",
      "[27: 330/1795] train lossD: -0.060136 lossG: 0.657001\n",
      "[27: 335/1795] train lossD: -0.046731 lossG: 0.650606\n",
      "[27: 340/1795] train lossD: -0.009693 lossG: 0.750921\n",
      "[27: 345/1795] train lossD: -0.029714 lossG: 0.673579\n",
      "[27: 350/1795] train lossD: -0.006772 lossG: 0.761109\n",
      "[27: 355/1795] train lossD: -0.016337 lossG: 0.770955\n",
      "[27: 360/1795] train lossD: -0.030340 lossG: 0.559074\n",
      "[27: 365/1795] train lossD: -0.024325 lossG: 0.856130\n",
      "[27: 370/1795] train lossD: -0.017465 lossG: 0.853853\n",
      "[27: 375/1795] train lossD: -0.053240 lossG: 0.792305\n",
      "[27: 380/1795] train lossD: -0.032759 lossG: 0.651623\n",
      "[27: 385/1795] train lossD: -0.050811 lossG: 0.677028\n",
      "[27: 390/1795] train lossD: -0.067724 lossG: 0.544162\n",
      "[27: 395/1795] train lossD: 0.001907 lossG: 0.463321\n",
      "[27: 400/1795] train lossD: -0.025945 lossG: 0.503004\n",
      "[27: 405/1795] train lossD: -0.045902 lossG: 0.582361\n",
      "[27: 410/1795] train lossD: -0.037099 lossG: 0.566072\n",
      "[27: 415/1795] train lossD: -0.038036 lossG: 0.556137\n",
      "[27: 420/1795] train lossD: -0.069259 lossG: 0.738297\n",
      "[27: 425/1795] train lossD: -0.019201 lossG: 0.607627\n",
      "[27: 430/1795] train lossD: -0.032756 lossG: 0.527958\n",
      "[27: 435/1795] train lossD: 0.010217 lossG: 0.506009\n",
      "[27: 440/1795] train lossD: 0.044770 lossG: 0.540737\n",
      "[27: 445/1795] train lossD: -0.034769 lossG: 0.528847\n",
      "[27: 450/1795] train lossD: -0.017314 lossG: 0.557628\n",
      "[27: 455/1795] train lossD: -0.054073 lossG: 0.421124\n",
      "[27: 460/1795] train lossD: 0.006308 lossG: 0.437271\n",
      "[27: 465/1795] train lossD: -0.035385 lossG: 0.716119\n",
      "[27: 470/1795] train lossD: -0.059643 lossG: 0.531058\n",
      "[27: 475/1795] train lossD: -0.036890 lossG: 0.439953\n",
      "[27: 480/1795] train lossD: -0.036858 lossG: 0.480010\n",
      "[27: 485/1795] train lossD: -0.019325 lossG: 0.592737\n",
      "[27: 490/1795] train lossD: -0.107233 lossG: 0.640881\n",
      "[27: 495/1795] train lossD: 0.000910 lossG: 0.441590\n",
      "[27: 500/1795] train lossD: 0.038741 lossG: 0.422486\n",
      "[27: 505/1795] train lossD: -0.060447 lossG: 0.462787\n",
      "[27: 510/1795] train lossD: -0.042990 lossG: 0.362257\n",
      "[27: 515/1795] train lossD: 0.005112 lossG: 0.472233\n",
      "[27: 520/1795] train lossD: -0.029020 lossG: 0.586542\n",
      "[27: 525/1795] train lossD: -0.073909 lossG: 0.640169\n",
      "[27: 530/1795] train lossD: -0.038224 lossG: 0.501059\n",
      "[27: 535/1795] train lossD: -0.019452 lossG: 0.488934\n",
      "[27: 540/1795] train lossD: -0.035415 lossG: 0.636001\n",
      "[27: 545/1795] train lossD: -0.020143 lossG: 0.597687\n",
      "[27: 550/1795] train lossD: -0.014520 lossG: 0.648574\n",
      "[27: 555/1795] train lossD: 0.028573 lossG: 0.545611\n",
      "[27: 560/1795] train lossD: 0.006058 lossG: 0.497574\n",
      "[27: 565/1795] train lossD: -0.045121 lossG: 0.653035\n",
      "[27: 570/1795] train lossD: -0.005050 lossG: 0.673342\n",
      "[27: 575/1795] train lossD: -0.019739 lossG: 0.686894\n",
      "[27: 580/1795] train lossD: -0.027677 lossG: 0.611648\n",
      "[27: 585/1795] train lossD: -0.037687 lossG: 0.608927\n",
      "[27: 590/1795] train lossD: -0.044480 lossG: 0.604231\n",
      "[27: 595/1795] train lossD: -0.021988 lossG: 0.609126\n",
      "[27: 600/1795] train lossD: -0.056206 lossG: 0.633828\n",
      "[27: 605/1795] train lossD: -0.033759 lossG: 0.566716\n",
      "[27: 610/1795] train lossD: 0.003241 lossG: 0.566382\n",
      "[27: 615/1795] train lossD: -0.073956 lossG: 0.627204\n",
      "[27: 620/1795] train lossD: -0.070946 lossG: 0.643454\n",
      "[27: 625/1795] train lossD: -0.077884 lossG: 0.485991\n",
      "[27: 630/1795] train lossD: -0.035209 lossG: 0.597946\n",
      "[27: 635/1795] train lossD: 0.010876 lossG: 0.556904\n",
      "[27: 640/1795] train lossD: -0.025729 lossG: 0.555918\n",
      "[27: 645/1795] train lossD: -0.068004 lossG: 0.398847\n",
      "[27: 650/1795] train lossD: -0.081424 lossG: 0.430750\n",
      "[27: 655/1795] train lossD: 0.005268 lossG: 0.420454\n",
      "[27: 660/1795] train lossD: -0.005579 lossG: 0.563084\n",
      "[27: 665/1795] train lossD: -0.024833 lossG: 0.570088\n",
      "[27: 670/1795] train lossD: -0.033965 lossG: 0.586677\n",
      "[27: 675/1795] train lossD: -0.079967 lossG: 0.493237\n",
      "[27: 680/1795] train lossD: -0.061294 lossG: 0.540417\n",
      "[27: 685/1795] train lossD: -0.049283 lossG: 0.575792\n",
      "[27: 690/1795] train lossD: -0.042934 lossG: 0.575453\n",
      "[27: 695/1795] train lossD: -0.049878 lossG: 0.536222\n",
      "[27: 700/1795] train lossD: 0.035120 lossG: 0.635321\n",
      "[27: 705/1795] train lossD: -0.042805 lossG: 0.715571\n",
      "[27: 710/1795] train lossD: -0.046352 lossG: 0.561101\n",
      "[27: 715/1795] train lossD: -0.066858 lossG: 0.540940\n",
      "[27: 720/1795] train lossD: -0.034845 lossG: 0.580852\n",
      "[27: 725/1795] train lossD: -0.025241 lossG: 0.624104\n",
      "[27: 730/1795] train lossD: 0.033138 lossG: 0.703860\n",
      "[27: 735/1795] train lossD: -0.012601 lossG: 0.730276\n",
      "[27: 740/1795] train lossD: -0.058809 lossG: 0.645817\n",
      "[27: 745/1795] train lossD: 0.023212 lossG: 0.719622\n",
      "[27: 750/1795] train lossD: -0.047129 lossG: 0.611314\n",
      "[27: 755/1795] train lossD: -0.005901 lossG: 0.533147\n",
      "[27: 760/1795] train lossD: -0.039051 lossG: 0.616857\n",
      "[27: 765/1795] train lossD: -0.079168 lossG: 0.705340\n",
      "[27: 770/1795] train lossD: -0.053937 lossG: 0.699092\n",
      "[27: 775/1795] train lossD: -0.004699 lossG: 0.699929\n",
      "[27: 780/1795] train lossD: -0.021385 lossG: 0.593715\n",
      "[27: 785/1795] train lossD: 0.057852 lossG: 0.521063\n",
      "[27: 790/1795] train lossD: -0.047555 lossG: 0.588668\n",
      "[27: 795/1795] train lossD: 0.003780 lossG: 0.564835\n",
      "[27: 800/1795] train lossD: 0.031224 lossG: 0.664389\n",
      "[27: 805/1795] train lossD: 0.059492 lossG: 0.543342\n",
      "[27: 810/1795] train lossD: -0.022894 lossG: 0.500788\n",
      "[27: 815/1795] train lossD: -0.031348 lossG: 0.375884\n",
      "[27: 820/1795] train lossD: -0.010012 lossG: 0.540939\n",
      "[27: 825/1795] train lossD: -0.019938 lossG: 0.552057\n",
      "[27: 830/1795] train lossD: -0.043571 lossG: 0.502671\n",
      "[27: 835/1795] train lossD: 0.007705 lossG: 0.467190\n",
      "[27: 840/1795] train lossD: -0.014460 lossG: 0.527632\n",
      "[27: 845/1795] train lossD: -0.018278 lossG: 0.592988\n",
      "[27: 850/1795] train lossD: -0.044954 lossG: 0.684855\n",
      "[27: 855/1795] train lossD: 0.018310 lossG: 0.445352\n",
      "[27: 860/1795] train lossD: -0.012250 lossG: 0.483473\n",
      "[27: 865/1795] train lossD: 0.006044 lossG: 0.696425\n",
      "[27: 870/1795] train lossD: -0.015519 lossG: 0.691375\n",
      "[27: 875/1795] train lossD: -0.023568 lossG: 0.532848\n",
      "[27: 880/1795] train lossD: -0.034749 lossG: 0.347013\n",
      "[27: 885/1795] train lossD: 0.011858 lossG: 0.569012\n",
      "[27: 890/1795] train lossD: -0.029243 lossG: 0.610371\n",
      "[27: 895/1795] train lossD: -0.025941 lossG: 0.684118\n",
      "[27: 900/1795] train lossD: -0.012012 lossG: 0.718874\n",
      "[27: 905/1795] train lossD: -0.041339 lossG: 0.645351\n",
      "[27: 910/1795] train lossD: -0.054217 lossG: 0.641372\n",
      "[27: 915/1795] train lossD: -0.038253 lossG: 0.608666\n",
      "[27: 920/1795] train lossD: 0.000963 lossG: 0.467287\n",
      "[27: 925/1795] train lossD: 0.092936 lossG: 0.586460\n",
      "[27: 930/1795] train lossD: -0.050343 lossG: 0.711811\n",
      "[27: 935/1795] train lossD: -0.006456 lossG: 0.659326\n",
      "[27: 940/1795] train lossD: -0.038539 lossG: 0.561187\n",
      "[27: 945/1795] train lossD: 0.020527 lossG: 0.493712\n",
      "[27: 950/1795] train lossD: -0.096224 lossG: 0.462226\n",
      "[27: 955/1795] train lossD: 0.127327 lossG: 0.580105\n",
      "[27: 960/1795] train lossD: -0.005113 lossG: 0.694862\n",
      "[27: 965/1795] train lossD: -0.066210 lossG: 0.506251\n",
      "[27: 970/1795] train lossD: -0.060539 lossG: 0.590927\n",
      "[27: 975/1795] train lossD: -0.025661 lossG: 0.735359\n",
      "[27: 980/1795] train lossD: -0.086575 lossG: 0.658456\n",
      "[27: 985/1795] train lossD: -0.007956 lossG: 0.777341\n",
      "[27: 990/1795] train lossD: -0.019661 lossG: 0.807745\n",
      "[27: 995/1795] train lossD: 0.007602 lossG: 0.527098\n",
      "[27: 1000/1795] train lossD: -0.000284 lossG: 0.619787\n",
      "[27: 1005/1795] train lossD: -0.009141 lossG: 0.680609\n",
      "[27: 1010/1795] train lossD: -0.040365 lossG: 0.551833\n",
      "[27: 1015/1795] train lossD: -0.098317 lossG: 0.676840\n",
      "[27: 1020/1795] train lossD: -0.000070 lossG: 0.514396\n",
      "[27: 1025/1795] train lossD: 0.019040 lossG: 0.510580\n",
      "[27: 1030/1795] train lossD: -0.070941 lossG: 0.579743\n",
      "[27: 1035/1795] train lossD: -0.041089 lossG: 0.464721\n",
      "[27: 1040/1795] train lossD: 0.061589 lossG: 0.321343\n",
      "[27: 1045/1795] train lossD: 0.011132 lossG: 0.491495\n",
      "[27: 1050/1795] train lossD: 0.059080 lossG: 0.530777\n",
      "[27: 1055/1795] train lossD: -0.046232 lossG: 0.666733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27: 1060/1795] train lossD: -0.035540 lossG: 0.474286\n",
      "[27: 1065/1795] train lossD: 0.048034 lossG: 0.549955\n",
      "[27: 1070/1795] train lossD: -0.043796 lossG: 0.513794\n",
      "[27: 1075/1795] train lossD: -0.031467 lossG: 0.585621\n",
      "[27: 1080/1795] train lossD: -0.023245 lossG: 0.646006\n",
      "[27: 1085/1795] train lossD: 0.099955 lossG: 0.575742\n",
      "[27: 1090/1795] train lossD: -0.038636 lossG: 0.799775\n",
      "[27: 1095/1795] train lossD: -0.068196 lossG: 0.607726\n",
      "[27: 1100/1795] train lossD: -0.035806 lossG: 0.605218\n",
      "[27: 1105/1795] train lossD: -0.056461 lossG: 0.481716\n",
      "[27: 1110/1795] train lossD: -0.053900 lossG: 0.614215\n",
      "[27: 1115/1795] train lossD: -0.055841 lossG: 0.509378\n",
      "[27: 1120/1795] train lossD: 0.013341 lossG: 0.457595\n",
      "[27: 1125/1795] train lossD: -0.026359 lossG: 0.357578\n",
      "[27: 1130/1795] train lossD: -0.011776 lossG: 0.492612\n",
      "[27: 1135/1795] train lossD: -0.046230 lossG: 0.547733\n",
      "[27: 1140/1795] train lossD: -0.061590 lossG: 0.470572\n",
      "[27: 1145/1795] train lossD: -0.003750 lossG: 0.530555\n",
      "[27: 1150/1795] train lossD: -0.037683 lossG: 0.486404\n",
      "[27: 1155/1795] train lossD: -0.045921 lossG: 0.646157\n",
      "[27: 1160/1795] train lossD: -0.015068 lossG: 0.636677\n",
      "[27: 1165/1795] train lossD: -0.016707 lossG: 0.602170\n",
      "[27: 1170/1795] train lossD: 0.025358 lossG: 0.551009\n",
      "[27: 1175/1795] train lossD: -0.000603 lossG: 0.518338\n",
      "[27: 1180/1795] train lossD: 0.007371 lossG: 0.766298\n",
      "[27: 1185/1795] train lossD: -0.045066 lossG: 0.787871\n",
      "[27: 1190/1795] train lossD: -0.042022 lossG: 0.717143\n",
      "[27: 1195/1795] train lossD: -0.110783 lossG: 0.750145\n",
      "[27: 1200/1795] train lossD: -0.003624 lossG: 0.684366\n",
      "[27: 1205/1795] train lossD: 0.032926 lossG: 0.549639\n",
      "[27: 1210/1795] train lossD: 0.016099 lossG: 0.582993\n",
      "[27: 1215/1795] train lossD: -0.083104 lossG: 0.585826\n",
      "[27: 1220/1795] train lossD: -0.060565 lossG: 0.581224\n",
      "[27: 1225/1795] train lossD: -0.014089 lossG: 0.598707\n",
      "[27: 1230/1795] train lossD: 0.016774 lossG: 0.780486\n",
      "[27: 1235/1795] train lossD: -0.026309 lossG: 0.577418\n",
      "[27: 1240/1795] train lossD: -0.024588 lossG: 0.411012\n",
      "[27: 1245/1795] train lossD: 0.023422 lossG: 0.328601\n",
      "[27: 1250/1795] train lossD: -0.025256 lossG: 0.403602\n",
      "[27: 1255/1795] train lossD: 0.007934 lossG: 0.444023\n",
      "[27: 1260/1795] train lossD: -0.010104 lossG: 0.578562\n",
      "[27: 1265/1795] train lossD: 0.033032 lossG: 0.615166\n",
      "[27: 1270/1795] train lossD: -0.039920 lossG: 0.792979\n",
      "[27: 1275/1795] train lossD: -0.045636 lossG: 0.711989\n",
      "[27: 1280/1795] train lossD: 0.018486 lossG: 0.453445\n",
      "[27: 1285/1795] train lossD: -0.044617 lossG: 0.578805\n",
      "[27: 1290/1795] train lossD: -0.042581 lossG: 0.641465\n",
      "[27: 1295/1795] train lossD: -0.060718 lossG: 0.545722\n",
      "[27: 1300/1795] train lossD: -0.034963 lossG: 0.606544\n",
      "[27: 1305/1795] train lossD: -0.012681 lossG: 0.653179\n",
      "[27: 1310/1795] train lossD: -0.045046 lossG: 0.620912\n",
      "[27: 1315/1795] train lossD: 0.062143 lossG: 0.417190\n",
      "[27: 1320/1795] train lossD: -0.036153 lossG: 0.513220\n",
      "[27: 1325/1795] train lossD: 0.032948 lossG: 0.530276\n",
      "[27: 1330/1795] train lossD: -0.014043 lossG: 0.598322\n",
      "[27: 1335/1795] train lossD: -0.062116 lossG: 0.605200\n",
      "[27: 1340/1795] train lossD: 0.004628 lossG: 0.627215\n",
      "[27: 1345/1795] train lossD: -0.030111 lossG: 0.605234\n",
      "[27: 1350/1795] train lossD: -0.071877 lossG: 0.755608\n",
      "[27: 1355/1795] train lossD: -0.043771 lossG: 0.665024\n",
      "[27: 1360/1795] train lossD: -0.058618 lossG: 0.411285\n",
      "[27: 1365/1795] train lossD: 0.015111 lossG: 0.382206\n",
      "[27: 1370/1795] train lossD: 0.023835 lossG: 0.454784\n",
      "[27: 1375/1795] train lossD: -0.057027 lossG: 0.422127\n",
      "[27: 1380/1795] train lossD: -0.033169 lossG: 0.351881\n",
      "[27: 1385/1795] train lossD: -0.022987 lossG: 0.298008\n",
      "[27: 1390/1795] train lossD: -0.030577 lossG: 0.419638\n",
      "[27: 1395/1795] train lossD: -0.053237 lossG: 0.337403\n",
      "[27: 1400/1795] train lossD: -0.049255 lossG: 0.557359\n",
      "[27: 1405/1795] train lossD: -0.060254 lossG: 0.442678\n",
      "[27: 1410/1795] train lossD: -0.011574 lossG: 0.724515\n",
      "[27: 1415/1795] train lossD: -0.039732 lossG: 0.799269\n",
      "[27: 1420/1795] train lossD: 0.002929 lossG: 0.844132\n",
      "[27: 1425/1795] train lossD: -0.104975 lossG: 0.870261\n",
      "[27: 1430/1795] train lossD: 0.012930 lossG: 0.688830\n",
      "[27: 1435/1795] train lossD: -0.044130 lossG: 0.620714\n",
      "[27: 1440/1795] train lossD: -0.012588 lossG: 0.479828\n",
      "[27: 1445/1795] train lossD: 0.017696 lossG: 0.567872\n",
      "[27: 1450/1795] train lossD: -0.040442 lossG: 0.665573\n",
      "[27: 1455/1795] train lossD: 0.006346 lossG: 0.674934\n",
      "[27: 1460/1795] train lossD: -0.053853 lossG: 0.716666\n",
      "[27: 1465/1795] train lossD: -0.045706 lossG: 0.772786\n",
      "[27: 1470/1795] train lossD: -0.019574 lossG: 0.577205\n",
      "[27: 1475/1795] train lossD: -0.077717 lossG: 0.528197\n",
      "[27: 1480/1795] train lossD: -0.040084 lossG: 0.492094\n",
      "[27: 1485/1795] train lossD: 0.013537 lossG: 0.637325\n",
      "[27: 1490/1795] train lossD: -0.020784 lossG: 0.716444\n",
      "[27: 1495/1795] train lossD: 0.036920 lossG: 0.783874\n",
      "[27: 1500/1795] train lossD: -0.078818 lossG: 0.712731\n",
      "[27: 1505/1795] train lossD: -0.007075 lossG: 0.700035\n",
      "[27: 1510/1795] train lossD: -0.034451 lossG: 0.439756\n",
      "[27: 1515/1795] train lossD: -0.023792 lossG: 0.495159\n",
      "[27: 1520/1795] train lossD: -0.007449 lossG: 0.388640\n",
      "[27: 1525/1795] train lossD: -0.035478 lossG: 0.470522\n",
      "[27: 1530/1795] train lossD: -0.063667 lossG: 0.670733\n",
      "[27: 1535/1795] train lossD: -0.061208 lossG: 0.529357\n",
      "[27: 1540/1795] train lossD: -0.039597 lossG: 0.486264\n",
      "[27: 1545/1795] train lossD: -0.079912 lossG: 0.618716\n",
      "[27: 1550/1795] train lossD: -0.044719 lossG: 0.612235\n",
      "[27: 1555/1795] train lossD: -0.005971 lossG: 0.605142\n",
      "[27: 1560/1795] train lossD: 0.011166 lossG: 0.491125\n",
      "[27: 1565/1795] train lossD: -0.052272 lossG: 0.492422\n",
      "[27: 1570/1795] train lossD: -0.034751 lossG: 0.587577\n",
      "[27: 1575/1795] train lossD: -0.040486 lossG: 0.667649\n",
      "[27: 1580/1795] train lossD: -0.039452 lossG: 0.451953\n",
      "[27: 1585/1795] train lossD: -0.053368 lossG: 0.654607\n",
      "[27: 1590/1795] train lossD: -0.010897 lossG: 0.585705\n",
      "[27: 1595/1795] train lossD: -0.064798 lossG: 0.743894\n",
      "[27: 1600/1795] train lossD: -0.042993 lossG: 0.444436\n",
      "[27: 1605/1795] train lossD: -0.031990 lossG: 0.719880\n",
      "[27: 1610/1795] train lossD: 0.013522 lossG: 0.521216\n",
      "[27: 1615/1795] train lossD: 0.005247 lossG: 0.621927\n",
      "[27: 1620/1795] train lossD: -0.003811 lossG: 0.617451\n",
      "[27: 1625/1795] train lossD: 0.009090 lossG: 0.546795\n",
      "[27: 1630/1795] train lossD: -0.034355 lossG: 0.667310\n",
      "[27: 1635/1795] train lossD: 0.019777 lossG: 0.548740\n",
      "[27: 1640/1795] train lossD: 0.031661 lossG: 0.594647\n",
      "[27: 1645/1795] train lossD: -0.013727 lossG: 0.583798\n",
      "[27: 1650/1795] train lossD: -0.028284 lossG: 0.578904\n",
      "[27: 1655/1795] train lossD: -0.080061 lossG: 0.653590\n",
      "[27: 1660/1795] train lossD: 0.040790 lossG: 0.702385\n",
      "[27: 1665/1795] train lossD: -0.040210 lossG: 0.692000\n",
      "[27: 1670/1795] train lossD: 0.012333 lossG: 0.527315\n",
      "[27: 1675/1795] train lossD: 0.010793 lossG: 0.593003\n",
      "[27: 1680/1795] train lossD: -0.036970 lossG: 0.496108\n",
      "[27: 1685/1795] train lossD: -0.033470 lossG: 0.582655\n",
      "[27: 1690/1795] train lossD: -0.045368 lossG: 0.746646\n",
      "[27: 1695/1795] train lossD: 0.009288 lossG: 0.535248\n",
      "[27: 1700/1795] train lossD: -0.049227 lossG: 0.686978\n",
      "[27: 1705/1795] train lossD: -0.009377 lossG: 0.532704\n",
      "[27: 1710/1795] train lossD: -0.014743 lossG: 0.663124\n",
      "[27: 1715/1795] train lossD: -0.001214 lossG: 0.556035\n",
      "[27: 1720/1795] train lossD: -0.057727 lossG: 0.482953\n",
      "[27: 1725/1795] train lossD: -0.000348 lossG: 0.603611\n",
      "[27: 1730/1795] train lossD: 0.005489 lossG: 0.671835\n",
      "[27: 1735/1795] train lossD: -0.094293 lossG: 0.695653\n",
      "[27: 1740/1795] train lossD: -0.019112 lossG: 0.598620\n",
      "[27: 1745/1795] train lossD: -0.098251 lossG: 0.685291\n",
      "[27: 1750/1795] train lossD: -0.059718 lossG: 0.704801\n",
      "[27: 1755/1795] train lossD: 0.040343 lossG: 0.782786\n",
      "[27: 1760/1795] train lossD: -0.047636 lossG: 0.621919\n",
      "[27: 1765/1795] train lossD: -0.037291 lossG: 0.667097\n",
      "[27: 1770/1795] train lossD: -0.007364 lossG: 0.593796\n",
      "[27: 1775/1795] train lossD: -0.037766 lossG: 0.763953\n",
      "[27: 1780/1795] train lossD: 0.000836 lossG: 0.726455\n",
      "[27: 1785/1795] train lossD: -0.049018 lossG: 0.764002\n",
      "[27: 1790/1795] train lossD: -0.016691 lossG: 0.735495\n",
      "0.042118966579437256\n",
      "[28: 0/1795] train lossD: 0.026107 lossG: 0.684362\n",
      "[28: 5/1795] train lossD: 0.003224 lossG: 0.627816\n",
      "[28: 10/1795] train lossD: 0.022463 lossG: 0.591909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28: 15/1795] train lossD: 0.030627 lossG: 0.699833\n",
      "[28: 20/1795] train lossD: -0.071733 lossG: 0.598578\n",
      "[28: 25/1795] train lossD: -0.102795 lossG: 0.780738\n",
      "[28: 30/1795] train lossD: -0.030592 lossG: 0.621627\n",
      "[28: 35/1795] train lossD: -0.026992 lossG: 0.710053\n",
      "[28: 40/1795] train lossD: -0.067009 lossG: 0.661292\n",
      "[28: 45/1795] train lossD: -0.006352 lossG: 0.615056\n",
      "[28: 50/1795] train lossD: -0.051164 lossG: 0.757068\n",
      "[28: 55/1795] train lossD: -0.008763 lossG: 0.530591\n",
      "[28: 60/1795] train lossD: -0.011413 lossG: 0.609337\n",
      "[28: 65/1795] train lossD: 0.022097 lossG: 0.549984\n",
      "[28: 70/1795] train lossD: -0.025264 lossG: 0.561104\n",
      "[28: 75/1795] train lossD: -0.067637 lossG: 0.446743\n",
      "[28: 80/1795] train lossD: 0.211227 lossG: 0.635241\n",
      "[28: 85/1795] train lossD: -0.074303 lossG: 0.663234\n",
      "[28: 90/1795] train lossD: -0.049464 lossG: 0.534384\n",
      "[28: 95/1795] train lossD: -0.025987 lossG: 0.594727\n",
      "[28: 100/1795] train lossD: -0.042800 lossG: 0.575203\n",
      "[28: 105/1795] train lossD: -0.042075 lossG: 0.742450\n",
      "[28: 110/1795] train lossD: -0.070779 lossG: 0.694297\n",
      "[28: 115/1795] train lossD: 0.000291 lossG: 0.738288\n",
      "[28: 120/1795] train lossD: 0.000479 lossG: 0.463254\n",
      "[28: 125/1795] train lossD: 0.032248 lossG: 0.612049\n",
      "[28: 130/1795] train lossD: -0.063484 lossG: 0.546774\n",
      "[28: 135/1795] train lossD: 0.001007 lossG: 0.642975\n",
      "[28: 140/1795] train lossD: -0.000907 lossG: 0.568103\n",
      "[28: 145/1795] train lossD: -0.016394 lossG: 0.490508\n",
      "[28: 150/1795] train lossD: -0.065677 lossG: 0.729782\n",
      "[28: 155/1795] train lossD: -0.050815 lossG: 0.489044\n",
      "[28: 160/1795] train lossD: 0.010952 lossG: 0.726621\n",
      "[28: 165/1795] train lossD: -0.024537 lossG: 0.506584\n",
      "[28: 170/1795] train lossD: 0.095415 lossG: 0.495325\n",
      "[28: 175/1795] train lossD: -0.035428 lossG: 0.588641\n",
      "[28: 180/1795] train lossD: 0.001003 lossG: 0.548255\n",
      "[28: 185/1795] train lossD: 0.134742 lossG: 0.662878\n",
      "[28: 190/1795] train lossD: -0.013839 lossG: 0.620683\n",
      "[28: 195/1795] train lossD: -0.067382 lossG: 0.697317\n",
      "[28: 200/1795] train lossD: 0.055310 lossG: 0.605119\n",
      "[28: 205/1795] train lossD: -0.011420 lossG: 0.602512\n",
      "[28: 210/1795] train lossD: -0.061019 lossG: 0.553188\n",
      "[28: 215/1795] train lossD: 0.008829 lossG: 0.759890\n",
      "[28: 220/1795] train lossD: -0.092436 lossG: 0.722538\n",
      "[28: 225/1795] train lossD: 0.015097 lossG: 0.620112\n",
      "[28: 230/1795] train lossD: 0.025499 lossG: 0.563050\n",
      "[28: 235/1795] train lossD: -0.021279 lossG: 0.666470\n",
      "[28: 240/1795] train lossD: -0.061772 lossG: 0.488634\n",
      "[28: 245/1795] train lossD: -0.050383 lossG: 0.564047\n",
      "[28: 250/1795] train lossD: 0.061254 lossG: 0.729166\n",
      "[28: 255/1795] train lossD: -0.073397 lossG: 0.649225\n",
      "[28: 260/1795] train lossD: 0.008516 lossG: 0.780363\n",
      "[28: 265/1795] train lossD: 0.009241 lossG: 0.568924\n",
      "[28: 270/1795] train lossD: -0.044596 lossG: 0.717291\n",
      "[28: 275/1795] train lossD: -0.036190 lossG: 0.450087\n",
      "[28: 280/1795] train lossD: -0.031042 lossG: 0.549202\n",
      "[28: 285/1795] train lossD: -0.034705 lossG: 0.372101\n",
      "[28: 290/1795] train lossD: 0.039756 lossG: 0.437278\n",
      "[28: 295/1795] train lossD: 0.052718 lossG: 0.347482\n",
      "[28: 300/1795] train lossD: -0.059774 lossG: 0.334264\n",
      "[28: 305/1795] train lossD: -0.003966 lossG: 0.424152\n",
      "[28: 310/1795] train lossD: -0.010942 lossG: 0.390135\n",
      "[28: 315/1795] train lossD: -0.015187 lossG: 0.421865\n",
      "[28: 320/1795] train lossD: -0.014193 lossG: 0.492741\n",
      "[28: 325/1795] train lossD: -0.052490 lossG: 0.395060\n",
      "[28: 330/1795] train lossD: -0.038745 lossG: 0.523764\n",
      "[28: 335/1795] train lossD: -0.052031 lossG: 0.606136\n",
      "[28: 340/1795] train lossD: -0.081779 lossG: 0.540547\n",
      "[28: 345/1795] train lossD: -0.074347 lossG: 0.532260\n",
      "[28: 350/1795] train lossD: -0.020495 lossG: 0.514410\n",
      "[28: 355/1795] train lossD: 0.060308 lossG: 0.629256\n",
      "[28: 360/1795] train lossD: 0.019039 lossG: 0.699741\n",
      "[28: 365/1795] train lossD: -0.054071 lossG: 0.783008\n",
      "[28: 370/1795] train lossD: -0.036619 lossG: 0.501889\n",
      "[28: 375/1795] train lossD: -0.028281 lossG: 0.604989\n",
      "[28: 380/1795] train lossD: -0.047015 lossG: 0.559844\n",
      "[28: 385/1795] train lossD: 0.002667 lossG: 0.687495\n",
      "[28: 390/1795] train lossD: -0.053508 lossG: 0.667808\n",
      "[28: 395/1795] train lossD: -0.056009 lossG: 0.623616\n",
      "[28: 400/1795] train lossD: -0.087667 lossG: 0.659758\n",
      "[28: 405/1795] train lossD: -0.049426 lossG: 0.644286\n",
      "[28: 410/1795] train lossD: 0.020450 lossG: 0.697953\n",
      "[28: 415/1795] train lossD: -0.051385 lossG: 0.746905\n",
      "[28: 420/1795] train lossD: -0.023759 lossG: 0.639776\n",
      "[28: 425/1795] train lossD: -0.060712 lossG: 0.725536\n",
      "[28: 430/1795] train lossD: -0.067909 lossG: 0.553260\n",
      "[28: 435/1795] train lossD: -0.101982 lossG: 0.524299\n",
      "[28: 440/1795] train lossD: -0.101462 lossG: 0.389910\n",
      "[28: 445/1795] train lossD: 0.001387 lossG: 0.687797\n",
      "[28: 450/1795] train lossD: -0.029848 lossG: 0.555068\n",
      "[28: 455/1795] train lossD: -0.061510 lossG: 0.539815\n",
      "[28: 460/1795] train lossD: -0.043248 lossG: 0.534712\n",
      "[28: 465/1795] train lossD: -0.055525 lossG: 0.441676\n",
      "[28: 470/1795] train lossD: -0.006145 lossG: 0.565458\n",
      "[28: 475/1795] train lossD: -0.028923 lossG: 0.558910\n",
      "[28: 480/1795] train lossD: -0.024763 lossG: 0.505056\n",
      "[28: 485/1795] train lossD: -0.035552 lossG: 0.591418\n",
      "[28: 490/1795] train lossD: -0.004843 lossG: 0.814654\n",
      "[28: 495/1795] train lossD: -0.032224 lossG: 0.654855\n",
      "[28: 500/1795] train lossD: -0.048198 lossG: 0.617729\n",
      "[28: 505/1795] train lossD: -0.039820 lossG: 0.533364\n",
      "[28: 510/1795] train lossD: 0.002813 lossG: 0.466617\n",
      "[28: 515/1795] train lossD: -0.044627 lossG: 0.550935\n",
      "[28: 520/1795] train lossD: 0.039873 lossG: 0.579610\n",
      "[28: 525/1795] train lossD: 0.009027 lossG: 0.537366\n",
      "[28: 530/1795] train lossD: -0.024303 lossG: 0.600925\n",
      "[28: 535/1795] train lossD: -0.056901 lossG: 0.575952\n",
      "[28: 540/1795] train lossD: -0.031854 lossG: 0.449092\n",
      "[28: 545/1795] train lossD: -0.045454 lossG: 0.580442\n",
      "[28: 550/1795] train lossD: -0.026061 lossG: 0.626650\n",
      "[28: 555/1795] train lossD: -0.045837 lossG: 0.573709\n",
      "[28: 560/1795] train lossD: -0.067639 lossG: 0.576308\n",
      "[28: 565/1795] train lossD: -0.072210 lossG: 0.745870\n",
      "[28: 570/1795] train lossD: -0.106016 lossG: 0.646902\n",
      "[28: 575/1795] train lossD: 0.016840 lossG: 0.704631\n",
      "[28: 580/1795] train lossD: -0.034657 lossG: 0.641210\n",
      "[28: 585/1795] train lossD: -0.034735 lossG: 0.505765\n",
      "[28: 590/1795] train lossD: -0.047921 lossG: 0.632226\n",
      "[28: 595/1795] train lossD: -0.058209 lossG: 0.526246\n",
      "[28: 600/1795] train lossD: -0.048719 lossG: 0.641337\n",
      "[28: 605/1795] train lossD: -0.023744 lossG: 0.513890\n",
      "[28: 610/1795] train lossD: 0.035428 lossG: 0.623976\n",
      "[28: 615/1795] train lossD: -0.029833 lossG: 0.635092\n",
      "[28: 620/1795] train lossD: -0.037515 lossG: 0.510278\n",
      "[28: 625/1795] train lossD: -0.043754 lossG: 0.473293\n",
      "[28: 630/1795] train lossD: -0.030690 lossG: 0.475478\n",
      "[28: 635/1795] train lossD: -0.031097 lossG: 0.512031\n",
      "[28: 640/1795] train lossD: -0.045055 lossG: 0.490203\n",
      "[28: 645/1795] train lossD: -0.001104 lossG: 0.513842\n",
      "[28: 650/1795] train lossD: 0.006878 lossG: 0.491611\n",
      "[28: 655/1795] train lossD: -0.011586 lossG: 0.556079\n",
      "[28: 660/1795] train lossD: -0.015488 lossG: 0.522402\n",
      "[28: 665/1795] train lossD: -0.014676 lossG: 0.672181\n",
      "[28: 670/1795] train lossD: 0.009524 lossG: 0.654825\n",
      "[28: 675/1795] train lossD: -0.035688 lossG: 0.553423\n",
      "[28: 680/1795] train lossD: -0.056033 lossG: 0.700954\n",
      "[28: 685/1795] train lossD: -0.033028 lossG: 0.465870\n",
      "[28: 690/1795] train lossD: -0.041741 lossG: 0.468904\n",
      "[28: 695/1795] train lossD: -0.024709 lossG: 0.460692\n",
      "[28: 700/1795] train lossD: 0.000027 lossG: 0.725249\n",
      "[28: 705/1795] train lossD: -0.026369 lossG: 0.599970\n",
      "[28: 710/1795] train lossD: 0.031191 lossG: 0.483522\n",
      "[28: 715/1795] train lossD: -0.049796 lossG: 0.474663\n",
      "[28: 720/1795] train lossD: -0.049722 lossG: 0.330200\n",
      "[28: 725/1795] train lossD: -0.078423 lossG: 0.558622\n",
      "[28: 730/1795] train lossD: -0.062717 lossG: 0.566654\n",
      "[28: 735/1795] train lossD: -0.069073 lossG: 0.477296\n",
      "[28: 740/1795] train lossD: -0.009340 lossG: 0.398411\n",
      "[28: 745/1795] train lossD: -0.061911 lossG: 0.327082\n",
      "[28: 750/1795] train lossD: -0.013763 lossG: 0.313086\n",
      "[28: 755/1795] train lossD: 0.119890 lossG: 0.275174\n",
      "[28: 760/1795] train lossD: -0.060357 lossG: 0.396902\n",
      "[28: 765/1795] train lossD: -0.076357 lossG: 0.511530\n",
      "[28: 770/1795] train lossD: -0.052058 lossG: 0.412120\n",
      "[28: 775/1795] train lossD: -0.055055 lossG: 0.570017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28: 780/1795] train lossD: 0.003950 lossG: 0.412329\n",
      "[28: 785/1795] train lossD: -0.053805 lossG: 0.449502\n",
      "[28: 790/1795] train lossD: 0.013990 lossG: 0.446561\n",
      "[28: 795/1795] train lossD: -0.002013 lossG: 0.459095\n",
      "[28: 800/1795] train lossD: -0.001518 lossG: 0.521331\n",
      "[28: 805/1795] train lossD: -0.053606 lossG: 0.591066\n",
      "[28: 810/1795] train lossD: -0.017965 lossG: 0.392807\n",
      "[28: 815/1795] train lossD: -0.010668 lossG: 0.298773\n",
      "[28: 820/1795] train lossD: -0.051493 lossG: 0.392892\n",
      "[28: 825/1795] train lossD: 0.009663 lossG: 0.491827\n",
      "[28: 830/1795] train lossD: -0.002058 lossG: 0.524606\n",
      "[28: 835/1795] train lossD: -0.043127 lossG: 0.506465\n",
      "[28: 840/1795] train lossD: -0.015004 lossG: 0.435228\n",
      "[28: 845/1795] train lossD: -0.075265 lossG: 0.435878\n",
      "[28: 850/1795] train lossD: -0.036958 lossG: 0.521057\n",
      "[28: 855/1795] train lossD: -0.046446 lossG: 0.478700\n",
      "[28: 860/1795] train lossD: 0.123036 lossG: 0.462337\n",
      "[28: 865/1795] train lossD: -0.075715 lossG: 0.417689\n",
      "[28: 870/1795] train lossD: -0.049175 lossG: 0.406658\n",
      "[28: 875/1795] train lossD: -0.016479 lossG: 0.510886\n",
      "[28: 880/1795] train lossD: -0.064585 lossG: 0.405877\n",
      "[28: 885/1795] train lossD: -0.004168 lossG: 0.331015\n",
      "[28: 890/1795] train lossD: -0.030835 lossG: 0.394196\n",
      "[28: 895/1795] train lossD: -0.025964 lossG: 0.482766\n",
      "[28: 900/1795] train lossD: -0.078255 lossG: 0.501258\n",
      "[28: 905/1795] train lossD: 0.020263 lossG: 0.418026\n",
      "[28: 910/1795] train lossD: -0.000805 lossG: 0.435085\n",
      "[28: 915/1795] train lossD: -0.022770 lossG: 0.443074\n",
      "[28: 920/1795] train lossD: -0.055266 lossG: 0.369617\n",
      "[28: 925/1795] train lossD: -0.044099 lossG: 0.425526\n",
      "[28: 930/1795] train lossD: 0.018545 lossG: 0.506942\n",
      "[28: 935/1795] train lossD: -0.063479 lossG: 0.424699\n",
      "[28: 940/1795] train lossD: -0.035020 lossG: 0.541342\n",
      "[28: 945/1795] train lossD: -0.087774 lossG: 0.518610\n",
      "[28: 950/1795] train lossD: -0.067238 lossG: 0.436991\n",
      "[28: 955/1795] train lossD: -0.052068 lossG: 0.383071\n",
      "[28: 960/1795] train lossD: -0.080558 lossG: 0.442061\n",
      "[28: 965/1795] train lossD: 0.013976 lossG: 0.436893\n",
      "[28: 970/1795] train lossD: -0.017892 lossG: 0.389427\n",
      "[28: 975/1795] train lossD: -0.067526 lossG: 0.349063\n",
      "[28: 980/1795] train lossD: -0.042503 lossG: 0.300893\n",
      "[28: 985/1795] train lossD: -0.052178 lossG: 0.471596\n",
      "[28: 990/1795] train lossD: -0.053439 lossG: 0.424118\n",
      "[28: 995/1795] train lossD: -0.025846 lossG: 0.427981\n",
      "[28: 1000/1795] train lossD: -0.000024 lossG: 0.478071\n",
      "[28: 1005/1795] train lossD: -0.012791 lossG: 0.503882\n",
      "[28: 1010/1795] train lossD: -0.053391 lossG: 0.438277\n",
      "[28: 1015/1795] train lossD: -0.068288 lossG: 0.511010\n",
      "[28: 1020/1795] train lossD: -0.032487 lossG: 0.410495\n",
      "[28: 1025/1795] train lossD: -0.051618 lossG: 0.477868\n",
      "[28: 1030/1795] train lossD: 0.018152 lossG: 0.531503\n",
      "[28: 1035/1795] train lossD: -0.044223 lossG: 0.570553\n",
      "[28: 1040/1795] train lossD: -0.018011 lossG: 0.520567\n",
      "[28: 1045/1795] train lossD: -0.090501 lossG: 0.561780\n",
      "[28: 1050/1795] train lossD: -0.095580 lossG: 0.483696\n",
      "[28: 1055/1795] train lossD: -0.009165 lossG: 0.692712\n",
      "[28: 1060/1795] train lossD: -0.043531 lossG: 0.707922\n",
      "[28: 1065/1795] train lossD: 0.046681 lossG: 0.590311\n",
      "[28: 1070/1795] train lossD: -0.032977 lossG: 0.562596\n",
      "[28: 1075/1795] train lossD: -0.004679 lossG: 0.501137\n",
      "[28: 1080/1795] train lossD: -0.045846 lossG: 0.454105\n",
      "[28: 1085/1795] train lossD: 0.003795 lossG: 0.608572\n",
      "[28: 1090/1795] train lossD: -0.039934 lossG: 0.477807\n",
      "[28: 1095/1795] train lossD: -0.028837 lossG: 0.487036\n",
      "[28: 1100/1795] train lossD: 0.133802 lossG: 0.432921\n",
      "[28: 1105/1795] train lossD: -0.032029 lossG: 0.527658\n",
      "[28: 1110/1795] train lossD: -0.065242 lossG: 0.490691\n",
      "[28: 1115/1795] train lossD: -0.054119 lossG: 0.542574\n",
      "[28: 1120/1795] train lossD: -0.040985 lossG: 0.562516\n",
      "[28: 1125/1795] train lossD: -0.042567 lossG: 0.654993\n",
      "[28: 1130/1795] train lossD: -0.039989 lossG: 0.593012\n",
      "[28: 1135/1795] train lossD: -0.035898 lossG: 0.517626\n",
      "[28: 1140/1795] train lossD: -0.062976 lossG: 0.603583\n",
      "[28: 1145/1795] train lossD: -0.051704 lossG: 0.431554\n",
      "[28: 1150/1795] train lossD: -0.026646 lossG: 0.538473\n",
      "[28: 1155/1795] train lossD: -0.041467 lossG: 0.487405\n",
      "[28: 1160/1795] train lossD: -0.024556 lossG: 0.572935\n",
      "[28: 1165/1795] train lossD: -0.004508 lossG: 0.376220\n",
      "[28: 1170/1795] train lossD: -0.033140 lossG: 0.567613\n",
      "[28: 1175/1795] train lossD: 0.018104 lossG: 0.595842\n",
      "[28: 1180/1795] train lossD: -0.050730 lossG: 0.465879\n",
      "[28: 1185/1795] train lossD: -0.084949 lossG: 0.516216\n",
      "[28: 1190/1795] train lossD: 0.008422 lossG: 0.647934\n",
      "[28: 1195/1795] train lossD: -0.161255 lossG: 0.723818\n",
      "[28: 1200/1795] train lossD: -0.004822 lossG: 0.542054\n",
      "[28: 1205/1795] train lossD: -0.066898 lossG: 0.572428\n",
      "[28: 1210/1795] train lossD: -0.043222 lossG: 0.570643\n",
      "[28: 1215/1795] train lossD: -0.093332 lossG: 0.716892\n",
      "[28: 1220/1795] train lossD: -0.017040 lossG: 0.586803\n",
      "[28: 1225/1795] train lossD: -0.030493 lossG: 0.532285\n",
      "[28: 1230/1795] train lossD: -0.054636 lossG: 0.570941\n",
      "[28: 1235/1795] train lossD: -0.042485 lossG: 0.419630\n",
      "[28: 1240/1795] train lossD: -0.062550 lossG: 0.653410\n",
      "[28: 1245/1795] train lossD: -0.021819 lossG: 0.585819\n",
      "[28: 1250/1795] train lossD: -0.063931 lossG: 0.561428\n",
      "[28: 1255/1795] train lossD: -0.064185 lossG: 0.519610\n",
      "[28: 1260/1795] train lossD: -0.029129 lossG: 0.571406\n",
      "[28: 1265/1795] train lossD: -0.042764 lossG: 0.360703\n",
      "[28: 1270/1795] train lossD: -0.063021 lossG: 0.507799\n",
      "[28: 1275/1795] train lossD: -0.066334 lossG: 0.549897\n",
      "[28: 1280/1795] train lossD: -0.047248 lossG: 0.649822\n",
      "[28: 1285/1795] train lossD: -0.033547 lossG: 0.702295\n",
      "[28: 1290/1795] train lossD: -0.065480 lossG: 0.382457\n",
      "[28: 1295/1795] train lossD: 0.129823 lossG: 0.582944\n",
      "[28: 1300/1795] train lossD: 0.082274 lossG: 0.462270\n",
      "[28: 1305/1795] train lossD: -0.035462 lossG: 0.549183\n",
      "[28: 1310/1795] train lossD: -0.063943 lossG: 0.627020\n",
      "[28: 1315/1795] train lossD: 0.004491 lossG: 0.497990\n",
      "[28: 1320/1795] train lossD: 0.010335 lossG: 0.598442\n",
      "[28: 1325/1795] train lossD: -0.040436 lossG: 0.588936\n",
      "[28: 1330/1795] train lossD: -0.020365 lossG: 0.601229\n",
      "[28: 1335/1795] train lossD: -0.036294 lossG: 0.497315\n",
      "[28: 1340/1795] train lossD: -0.070343 lossG: 0.600302\n",
      "[28: 1345/1795] train lossD: -0.086534 lossG: 0.411151\n",
      "[28: 1350/1795] train lossD: -0.053520 lossG: 0.600027\n",
      "[28: 1355/1795] train lossD: -0.049484 lossG: 0.387534\n",
      "[28: 1360/1795] train lossD: -0.030830 lossG: 0.567311\n",
      "[28: 1365/1795] train lossD: -0.045361 lossG: 0.597387\n",
      "[28: 1370/1795] train lossD: -0.052614 lossG: 0.445478\n",
      "[28: 1375/1795] train lossD: -0.040172 lossG: 0.515909\n",
      "[28: 1380/1795] train lossD: 0.004115 lossG: 0.454020\n",
      "[28: 1385/1795] train lossD: -0.081238 lossG: 0.616114\n",
      "[28: 1390/1795] train lossD: -0.036862 lossG: 0.474761\n",
      "[28: 1395/1795] train lossD: -0.076678 lossG: 0.498633\n",
      "[28: 1400/1795] train lossD: -0.087971 lossG: 0.577150\n",
      "[28: 1405/1795] train lossD: -0.028168 lossG: 0.559856\n",
      "[28: 1410/1795] train lossD: -0.048367 lossG: 0.529446\n",
      "[28: 1415/1795] train lossD: -0.042665 lossG: 0.433046\n",
      "[28: 1420/1795] train lossD: -0.114160 lossG: 0.578940\n",
      "[28: 1425/1795] train lossD: -0.050070 lossG: 0.583433\n",
      "[28: 1430/1795] train lossD: -0.045673 lossG: 0.595738\n",
      "[28: 1435/1795] train lossD: -0.013656 lossG: 0.646254\n",
      "[28: 1440/1795] train lossD: -0.021881 lossG: 0.635840\n",
      "[28: 1445/1795] train lossD: 0.143150 lossG: 0.461021\n",
      "[28: 1450/1795] train lossD: -0.010361 lossG: 0.442067\n",
      "[28: 1455/1795] train lossD: -0.039626 lossG: 0.370267\n",
      "[28: 1460/1795] train lossD: -0.034807 lossG: 0.631166\n",
      "[28: 1465/1795] train lossD: -0.092214 lossG: 0.548698\n",
      "[28: 1470/1795] train lossD: -0.067671 lossG: 0.522610\n",
      "[28: 1475/1795] train lossD: -0.041607 lossG: 0.416260\n",
      "[28: 1480/1795] train lossD: -0.057036 lossG: 0.321268\n",
      "[28: 1485/1795] train lossD: -0.052955 lossG: 0.642682\n",
      "[28: 1490/1795] train lossD: 0.029620 lossG: 0.511880\n",
      "[28: 1495/1795] train lossD: -0.065998 lossG: 0.502960\n",
      "[28: 1500/1795] train lossD: -0.071966 lossG: 0.591150\n",
      "[28: 1505/1795] train lossD: -0.042706 lossG: 0.602138\n",
      "[28: 1510/1795] train lossD: -0.064756 lossG: 0.421226\n",
      "[28: 1515/1795] train lossD: -0.010424 lossG: 0.405701\n",
      "[28: 1520/1795] train lossD: -0.068488 lossG: 0.610348\n",
      "[28: 1525/1795] train lossD: -0.096440 lossG: 0.679990\n",
      "[28: 1530/1795] train lossD: -0.065241 lossG: 0.496583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28: 1535/1795] train lossD: -0.013533 lossG: 0.493431\n",
      "[28: 1540/1795] train lossD: -0.052588 lossG: 0.498128\n",
      "[28: 1545/1795] train lossD: 0.014689 lossG: 0.530448\n",
      "[28: 1550/1795] train lossD: -0.024900 lossG: 0.541861\n",
      "[28: 1555/1795] train lossD: 0.194900 lossG: 0.710702\n",
      "[28: 1560/1795] train lossD: -0.043851 lossG: 0.693839\n",
      "[28: 1565/1795] train lossD: -0.080285 lossG: 0.608520\n",
      "[28: 1570/1795] train lossD: -0.054225 lossG: 0.571116\n",
      "[28: 1575/1795] train lossD: -0.052615 lossG: 0.619705\n",
      "[28: 1580/1795] train lossD: 0.029652 lossG: 0.489288\n",
      "[28: 1585/1795] train lossD: -0.073874 lossG: 0.451068\n",
      "[28: 1590/1795] train lossD: 0.020505 lossG: 0.453713\n",
      "[28: 1595/1795] train lossD: -0.055074 lossG: 0.472399\n",
      "[28: 1600/1795] train lossD: -0.030440 lossG: 0.461638\n",
      "[28: 1605/1795] train lossD: -0.098707 lossG: 0.451589\n",
      "[28: 1610/1795] train lossD: -0.033488 lossG: 0.403385\n",
      "[28: 1615/1795] train lossD: -0.024092 lossG: 0.441528\n",
      "[28: 1620/1795] train lossD: -0.036855 lossG: 0.470912\n",
      "[28: 1625/1795] train lossD: -0.063639 lossG: 0.512544\n",
      "[28: 1630/1795] train lossD: -0.031853 lossG: 0.487404\n",
      "[28: 1635/1795] train lossD: -0.033239 lossG: 0.563595\n",
      "[28: 1640/1795] train lossD: -0.062894 lossG: 0.522244\n",
      "[28: 1645/1795] train lossD: 0.019431 lossG: 0.544083\n",
      "[28: 1650/1795] train lossD: 0.083695 lossG: 0.481723\n",
      "[28: 1655/1795] train lossD: -0.065415 lossG: 0.434935\n",
      "[28: 1660/1795] train lossD: -0.037217 lossG: 0.413202\n",
      "[28: 1665/1795] train lossD: -0.048785 lossG: 0.569042\n",
      "[28: 1670/1795] train lossD: -0.017641 lossG: 0.600893\n",
      "[28: 1675/1795] train lossD: -0.040015 lossG: 0.652186\n",
      "[28: 1680/1795] train lossD: -0.043000 lossG: 0.528360\n",
      "[28: 1685/1795] train lossD: -0.141040 lossG: 0.508305\n",
      "[28: 1690/1795] train lossD: -0.032469 lossG: 0.437701\n",
      "[28: 1695/1795] train lossD: 0.036492 lossG: 0.503755\n",
      "[28: 1700/1795] train lossD: -0.031894 lossG: 0.494043\n",
      "[28: 1705/1795] train lossD: -0.018608 lossG: 0.390947\n",
      "[28: 1710/1795] train lossD: 0.040999 lossG: 0.516873\n",
      "[28: 1715/1795] train lossD: -0.021260 lossG: 0.438264\n",
      "[28: 1720/1795] train lossD: -0.082524 lossG: 0.430334\n",
      "[28: 1725/1795] train lossD: -0.063157 lossG: 0.686363\n",
      "[28: 1730/1795] train lossD: -0.078179 lossG: 0.556075\n",
      "[28: 1735/1795] train lossD: -0.075260 lossG: 0.475120\n",
      "[28: 1740/1795] train lossD: -0.006337 lossG: 0.442447\n",
      "[28: 1745/1795] train lossD: -0.055809 lossG: 0.455075\n",
      "[28: 1750/1795] train lossD: -0.022780 lossG: 0.485652\n",
      "[28: 1755/1795] train lossD: -0.030677 lossG: 0.490167\n",
      "[28: 1760/1795] train lossD: -0.112145 lossG: 0.583996\n",
      "[28: 1765/1795] train lossD: 0.148409 lossG: 0.579985\n",
      "[28: 1770/1795] train lossD: -0.047200 lossG: 0.476656\n",
      "[28: 1775/1795] train lossD: -0.029269 lossG: 0.452532\n",
      "[28: 1780/1795] train lossD: -0.024369 lossG: 0.475672\n",
      "[28: 1785/1795] train lossD: -0.089864 lossG: 0.528626\n",
      "[28: 1790/1795] train lossD: -0.102499 lossG: 0.417213\n",
      "0.03937861695885658\n",
      "[29: 0/1795] train lossD: -0.013578 lossG: 0.448670\n",
      "[29: 5/1795] train lossD: -0.072208 lossG: 0.647637\n",
      "[29: 10/1795] train lossD: -0.048385 lossG: 0.451687\n",
      "[29: 15/1795] train lossD: -0.110141 lossG: 0.543038\n",
      "[29: 20/1795] train lossD: -0.051955 lossG: 0.463399\n",
      "[29: 25/1795] train lossD: -0.048563 lossG: 0.273692\n",
      "[29: 30/1795] train lossD: -0.072498 lossG: 0.312292\n",
      "[29: 35/1795] train lossD: -0.014957 lossG: 0.506794\n",
      "[29: 40/1795] train lossD: -0.085014 lossG: 0.434972\n",
      "[29: 45/1795] train lossD: -0.046762 lossG: 0.529613\n",
      "[29: 50/1795] train lossD: -0.021756 lossG: 0.403249\n",
      "[29: 55/1795] train lossD: -0.010293 lossG: 0.452581\n",
      "[29: 60/1795] train lossD: -0.004455 lossG: 0.546650\n",
      "[29: 65/1795] train lossD: -0.068602 lossG: 0.597173\n",
      "[29: 70/1795] train lossD: -0.044499 lossG: 0.680264\n",
      "[29: 75/1795] train lossD: -0.042396 lossG: 0.596019\n",
      "[29: 80/1795] train lossD: 0.022921 lossG: 0.432820\n",
      "[29: 85/1795] train lossD: -0.039160 lossG: 0.506873\n",
      "[29: 90/1795] train lossD: -0.046453 lossG: 0.456977\n",
      "[29: 95/1795] train lossD: -0.030873 lossG: 0.536338\n",
      "[29: 100/1795] train lossD: -0.063710 lossG: 0.617673\n",
      "[29: 105/1795] train lossD: 0.028147 lossG: 0.393195\n",
      "[29: 110/1795] train lossD: -0.037134 lossG: 0.380374\n",
      "[29: 115/1795] train lossD: -0.070458 lossG: 0.393662\n",
      "[29: 120/1795] train lossD: -0.066995 lossG: 0.439596\n",
      "[29: 125/1795] train lossD: -0.075333 lossG: 0.391971\n",
      "[29: 130/1795] train lossD: -0.076414 lossG: 0.492797\n",
      "[29: 135/1795] train lossD: -0.016479 lossG: 0.385212\n",
      "[29: 140/1795] train lossD: -0.008432 lossG: 0.428355\n",
      "[29: 145/1795] train lossD: -0.112432 lossG: 0.495742\n",
      "[29: 150/1795] train lossD: -0.054265 lossG: 0.464532\n",
      "[29: 155/1795] train lossD: 0.008762 lossG: 0.541490\n",
      "[29: 160/1795] train lossD: -0.077653 lossG: 0.550671\n",
      "[29: 165/1795] train lossD: -0.030450 lossG: 0.468803\n",
      "[29: 170/1795] train lossD: 0.023256 lossG: 0.409209\n",
      "[29: 175/1795] train lossD: -0.116232 lossG: 0.328486\n",
      "[29: 180/1795] train lossD: -0.056028 lossG: 0.495060\n",
      "[29: 185/1795] train lossD: -0.055246 lossG: 0.507381\n",
      "[29: 190/1795] train lossD: -0.077029 lossG: 0.469775\n",
      "[29: 195/1795] train lossD: 0.154957 lossG: 0.575863\n",
      "[29: 200/1795] train lossD: -0.002693 lossG: 0.480486\n",
      "[29: 205/1795] train lossD: -0.051547 lossG: 0.392408\n",
      "[29: 210/1795] train lossD: 0.035912 lossG: 0.494851\n",
      "[29: 215/1795] train lossD: -0.040315 lossG: 0.397091\n",
      "[29: 220/1795] train lossD: -0.061780 lossG: 0.396340\n",
      "[29: 225/1795] train lossD: -0.042638 lossG: 0.427783\n",
      "[29: 230/1795] train lossD: 0.214543 lossG: 0.370016\n",
      "[29: 235/1795] train lossD: -0.052223 lossG: 0.378257\n",
      "[29: 240/1795] train lossD: -0.047955 lossG: 0.407535\n",
      "[29: 245/1795] train lossD: -0.033348 lossG: 0.312536\n",
      "[29: 250/1795] train lossD: -0.003152 lossG: 0.423841\n",
      "[29: 255/1795] train lossD: -0.010130 lossG: 0.470735\n",
      "[29: 260/1795] train lossD: -0.001184 lossG: 0.510343\n",
      "[29: 265/1795] train lossD: -0.043667 lossG: 0.516530\n",
      "[29: 270/1795] train lossD: -0.064688 lossG: 0.608409\n",
      "[29: 275/1795] train lossD: -0.017689 lossG: 0.400521\n",
      "[29: 280/1795] train lossD: 0.016756 lossG: 0.523179\n",
      "[29: 285/1795] train lossD: -0.053784 lossG: 0.475304\n",
      "[29: 290/1795] train lossD: -0.074877 lossG: 0.513456\n",
      "[29: 295/1795] train lossD: -0.060520 lossG: 0.385558\n",
      "[29: 300/1795] train lossD: -0.015476 lossG: 0.526273\n",
      "[29: 305/1795] train lossD: -0.047104 lossG: 0.458979\n",
      "[29: 310/1795] train lossD: -0.037866 lossG: 0.438017\n",
      "[29: 315/1795] train lossD: -0.010990 lossG: 0.479543\n",
      "[29: 320/1795] train lossD: -0.077496 lossG: 0.500194\n",
      "[29: 325/1795] train lossD: -0.016232 lossG: 0.579407\n",
      "[29: 330/1795] train lossD: -0.153526 lossG: 0.454654\n",
      "[29: 335/1795] train lossD: -0.024822 lossG: 0.467256\n",
      "[29: 340/1795] train lossD: 0.023738 lossG: 0.399332\n",
      "[29: 345/1795] train lossD: -0.028327 lossG: 0.422175\n",
      "[29: 350/1795] train lossD: -0.026241 lossG: 0.535513\n",
      "[29: 355/1795] train lossD: -0.005762 lossG: 0.557007\n",
      "[29: 360/1795] train lossD: -0.015842 lossG: 0.475228\n",
      "[29: 365/1795] train lossD: -0.023490 lossG: 0.542001\n",
      "[29: 370/1795] train lossD: -0.008033 lossG: 0.423225\n",
      "[29: 375/1795] train lossD: 0.050836 lossG: 0.466466\n",
      "[29: 380/1795] train lossD: -0.049746 lossG: 0.446333\n",
      "[29: 385/1795] train lossD: 0.011160 lossG: 0.369231\n",
      "[29: 390/1795] train lossD: 0.007044 lossG: 0.454871\n",
      "[29: 395/1795] train lossD: 0.031937 lossG: 0.370302\n",
      "[29: 400/1795] train lossD: -0.070120 lossG: 0.271901\n",
      "[29: 405/1795] train lossD: -0.077155 lossG: 0.330519\n",
      "[29: 410/1795] train lossD: -0.068223 lossG: 0.427801\n",
      "[29: 415/1795] train lossD: -0.010934 lossG: 0.336489\n",
      "[29: 420/1795] train lossD: -0.084216 lossG: 0.383978\n",
      "[29: 425/1795] train lossD: 0.009911 lossG: 0.437096\n",
      "[29: 430/1795] train lossD: -0.014834 lossG: 0.428671\n",
      "[29: 435/1795] train lossD: -0.017101 lossG: 0.388135\n",
      "[29: 440/1795] train lossD: -0.059740 lossG: 0.490097\n",
      "[29: 445/1795] train lossD: -0.064704 lossG: 0.465285\n",
      "[29: 450/1795] train lossD: -0.136672 lossG: 0.421996\n",
      "[29: 455/1795] train lossD: -0.025157 lossG: 0.599256\n",
      "[29: 460/1795] train lossD: 0.136906 lossG: 0.624880\n",
      "[29: 465/1795] train lossD: -0.023607 lossG: 0.583806\n",
      "[29: 470/1795] train lossD: 0.009699 lossG: 0.494084\n",
      "[29: 475/1795] train lossD: -0.031354 lossG: 0.462817\n",
      "[29: 480/1795] train lossD: -0.073828 lossG: 0.631278\n",
      "[29: 485/1795] train lossD: 0.058811 lossG: 0.499799\n",
      "[29: 490/1795] train lossD: -0.083947 lossG: 0.374835\n",
      "[29: 495/1795] train lossD: -0.016828 lossG: 0.495701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29: 500/1795] train lossD: -0.024060 lossG: 0.429657\n",
      "[29: 505/1795] train lossD: 0.019389 lossG: 0.531169\n",
      "[29: 510/1795] train lossD: -0.034160 lossG: 0.464504\n",
      "[29: 515/1795] train lossD: -0.038182 lossG: 0.527086\n",
      "[29: 520/1795] train lossD: -0.003538 lossG: 0.408677\n",
      "[29: 525/1795] train lossD: 0.072502 lossG: 0.575331\n",
      "[29: 530/1795] train lossD: -0.013812 lossG: 0.455067\n",
      "[29: 535/1795] train lossD: -0.006009 lossG: 0.445223\n",
      "[29: 540/1795] train lossD: -0.154052 lossG: 0.513373\n",
      "[29: 545/1795] train lossD: -0.005409 lossG: 0.470302\n",
      "[29: 550/1795] train lossD: -0.024165 lossG: 0.526904\n",
      "[29: 555/1795] train lossD: -0.089679 lossG: 0.503636\n",
      "[29: 560/1795] train lossD: -0.002100 lossG: 0.491406\n",
      "[29: 565/1795] train lossD: -0.027020 lossG: 0.564512\n",
      "[29: 570/1795] train lossD: -0.043632 lossG: 0.513456\n",
      "[29: 575/1795] train lossD: 0.074943 lossG: 0.623375\n",
      "[29: 580/1795] train lossD: -0.006660 lossG: 0.439501\n",
      "[29: 585/1795] train lossD: -0.026359 lossG: 0.505490\n",
      "[29: 590/1795] train lossD: -0.075328 lossG: 0.622168\n",
      "[29: 595/1795] train lossD: -0.060776 lossG: 0.533749\n",
      "[29: 600/1795] train lossD: -0.021031 lossG: 0.393590\n",
      "[29: 605/1795] train lossD: -0.004123 lossG: 0.621204\n",
      "[29: 610/1795] train lossD: -0.057424 lossG: 0.540684\n",
      "[29: 615/1795] train lossD: -0.047870 lossG: 0.386705\n",
      "[29: 620/1795] train lossD: -0.062055 lossG: 0.344433\n",
      "[29: 625/1795] train lossD: -0.053989 lossG: 0.412941\n",
      "[29: 630/1795] train lossD: 0.026984 lossG: 0.442461\n",
      "[29: 635/1795] train lossD: -0.024926 lossG: 0.554350\n",
      "[29: 640/1795] train lossD: -0.014236 lossG: 0.564311\n",
      "[29: 645/1795] train lossD: 0.018183 lossG: 0.587160\n",
      "[29: 650/1795] train lossD: -0.036145 lossG: 0.635700\n",
      "[29: 655/1795] train lossD: 0.018920 lossG: 0.333878\n",
      "[29: 660/1795] train lossD: -0.027536 lossG: 0.556493\n",
      "[29: 665/1795] train lossD: -0.055986 lossG: 0.578009\n",
      "[29: 670/1795] train lossD: -0.049103 lossG: 0.539108\n",
      "[29: 675/1795] train lossD: -0.104170 lossG: 0.560469\n",
      "[29: 680/1795] train lossD: 0.132986 lossG: 0.532826\n",
      "[29: 685/1795] train lossD: -0.084660 lossG: 0.471603\n",
      "[29: 690/1795] train lossD: 0.043698 lossG: 0.293450\n",
      "[29: 695/1795] train lossD: 0.002810 lossG: 0.340390\n",
      "[29: 700/1795] train lossD: -0.038130 lossG: 0.353721\n",
      "[29: 705/1795] train lossD: -0.058802 lossG: 0.603350\n",
      "[29: 710/1795] train lossD: -0.041385 lossG: 0.401881\n",
      "[29: 715/1795] train lossD: 0.021111 lossG: 0.666338\n",
      "[29: 720/1795] train lossD: -0.025654 lossG: 0.673938\n",
      "[29: 725/1795] train lossD: -0.057564 lossG: 0.697957\n",
      "[29: 730/1795] train lossD: -0.035870 lossG: 0.689059\n",
      "[29: 735/1795] train lossD: -0.039494 lossG: 0.676637\n",
      "[29: 740/1795] train lossD: 0.024929 lossG: 0.486900\n",
      "[29: 745/1795] train lossD: -0.050162 lossG: 0.391294\n",
      "[29: 750/1795] train lossD: 0.019311 lossG: 0.506608\n",
      "[29: 755/1795] train lossD: -0.028999 lossG: 0.553450\n",
      "[29: 760/1795] train lossD: -0.046692 lossG: 0.631912\n",
      "[29: 765/1795] train lossD: -0.001639 lossG: 0.385589\n",
      "[29: 770/1795] train lossD: 0.072587 lossG: 0.376872\n",
      "[29: 775/1795] train lossD: -0.002390 lossG: 0.365653\n",
      "[29: 780/1795] train lossD: -0.065956 lossG: 0.354713\n",
      "[29: 785/1795] train lossD: -0.124742 lossG: 0.424027\n",
      "[29: 790/1795] train lossD: -0.033480 lossG: 0.453295\n",
      "[29: 795/1795] train lossD: 0.031427 lossG: 0.441252\n",
      "[29: 800/1795] train lossD: -0.035512 lossG: 0.403314\n",
      "[29: 805/1795] train lossD: 0.056381 lossG: 0.545700\n",
      "[29: 810/1795] train lossD: 0.038453 lossG: 0.592070\n",
      "[29: 815/1795] train lossD: 0.035618 lossG: 0.470979\n",
      "[29: 820/1795] train lossD: -0.004800 lossG: 0.418285\n",
      "[29: 825/1795] train lossD: -0.064756 lossG: 0.608368\n",
      "[29: 830/1795] train lossD: -0.060628 lossG: 0.569941\n",
      "[29: 835/1795] train lossD: -0.026659 lossG: 0.252771\n",
      "[29: 840/1795] train lossD: 0.093225 lossG: 0.439919\n",
      "[29: 845/1795] train lossD: -0.017727 lossG: 0.474624\n",
      "[29: 850/1795] train lossD: -0.013722 lossG: 0.422094\n",
      "[29: 855/1795] train lossD: -0.019013 lossG: 0.416992\n",
      "[29: 860/1795] train lossD: 0.121011 lossG: 0.503530\n",
      "[29: 865/1795] train lossD: -0.070849 lossG: 0.251918\n",
      "[29: 870/1795] train lossD: -0.041567 lossG: 0.457791\n",
      "[29: 875/1795] train lossD: -0.060438 lossG: 0.454158\n",
      "[29: 880/1795] train lossD: -0.037536 lossG: 0.302701\n",
      "[29: 885/1795] train lossD: 0.030088 lossG: 0.423689\n",
      "[29: 890/1795] train lossD: -0.020549 lossG: 0.363864\n",
      "[29: 895/1795] train lossD: -0.041750 lossG: 0.458804\n",
      "[29: 900/1795] train lossD: 0.044466 lossG: 0.361132\n",
      "[29: 905/1795] train lossD: -0.159589 lossG: 0.495071\n",
      "[29: 910/1795] train lossD: -0.073750 lossG: 0.224322\n",
      "[29: 915/1795] train lossD: -0.010191 lossG: 0.350485\n",
      "[29: 920/1795] train lossD: -0.027926 lossG: 0.384388\n",
      "[29: 925/1795] train lossD: -0.024581 lossG: 0.420017\n",
      "[29: 930/1795] train lossD: -0.096085 lossG: 0.527623\n",
      "[29: 935/1795] train lossD: 0.015802 lossG: 0.394927\n",
      "[29: 940/1795] train lossD: -0.031197 lossG: 0.486319\n",
      "[29: 945/1795] train lossD: -0.102151 lossG: 0.392747\n",
      "[29: 950/1795] train lossD: -0.058857 lossG: 0.462104\n",
      "[29: 955/1795] train lossD: -0.023730 lossG: 0.331255\n",
      "[29: 960/1795] train lossD: 0.007134 lossG: 0.394922\n",
      "[29: 965/1795] train lossD: 0.059677 lossG: 0.514131\n",
      "[29: 970/1795] train lossD: -0.050626 lossG: 0.373000\n",
      "[29: 975/1795] train lossD: -0.033558 lossG: 0.327852\n",
      "[29: 980/1795] train lossD: 0.029096 lossG: 0.371784\n",
      "[29: 985/1795] train lossD: -0.023360 lossG: 0.438011\n",
      "[29: 990/1795] train lossD: -0.028353 lossG: 0.446206\n",
      "[29: 995/1795] train lossD: -0.020697 lossG: 0.464277\n",
      "[29: 1000/1795] train lossD: -0.059680 lossG: 0.542181\n",
      "[29: 1005/1795] train lossD: 0.000768 lossG: 0.568503\n",
      "[29: 1010/1795] train lossD: -0.023446 lossG: 0.425293\n",
      "[29: 1015/1795] train lossD: -0.094177 lossG: 0.335919\n",
      "[29: 1020/1795] train lossD: -0.061846 lossG: 0.315746\n",
      "[29: 1025/1795] train lossD: -0.076011 lossG: 0.338845\n",
      "[29: 1030/1795] train lossD: 0.018808 lossG: 0.384552\n",
      "[29: 1035/1795] train lossD: -0.054497 lossG: 0.526842\n",
      "[29: 1040/1795] train lossD: 0.002084 lossG: 0.447640\n",
      "[29: 1045/1795] train lossD: 0.010906 lossG: 0.365457\n",
      "[29: 1050/1795] train lossD: -0.168519 lossG: 0.526680\n",
      "[29: 1055/1795] train lossD: -0.045523 lossG: 0.244914\n",
      "[29: 1060/1795] train lossD: -0.031965 lossG: 0.332008\n",
      "[29: 1065/1795] train lossD: -0.009752 lossG: 0.317137\n",
      "[29: 1070/1795] train lossD: -0.039106 lossG: 0.480689\n",
      "[29: 1075/1795] train lossD: -0.067012 lossG: 0.465007\n",
      "[29: 1080/1795] train lossD: -0.059298 lossG: 0.425314\n",
      "[29: 1085/1795] train lossD: -0.089280 lossG: 0.502521\n",
      "[29: 1090/1795] train lossD: -0.004589 lossG: 0.497031\n",
      "[29: 1095/1795] train lossD: -0.089599 lossG: 0.375887\n",
      "[29: 1100/1795] train lossD: 0.027917 lossG: 0.395693\n",
      "[29: 1105/1795] train lossD: 0.007408 lossG: 0.482850\n",
      "[29: 1110/1795] train lossD: -0.006163 lossG: 0.507920\n",
      "[29: 1115/1795] train lossD: -0.017427 lossG: 0.505937\n",
      "[29: 1120/1795] train lossD: -0.109012 lossG: 0.680822\n",
      "[29: 1125/1795] train lossD: -0.003242 lossG: 0.520276\n",
      "[29: 1130/1795] train lossD: 0.027046 lossG: 0.406461\n",
      "[29: 1135/1795] train lossD: -0.114319 lossG: 0.254957\n",
      "[29: 1140/1795] train lossD: -0.037237 lossG: 0.392170\n",
      "[29: 1145/1795] train lossD: -0.047437 lossG: 0.440403\n",
      "[29: 1150/1795] train lossD: -0.017671 lossG: 0.485505\n",
      "[29: 1155/1795] train lossD: -0.053454 lossG: 0.437549\n",
      "[29: 1160/1795] train lossD: 0.036680 lossG: 0.352246\n",
      "[29: 1165/1795] train lossD: -0.044492 lossG: 0.315458\n",
      "[29: 1170/1795] train lossD: -0.066879 lossG: 0.260767\n",
      "[29: 1175/1795] train lossD: 0.031993 lossG: 0.374904\n",
      "[29: 1180/1795] train lossD: -0.051205 lossG: 0.473943\n",
      "[29: 1185/1795] train lossD: -0.055502 lossG: 0.459438\n",
      "[29: 1190/1795] train lossD: 0.007474 lossG: 0.438214\n",
      "[29: 1195/1795] train lossD: -0.054156 lossG: 0.493174\n",
      "[29: 1200/1795] train lossD: -0.037691 lossG: 0.358365\n",
      "[29: 1205/1795] train lossD: 0.129171 lossG: 0.516665\n",
      "[29: 1210/1795] train lossD: 0.007801 lossG: 0.380594\n",
      "[29: 1215/1795] train lossD: -0.013718 lossG: 0.225545\n",
      "[29: 1220/1795] train lossD: 0.017883 lossG: 0.399502\n",
      "[29: 1225/1795] train lossD: -0.041605 lossG: 0.312659\n",
      "[29: 1230/1795] train lossD: 0.052600 lossG: 0.381311\n",
      "[29: 1235/1795] train lossD: 0.003985 lossG: 0.432845\n",
      "[29: 1240/1795] train lossD: -0.054473 lossG: 0.346219\n",
      "[29: 1245/1795] train lossD: 0.040134 lossG: 0.328938\n",
      "[29: 1250/1795] train lossD: -0.013605 lossG: 0.343994\n",
      "[29: 1255/1795] train lossD: -0.036513 lossG: 0.371286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29: 1260/1795] train lossD: -0.004777 lossG: 0.299846\n",
      "[29: 1265/1795] train lossD: 0.066032 lossG: 0.459422\n",
      "[29: 1270/1795] train lossD: -0.020822 lossG: 0.301913\n",
      "[29: 1275/1795] train lossD: -0.036584 lossG: 0.254454\n",
      "[29: 1280/1795] train lossD: -0.017970 lossG: 0.276935\n",
      "[29: 1285/1795] train lossD: 0.008627 lossG: 0.307616\n",
      "[29: 1290/1795] train lossD: 0.026034 lossG: 0.406336\n",
      "[29: 1295/1795] train lossD: -0.052766 lossG: 0.212966\n",
      "[29: 1300/1795] train lossD: -0.035116 lossG: 0.302225\n",
      "[29: 1305/1795] train lossD: -0.020936 lossG: 0.270811\n",
      "[29: 1310/1795] train lossD: -0.007863 lossG: 0.407109\n",
      "[29: 1315/1795] train lossD: -0.056468 lossG: 0.237433\n",
      "[29: 1320/1795] train lossD: -0.030519 lossG: 0.371819\n",
      "[29: 1325/1795] train lossD: -0.062172 lossG: 0.301643\n",
      "[29: 1330/1795] train lossD: -0.019609 lossG: 0.411387\n",
      "[29: 1335/1795] train lossD: -0.038184 lossG: 0.488131\n",
      "[29: 1340/1795] train lossD: 0.009398 lossG: 0.419920\n",
      "[29: 1345/1795] train lossD: 0.052733 lossG: 0.446824\n",
      "[29: 1350/1795] train lossD: 0.089348 lossG: 0.389252\n",
      "[29: 1355/1795] train lossD: 0.044333 lossG: 0.323709\n",
      "[29: 1360/1795] train lossD: -0.141112 lossG: 0.264811\n",
      "[29: 1365/1795] train lossD: -0.069944 lossG: 0.239563\n",
      "[29: 1370/1795] train lossD: -0.042801 lossG: 0.323181\n",
      "[29: 1375/1795] train lossD: -0.031730 lossG: 0.304613\n",
      "[29: 1380/1795] train lossD: 0.015168 lossG: 0.380929\n",
      "[29: 1385/1795] train lossD: -0.021991 lossG: 0.416882\n",
      "[29: 1390/1795] train lossD: -0.044233 lossG: 0.300157\n",
      "[29: 1395/1795] train lossD: -0.021581 lossG: 0.260927\n",
      "[29: 1400/1795] train lossD: -0.083467 lossG: 0.536017\n",
      "[29: 1405/1795] train lossD: -0.051800 lossG: 0.512719\n",
      "[29: 1410/1795] train lossD: -0.003556 lossG: 0.378411\n",
      "[29: 1415/1795] train lossD: -0.035313 lossG: 0.350483\n",
      "[29: 1420/1795] train lossD: -0.070024 lossG: 0.369921\n",
      "[29: 1425/1795] train lossD: -0.040388 lossG: 0.515913\n",
      "[29: 1430/1795] train lossD: -0.019272 lossG: 0.297706\n",
      "[29: 1435/1795] train lossD: -0.000420 lossG: 0.272320\n",
      "[29: 1440/1795] train lossD: -0.052347 lossG: 0.308429\n",
      "[29: 1445/1795] train lossD: -0.073885 lossG: 0.307826\n",
      "[29: 1450/1795] train lossD: -0.001655 lossG: 0.283580\n",
      "[29: 1455/1795] train lossD: -0.045339 lossG: 0.238390\n",
      "[29: 1460/1795] train lossD: 0.025305 lossG: 0.312049\n",
      "[29: 1465/1795] train lossD: -0.029636 lossG: 0.392893\n",
      "[29: 1470/1795] train lossD: -0.042350 lossG: 0.465689\n",
      "[29: 1475/1795] train lossD: -0.019022 lossG: 0.360651\n",
      "[29: 1480/1795] train lossD: -0.026119 lossG: 0.363519\n",
      "[29: 1485/1795] train lossD: -0.029281 lossG: 0.359402\n",
      "[29: 1490/1795] train lossD: 0.722853 lossG: 0.294586\n",
      "[29: 1495/1795] train lossD: 0.003797 lossG: 0.374185\n",
      "[29: 1500/1795] train lossD: 0.013993 lossG: 0.352739\n",
      "[29: 1505/1795] train lossD: -0.045032 lossG: 0.310050\n",
      "[29: 1510/1795] train lossD: -0.059781 lossG: 0.336704\n",
      "[29: 1515/1795] train lossD: -0.127383 lossG: 0.275313\n",
      "[29: 1520/1795] train lossD: 0.031605 lossG: 0.351649\n",
      "[29: 1525/1795] train lossD: -0.023241 lossG: 0.399174\n",
      "[29: 1530/1795] train lossD: -0.053055 lossG: 0.266260\n",
      "[29: 1535/1795] train lossD: 0.160806 lossG: 0.165852\n",
      "[29: 1540/1795] train lossD: -0.028035 lossG: 0.203475\n",
      "[29: 1545/1795] train lossD: -0.019314 lossG: 0.247707\n",
      "[29: 1550/1795] train lossD: -0.067256 lossG: 0.235047\n",
      "[29: 1555/1795] train lossD: -0.020358 lossG: 0.297551\n",
      "[29: 1560/1795] train lossD: 0.250072 lossG: 0.581239\n",
      "[29: 1565/1795] train lossD: 0.005117 lossG: 0.637944\n",
      "[29: 1570/1795] train lossD: -0.057316 lossG: 0.629672\n",
      "[29: 1575/1795] train lossD: -0.071698 lossG: 0.594946\n",
      "[29: 1580/1795] train lossD: -0.075131 lossG: 0.526958\n",
      "[29: 1585/1795] train lossD: -0.100671 lossG: 0.438480\n",
      "[29: 1590/1795] train lossD: 0.063466 lossG: 0.306325\n",
      "[29: 1595/1795] train lossD: 0.001079 lossG: 0.317081\n",
      "[29: 1600/1795] train lossD: -0.042279 lossG: 0.483150\n",
      "[29: 1605/1795] train lossD: -0.059201 lossG: 0.379487\n",
      "[29: 1610/1795] train lossD: -0.059038 lossG: 0.289046\n",
      "[29: 1615/1795] train lossD: -0.020847 lossG: 0.346618\n",
      "[29: 1620/1795] train lossD: -0.069034 lossG: 0.136140\n",
      "[29: 1625/1795] train lossD: 0.016250 lossG: 0.276627\n",
      "[29: 1630/1795] train lossD: -0.148046 lossG: 0.277566\n",
      "[29: 1635/1795] train lossD: -0.054455 lossG: 0.247315\n",
      "[29: 1640/1795] train lossD: -0.025546 lossG: 0.336500\n",
      "[29: 1645/1795] train lossD: -0.052463 lossG: 0.280326\n",
      "[29: 1650/1795] train lossD: -0.003106 lossG: 0.402565\n",
      "[29: 1655/1795] train lossD: -0.034554 lossG: 0.342603\n",
      "[29: 1660/1795] train lossD: -0.038963 lossG: 0.464554\n",
      "[29: 1665/1795] train lossD: -0.099557 lossG: 0.189922\n",
      "[29: 1670/1795] train lossD: 0.014979 lossG: 0.336990\n",
      "[29: 1675/1795] train lossD: -0.028982 lossG: 0.305287\n",
      "[29: 1680/1795] train lossD: 0.004933 lossG: 0.324791\n",
      "[29: 1685/1795] train lossD: 0.117833 lossG: 0.254569\n",
      "[29: 1690/1795] train lossD: -0.067658 lossG: 0.444238\n",
      "[29: 1695/1795] train lossD: -0.019903 lossG: 0.271346\n",
      "[29: 1700/1795] train lossD: -0.134786 lossG: 0.446832\n",
      "[29: 1705/1795] train lossD: -0.102473 lossG: 0.234601\n",
      "[29: 1710/1795] train lossD: -0.014331 lossG: 0.312014\n",
      "[29: 1715/1795] train lossD: -0.116845 lossG: 0.281876\n",
      "[29: 1720/1795] train lossD: -0.035539 lossG: 0.420718\n",
      "[29: 1725/1795] train lossD: -0.037280 lossG: 0.258814\n",
      "[29: 1730/1795] train lossD: -0.073021 lossG: 0.256754\n",
      "[29: 1735/1795] train lossD: -0.034121 lossG: 0.262585\n",
      "[29: 1740/1795] train lossD: 0.055196 lossG: 0.293326\n",
      "[29: 1745/1795] train lossD: -0.022162 lossG: 0.237462\n",
      "[29: 1750/1795] train lossD: -0.003198 lossG: 0.285370\n",
      "[29: 1755/1795] train lossD: -0.058428 lossG: 0.348755\n",
      "[29: 1760/1795] train lossD: -0.089632 lossG: 0.306979\n",
      "[29: 1765/1795] train lossD: -0.060682 lossG: 0.352544\n",
      "[29: 1770/1795] train lossD: -0.055761 lossG: 0.373811\n",
      "[29: 1775/1795] train lossD: -0.093782 lossG: 0.491460\n",
      "[29: 1780/1795] train lossD: -0.065999 lossG: 0.410858\n",
      "[29: 1785/1795] train lossD: 0.007955 lossG: 0.377443\n",
      "[29: 1790/1795] train lossD: -0.047646 lossG: 0.413551\n",
      "0.039278384298086166\n",
      "[30: 0/1795] train lossD: 0.020671 lossG: 0.156423\n",
      "[30: 5/1795] train lossD: 0.008528 lossG: 0.401975\n",
      "[30: 10/1795] train lossD: 0.004257 lossG: 0.371358\n",
      "[30: 15/1795] train lossD: -0.018142 lossG: 0.370815\n",
      "[30: 20/1795] train lossD: -0.065105 lossG: 0.245965\n",
      "[30: 25/1795] train lossD: 0.020588 lossG: 0.261882\n",
      "[30: 30/1795] train lossD: -0.022731 lossG: 0.283022\n",
      "[30: 35/1795] train lossD: -0.030070 lossG: 0.350674\n",
      "[30: 40/1795] train lossD: -0.042128 lossG: 0.202190\n",
      "[30: 45/1795] train lossD: -0.113699 lossG: 0.207092\n",
      "[30: 50/1795] train lossD: -0.015109 lossG: 0.270381\n",
      "[30: 55/1795] train lossD: -0.125985 lossG: 0.338000\n",
      "[30: 60/1795] train lossD: -0.071330 lossG: 0.195922\n",
      "[30: 65/1795] train lossD: -0.043030 lossG: 0.181093\n",
      "[30: 70/1795] train lossD: -0.031986 lossG: 0.250112\n",
      "[30: 75/1795] train lossD: -0.058210 lossG: 0.216662\n",
      "[30: 80/1795] train lossD: 0.082478 lossG: 0.090619\n",
      "[30: 85/1795] train lossD: -0.023217 lossG: 0.340852\n",
      "[30: 90/1795] train lossD: -0.212458 lossG: 0.243062\n",
      "[30: 95/1795] train lossD: -0.062160 lossG: 0.200118\n",
      "[30: 100/1795] train lossD: 0.188229 lossG: 0.331659\n",
      "[30: 105/1795] train lossD: -0.021676 lossG: 0.376221\n",
      "[30: 110/1795] train lossD: -0.008684 lossG: 0.219374\n",
      "[30: 115/1795] train lossD: -0.061319 lossG: 0.358442\n",
      "[30: 120/1795] train lossD: 0.001064 lossG: 0.383270\n",
      "[30: 125/1795] train lossD: -0.071025 lossG: 0.390687\n",
      "[30: 130/1795] train lossD: 0.422656 lossG: 0.396400\n",
      "[30: 135/1795] train lossD: 0.002204 lossG: 0.426247\n",
      "[30: 140/1795] train lossD: -0.048498 lossG: 0.474647\n",
      "[30: 145/1795] train lossD: -0.031626 lossG: 0.339636\n",
      "[30: 150/1795] train lossD: -0.033398 lossG: 0.358719\n",
      "[30: 155/1795] train lossD: -0.020427 lossG: 0.275851\n",
      "[30: 160/1795] train lossD: -0.074489 lossG: 0.291454\n",
      "[30: 165/1795] train lossD: -0.098412 lossG: 0.314974\n",
      "[30: 170/1795] train lossD: -0.029813 lossG: 0.271350\n",
      "[30: 175/1795] train lossD: -0.032814 lossG: 0.172342\n",
      "[30: 180/1795] train lossD: -0.035664 lossG: 0.326350\n",
      "[30: 185/1795] train lossD: -0.009942 lossG: 0.165869\n",
      "[30: 190/1795] train lossD: 0.023648 lossG: 0.339883\n",
      "[30: 195/1795] train lossD: -0.004862 lossG: 0.384845\n",
      "[30: 200/1795] train lossD: -0.106623 lossG: 0.236400\n",
      "[30: 205/1795] train lossD: -0.004384 lossG: 0.380809\n",
      "[30: 210/1795] train lossD: -0.032190 lossG: 0.195096\n",
      "[30: 215/1795] train lossD: -0.053017 lossG: 0.461075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30: 220/1795] train lossD: -0.027487 lossG: 0.396346\n",
      "[30: 225/1795] train lossD: -0.086833 lossG: 0.318621\n",
      "[30: 230/1795] train lossD: -0.069398 lossG: 0.385756\n",
      "[30: 235/1795] train lossD: -0.011129 lossG: 0.376955\n",
      "[30: 240/1795] train lossD: -0.059231 lossG: 0.425304\n",
      "[30: 245/1795] train lossD: -0.149182 lossG: 0.260304\n",
      "[30: 250/1795] train lossD: -0.002772 lossG: 0.362716\n",
      "[30: 255/1795] train lossD: 0.032194 lossG: 0.378438\n",
      "[30: 260/1795] train lossD: -0.072022 lossG: 0.371550\n",
      "[30: 265/1795] train lossD: -0.024845 lossG: 0.285173\n",
      "[30: 270/1795] train lossD: -0.104768 lossG: 0.419056\n",
      "[30: 275/1795] train lossD: -0.029174 lossG: 0.140986\n",
      "[30: 280/1795] train lossD: -0.032998 lossG: 0.185137\n",
      "[30: 285/1795] train lossD: -0.065249 lossG: 0.378185\n",
      "[30: 290/1795] train lossD: 0.002622 lossG: 0.278978\n",
      "[30: 295/1795] train lossD: -0.034664 lossG: 0.306806\n",
      "[30: 300/1795] train lossD: 0.008997 lossG: 0.406598\n",
      "[30: 305/1795] train lossD: -0.103157 lossG: 0.393049\n",
      "[30: 310/1795] train lossD: -0.031344 lossG: 0.499655\n",
      "[30: 315/1795] train lossD: -0.046200 lossG: 0.441990\n",
      "[30: 320/1795] train lossD: -0.025027 lossG: 0.370269\n",
      "[30: 325/1795] train lossD: -0.071416 lossG: 0.258996\n",
      "[30: 330/1795] train lossD: -0.071199 lossG: 0.400525\n",
      "[30: 335/1795] train lossD: -0.002762 lossG: 0.298008\n",
      "[30: 340/1795] train lossD: -0.040989 lossG: 0.348114\n",
      "[30: 345/1795] train lossD: -0.023984 lossG: 0.394036\n",
      "[30: 350/1795] train lossD: -0.040367 lossG: 0.372347\n",
      "[30: 355/1795] train lossD: -0.038197 lossG: 0.362058\n",
      "[30: 360/1795] train lossD: -0.062712 lossG: 0.382951\n",
      "[30: 365/1795] train lossD: -0.049407 lossG: 0.353174\n",
      "[30: 370/1795] train lossD: -0.000175 lossG: 0.329929\n",
      "[30: 375/1795] train lossD: -0.012226 lossG: 0.331546\n",
      "[30: 380/1795] train lossD: -0.125020 lossG: 0.520351\n",
      "[30: 385/1795] train lossD: -0.083969 lossG: 0.541206\n",
      "[30: 390/1795] train lossD: 0.016955 lossG: 0.387852\n",
      "[30: 395/1795] train lossD: 0.000901 lossG: 0.385193\n",
      "[30: 400/1795] train lossD: -0.018241 lossG: 0.377902\n",
      "[30: 405/1795] train lossD: -0.033732 lossG: 0.283149\n",
      "[30: 410/1795] train lossD: -0.027844 lossG: 0.328505\n",
      "[30: 415/1795] train lossD: -0.071735 lossG: 0.419778\n",
      "[30: 420/1795] train lossD: 0.047203 lossG: 0.401039\n",
      "[30: 425/1795] train lossD: 0.003516 lossG: 0.369818\n",
      "[30: 430/1795] train lossD: 0.131997 lossG: 0.343947\n",
      "[30: 435/1795] train lossD: -0.085795 lossG: 0.290251\n",
      "[30: 440/1795] train lossD: -0.057588 lossG: 0.200947\n",
      "[30: 445/1795] train lossD: -0.011331 lossG: 0.219052\n",
      "[30: 450/1795] train lossD: 0.000831 lossG: 0.440804\n",
      "[30: 455/1795] train lossD: -0.086598 lossG: 0.466099\n",
      "[30: 460/1795] train lossD: -0.026964 lossG: 0.272280\n",
      "[30: 465/1795] train lossD: -0.122587 lossG: 0.280534\n",
      "[30: 470/1795] train lossD: -0.017625 lossG: 0.417013\n",
      "[30: 475/1795] train lossD: -0.043769 lossG: 0.140764\n",
      "[30: 480/1795] train lossD: 0.011607 lossG: 0.329509\n",
      "[30: 485/1795] train lossD: -0.093407 lossG: 0.262635\n",
      "[30: 490/1795] train lossD: -0.143320 lossG: 0.254252\n",
      "[30: 495/1795] train lossD: -0.083923 lossG: 0.190243\n",
      "[30: 500/1795] train lossD: 0.001017 lossG: 0.225034\n",
      "[30: 505/1795] train lossD: 0.003416 lossG: 0.297860\n",
      "[30: 510/1795] train lossD: 0.026621 lossG: 0.315864\n",
      "[30: 515/1795] train lossD: -0.009085 lossG: 0.304933\n",
      "[30: 520/1795] train lossD: -0.012115 lossG: 0.441932\n",
      "[30: 525/1795] train lossD: -0.017680 lossG: 0.360962\n",
      "[30: 530/1795] train lossD: -0.043778 lossG: 0.490167\n",
      "[30: 535/1795] train lossD: -0.021955 lossG: 0.382919\n",
      "[30: 540/1795] train lossD: -0.028377 lossG: 0.447082\n",
      "[30: 545/1795] train lossD: -0.093730 lossG: 0.295687\n",
      "[30: 550/1795] train lossD: -0.087728 lossG: 0.273351\n",
      "[30: 555/1795] train lossD: 0.016756 lossG: 0.401952\n",
      "[30: 560/1795] train lossD: -0.003293 lossG: 0.350211\n",
      "[30: 565/1795] train lossD: -0.003810 lossG: 0.368889\n",
      "[30: 570/1795] train lossD: -0.011129 lossG: 0.332768\n",
      "[30: 575/1795] train lossD: -0.031130 lossG: 0.315841\n",
      "[30: 580/1795] train lossD: -0.025631 lossG: 0.416324\n",
      "[30: 585/1795] train lossD: -0.018884 lossG: 0.363137\n",
      "[30: 590/1795] train lossD: -0.071435 lossG: 0.443768\n",
      "[30: 595/1795] train lossD: -0.121582 lossG: 0.252009\n",
      "[30: 600/1795] train lossD: 0.001901 lossG: 0.345474\n",
      "[30: 605/1795] train lossD: -0.017353 lossG: 0.385480\n",
      "[30: 610/1795] train lossD: -0.042620 lossG: 0.340486\n",
      "[30: 615/1795] train lossD: 0.003226 lossG: 0.333795\n",
      "[30: 620/1795] train lossD: -0.012105 lossG: 0.257559\n",
      "[30: 625/1795] train lossD: -0.048850 lossG: 0.239255\n",
      "[30: 630/1795] train lossD: -0.097048 lossG: 0.333309\n",
      "[30: 635/1795] train lossD: -0.120220 lossG: 0.265711\n",
      "[30: 640/1795] train lossD: -0.018881 lossG: 0.298754\n",
      "[30: 645/1795] train lossD: -0.011549 lossG: 0.248383\n",
      "[30: 650/1795] train lossD: 0.437670 lossG: 0.217034\n",
      "[30: 655/1795] train lossD: -0.025257 lossG: 0.303195\n",
      "[30: 660/1795] train lossD: 0.000984 lossG: 0.272724\n",
      "[30: 665/1795] train lossD: 0.017095 lossG: 0.365240\n",
      "[30: 670/1795] train lossD: -0.148961 lossG: 0.431274\n",
      "[30: 675/1795] train lossD: 0.091035 lossG: 0.311001\n",
      "[30: 680/1795] train lossD: -0.046330 lossG: 0.361506\n",
      "[30: 685/1795] train lossD: -0.040885 lossG: 0.413196\n",
      "[30: 690/1795] train lossD: 0.067055 lossG: 0.344115\n",
      "[30: 695/1795] train lossD: -0.085490 lossG: 0.406843\n",
      "[30: 700/1795] train lossD: -0.054166 lossG: 0.375728\n",
      "[30: 705/1795] train lossD: 0.030678 lossG: 0.367214\n",
      "[30: 710/1795] train lossD: 0.017775 lossG: 0.429039\n",
      "[30: 715/1795] train lossD: 0.003405 lossG: 0.486816\n",
      "[30: 720/1795] train lossD: -0.015638 lossG: 0.521786\n",
      "[30: 725/1795] train lossD: -0.047514 lossG: 0.580084\n",
      "[30: 730/1795] train lossD: -0.040541 lossG: 0.518553\n",
      "[30: 735/1795] train lossD: -0.083067 lossG: 0.428297\n",
      "[30: 740/1795] train lossD: -0.010403 lossG: 0.446811\n",
      "[30: 745/1795] train lossD: -0.033554 lossG: 0.417816\n",
      "[30: 750/1795] train lossD: -0.070284 lossG: 0.480895\n",
      "[30: 755/1795] train lossD: -0.013681 lossG: 0.320613\n",
      "[30: 760/1795] train lossD: 0.048346 lossG: 0.417401\n",
      "[30: 765/1795] train lossD: -0.036481 lossG: 0.428815\n",
      "[30: 770/1795] train lossD: -0.001302 lossG: 0.329879\n",
      "[30: 775/1795] train lossD: 0.032628 lossG: 0.336257\n",
      "[30: 780/1795] train lossD: 0.038015 lossG: 0.309079\n",
      "[30: 785/1795] train lossD: 0.005505 lossG: 0.302357\n",
      "[30: 790/1795] train lossD: 0.004383 lossG: 0.275060\n",
      "[30: 795/1795] train lossD: -0.003835 lossG: 0.328207\n",
      "[30: 800/1795] train lossD: -0.077863 lossG: 0.300850\n",
      "[30: 805/1795] train lossD: -0.030825 lossG: 0.543202\n",
      "[30: 810/1795] train lossD: -0.053058 lossG: 0.466177\n",
      "[30: 815/1795] train lossD: 0.123590 lossG: 0.307190\n",
      "[30: 820/1795] train lossD: -0.051605 lossG: 0.369088\n",
      "[30: 825/1795] train lossD: -0.035521 lossG: 0.393499\n",
      "[30: 830/1795] train lossD: -0.026974 lossG: 0.319935\n",
      "[30: 835/1795] train lossD: -0.014491 lossG: 0.507769\n",
      "[30: 840/1795] train lossD: -0.103879 lossG: 0.308087\n",
      "[30: 845/1795] train lossD: -0.035546 lossG: 0.234428\n",
      "[30: 850/1795] train lossD: -0.029075 lossG: 0.181399\n",
      "[30: 855/1795] train lossD: -0.028882 lossG: 0.313326\n",
      "[30: 860/1795] train lossD: -0.042587 lossG: 0.353808\n",
      "[30: 865/1795] train lossD: -0.065224 lossG: 0.139291\n",
      "[30: 870/1795] train lossD: -0.053349 lossG: 0.299154\n",
      "[30: 875/1795] train lossD: -0.003699 lossG: 0.337901\n",
      "[30: 880/1795] train lossD: -0.038780 lossG: 0.389064\n",
      "[30: 885/1795] train lossD: -0.011664 lossG: 0.321144\n",
      "[30: 890/1795] train lossD: -0.010461 lossG: 0.329923\n",
      "[30: 895/1795] train lossD: 0.002596 lossG: 0.277670\n",
      "[30: 900/1795] train lossD: -0.039364 lossG: 0.236603\n",
      "[30: 905/1795] train lossD: -0.050418 lossG: 0.349247\n",
      "[30: 910/1795] train lossD: -0.027251 lossG: 0.348508\n",
      "[30: 915/1795] train lossD: 0.047830 lossG: 0.352027\n",
      "[30: 920/1795] train lossD: 0.057920 lossG: 0.356359\n",
      "[30: 925/1795] train lossD: -0.114946 lossG: 0.215027\n",
      "[30: 930/1795] train lossD: -0.051365 lossG: 0.523330\n",
      "[30: 935/1795] train lossD: 0.035224 lossG: 0.446424\n",
      "[30: 940/1795] train lossD: -0.014705 lossG: 0.293452\n",
      "[30: 945/1795] train lossD: -0.043258 lossG: 0.412070\n",
      "[30: 950/1795] train lossD: 0.002648 lossG: 0.452982\n",
      "[30: 955/1795] train lossD: 0.038270 lossG: 0.369718\n",
      "[30: 960/1795] train lossD: -0.061714 lossG: 0.415652\n",
      "[30: 965/1795] train lossD: -0.048341 lossG: 0.445710\n",
      "[30: 970/1795] train lossD: -0.116222 lossG: 0.355695\n",
      "[30: 975/1795] train lossD: -0.047265 lossG: 0.226423\n",
      "[30: 980/1795] train lossD: -0.042311 lossG: 0.197667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30: 985/1795] train lossD: -0.059574 lossG: 0.413514\n",
      "[30: 990/1795] train lossD: -0.115331 lossG: 0.222328\n",
      "[30: 995/1795] train lossD: -0.066331 lossG: 0.270630\n",
      "[30: 1000/1795] train lossD: -0.065779 lossG: 0.249970\n",
      "[30: 1005/1795] train lossD: 1.152403 lossG: 0.279731\n",
      "[30: 1010/1795] train lossD: 0.030322 lossG: 0.364849\n",
      "[30: 1015/1795] train lossD: -0.081442 lossG: 0.371077\n",
      "[30: 1020/1795] train lossD: -0.005645 lossG: 0.341780\n",
      "[30: 1025/1795] train lossD: -0.082081 lossG: 0.253829\n",
      "[30: 1030/1795] train lossD: 0.021961 lossG: 0.218934\n",
      "[30: 1035/1795] train lossD: -0.051907 lossG: 0.220690\n",
      "[30: 1040/1795] train lossD: -0.096355 lossG: 0.217185\n",
      "[30: 1045/1795] train lossD: 0.165945 lossG: 0.266896\n",
      "[30: 1050/1795] train lossD: -0.048959 lossG: 0.353406\n",
      "[30: 1055/1795] train lossD: -0.045907 lossG: 0.347763\n",
      "[30: 1060/1795] train lossD: -0.050516 lossG: 0.355093\n",
      "[30: 1065/1795] train lossD: -0.028892 lossG: 0.290722\n",
      "[30: 1070/1795] train lossD: -0.040585 lossG: 0.275446\n",
      "[30: 1075/1795] train lossD: -0.124711 lossG: 0.270966\n",
      "[30: 1080/1795] train lossD: -0.016676 lossG: 0.421808\n",
      "[30: 1085/1795] train lossD: -0.075540 lossG: 0.421212\n",
      "[30: 1090/1795] train lossD: -0.065778 lossG: 0.445242\n",
      "[30: 1095/1795] train lossD: -0.045743 lossG: 0.290935\n",
      "[30: 1100/1795] train lossD: 0.021447 lossG: 0.280668\n",
      "[30: 1105/1795] train lossD: -0.022469 lossG: 0.295641\n",
      "[30: 1110/1795] train lossD: -0.053986 lossG: 0.310487\n",
      "[30: 1115/1795] train lossD: -0.020190 lossG: 0.291171\n",
      "[30: 1120/1795] train lossD: -0.028645 lossG: 0.215194\n",
      "[30: 1125/1795] train lossD: -0.057303 lossG: 0.383423\n",
      "[30: 1130/1795] train lossD: 0.001165 lossG: 0.344458\n",
      "[30: 1135/1795] train lossD: -0.084068 lossG: 0.442948\n",
      "[30: 1140/1795] train lossD: -0.162320 lossG: 0.340366\n",
      "[30: 1145/1795] train lossD: 0.576072 lossG: 0.277702\n",
      "[30: 1150/1795] train lossD: -0.017282 lossG: 0.360694\n",
      "[30: 1155/1795] train lossD: -0.017314 lossG: 0.373252\n",
      "[30: 1160/1795] train lossD: -0.095751 lossG: 0.387688\n",
      "[30: 1165/1795] train lossD: -0.075549 lossG: 0.309969\n",
      "[30: 1170/1795] train lossD: -0.125719 lossG: 0.362106\n",
      "[30: 1175/1795] train lossD: 0.028353 lossG: 0.356134\n",
      "[30: 1180/1795] train lossD: -0.024985 lossG: 0.389798\n",
      "[30: 1185/1795] train lossD: -0.059099 lossG: 0.328658\n",
      "[30: 1190/1795] train lossD: -0.087952 lossG: 0.501626\n",
      "[30: 1195/1795] train lossD: -0.116286 lossG: 0.418182\n",
      "[30: 1200/1795] train lossD: -0.011942 lossG: 0.341202\n",
      "[30: 1205/1795] train lossD: -0.049026 lossG: 0.286073\n",
      "[30: 1210/1795] train lossD: -0.054383 lossG: 0.409180\n",
      "[30: 1215/1795] train lossD: -0.062961 lossG: 0.432603\n",
      "[30: 1220/1795] train lossD: 0.121820 lossG: 0.464497\n",
      "[30: 1225/1795] train lossD: -0.023785 lossG: 0.400404\n",
      "[30: 1230/1795] train lossD: 0.007351 lossG: 0.341269\n",
      "[30: 1235/1795] train lossD: -0.072582 lossG: 0.332022\n",
      "[30: 1240/1795] train lossD: 0.019995 lossG: 0.538263\n",
      "[30: 1245/1795] train lossD: -0.076333 lossG: 0.503855\n",
      "[30: 1250/1795] train lossD: -0.021799 lossG: 0.414620\n",
      "[30: 1255/1795] train lossD: -0.037630 lossG: 0.259580\n",
      "[30: 1260/1795] train lossD: -0.080831 lossG: 0.267383\n",
      "[30: 1265/1795] train lossD: -0.041335 lossG: 0.375502\n",
      "[30: 1270/1795] train lossD: -0.091934 lossG: 0.209418\n",
      "[30: 1275/1795] train lossD: -0.067399 lossG: 0.147049\n",
      "[30: 1280/1795] train lossD: -0.068621 lossG: 0.438331\n",
      "[30: 1285/1795] train lossD: -0.070639 lossG: 0.373258\n",
      "[30: 1290/1795] train lossD: 0.024226 lossG: 0.366473\n",
      "[30: 1295/1795] train lossD: -0.016784 lossG: 0.214419\n",
      "[30: 1300/1795] train lossD: -0.023627 lossG: 0.309748\n",
      "[30: 1305/1795] train lossD: -0.063056 lossG: 0.196263\n",
      "[30: 1310/1795] train lossD: -0.011462 lossG: 0.231342\n",
      "[30: 1315/1795] train lossD: -0.019718 lossG: 0.452307\n",
      "[30: 1320/1795] train lossD: -0.017541 lossG: 0.373984\n",
      "[30: 1325/1795] train lossD: -0.053449 lossG: 0.453244\n",
      "[30: 1330/1795] train lossD: 0.087822 lossG: 0.382035\n",
      "[30: 1335/1795] train lossD: -0.086510 lossG: 0.419444\n",
      "[30: 1340/1795] train lossD: -0.024158 lossG: 0.291960\n",
      "[30: 1345/1795] train lossD: -0.024376 lossG: 0.416642\n",
      "[30: 1350/1795] train lossD: 0.092146 lossG: 0.243960\n",
      "[30: 1355/1795] train lossD: 0.022529 lossG: 0.283705\n",
      "[30: 1360/1795] train lossD: 0.159189 lossG: 0.405896\n",
      "[30: 1365/1795] train lossD: 0.017801 lossG: 0.399587\n",
      "[30: 1370/1795] train lossD: -0.062665 lossG: 0.403772\n",
      "[30: 1375/1795] train lossD: -0.060701 lossG: 0.339856\n",
      "[30: 1380/1795] train lossD: -0.006747 lossG: 0.390861\n",
      "[30: 1385/1795] train lossD: -0.008412 lossG: 0.434212\n",
      "[30: 1390/1795] train lossD: -0.078530 lossG: 0.317597\n",
      "[30: 1395/1795] train lossD: 0.011401 lossG: 0.426456\n",
      "[30: 1400/1795] train lossD: -0.018598 lossG: 0.345226\n",
      "[30: 1405/1795] train lossD: -0.029621 lossG: 0.309753\n",
      "[30: 1410/1795] train lossD: -0.098852 lossG: 0.449841\n",
      "[30: 1415/1795] train lossD: -0.083245 lossG: 0.245633\n",
      "[30: 1420/1795] train lossD: -0.006324 lossG: 0.444943\n",
      "[30: 1425/1795] train lossD: 0.012367 lossG: 0.423719\n",
      "[30: 1430/1795] train lossD: -0.084053 lossG: 0.386612\n",
      "[30: 1435/1795] train lossD: -0.030090 lossG: 0.453410\n",
      "[30: 1440/1795] train lossD: -0.078117 lossG: 0.329477\n",
      "[30: 1445/1795] train lossD: -0.017075 lossG: 0.443217\n",
      "[30: 1450/1795] train lossD: -0.034101 lossG: 0.442622\n",
      "[30: 1455/1795] train lossD: 0.013445 lossG: 0.377552\n",
      "[30: 1460/1795] train lossD: -0.034511 lossG: 0.360941\n",
      "[30: 1465/1795] train lossD: 0.020654 lossG: 0.401107\n",
      "[30: 1470/1795] train lossD: -0.092145 lossG: 0.390053\n",
      "[30: 1475/1795] train lossD: -0.069697 lossG: 0.326552\n",
      "[30: 1480/1795] train lossD: -0.019894 lossG: 0.402031\n",
      "[30: 1485/1795] train lossD: 0.020561 lossG: 0.366714\n",
      "[30: 1490/1795] train lossD: -0.034847 lossG: 0.394283\n",
      "[30: 1495/1795] train lossD: -0.017127 lossG: 0.379128\n",
      "[30: 1500/1795] train lossD: -0.151788 lossG: 0.366584\n",
      "[30: 1505/1795] train lossD: -0.015566 lossG: 0.371705\n",
      "[30: 1510/1795] train lossD: -0.013635 lossG: 0.442812\n",
      "[30: 1515/1795] train lossD: 0.000354 lossG: 0.312423\n",
      "[30: 1520/1795] train lossD: -0.047314 lossG: 0.354308\n",
      "[30: 1525/1795] train lossD: -0.084753 lossG: 0.272001\n",
      "[30: 1530/1795] train lossD: -0.010164 lossG: 0.241115\n",
      "[30: 1535/1795] train lossD: 0.004432 lossG: 0.216596\n",
      "[30: 1540/1795] train lossD: -0.026362 lossG: 0.081010\n",
      "[30: 1545/1795] train lossD: -0.046741 lossG: 0.353550\n",
      "[30: 1550/1795] train lossD: -0.051350 lossG: 0.324648\n",
      "[30: 1555/1795] train lossD: 0.026207 lossG: 0.326036\n",
      "[30: 1560/1795] train lossD: -0.049054 lossG: 0.284132\n",
      "[30: 1565/1795] train lossD: -0.034528 lossG: 0.322860\n",
      "[30: 1570/1795] train lossD: 0.022035 lossG: 0.205449\n",
      "[30: 1575/1795] train lossD: -0.097808 lossG: 0.170893\n",
      "[30: 1580/1795] train lossD: -0.066995 lossG: 0.184071\n",
      "[30: 1585/1795] train lossD: 0.017560 lossG: 0.031444\n",
      "[30: 1590/1795] train lossD: -0.039339 lossG: 0.285578\n",
      "[30: 1595/1795] train lossD: -0.138098 lossG: 0.364910\n",
      "[30: 1600/1795] train lossD: -0.056274 lossG: 0.258165\n",
      "[30: 1605/1795] train lossD: -0.076063 lossG: 0.185407\n",
      "[30: 1610/1795] train lossD: 0.026047 lossG: 0.313297\n",
      "[30: 1615/1795] train lossD: -0.009218 lossG: 0.365070\n",
      "[30: 1620/1795] train lossD: -0.039881 lossG: 0.262567\n",
      "[30: 1625/1795] train lossD: -0.092711 lossG: 0.203461\n",
      "[30: 1630/1795] train lossD: -0.087784 lossG: 0.591612\n",
      "[30: 1635/1795] train lossD: -0.050010 lossG: 0.300573\n",
      "[30: 1640/1795] train lossD: -0.021325 lossG: 0.399285\n",
      "[30: 1645/1795] train lossD: -0.033466 lossG: 0.201413\n",
      "[30: 1650/1795] train lossD: 0.040370 lossG: 0.291558\n",
      "[30: 1655/1795] train lossD: -0.009432 lossG: 0.281213\n",
      "[30: 1660/1795] train lossD: 0.006682 lossG: 0.352870\n",
      "[30: 1665/1795] train lossD: 0.016697 lossG: 0.404462\n",
      "[30: 1670/1795] train lossD: 0.010139 lossG: 0.321604\n",
      "[30: 1675/1795] train lossD: -0.026241 lossG: 0.237642\n",
      "[30: 1680/1795] train lossD: -0.037033 lossG: 0.285511\n",
      "[30: 1685/1795] train lossD: -0.092725 lossG: 0.205192\n",
      "[30: 1690/1795] train lossD: -0.128865 lossG: 0.343327\n",
      "[30: 1695/1795] train lossD: -0.062310 lossG: 0.247027\n",
      "[30: 1700/1795] train lossD: -0.154531 lossG: 0.138716\n",
      "[30: 1705/1795] train lossD: 0.020291 lossG: 0.220576\n",
      "[30: 1710/1795] train lossD: -0.019442 lossG: 0.399565\n",
      "[30: 1715/1795] train lossD: 0.039564 lossG: 0.315700\n",
      "[30: 1720/1795] train lossD: 0.039698 lossG: 0.357655\n",
      "[30: 1725/1795] train lossD: -0.101198 lossG: 0.366628\n",
      "[30: 1730/1795] train lossD: -0.025926 lossG: 0.265700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30: 1735/1795] train lossD: -0.010488 lossG: 0.317983\n",
      "[30: 1740/1795] train lossD: -0.030965 lossG: 0.194464\n",
      "[30: 1745/1795] train lossD: -0.070840 lossG: 0.254682\n",
      "[30: 1750/1795] train lossD: 0.047093 lossG: 0.193091\n",
      "[30: 1755/1795] train lossD: 0.028714 lossG: 0.122793\n",
      "[30: 1760/1795] train lossD: -0.012188 lossG: 0.247677\n",
      "[30: 1765/1795] train lossD: -0.012634 lossG: 0.338915\n",
      "[30: 1770/1795] train lossD: -0.084286 lossG: 0.278417\n",
      "[30: 1775/1795] train lossD: -0.085456 lossG: 0.263182\n",
      "[30: 1780/1795] train lossD: 0.072644 lossG: 0.231882\n",
      "[30: 1785/1795] train lossD: 0.001312 lossG: 0.314737\n",
      "[30: 1790/1795] train lossD: 0.023875 lossG: 0.410739\n",
      "0.050072867423295975\n",
      "[31: 0/1795] train lossD: -0.033645 lossG: 0.158504\n",
      "[31: 5/1795] train lossD: -0.012378 lossG: 0.247225\n",
      "[31: 10/1795] train lossD: -0.039368 lossG: 0.201827\n",
      "[31: 15/1795] train lossD: -0.070229 lossG: 0.374248\n",
      "[31: 20/1795] train lossD: 0.002683 lossG: 0.339649\n",
      "[31: 25/1795] train lossD: -0.196342 lossG: 0.373523\n",
      "[31: 30/1795] train lossD: -0.150022 lossG: 0.177260\n",
      "[31: 35/1795] train lossD: -0.012595 lossG: 0.313904\n",
      "[31: 40/1795] train lossD: -0.035757 lossG: 0.380597\n",
      "[31: 45/1795] train lossD: 0.005159 lossG: 0.382032\n",
      "[31: 50/1795] train lossD: -0.132885 lossG: 0.284272\n",
      "[31: 55/1795] train lossD: -0.043707 lossG: 0.264785\n",
      "[31: 60/1795] train lossD: -0.022844 lossG: 0.201997\n",
      "[31: 65/1795] train lossD: 0.009901 lossG: 0.202650\n",
      "[31: 70/1795] train lossD: -0.039411 lossG: 0.355619\n",
      "[31: 75/1795] train lossD: -0.088717 lossG: 0.130707\n",
      "[31: 80/1795] train lossD: -0.052363 lossG: 0.316525\n",
      "[31: 85/1795] train lossD: -0.064964 lossG: 0.188130\n",
      "[31: 90/1795] train lossD: -0.001967 lossG: 0.140409\n",
      "[31: 95/1795] train lossD: -0.132832 lossG: 0.204848\n",
      "[31: 100/1795] train lossD: 0.105784 lossG: 0.194899\n",
      "[31: 105/1795] train lossD: -0.067895 lossG: 0.151673\n",
      "[31: 110/1795] train lossD: -0.055507 lossG: 0.160149\n",
      "[31: 115/1795] train lossD: -0.106122 lossG: 0.178461\n",
      "[31: 120/1795] train lossD: -0.130299 lossG: 0.117451\n",
      "[31: 125/1795] train lossD: 0.102089 lossG: 0.289982\n",
      "[31: 130/1795] train lossD: -0.020547 lossG: 0.279913\n",
      "[31: 135/1795] train lossD: -0.057916 lossG: 0.208309\n",
      "[31: 140/1795] train lossD: -0.042433 lossG: 0.205565\n",
      "[31: 145/1795] train lossD: -0.012908 lossG: 0.388112\n",
      "[31: 150/1795] train lossD: -0.096763 lossG: 0.300894\n",
      "[31: 155/1795] train lossD: -0.026524 lossG: 0.192250\n",
      "[31: 160/1795] train lossD: 0.010042 lossG: 0.197915\n",
      "[31: 165/1795] train lossD: -0.103898 lossG: 0.106841\n",
      "[31: 170/1795] train lossD: -0.066485 lossG: 0.144385\n",
      "[31: 175/1795] train lossD: -0.035950 lossG: 0.109203\n",
      "[31: 180/1795] train lossD: -0.040875 lossG: 0.211421\n",
      "[31: 185/1795] train lossD: 0.006358 lossG: 0.287333\n",
      "[31: 190/1795] train lossD: -0.102242 lossG: 0.278634\n",
      "[31: 195/1795] train lossD: 0.014953 lossG: 0.241777\n",
      "[31: 200/1795] train lossD: -0.040261 lossG: 0.222290\n",
      "[31: 205/1795] train lossD: -0.059844 lossG: 0.184483\n",
      "[31: 210/1795] train lossD: 0.018564 lossG: 0.065273\n",
      "[31: 215/1795] train lossD: 0.014889 lossG: 0.174589\n",
      "[31: 220/1795] train lossD: -0.038462 lossG: 0.217453\n",
      "[31: 225/1795] train lossD: -0.107332 lossG: 0.187201\n",
      "[31: 230/1795] train lossD: -0.022940 lossG: 0.147848\n",
      "[31: 235/1795] train lossD: -0.111865 lossG: 0.127896\n",
      "[31: 240/1795] train lossD: -0.048434 lossG: 0.176987\n",
      "[31: 245/1795] train lossD: -0.170962 lossG: 0.154928\n",
      "[31: 250/1795] train lossD: -0.017468 lossG: 0.071482\n",
      "[31: 255/1795] train lossD: 0.006373 lossG: 0.197477\n",
      "[31: 260/1795] train lossD: -0.114416 lossG: 0.173470\n",
      "[31: 265/1795] train lossD: -0.027787 lossG: 0.155062\n",
      "[31: 270/1795] train lossD: -0.057571 lossG: 0.124072\n",
      "[31: 275/1795] train lossD: -0.063147 lossG: 0.201065\n",
      "[31: 280/1795] train lossD: -0.062747 lossG: 0.170249\n",
      "[31: 285/1795] train lossD: 0.082207 lossG: 0.042308\n",
      "[31: 290/1795] train lossD: -0.011266 lossG: 0.054921\n",
      "[31: 295/1795] train lossD: -0.036979 lossG: 0.056638\n",
      "[31: 300/1795] train lossD: -0.083493 lossG: 0.113529\n",
      "[31: 305/1795] train lossD: 0.057192 lossG: 0.172502\n",
      "[31: 310/1795] train lossD: 0.001760 lossG: 0.176384\n",
      "[31: 315/1795] train lossD: -0.063320 lossG: 0.203624\n",
      "[31: 320/1795] train lossD: -0.060261 lossG: 0.125953\n",
      "[31: 325/1795] train lossD: 0.025419 lossG: 0.143580\n",
      "[31: 330/1795] train lossD: -0.220858 lossG: 0.183817\n",
      "[31: 335/1795] train lossD: -0.125761 lossG: 0.324149\n",
      "[31: 340/1795] train lossD: -0.057388 lossG: 0.319642\n",
      "[31: 345/1795] train lossD: -0.042980 lossG: 0.084652\n",
      "[31: 350/1795] train lossD: -0.074879 lossG: 0.172041\n",
      "[31: 355/1795] train lossD: -0.030811 lossG: 0.133965\n",
      "[31: 360/1795] train lossD: -0.026003 lossG: 0.051109\n",
      "[31: 365/1795] train lossD: -0.069001 lossG: 0.309115\n",
      "[31: 370/1795] train lossD: -0.094582 lossG: 0.226409\n",
      "[31: 375/1795] train lossD: 0.017068 lossG: 0.077313\n",
      "[31: 380/1795] train lossD: 0.021732 lossG: 0.295843\n",
      "[31: 385/1795] train lossD: -0.007913 lossG: 0.384893\n",
      "[31: 390/1795] train lossD: -0.086735 lossG: 0.237723\n",
      "[31: 395/1795] train lossD: -0.032838 lossG: 0.275363\n",
      "[31: 400/1795] train lossD: 0.010545 lossG: 0.093002\n",
      "[31: 405/1795] train lossD: -0.030641 lossG: 0.210314\n",
      "[31: 410/1795] train lossD: -0.126524 lossG: 0.176612\n",
      "[31: 415/1795] train lossD: -0.016211 lossG: 0.311257\n",
      "[31: 420/1795] train lossD: -0.009992 lossG: 0.194668\n",
      "[31: 425/1795] train lossD: -0.039301 lossG: 0.313248\n",
      "[31: 430/1795] train lossD: -0.063305 lossG: 0.180107\n",
      "[31: 435/1795] train lossD: 0.005469 lossG: 0.101804\n",
      "[31: 440/1795] train lossD: -0.040530 lossG: 0.116547\n",
      "[31: 445/1795] train lossD: -0.024836 lossG: 0.182697\n",
      "[31: 450/1795] train lossD: -0.141058 lossG: 0.167626\n",
      "[31: 455/1795] train lossD: 0.017659 lossG: 0.212301\n",
      "[31: 460/1795] train lossD: -0.163713 lossG: 0.192949\n",
      "[31: 465/1795] train lossD: -0.061829 lossG: 0.077977\n",
      "[31: 470/1795] train lossD: -0.017114 lossG: 0.205459\n",
      "[31: 475/1795] train lossD: 0.041726 lossG: 0.223250\n",
      "[31: 480/1795] train lossD: 0.426005 lossG: 0.146962\n",
      "[31: 485/1795] train lossD: 0.279164 lossG: 0.294248\n",
      "[31: 490/1795] train lossD: 0.245753 lossG: 0.312630\n",
      "[31: 495/1795] train lossD: 0.196489 lossG: 0.381684\n",
      "[31: 500/1795] train lossD: 0.244020 lossG: 0.376885\n",
      "[31: 505/1795] train lossD: 0.114942 lossG: 0.314778\n",
      "[31: 510/1795] train lossD: 0.084893 lossG: 0.362513\n",
      "[31: 515/1795] train lossD: 0.029979 lossG: 0.386238\n",
      "[31: 520/1795] train lossD: -0.034229 lossG: 0.430276\n",
      "[31: 525/1795] train lossD: 0.104740 lossG: 0.329955\n",
      "[31: 530/1795] train lossD: 0.016978 lossG: 0.256625\n",
      "[31: 535/1795] train lossD: 0.022912 lossG: 0.198799\n",
      "[31: 540/1795] train lossD: -0.006631 lossG: 0.176969\n",
      "[31: 545/1795] train lossD: 0.006102 lossG: 0.255599\n",
      "[31: 550/1795] train lossD: -0.026412 lossG: 0.258592\n",
      "[31: 555/1795] train lossD: -0.013416 lossG: 0.179431\n",
      "[31: 560/1795] train lossD: -0.016352 lossG: 0.214594\n",
      "[31: 565/1795] train lossD: -0.052018 lossG: 0.171580\n",
      "[31: 570/1795] train lossD: -0.021290 lossG: 0.169394\n",
      "[31: 575/1795] train lossD: -0.037060 lossG: 0.155933\n",
      "[31: 580/1795] train lossD: -0.013695 lossG: 0.185053\n",
      "[31: 585/1795] train lossD: -0.023807 lossG: 0.175348\n",
      "[31: 590/1795] train lossD: -0.017245 lossG: 0.098343\n",
      "[31: 595/1795] train lossD: 0.172806 lossG: 0.030449\n",
      "[31: 600/1795] train lossD: -0.034172 lossG: 0.239078\n",
      "[31: 605/1795] train lossD: 0.049396 lossG: 0.150311\n",
      "[31: 610/1795] train lossD: -0.086094 lossG: 0.079120\n",
      "[31: 615/1795] train lossD: -0.131313 lossG: 0.257458\n",
      "[31: 620/1795] train lossD: -0.032367 lossG: 0.093725\n",
      "[31: 625/1795] train lossD: -0.049184 lossG: 0.087408\n",
      "[31: 630/1795] train lossD: -0.022132 lossG: 0.123020\n",
      "[31: 635/1795] train lossD: -0.127096 lossG: 0.087282\n",
      "[31: 640/1795] train lossD: 0.033247 lossG: 0.232440\n",
      "[31: 645/1795] train lossD: 0.028465 lossG: 0.248977\n",
      "[31: 650/1795] train lossD: -0.072332 lossG: 0.294607\n",
      "[31: 655/1795] train lossD: -0.047421 lossG: 0.369017\n",
      "[31: 660/1795] train lossD: 0.087896 lossG: 0.133936\n",
      "[31: 665/1795] train lossD: -0.037075 lossG: 0.235294\n",
      "[31: 670/1795] train lossD: -0.150087 lossG: 0.275558\n",
      "[31: 675/1795] train lossD: -0.155524 lossG: 0.147494\n",
      "[31: 680/1795] train lossD: -0.067879 lossG: 0.406985\n",
      "[31: 685/1795] train lossD: -0.036593 lossG: 0.192770\n",
      "[31: 690/1795] train lossD: 0.182206 lossG: 0.292102\n",
      "[31: 695/1795] train lossD: -0.031693 lossG: 0.299853\n",
      "[31: 700/1795] train lossD: -0.120654 lossG: 0.378745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31: 705/1795] train lossD: -0.037931 lossG: 0.183127\n",
      "[31: 710/1795] train lossD: -0.087363 lossG: 0.242757\n",
      "[31: 715/1795] train lossD: 0.025753 lossG: 0.073316\n",
      "[31: 720/1795] train lossD: 0.005477 lossG: 0.104079\n",
      "[31: 725/1795] train lossD: -0.002424 lossG: 0.074931\n",
      "[31: 730/1795] train lossD: -0.006142 lossG: 0.106120\n",
      "[31: 735/1795] train lossD: -0.036253 lossG: 0.176826\n",
      "[31: 740/1795] train lossD: -0.102418 lossG: 0.108394\n",
      "[31: 745/1795] train lossD: -0.045106 lossG: 0.082630\n",
      "[31: 750/1795] train lossD: -0.060026 lossG: 0.242030\n",
      "[31: 755/1795] train lossD: -0.024850 lossG: 0.174597\n",
      "[31: 760/1795] train lossD: 0.007475 lossG: 0.242622\n",
      "[31: 765/1795] train lossD: -0.018803 lossG: 0.388583\n",
      "[31: 770/1795] train lossD: 0.049883 lossG: 0.361039\n",
      "[31: 775/1795] train lossD: 0.011243 lossG: 0.349973\n",
      "[31: 780/1795] train lossD: 0.009549 lossG: 0.429242\n",
      "[31: 785/1795] train lossD: 0.018371 lossG: 0.347906\n",
      "[31: 790/1795] train lossD: -0.060588 lossG: 0.257503\n",
      "[31: 795/1795] train lossD: -0.144894 lossG: 0.124410\n",
      "[31: 800/1795] train lossD: -0.079711 lossG: 0.203546\n",
      "[31: 805/1795] train lossD: -0.015053 lossG: 0.173869\n",
      "[31: 810/1795] train lossD: -0.060169 lossG: 0.130112\n",
      "[31: 815/1795] train lossD: 0.081141 lossG: 0.175836\n",
      "[31: 820/1795] train lossD: 0.037552 lossG: 0.198510\n",
      "[31: 825/1795] train lossD: -0.129324 lossG: 0.180838\n",
      "[31: 830/1795] train lossD: -0.013363 lossG: 0.174078\n",
      "[31: 835/1795] train lossD: 0.061039 lossG: 0.369485\n",
      "[31: 840/1795] train lossD: -0.001150 lossG: 0.369413\n",
      "[31: 845/1795] train lossD: -0.031858 lossG: 0.461013\n",
      "[31: 850/1795] train lossD: -0.043308 lossG: 0.240258\n",
      "[31: 855/1795] train lossD: -0.015285 lossG: 0.316779\n",
      "[31: 860/1795] train lossD: -0.015026 lossG: 0.247800\n",
      "[31: 865/1795] train lossD: -0.005971 lossG: 0.279539\n",
      "[31: 870/1795] train lossD: -0.003725 lossG: 0.070024\n",
      "[31: 875/1795] train lossD: -0.067909 lossG: 0.215472\n",
      "[31: 880/1795] train lossD: -0.183952 lossG: 0.384572\n",
      "[31: 885/1795] train lossD: -0.048601 lossG: 0.216214\n",
      "[31: 890/1795] train lossD: -0.031976 lossG: 0.312548\n",
      "[31: 895/1795] train lossD: -0.028058 lossG: 0.132598\n",
      "[31: 900/1795] train lossD: -0.030984 lossG: 0.235966\n",
      "[31: 905/1795] train lossD: 0.132385 lossG: 0.129968\n",
      "[31: 910/1795] train lossD: -0.006408 lossG: 0.239481\n",
      "[31: 915/1795] train lossD: -0.082453 lossG: 0.249623\n",
      "[31: 920/1795] train lossD: -0.067140 lossG: 0.272177\n",
      "[31: 925/1795] train lossD: -0.072936 lossG: 0.319478\n",
      "[31: 930/1795] train lossD: -0.003184 lossG: 0.377794\n",
      "[31: 935/1795] train lossD: -0.010581 lossG: 0.337496\n",
      "[31: 940/1795] train lossD: -0.075494 lossG: 0.331631\n",
      "[31: 945/1795] train lossD: -0.132601 lossG: 0.407766\n",
      "[31: 950/1795] train lossD: -0.081705 lossG: 0.427309\n",
      "[31: 955/1795] train lossD: -0.100384 lossG: 0.311629\n",
      "[31: 960/1795] train lossD: -0.055054 lossG: 0.289924\n",
      "[31: 965/1795] train lossD: -0.059057 lossG: 0.293375\n",
      "[31: 970/1795] train lossD: -0.087459 lossG: 0.274139\n",
      "[31: 975/1795] train lossD: -0.010838 lossG: 0.203961\n",
      "[31: 980/1795] train lossD: -0.010317 lossG: 0.110451\n",
      "[31: 985/1795] train lossD: -0.040220 lossG: 0.337049\n",
      "[31: 990/1795] train lossD: -0.050130 lossG: 0.335388\n",
      "[31: 995/1795] train lossD: -0.224266 lossG: 0.249267\n",
      "[31: 1000/1795] train lossD: -0.105809 lossG: 0.405695\n",
      "[31: 1005/1795] train lossD: -0.133917 lossG: 0.250671\n",
      "[31: 1010/1795] train lossD: -0.105532 lossG: 0.348331\n",
      "[31: 1015/1795] train lossD: -0.005524 lossG: 0.122000\n",
      "[31: 1020/1795] train lossD: -0.095811 lossG: 0.127793\n",
      "[31: 1025/1795] train lossD: -0.025247 lossG: 0.369928\n",
      "[31: 1030/1795] train lossD: 0.004254 lossG: 0.269584\n",
      "[31: 1035/1795] train lossD: -0.131319 lossG: 0.333337\n",
      "[31: 1040/1795] train lossD: -0.030322 lossG: 0.070760\n",
      "[31: 1045/1795] train lossD: -0.055165 lossG: 0.067625\n",
      "[31: 1050/1795] train lossD: -0.170796 lossG: 0.037231\n",
      "[31: 1055/1795] train lossD: -0.069264 lossG: 0.151808\n",
      "[31: 1060/1795] train lossD: -0.070018 lossG: 0.151969\n",
      "[31: 1065/1795] train lossD: -0.123070 lossG: 0.257648\n",
      "[31: 1070/1795] train lossD: 0.001249 lossG: 0.246444\n",
      "[31: 1075/1795] train lossD: 0.032336 lossG: 0.230889\n",
      "[31: 1080/1795] train lossD: -0.064804 lossG: 0.255008\n",
      "[31: 1085/1795] train lossD: -0.080020 lossG: 0.165289\n",
      "[31: 1090/1795] train lossD: 0.002032 lossG: 0.192198\n",
      "[31: 1095/1795] train lossD: -0.084970 lossG: 0.097793\n",
      "[31: 1100/1795] train lossD: -0.063028 lossG: 0.124079\n",
      "[31: 1105/1795] train lossD: -0.063175 lossG: 0.091577\n",
      "[31: 1110/1795] train lossD: 0.009342 lossG: 0.215009\n",
      "[31: 1115/1795] train lossD: -0.001148 lossG: 0.057103\n",
      "[31: 1120/1795] train lossD: -0.099334 lossG: 0.121718\n",
      "[31: 1125/1795] train lossD: -0.113287 lossG: 0.245027\n",
      "[31: 1130/1795] train lossD: -0.089621 lossG: 0.108566\n",
      "[31: 1135/1795] train lossD: -0.114377 lossG: 0.253118\n",
      "[31: 1140/1795] train lossD: -0.025646 lossG: 0.216281\n",
      "[31: 1145/1795] train lossD: -0.065243 lossG: 0.162145\n",
      "[31: 1150/1795] train lossD: -0.084505 lossG: 0.207870\n",
      "[31: 1155/1795] train lossD: -0.050589 lossG: 0.190443\n",
      "[31: 1160/1795] train lossD: -0.066535 lossG: 0.175358\n",
      "[31: 1165/1795] train lossD: -0.018125 lossG: 0.124988\n",
      "[31: 1170/1795] train lossD: -0.084212 lossG: 0.159138\n",
      "[31: 1175/1795] train lossD: -0.043409 lossG: 0.359902\n",
      "[31: 1180/1795] train lossD: -0.059083 lossG: 0.208026\n",
      "[31: 1185/1795] train lossD: -0.203574 lossG: 0.335442\n",
      "[31: 1190/1795] train lossD: -0.095392 lossG: -0.017257\n",
      "[31: 1195/1795] train lossD: 0.040220 lossG: 0.247194\n",
      "[31: 1200/1795] train lossD: -0.017310 lossG: 0.362425\n",
      "[31: 1205/1795] train lossD: -0.040134 lossG: 0.092270\n",
      "[31: 1210/1795] train lossD: -0.067860 lossG: 0.212208\n",
      "[31: 1215/1795] train lossD: -0.099954 lossG: 0.186870\n",
      "[31: 1220/1795] train lossD: -0.033457 lossG: 0.184402\n",
      "[31: 1225/1795] train lossD: -0.191520 lossG: 0.263287\n",
      "[31: 1230/1795] train lossD: -0.015232 lossG: 0.071716\n",
      "[31: 1235/1795] train lossD: -0.014579 lossG: 0.222480\n",
      "[31: 1240/1795] train lossD: 0.020771 lossG: 0.262833\n",
      "[31: 1245/1795] train lossD: -0.035773 lossG: 0.325645\n",
      "[31: 1250/1795] train lossD: -0.014527 lossG: 0.478803\n",
      "[31: 1255/1795] train lossD: -0.008446 lossG: 0.458565\n",
      "[31: 1260/1795] train lossD: -0.098981 lossG: 0.378954\n",
      "[31: 1265/1795] train lossD: -0.046895 lossG: 0.302379\n",
      "[31: 1270/1795] train lossD: 0.031823 lossG: 0.325918\n",
      "[31: 1275/1795] train lossD: -0.065576 lossG: 0.244619\n",
      "[31: 1280/1795] train lossD: -0.068399 lossG: 0.182459\n",
      "[31: 1285/1795] train lossD: -0.035221 lossG: 0.165787\n",
      "[31: 1290/1795] train lossD: -0.094764 lossG: 0.277574\n",
      "[31: 1295/1795] train lossD: -0.077840 lossG: -0.032147\n",
      "[31: 1300/1795] train lossD: -0.003871 lossG: 0.147199\n",
      "[31: 1305/1795] train lossD: -0.116330 lossG: 0.255146\n",
      "[31: 1310/1795] train lossD: -0.034499 lossG: 0.219951\n",
      "[31: 1315/1795] train lossD: -0.049761 lossG: 0.251575\n",
      "[31: 1320/1795] train lossD: 0.044252 lossG: 0.125343\n",
      "[31: 1325/1795] train lossD: -0.026345 lossG: 0.009773\n",
      "[31: 1330/1795] train lossD: -0.183767 lossG: 0.191657\n",
      "[31: 1335/1795] train lossD: -0.031941 lossG: 0.123793\n",
      "[31: 1340/1795] train lossD: 4.157715 lossG: 0.234018\n",
      "[31: 1345/1795] train lossD: 0.029013 lossG: 0.253465\n",
      "[31: 1350/1795] train lossD: 0.019418 lossG: 0.249024\n",
      "[31: 1355/1795] train lossD: 0.076472 lossG: 0.214249\n",
      "[31: 1360/1795] train lossD: 0.007171 lossG: 0.248423\n",
      "[31: 1365/1795] train lossD: -0.013685 lossG: 0.272019\n",
      "[31: 1370/1795] train lossD: -0.018177 lossG: 0.300387\n",
      "[31: 1375/1795] train lossD: -0.019902 lossG: 0.231161\n",
      "[31: 1380/1795] train lossD: -0.044635 lossG: 0.206390\n",
      "[31: 1385/1795] train lossD: 0.060725 lossG: 0.127931\n",
      "[31: 1390/1795] train lossD: -0.203691 lossG: 0.196880\n",
      "[31: 1395/1795] train lossD: -0.071162 lossG: 0.171224\n",
      "[31: 1400/1795] train lossD: -0.132620 lossG: 0.148636\n",
      "[31: 1405/1795] train lossD: -0.186459 lossG: 0.333473\n",
      "[31: 1410/1795] train lossD: -0.111161 lossG: 0.236244\n",
      "[31: 1415/1795] train lossD: -0.109215 lossG: 0.174754\n",
      "[31: 1420/1795] train lossD: -0.174071 lossG: 0.077450\n",
      "[31: 1425/1795] train lossD: 0.011045 lossG: 0.143298\n",
      "[31: 1430/1795] train lossD: 0.072030 lossG: 0.210575\n",
      "[31: 1435/1795] train lossD: -0.018907 lossG: 0.169291\n",
      "[31: 1440/1795] train lossD: -0.129575 lossG: 0.122024\n",
      "[31: 1445/1795] train lossD: -0.114435 lossG: 0.284525\n",
      "[31: 1450/1795] train lossD: -0.073247 lossG: 0.270140\n",
      "[31: 1455/1795] train lossD: -0.097954 lossG: 0.132503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31: 1460/1795] train lossD: 0.476222 lossG: 0.042799\n",
      "[31: 1465/1795] train lossD: 0.033521 lossG: 0.143484\n",
      "[31: 1470/1795] train lossD: -0.077929 lossG: 0.259879\n",
      "[31: 1475/1795] train lossD: -0.090016 lossG: 0.334943\n",
      "[31: 1480/1795] train lossD: -0.112552 lossG: 0.319368\n",
      "[31: 1485/1795] train lossD: -0.043199 lossG: 0.293971\n",
      "[31: 1490/1795] train lossD: -0.015970 lossG: 0.368353\n",
      "[31: 1495/1795] train lossD: 0.034919 lossG: 0.309500\n",
      "[31: 1500/1795] train lossD: -0.104311 lossG: 0.071292\n",
      "[31: 1505/1795] train lossD: -0.053560 lossG: 0.437859\n",
      "[31: 1510/1795] train lossD: -0.045770 lossG: 0.441377\n",
      "[31: 1515/1795] train lossD: 0.052019 lossG: 0.452400\n",
      "[31: 1520/1795] train lossD: 0.044944 lossG: 0.404527\n",
      "[31: 1525/1795] train lossD: 0.004882 lossG: 0.345974\n",
      "[31: 1530/1795] train lossD: -0.000199 lossG: 0.235541\n",
      "[31: 1535/1795] train lossD: 0.000079 lossG: 0.188162\n",
      "[31: 1540/1795] train lossD: 0.018389 lossG: 0.179067\n",
      "[31: 1545/1795] train lossD: -0.115499 lossG: 0.143168\n",
      "[31: 1550/1795] train lossD: -0.083904 lossG: 0.187271\n",
      "[31: 1555/1795] train lossD: -0.016852 lossG: 0.271110\n",
      "[31: 1560/1795] train lossD: -0.075108 lossG: 0.056835\n",
      "[31: 1565/1795] train lossD: -0.031930 lossG: 0.304338\n",
      "[31: 1570/1795] train lossD: -0.113332 lossG: 0.306357\n",
      "[31: 1575/1795] train lossD: -0.112327 lossG: 0.248716\n",
      "[31: 1580/1795] train lossD: -0.122303 lossG: 0.098942\n",
      "[31: 1585/1795] train lossD: -0.044546 lossG: 0.229695\n",
      "[31: 1590/1795] train lossD: -0.044724 lossG: 0.139119\n",
      "[31: 1595/1795] train lossD: -0.139306 lossG: 0.191598\n",
      "[31: 1600/1795] train lossD: -0.167886 lossG: 0.136856\n",
      "[31: 1605/1795] train lossD: -0.114272 lossG: 0.057862\n",
      "[31: 1610/1795] train lossD: 0.014993 lossG: 0.222079\n",
      "[31: 1615/1795] train lossD: -0.022420 lossG: 0.214551\n",
      "[31: 1620/1795] train lossD: -0.065664 lossG: 0.160071\n",
      "[31: 1625/1795] train lossD: -0.085139 lossG: 0.258182\n",
      "[31: 1630/1795] train lossD: -0.113993 lossG: 0.224283\n",
      "[31: 1635/1795] train lossD: -0.061322 lossG: 0.265945\n",
      "[31: 1640/1795] train lossD: -0.145188 lossG: 0.098739\n",
      "[31: 1645/1795] train lossD: -0.089471 lossG: 0.265281\n",
      "[31: 1650/1795] train lossD: -0.236675 lossG: 0.219147\n",
      "[31: 1655/1795] train lossD: -0.045219 lossG: 0.071501\n",
      "[31: 1660/1795] train lossD: -0.150011 lossG: 0.308528\n",
      "[31: 1665/1795] train lossD: 0.019966 lossG: 0.142098\n",
      "[31: 1670/1795] train lossD: 0.020093 lossG: 0.040966\n",
      "[31: 1675/1795] train lossD: -0.033956 lossG: 0.170707\n",
      "[31: 1680/1795] train lossD: -0.164476 lossG: 0.032451\n",
      "[31: 1685/1795] train lossD: 0.011594 lossG: 0.151226\n",
      "[31: 1690/1795] train lossD: -0.007997 lossG: 0.134499\n",
      "[31: 1695/1795] train lossD: 0.117272 lossG: -0.084444\n",
      "[31: 1700/1795] train lossD: -0.114418 lossG: 0.280210\n",
      "[31: 1705/1795] train lossD: -0.153533 lossG: 0.353261\n",
      "[31: 1710/1795] train lossD: 0.237677 lossG: 0.237766\n",
      "[31: 1715/1795] train lossD: -0.042537 lossG: 0.323952\n",
      "[31: 1720/1795] train lossD: -0.030148 lossG: 0.256292\n",
      "[31: 1725/1795] train lossD: -0.170737 lossG: 0.095529\n",
      "[31: 1730/1795] train lossD: -0.026583 lossG: 0.222916\n",
      "[31: 1735/1795] train lossD: 0.010307 lossG: 0.298142\n",
      "[31: 1740/1795] train lossD: 0.036277 lossG: 0.306508\n",
      "[31: 1745/1795] train lossD: -0.104427 lossG: 0.393922\n",
      "[31: 1750/1795] train lossD: -0.194140 lossG: 0.261144\n",
      "[31: 1755/1795] train lossD: 0.089211 lossG: 0.390401\n",
      "[31: 1760/1795] train lossD: -0.077976 lossG: 0.218969\n",
      "[31: 1765/1795] train lossD: -0.067847 lossG: 0.235844\n",
      "[31: 1770/1795] train lossD: 0.110506 lossG: 0.234164\n",
      "[31: 1775/1795] train lossD: 0.002880 lossG: 0.274307\n",
      "[31: 1780/1795] train lossD: -0.049745 lossG: 0.363741\n",
      "[31: 1785/1795] train lossD: -0.070416 lossG: 0.242781\n",
      "[31: 1790/1795] train lossD: 0.086260 lossG: 0.258368\n",
      "0.03799403831362724\n",
      "[32: 0/1795] train lossD: 0.043804 lossG: 0.127519\n",
      "[32: 5/1795] train lossD: 0.016253 lossG: 0.165402\n",
      "[32: 10/1795] train lossD: -0.006288 lossG: 0.308745\n",
      "[32: 15/1795] train lossD: -0.014086 lossG: 0.237463\n",
      "[32: 20/1795] train lossD: -0.212065 lossG: 0.248070\n",
      "[32: 25/1795] train lossD: -0.168545 lossG: 0.231120\n",
      "[32: 30/1795] train lossD: -0.176264 lossG: 0.140419\n",
      "[32: 35/1795] train lossD: -0.102301 lossG: 0.222372\n",
      "[32: 40/1795] train lossD: 0.039052 lossG: 0.127374\n",
      "[32: 45/1795] train lossD: -0.106862 lossG: 0.111334\n",
      "[32: 50/1795] train lossD: -0.007367 lossG: 0.235867\n",
      "[32: 55/1795] train lossD: -0.011725 lossG: 0.224922\n",
      "[32: 60/1795] train lossD: 0.003970 lossG: 0.219704\n",
      "[32: 65/1795] train lossD: -0.040732 lossG: 0.334364\n",
      "[32: 70/1795] train lossD: -0.018716 lossG: 0.248099\n",
      "[32: 75/1795] train lossD: -0.072035 lossG: 0.288089\n",
      "[32: 80/1795] train lossD: -0.266425 lossG: 0.147383\n",
      "[32: 85/1795] train lossD: 0.131087 lossG: 0.209514\n",
      "[32: 90/1795] train lossD: -0.213280 lossG: 0.001721\n",
      "[32: 95/1795] train lossD: 0.001842 lossG: 0.309357\n",
      "[32: 100/1795] train lossD: -0.043097 lossG: 0.288087\n",
      "[32: 105/1795] train lossD: -0.047357 lossG: 0.313625\n",
      "[32: 110/1795] train lossD: -0.033265 lossG: 0.247121\n",
      "[32: 115/1795] train lossD: -0.044910 lossG: 0.231466\n",
      "[32: 120/1795] train lossD: -0.007008 lossG: 0.183818\n",
      "[32: 125/1795] train lossD: -0.228269 lossG: 0.210300\n",
      "[32: 130/1795] train lossD: -0.054939 lossG: 0.101387\n",
      "[32: 135/1795] train lossD: -0.108297 lossG: 0.090169\n",
      "[32: 140/1795] train lossD: 1.747955 lossG: 0.247655\n",
      "[32: 145/1795] train lossD: -0.016537 lossG: 0.325864\n",
      "[32: 150/1795] train lossD: -0.043531 lossG: 0.277185\n",
      "[32: 155/1795] train lossD: -0.121250 lossG: 0.343173\n",
      "[32: 160/1795] train lossD: -0.028022 lossG: 0.324646\n",
      "[32: 165/1795] train lossD: -0.085211 lossG: 0.231770\n",
      "[32: 170/1795] train lossD: -0.087342 lossG: 0.311300\n",
      "[32: 175/1795] train lossD: -0.232299 lossG: 0.201773\n",
      "[32: 180/1795] train lossD: 0.063551 lossG: 0.155541\n",
      "[32: 185/1795] train lossD: -0.203762 lossG: 0.136090\n",
      "[32: 190/1795] train lossD: -0.233706 lossG: 0.207249\n",
      "[32: 195/1795] train lossD: -0.139330 lossG: 0.255971\n",
      "[32: 200/1795] train lossD: -0.021930 lossG: 0.324057\n",
      "[32: 205/1795] train lossD: 0.527629 lossG: 0.213378\n",
      "[32: 210/1795] train lossD: -0.130986 lossG: 0.115229\n",
      "[32: 215/1795] train lossD: -0.140925 lossG: 0.238001\n",
      "[32: 220/1795] train lossD: 0.015816 lossG: 0.402439\n",
      "[32: 225/1795] train lossD: -0.035871 lossG: 0.292794\n",
      "[32: 230/1795] train lossD: -0.183403 lossG: 0.489134\n",
      "[32: 235/1795] train lossD: -0.037554 lossG: 0.242683\n",
      "[32: 240/1795] train lossD: -0.143238 lossG: 0.196212\n",
      "[32: 245/1795] train lossD: -0.266621 lossG: 0.219688\n",
      "[32: 250/1795] train lossD: -0.023415 lossG: 0.325212\n",
      "[32: 255/1795] train lossD: 0.046276 lossG: 0.067174\n",
      "[32: 260/1795] train lossD: -0.115307 lossG: 0.219980\n",
      "[32: 265/1795] train lossD: -0.010548 lossG: 0.113719\n",
      "[32: 270/1795] train lossD: -0.068551 lossG: 0.333307\n",
      "[32: 275/1795] train lossD: -0.009397 lossG: 0.263285\n",
      "[32: 280/1795] train lossD: 0.001178 lossG: 0.225794\n",
      "[32: 285/1795] train lossD: -0.034904 lossG: 0.307271\n",
      "[32: 290/1795] train lossD: -0.012250 lossG: 0.240695\n",
      "[32: 295/1795] train lossD: -0.056926 lossG: 0.216559\n",
      "[32: 300/1795] train lossD: -0.063341 lossG: 0.088545\n",
      "[32: 305/1795] train lossD: -0.091657 lossG: 0.181831\n",
      "[32: 310/1795] train lossD: -0.002883 lossG: 0.229837\n",
      "[32: 315/1795] train lossD: -0.052758 lossG: 0.029523\n",
      "[32: 320/1795] train lossD: -0.027125 lossG: 0.012208\n",
      "[32: 325/1795] train lossD: -0.085647 lossG: 0.157390\n",
      "[32: 330/1795] train lossD: 0.013444 lossG: 0.040229\n",
      "[32: 335/1795] train lossD: -0.166780 lossG: 0.064986\n",
      "[32: 340/1795] train lossD: -0.132991 lossG: 0.270178\n",
      "[32: 345/1795] train lossD: -0.089552 lossG: 0.283288\n",
      "[32: 350/1795] train lossD: -0.169491 lossG: 0.246583\n",
      "[32: 355/1795] train lossD: -0.097310 lossG: 0.153854\n",
      "[32: 360/1795] train lossD: -0.265074 lossG: 0.259943\n",
      "[32: 365/1795] train lossD: -0.046455 lossG: 0.359034\n",
      "[32: 370/1795] train lossD: -0.028130 lossG: 0.407870\n",
      "[32: 375/1795] train lossD: -0.007966 lossG: 0.314197\n",
      "[32: 380/1795] train lossD: -0.097274 lossG: 0.384275\n",
      "[32: 385/1795] train lossD: -0.011662 lossG: 0.399292\n",
      "[32: 390/1795] train lossD: 0.011186 lossG: 0.377212\n",
      "[32: 395/1795] train lossD: -0.045735 lossG: 0.428208\n",
      "[32: 400/1795] train lossD: -0.089359 lossG: 0.321827\n",
      "[32: 405/1795] train lossD: -0.050342 lossG: 0.207130\n",
      "[32: 410/1795] train lossD: 0.216032 lossG: 0.240903\n",
      "[32: 415/1795] train lossD: 0.038742 lossG: 0.288560\n",
      "[32: 420/1795] train lossD: 0.020216 lossG: 0.316212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32: 425/1795] train lossD: -0.006895 lossG: 0.224854\n",
      "[32: 430/1795] train lossD: -0.068225 lossG: 0.232318\n",
      "[32: 435/1795] train lossD: -0.261806 lossG: 0.206755\n",
      "[32: 440/1795] train lossD: -0.005766 lossG: 0.275461\n",
      "[32: 445/1795] train lossD: -0.094080 lossG: 0.328015\n",
      "[32: 450/1795] train lossD: -0.082540 lossG: 0.087431\n",
      "[32: 455/1795] train lossD: -0.059861 lossG: 0.308436\n",
      "[32: 460/1795] train lossD: 0.042005 lossG: 0.290031\n",
      "[32: 465/1795] train lossD: -0.016257 lossG: 0.432196\n",
      "[32: 470/1795] train lossD: -0.072216 lossG: 0.249997\n",
      "[32: 475/1795] train lossD: -0.102996 lossG: 0.202560\n",
      "[32: 480/1795] train lossD: -0.064943 lossG: 0.343191\n",
      "[32: 485/1795] train lossD: -0.253271 lossG: 0.213957\n",
      "[32: 490/1795] train lossD: -0.100088 lossG: 0.296909\n",
      "[32: 495/1795] train lossD: 0.134507 lossG: 0.061329\n",
      "[32: 500/1795] train lossD: -0.021049 lossG: 0.238572\n",
      "[32: 505/1795] train lossD: 0.019637 lossG: 0.265480\n",
      "[32: 510/1795] train lossD: -0.048352 lossG: 0.262985\n",
      "[32: 515/1795] train lossD: 0.116685 lossG: 0.086344\n",
      "[32: 520/1795] train lossD: -0.234313 lossG: 0.168722\n",
      "[32: 525/1795] train lossD: -0.249025 lossG: 0.228947\n",
      "[32: 530/1795] train lossD: -0.225180 lossG: 0.268558\n",
      "[32: 535/1795] train lossD: -0.218687 lossG: -0.025447\n",
      "[32: 540/1795] train lossD: 0.099962 lossG: 0.279608\n",
      "[32: 545/1795] train lossD: 0.044041 lossG: 0.335158\n",
      "[32: 550/1795] train lossD: -0.002871 lossG: 0.343328\n",
      "[32: 555/1795] train lossD: 0.031426 lossG: 0.384041\n",
      "[32: 560/1795] train lossD: -0.035030 lossG: 0.404724\n",
      "[32: 565/1795] train lossD: -0.004297 lossG: 0.453931\n",
      "[32: 570/1795] train lossD: -0.029035 lossG: 0.547763\n",
      "[32: 575/1795] train lossD: 0.039902 lossG: 0.464668\n",
      "[32: 580/1795] train lossD: -0.006969 lossG: 0.421691\n",
      "[32: 585/1795] train lossD: -0.029247 lossG: 0.282371\n",
      "[32: 590/1795] train lossD: 0.007595 lossG: 0.323103\n",
      "[32: 595/1795] train lossD: -0.041044 lossG: 0.275164\n",
      "[32: 600/1795] train lossD: -0.265660 lossG: 0.280466\n",
      "[32: 605/1795] train lossD: -0.131899 lossG: 0.187401\n",
      "[32: 610/1795] train lossD: -0.050909 lossG: 0.323119\n",
      "[32: 615/1795] train lossD: 0.006506 lossG: 0.138793\n",
      "[32: 620/1795] train lossD: -0.033522 lossG: 0.219852\n",
      "[32: 625/1795] train lossD: -0.185429 lossG: 0.170367\n",
      "[32: 630/1795] train lossD: -0.083166 lossG: 0.173813\n",
      "[32: 635/1795] train lossD: -0.365949 lossG: 0.154916\n",
      "[32: 640/1795] train lossD: -0.243565 lossG: 0.282257\n",
      "[32: 645/1795] train lossD: 0.436996 lossG: 0.248164\n",
      "[32: 650/1795] train lossD: 0.107345 lossG: 0.350705\n",
      "[32: 655/1795] train lossD: 0.025447 lossG: 0.328293\n",
      "[32: 660/1795] train lossD: 0.048866 lossG: 0.433705\n",
      "[32: 665/1795] train lossD: -0.011989 lossG: 0.474585\n",
      "[32: 670/1795] train lossD: -0.039921 lossG: 0.336948\n",
      "[32: 675/1795] train lossD: -0.063901 lossG: 0.018919\n",
      "[32: 680/1795] train lossD: -0.114384 lossG: 0.153148\n",
      "[32: 685/1795] train lossD: -0.027851 lossG: 0.491303\n",
      "[32: 690/1795] train lossD: -0.028148 lossG: 0.479516\n",
      "[32: 695/1795] train lossD: -0.021617 lossG: 0.427998\n",
      "[32: 700/1795] train lossD: 0.051821 lossG: 0.379396\n",
      "[32: 705/1795] train lossD: -0.049849 lossG: 0.403186\n",
      "[32: 710/1795] train lossD: 0.026788 lossG: 0.151236\n",
      "[32: 715/1795] train lossD: 0.008378 lossG: 0.131683\n",
      "[32: 720/1795] train lossD: -0.102805 lossG: 0.279525\n",
      "[32: 725/1795] train lossD: -0.096826 lossG: 0.483654\n",
      "[32: 730/1795] train lossD: 0.004661 lossG: 0.319605\n",
      "[32: 735/1795] train lossD: -0.037805 lossG: 0.358848\n",
      "[32: 740/1795] train lossD: -0.134936 lossG: 0.221529\n",
      "[32: 745/1795] train lossD: -0.039794 lossG: 0.105814\n",
      "[32: 750/1795] train lossD: -0.038010 lossG: -0.011970\n",
      "[32: 755/1795] train lossD: 0.366903 lossG: -0.038531\n",
      "[32: 760/1795] train lossD: -0.026167 lossG: 0.234559\n",
      "[32: 765/1795] train lossD: -0.062032 lossG: 0.153280\n",
      "[32: 770/1795] train lossD: -0.241095 lossG: 0.193209\n",
      "[32: 775/1795] train lossD: -0.001529 lossG: 0.048426\n",
      "[32: 780/1795] train lossD: -0.245227 lossG: -0.139412\n",
      "[32: 785/1795] train lossD: -0.103140 lossG: 0.301633\n",
      "[32: 790/1795] train lossD: 0.025853 lossG: 0.352527\n",
      "[32: 795/1795] train lossD: -0.026682 lossG: 0.380947\n",
      "[32: 800/1795] train lossD: -0.017848 lossG: 0.434182\n",
      "[32: 805/1795] train lossD: 0.055562 lossG: 0.248960\n",
      "[32: 810/1795] train lossD: -0.012545 lossG: 0.296200\n",
      "[32: 815/1795] train lossD: 0.006617 lossG: 0.249021\n",
      "[32: 820/1795] train lossD: -0.016576 lossG: 0.248291\n",
      "[32: 825/1795] train lossD: -0.185135 lossG: 0.015054\n",
      "[32: 830/1795] train lossD: -0.163950 lossG: 0.060349\n",
      "[32: 835/1795] train lossD: -0.173807 lossG: 0.230145\n",
      "[32: 840/1795] train lossD: -0.054365 lossG: 0.334919\n",
      "[32: 845/1795] train lossD: -0.051025 lossG: 0.305958\n",
      "[32: 850/1795] train lossD: 0.001639 lossG: 0.261629\n",
      "[32: 855/1795] train lossD: -0.344668 lossG: 0.162849\n",
      "[32: 860/1795] train lossD: 0.000385 lossG: 0.078657\n",
      "[32: 865/1795] train lossD: 0.011971 lossG: 0.073962\n",
      "[32: 870/1795] train lossD: -0.016850 lossG: 0.071330\n",
      "[32: 875/1795] train lossD: -0.109875 lossG: 0.005278\n",
      "[32: 880/1795] train lossD: -0.208181 lossG: 0.130406\n",
      "[32: 885/1795] train lossD: -0.186060 lossG: 0.038085\n",
      "[32: 890/1795] train lossD: -0.031811 lossG: 0.016861\n",
      "[32: 895/1795] train lossD: -0.027086 lossG: 0.164414\n",
      "[32: 900/1795] train lossD: -0.013719 lossG: 0.169061\n",
      "[32: 905/1795] train lossD: -0.014635 lossG: 0.174004\n",
      "[32: 910/1795] train lossD: -0.010552 lossG: 0.186402\n",
      "[32: 915/1795] train lossD: -0.020945 lossG: 0.181079\n",
      "[32: 920/1795] train lossD: -0.105998 lossG: 0.127488\n",
      "[32: 925/1795] train lossD: -0.254114 lossG: 0.111209\n",
      "[32: 930/1795] train lossD: -0.069296 lossG: 0.380920\n",
      "[32: 935/1795] train lossD: -0.012276 lossG: 0.123861\n",
      "[32: 940/1795] train lossD: 0.214681 lossG: 0.191760\n",
      "[32: 945/1795] train lossD: -0.095915 lossG: 0.284181\n",
      "[32: 950/1795] train lossD: -0.064739 lossG: 0.197146\n",
      "[32: 955/1795] train lossD: 0.010445 lossG: 0.150524\n",
      "[32: 960/1795] train lossD: -0.069916 lossG: 0.247599\n",
      "[32: 965/1795] train lossD: -0.045855 lossG: 0.163612\n",
      "[32: 970/1795] train lossD: -0.072451 lossG: 0.063748\n",
      "[32: 975/1795] train lossD: -0.207524 lossG: 0.271827\n",
      "[32: 980/1795] train lossD: -0.140213 lossG: -0.080396\n",
      "[32: 985/1795] train lossD: 0.249459 lossG: 0.267802\n",
      "[32: 990/1795] train lossD: 0.009775 lossG: 0.405276\n",
      "[32: 995/1795] train lossD: 0.076447 lossG: 0.314782\n",
      "[32: 1000/1795] train lossD: -0.111475 lossG: 0.297499\n",
      "[32: 1005/1795] train lossD: -0.308748 lossG: -0.003296\n",
      "[32: 1010/1795] train lossD: -0.080193 lossG: 0.254434\n",
      "[32: 1015/1795] train lossD: 0.006517 lossG: 0.310932\n",
      "[32: 1020/1795] train lossD: -0.050362 lossG: 0.280565\n",
      "[32: 1025/1795] train lossD: 0.032440 lossG: 0.408274\n",
      "[32: 1030/1795] train lossD: -0.203555 lossG: 0.189143\n",
      "[32: 1035/1795] train lossD: -0.068144 lossG: -0.045537\n",
      "[32: 1040/1795] train lossD: 0.282631 lossG: 0.015716\n",
      "[32: 1045/1795] train lossD: -0.105994 lossG: 0.087163\n",
      "[32: 1050/1795] train lossD: -0.060668 lossG: 0.009270\n",
      "[32: 1055/1795] train lossD: -0.056897 lossG: 0.178675\n",
      "[32: 1060/1795] train lossD: -0.019487 lossG: 0.224671\n",
      "[32: 1065/1795] train lossD: -0.085635 lossG: 0.210331\n",
      "[32: 1070/1795] train lossD: -0.044768 lossG: 0.255217\n",
      "[32: 1075/1795] train lossD: -0.073958 lossG: 0.289892\n",
      "[32: 1080/1795] train lossD: 0.042188 lossG: 0.246944\n",
      "[32: 1085/1795] train lossD: -0.080322 lossG: -0.057846\n",
      "[32: 1090/1795] train lossD: 0.212013 lossG: -0.271309\n",
      "[32: 1095/1795] train lossD: -0.138669 lossG: 0.173008\n",
      "[32: 1100/1795] train lossD: -0.175090 lossG: 0.270076\n",
      "[32: 1105/1795] train lossD: 0.096360 lossG: 0.059103\n",
      "[32: 1110/1795] train lossD: -0.150023 lossG: 0.240207\n",
      "[32: 1115/1795] train lossD: -0.288640 lossG: 0.325258\n",
      "[32: 1120/1795] train lossD: -0.364010 lossG: 0.176725\n",
      "[32: 1125/1795] train lossD: -0.106509 lossG: 0.183726\n",
      "[32: 1130/1795] train lossD: -0.031068 lossG: 0.169740\n",
      "[32: 1135/1795] train lossD: -0.201985 lossG: 0.121762\n",
      "[32: 1140/1795] train lossD: -0.069186 lossG: 0.450379\n",
      "[32: 1145/1795] train lossD: 0.020522 lossG: 0.430118\n",
      "[32: 1150/1795] train lossD: -0.019411 lossG: -0.030498\n",
      "[32: 1155/1795] train lossD: -0.021998 lossG: 0.193077\n",
      "[32: 1160/1795] train lossD: -0.095746 lossG: 0.341190\n",
      "[32: 1165/1795] train lossD: -0.087990 lossG: 0.291665\n",
      "[32: 1170/1795] train lossD: 0.293551 lossG: 0.211691\n",
      "[32: 1175/1795] train lossD: 0.072306 lossG: 0.308465\n",
      "[32: 1180/1795] train lossD: -0.020145 lossG: 0.362063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32: 1185/1795] train lossD: -0.010360 lossG: 0.354198\n",
      "[32: 1190/1795] train lossD: 0.022936 lossG: 0.309793\n",
      "[32: 1195/1795] train lossD: -0.051545 lossG: 0.234706\n",
      "[32: 1200/1795] train lossD: 0.041567 lossG: 0.302259\n",
      "[32: 1205/1795] train lossD: -0.124594 lossG: 0.324920\n",
      "[32: 1210/1795] train lossD: -0.144175 lossG: 0.241242\n",
      "[32: 1215/1795] train lossD: 0.158823 lossG: 0.310603\n",
      "[32: 1220/1795] train lossD: -0.166296 lossG: 0.377716\n",
      "[32: 1225/1795] train lossD: -0.006146 lossG: 0.293927\n",
      "[32: 1230/1795] train lossD: -0.208391 lossG: 0.081731\n",
      "[32: 1235/1795] train lossD: 0.015303 lossG: 0.370363\n",
      "[32: 1240/1795] train lossD: -0.076651 lossG: 0.514382\n",
      "[32: 1245/1795] train lossD: -0.048553 lossG: 0.411325\n",
      "[32: 1250/1795] train lossD: 0.006357 lossG: 0.358407\n",
      "[32: 1255/1795] train lossD: -0.096540 lossG: 0.192679\n",
      "[32: 1260/1795] train lossD: -0.144039 lossG: 0.180267\n",
      "[32: 1265/1795] train lossD: -0.337227 lossG: 0.300207\n",
      "[32: 1270/1795] train lossD: -0.171683 lossG: 0.248842\n",
      "[32: 1275/1795] train lossD: -0.072363 lossG: -0.104609\n",
      "[32: 1280/1795] train lossD: -0.076288 lossG: 0.197317\n",
      "[32: 1285/1795] train lossD: -0.277373 lossG: 0.007342\n",
      "[32: 1290/1795] train lossD: -0.138386 lossG: 0.223936\n",
      "[32: 1295/1795] train lossD: -0.132413 lossG: 0.231165\n",
      "[32: 1300/1795] train lossD: -0.036433 lossG: 0.315642\n",
      "[32: 1305/1795] train lossD: -0.045633 lossG: 0.430532\n",
      "[32: 1310/1795] train lossD: -0.213265 lossG: 0.324074\n",
      "[32: 1315/1795] train lossD: -0.001062 lossG: 0.300101\n",
      "[32: 1320/1795] train lossD: 0.001431 lossG: 0.361461\n",
      "[32: 1325/1795] train lossD: -0.016673 lossG: 0.370190\n",
      "[32: 1330/1795] train lossD: -0.100487 lossG: 0.395760\n",
      "[32: 1335/1795] train lossD: -0.053097 lossG: 0.302271\n",
      "[32: 1340/1795] train lossD: -0.338533 lossG: 0.190493\n",
      "[32: 1345/1795] train lossD: -0.052077 lossG: 0.245136\n",
      "[32: 1350/1795] train lossD: -0.165819 lossG: 0.016788\n",
      "[32: 1355/1795] train lossD: -0.236922 lossG: 0.007079\n",
      "[32: 1360/1795] train lossD: -0.291836 lossG: 0.280511\n",
      "[32: 1365/1795] train lossD: -0.040437 lossG: 0.157581\n",
      "[32: 1370/1795] train lossD: -0.109113 lossG: 0.148649\n",
      "[32: 1375/1795] train lossD: 0.086621 lossG: 0.327450\n",
      "[32: 1380/1795] train lossD: -0.082854 lossG: -0.071128\n",
      "[32: 1385/1795] train lossD: -0.030549 lossG: 0.184282\n",
      "[32: 1390/1795] train lossD: -0.144986 lossG: 0.374049\n",
      "[32: 1395/1795] train lossD: 0.030080 lossG: 0.107029\n",
      "[32: 1400/1795] train lossD: -0.204312 lossG: 0.129059\n",
      "[32: 1405/1795] train lossD: -0.084582 lossG: 0.074509\n",
      "[32: 1410/1795] train lossD: 0.043421 lossG: 0.252072\n",
      "[32: 1415/1795] train lossD: -0.089212 lossG: 0.045440\n",
      "[32: 1420/1795] train lossD: -0.036115 lossG: 0.224252\n",
      "[32: 1425/1795] train lossD: -0.098739 lossG: 0.141819\n",
      "[32: 1430/1795] train lossD: 0.022884 lossG: 0.281346\n",
      "[32: 1435/1795] train lossD: 0.030820 lossG: 0.260454\n",
      "[32: 1440/1795] train lossD: -0.003644 lossG: 0.221122\n",
      "[32: 1445/1795] train lossD: 0.009325 lossG: 0.285331\n",
      "[32: 1450/1795] train lossD: -0.170017 lossG: 0.036943\n",
      "[32: 1455/1795] train lossD: 1.363275 lossG: 0.282942\n",
      "[32: 1460/1795] train lossD: 0.063011 lossG: 0.376731\n",
      "[32: 1465/1795] train lossD: 0.003637 lossG: 0.544472\n",
      "[32: 1470/1795] train lossD: -0.053108 lossG: 0.497126\n",
      "[32: 1475/1795] train lossD: 0.022558 lossG: 0.440117\n",
      "[32: 1480/1795] train lossD: 0.018372 lossG: 0.380772\n",
      "[32: 1485/1795] train lossD: -0.034416 lossG: 0.395705\n",
      "[32: 1490/1795] train lossD: -0.234024 lossG: 0.176324\n",
      "[32: 1495/1795] train lossD: 0.014053 lossG: 0.362412\n",
      "[32: 1500/1795] train lossD: -0.104007 lossG: 0.064525\n",
      "[32: 1505/1795] train lossD: -0.101035 lossG: 0.256274\n",
      "[32: 1510/1795] train lossD: -0.103796 lossG: 0.300368\n",
      "[32: 1515/1795] train lossD: -0.020713 lossG: 0.159251\n",
      "[32: 1520/1795] train lossD: -0.014311 lossG: 0.141517\n",
      "[32: 1525/1795] train lossD: 0.039241 lossG: 0.195862\n",
      "[32: 1530/1795] train lossD: -0.102197 lossG: 0.214835\n",
      "[32: 1535/1795] train lossD: -0.294771 lossG: 0.251889\n",
      "[32: 1540/1795] train lossD: -0.202330 lossG: 0.103804\n",
      "[32: 1545/1795] train lossD: -0.078026 lossG: 0.396614\n",
      "[32: 1550/1795] train lossD: 0.052127 lossG: 0.271571\n",
      "[32: 1555/1795] train lossD: 0.036261 lossG: 0.215454\n",
      "[32: 1560/1795] train lossD: -0.084741 lossG: 0.333180\n",
      "[32: 1565/1795] train lossD: -0.032893 lossG: 0.149596\n",
      "[32: 1570/1795] train lossD: 0.030099 lossG: 0.254639\n",
      "[32: 1575/1795] train lossD: -0.151321 lossG: 0.117813\n",
      "[32: 1580/1795] train lossD: -0.111092 lossG: -0.033013\n",
      "[32: 1585/1795] train lossD: 0.079511 lossG: 0.303428\n",
      "[32: 1590/1795] train lossD: -0.013238 lossG: 0.366831\n",
      "[32: 1595/1795] train lossD: -0.020453 lossG: 0.447388\n",
      "[32: 1600/1795] train lossD: 0.057555 lossG: 0.396245\n",
      "[32: 1605/1795] train lossD: 0.041498 lossG: 0.470895\n",
      "[32: 1610/1795] train lossD: 0.063913 lossG: 0.460660\n",
      "[32: 1615/1795] train lossD: 0.004249 lossG: 0.450917\n",
      "[32: 1620/1795] train lossD: -0.087193 lossG: 0.438486\n",
      "[32: 1625/1795] train lossD: -0.125708 lossG: 0.259890\n",
      "[32: 1630/1795] train lossD: 0.038564 lossG: 0.306614\n",
      "[32: 1635/1795] train lossD: -0.139181 lossG: 0.090002\n",
      "[32: 1640/1795] train lossD: -0.055454 lossG: 0.328900\n",
      "[32: 1645/1795] train lossD: -0.154162 lossG: -0.056761\n",
      "[32: 1650/1795] train lossD: -0.022572 lossG: 0.142459\n",
      "[32: 1655/1795] train lossD: -0.065635 lossG: -0.009084\n",
      "[32: 1660/1795] train lossD: -0.178481 lossG: -0.044832\n",
      "[32: 1665/1795] train lossD: -0.140164 lossG: 0.349353\n",
      "[32: 1670/1795] train lossD: -0.051954 lossG: 0.375134\n",
      "[32: 1675/1795] train lossD: -0.052865 lossG: 0.285975\n",
      "[32: 1680/1795] train lossD: -0.001636 lossG: 0.243416\n",
      "[32: 1685/1795] train lossD: -0.086225 lossG: 0.253244\n",
      "[32: 1690/1795] train lossD: -0.134630 lossG: 0.240085\n",
      "[32: 1695/1795] train lossD: -0.254174 lossG: 0.228415\n",
      "[32: 1700/1795] train lossD: -0.114008 lossG: 0.214808\n",
      "[32: 1705/1795] train lossD: -0.203485 lossG: 0.034232\n",
      "[32: 1710/1795] train lossD: -0.354595 lossG: 0.161364\n",
      "[32: 1715/1795] train lossD: -0.047362 lossG: 0.333158\n",
      "[32: 1720/1795] train lossD: -0.157096 lossG: 0.110843\n",
      "[32: 1725/1795] train lossD: 0.076192 lossG: 0.161398\n",
      "[32: 1730/1795] train lossD: 0.011151 lossG: -0.176240\n",
      "[32: 1735/1795] train lossD: -0.036485 lossG: 0.058387\n",
      "[32: 1740/1795] train lossD: -0.012085 lossG: 0.250012\n",
      "[32: 1745/1795] train lossD: -0.087228 lossG: 0.104856\n",
      "[32: 1750/1795] train lossD: -0.035286 lossG: 0.268557\n",
      "[32: 1755/1795] train lossD: -0.195087 lossG: 0.021095\n",
      "[32: 1760/1795] train lossD: -0.123886 lossG: 0.311062\n",
      "[32: 1765/1795] train lossD: -0.110070 lossG: 0.089127\n",
      "[32: 1770/1795] train lossD: -0.055208 lossG: 0.112371\n",
      "[32: 1775/1795] train lossD: -0.162452 lossG: 0.134591\n",
      "[32: 1780/1795] train lossD: -0.174755 lossG: 0.150033\n",
      "[32: 1785/1795] train lossD: 1.448511 lossG: 0.105872\n",
      "[32: 1790/1795] train lossD: 0.588599 lossG: 0.349180\n",
      "0.05065019801259041\n",
      "[33: 0/1795] train lossD: 0.329906 lossG: 0.450513\n",
      "[33: 5/1795] train lossD: 0.187498 lossG: 0.415458\n",
      "[33: 10/1795] train lossD: 0.257652 lossG: 0.419972\n",
      "[33: 15/1795] train lossD: 0.193915 lossG: 0.419172\n",
      "[33: 20/1795] train lossD: 0.086325 lossG: 0.549322\n",
      "[33: 25/1795] train lossD: 0.026225 lossG: 0.475139\n",
      "[33: 30/1795] train lossD: 0.021876 lossG: 0.412566\n",
      "[33: 35/1795] train lossD: 0.042815 lossG: 0.391724\n",
      "[33: 40/1795] train lossD: 0.062343 lossG: 0.403553\n",
      "[33: 45/1795] train lossD: 0.010621 lossG: 0.392239\n",
      "[33: 50/1795] train lossD: -0.022727 lossG: 0.347049\n",
      "[33: 55/1795] train lossD: 0.018019 lossG: 0.287703\n",
      "[33: 60/1795] train lossD: -0.006062 lossG: 0.262345\n",
      "[33: 65/1795] train lossD: -0.040201 lossG: 0.213425\n",
      "[33: 70/1795] train lossD: -0.006758 lossG: 0.359241\n",
      "[33: 75/1795] train lossD: 0.040608 lossG: 0.336151\n",
      "[33: 80/1795] train lossD: -0.010843 lossG: 0.309344\n",
      "[33: 85/1795] train lossD: -0.001380 lossG: 0.235117\n",
      "[33: 90/1795] train lossD: -0.058960 lossG: -0.035369\n",
      "[33: 95/1795] train lossD: 0.012752 lossG: 0.284522\n",
      "[33: 100/1795] train lossD: 0.022740 lossG: 0.289013\n",
      "[33: 105/1795] train lossD: 0.041075 lossG: 0.242553\n",
      "[33: 110/1795] train lossD: -0.050497 lossG: 0.285100\n",
      "[33: 115/1795] train lossD: -0.014507 lossG: 0.343765\n",
      "[33: 120/1795] train lossD: -0.033613 lossG: 0.086187\n",
      "[33: 125/1795] train lossD: -0.096265 lossG: 0.064941\n",
      "[33: 130/1795] train lossD: -0.025225 lossG: 0.389076\n",
      "[33: 135/1795] train lossD: -0.082278 lossG: 0.357834\n",
      "[33: 140/1795] train lossD: -0.053821 lossG: 0.247853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33: 145/1795] train lossD: -0.096792 lossG: 0.214266\n",
      "[33: 150/1795] train lossD: -0.063098 lossG: 0.074166\n",
      "[33: 155/1795] train lossD: -0.026707 lossG: 0.274490\n",
      "[33: 160/1795] train lossD: 0.042188 lossG: 0.296656\n",
      "[33: 165/1795] train lossD: 0.079762 lossG: 0.215749\n",
      "[33: 170/1795] train lossD: -0.186534 lossG: 0.259010\n",
      "[33: 175/1795] train lossD: -0.226231 lossG: 0.002254\n",
      "[33: 180/1795] train lossD: 0.017006 lossG: 0.322175\n",
      "[33: 185/1795] train lossD: -0.041535 lossG: 0.335604\n",
      "[33: 190/1795] train lossD: 0.069385 lossG: 0.284838\n",
      "[33: 195/1795] train lossD: -0.062112 lossG: 0.374908\n",
      "[33: 200/1795] train lossD: -0.016133 lossG: 0.328888\n",
      "[33: 205/1795] train lossD: 0.014077 lossG: 0.270000\n",
      "[33: 210/1795] train lossD: -0.041423 lossG: 0.285093\n",
      "[33: 215/1795] train lossD: -0.128909 lossG: 0.260109\n",
      "[33: 220/1795] train lossD: -0.124303 lossG: 0.246519\n",
      "[33: 225/1795] train lossD: -0.344824 lossG: 0.112746\n",
      "[33: 230/1795] train lossD: -0.132590 lossG: 0.258573\n",
      "[33: 235/1795] train lossD: -0.128432 lossG: 0.058571\n",
      "[33: 240/1795] train lossD: -0.027808 lossG: 0.229076\n",
      "[33: 245/1795] train lossD: -0.193766 lossG: 0.332826\n",
      "[33: 250/1795] train lossD: 0.120891 lossG: -0.015997\n",
      "[33: 255/1795] train lossD: -0.126558 lossG: 0.123203\n",
      "[33: 260/1795] train lossD: -0.060132 lossG: 0.095299\n",
      "[33: 265/1795] train lossD: 0.168393 lossG: -0.051615\n",
      "[33: 270/1795] train lossD: -0.158041 lossG: 0.264372\n",
      "[33: 275/1795] train lossD: -0.028691 lossG: 0.365316\n",
      "[33: 280/1795] train lossD: -0.043213 lossG: 0.378652\n",
      "[33: 285/1795] train lossD: -0.012137 lossG: 0.404952\n",
      "[33: 290/1795] train lossD: -0.043505 lossG: 0.363780\n",
      "[33: 295/1795] train lossD: -0.045469 lossG: 0.324718\n",
      "[33: 300/1795] train lossD: -0.231949 lossG: 0.144082\n",
      "[33: 305/1795] train lossD: 0.053653 lossG: 0.165168\n",
      "[33: 310/1795] train lossD: -0.098004 lossG: 0.355205\n",
      "[33: 315/1795] train lossD: -0.029736 lossG: 0.387159\n",
      "[33: 320/1795] train lossD: -0.000073 lossG: 0.347631\n",
      "[33: 325/1795] train lossD: -0.087013 lossG: 0.319334\n",
      "[33: 330/1795] train lossD: -0.088240 lossG: 0.227964\n",
      "[33: 335/1795] train lossD: -0.060547 lossG: 0.251824\n",
      "[33: 340/1795] train lossD: -0.343622 lossG: 0.219788\n",
      "[33: 345/1795] train lossD: -0.242992 lossG: 0.254288\n",
      "[33: 350/1795] train lossD: -0.070464 lossG: -0.018297\n",
      "[33: 355/1795] train lossD: -0.109213 lossG: 0.208860\n",
      "[33: 360/1795] train lossD: 0.020329 lossG: 0.245360\n",
      "[33: 365/1795] train lossD: -0.078141 lossG: 0.143729\n",
      "[33: 370/1795] train lossD: -0.004880 lossG: 0.294758\n",
      "[33: 375/1795] train lossD: -0.046211 lossG: 0.291291\n",
      "[33: 380/1795] train lossD: -0.007856 lossG: 0.380037\n",
      "[33: 385/1795] train lossD: -0.196242 lossG: -0.162103\n",
      "[33: 390/1795] train lossD: 0.158262 lossG: 0.232485\n",
      "[33: 395/1795] train lossD: -0.039349 lossG: 0.319344\n",
      "[33: 400/1795] train lossD: 0.001629 lossG: 0.376064\n",
      "[33: 405/1795] train lossD: 0.000064 lossG: 0.437970\n",
      "[33: 410/1795] train lossD: -0.021636 lossG: 0.337895\n",
      "[33: 415/1795] train lossD: 1.475021 lossG: 0.350118\n",
      "[33: 420/1795] train lossD: 0.001264 lossG: 0.435633\n",
      "[33: 425/1795] train lossD: -0.023007 lossG: 0.408751\n",
      "[33: 430/1795] train lossD: -0.007385 lossG: 0.399571\n",
      "[33: 435/1795] train lossD: -0.000806 lossG: 0.409902\n",
      "[33: 440/1795] train lossD: 0.071138 lossG: 0.364213\n",
      "[33: 445/1795] train lossD: 0.037613 lossG: 0.317561\n",
      "[33: 450/1795] train lossD: 0.015934 lossG: 0.340721\n",
      "[33: 455/1795] train lossD: 0.009340 lossG: 0.300656\n",
      "[33: 460/1795] train lossD: -0.087734 lossG: 0.050954\n",
      "[33: 465/1795] train lossD: -0.200683 lossG: 0.294559\n",
      "[33: 470/1795] train lossD: -0.279051 lossG: 0.146886\n",
      "[33: 475/1795] train lossD: -0.144021 lossG: 0.207538\n",
      "[33: 480/1795] train lossD: -0.337412 lossG: 0.040084\n",
      "[33: 485/1795] train lossD: -0.047304 lossG: 0.205333\n",
      "[33: 490/1795] train lossD: -0.001299 lossG: 0.308264\n",
      "[33: 495/1795] train lossD: -0.071637 lossG: 0.227340\n",
      "[33: 500/1795] train lossD: 0.009319 lossG: 0.300622\n",
      "[33: 505/1795] train lossD: 0.023691 lossG: 0.412451\n",
      "[33: 510/1795] train lossD: -0.003636 lossG: 0.386722\n",
      "[33: 515/1795] train lossD: -0.007392 lossG: 0.341392\n",
      "[33: 520/1795] train lossD: -0.110987 lossG: 0.140904\n",
      "[33: 525/1795] train lossD: -0.042095 lossG: 0.190288\n",
      "[33: 530/1795] train lossD: -0.259045 lossG: 0.180971\n",
      "[33: 535/1795] train lossD: -0.130744 lossG: -0.106501\n",
      "[33: 540/1795] train lossD: 2.682208 lossG: 0.232006\n",
      "[33: 545/1795] train lossD: 0.074382 lossG: 0.215956\n",
      "[33: 550/1795] train lossD: -0.006543 lossG: 0.290972\n",
      "[33: 555/1795] train lossD: -0.002696 lossG: 0.317141\n",
      "[33: 560/1795] train lossD: -0.008539 lossG: 0.310166\n",
      "[33: 565/1795] train lossD: 0.006949 lossG: 0.337334\n",
      "[33: 570/1795] train lossD: 0.048538 lossG: 0.278253\n",
      "[33: 575/1795] train lossD: -0.015914 lossG: 0.290449\n",
      "[33: 580/1795] train lossD: -0.029746 lossG: 0.332949\n",
      "[33: 585/1795] train lossD: -0.060482 lossG: 0.288691\n",
      "[33: 590/1795] train lossD: -0.308996 lossG: 0.205958\n",
      "[33: 595/1795] train lossD: 0.004250 lossG: 0.339708\n",
      "[33: 600/1795] train lossD: 0.031998 lossG: 0.324900\n",
      "[33: 605/1795] train lossD: -0.174388 lossG: 0.072382\n",
      "[33: 610/1795] train lossD: 0.115741 lossG: 0.250564\n",
      "[33: 615/1795] train lossD: -0.022880 lossG: -0.004216\n",
      "[33: 620/1795] train lossD: -0.239498 lossG: 0.307057\n",
      "[33: 625/1795] train lossD: -0.182454 lossG: 0.062552\n",
      "[33: 630/1795] train lossD: -0.264850 lossG: 0.036820\n",
      "[33: 635/1795] train lossD: -0.073925 lossG: 0.357923\n",
      "[33: 640/1795] train lossD: -0.112292 lossG: 0.089353\n",
      "[33: 645/1795] train lossD: -0.032359 lossG: 0.253782\n",
      "[33: 650/1795] train lossD: -0.275660 lossG: 0.003638\n",
      "[33: 655/1795] train lossD: 0.015657 lossG: 0.395493\n",
      "[33: 660/1795] train lossD: -0.002738 lossG: 0.396692\n",
      "[33: 665/1795] train lossD: 0.155693 lossG: 0.251473\n",
      "[33: 670/1795] train lossD: -0.034292 lossG: 0.331885\n",
      "[33: 675/1795] train lossD: 0.003542 lossG: 0.309922\n",
      "[33: 680/1795] train lossD: -0.017843 lossG: 0.294955\n",
      "[33: 685/1795] train lossD: -0.063315 lossG: 0.321054\n",
      "[33: 690/1795] train lossD: 0.120939 lossG: 0.380007\n",
      "[33: 695/1795] train lossD: -0.319214 lossG: 0.148014\n",
      "[33: 700/1795] train lossD: -0.381199 lossG: 0.184847\n",
      "[33: 705/1795] train lossD: -0.164398 lossG: 0.228456\n",
      "[33: 710/1795] train lossD: -0.168379 lossG: -0.031765\n",
      "[33: 715/1795] train lossD: -0.064441 lossG: 0.132562\n",
      "[33: 720/1795] train lossD: -0.364410 lossG: 0.122656\n",
      "[33: 725/1795] train lossD: -0.301522 lossG: -0.301076\n",
      "[33: 730/1795] train lossD: -0.175540 lossG: 0.241179\n",
      "[33: 735/1795] train lossD: 0.054147 lossG: 0.126324\n",
      "[33: 740/1795] train lossD: -0.122653 lossG: 0.187076\n",
      "[33: 745/1795] train lossD: -0.372126 lossG: 0.167674\n",
      "[33: 750/1795] train lossD: -0.088616 lossG: 0.259588\n",
      "[33: 755/1795] train lossD: -0.201932 lossG: 0.212093\n",
      "[33: 760/1795] train lossD: -0.617271 lossG: 0.373941\n",
      "[33: 765/1795] train lossD: -0.404550 lossG: 0.295234\n",
      "[33: 770/1795] train lossD: 0.042626 lossG: 0.229346\n",
      "[33: 775/1795] train lossD: -0.161328 lossG: 0.405403\n",
      "[33: 780/1795] train lossD: -0.237631 lossG: -0.070746\n",
      "[33: 785/1795] train lossD: -0.079880 lossG: 0.143428\n",
      "[33: 790/1795] train lossD: 0.264289 lossG: 0.360250\n",
      "[33: 795/1795] train lossD: 0.056167 lossG: 0.435906\n",
      "[33: 800/1795] train lossD: -0.054666 lossG: 0.253436\n",
      "[33: 805/1795] train lossD: -0.487875 lossG: 0.300345\n",
      "[33: 810/1795] train lossD: -0.268320 lossG: 0.251631\n",
      "[33: 815/1795] train lossD: 0.091475 lossG: 0.097540\n",
      "[33: 820/1795] train lossD: 0.026081 lossG: 0.098457\n",
      "[33: 825/1795] train lossD: 0.062098 lossG: 0.160689\n",
      "[33: 830/1795] train lossD: -0.140475 lossG: 0.197360\n",
      "[33: 835/1795] train lossD: -0.070739 lossG: 0.374092\n",
      "[33: 840/1795] train lossD: -0.220974 lossG: 0.260278\n",
      "[33: 845/1795] train lossD: 0.074490 lossG: 0.322784\n",
      "[33: 850/1795] train lossD: 0.048799 lossG: 0.340863\n",
      "[33: 855/1795] train lossD: -0.007384 lossG: 0.420196\n",
      "[33: 860/1795] train lossD: -0.003668 lossG: 0.396703\n",
      "[33: 865/1795] train lossD: -0.112217 lossG: 0.341879\n",
      "[33: 870/1795] train lossD: -0.119508 lossG: 0.211211\n",
      "[33: 875/1795] train lossD: -0.459618 lossG: 0.103991\n",
      "[33: 880/1795] train lossD: -0.094373 lossG: 0.335328\n",
      "[33: 885/1795] train lossD: -0.496351 lossG: 0.178897\n",
      "[33: 890/1795] train lossD: -0.193899 lossG: 0.257669\n",
      "[33: 895/1795] train lossD: -0.047371 lossG: 0.083587\n",
      "[33: 900/1795] train lossD: 0.048730 lossG: 0.023775\n",
      "[33: 905/1795] train lossD: 0.043517 lossG: 0.146178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33: 910/1795] train lossD: -0.039068 lossG: 0.092258\n",
      "[33: 915/1795] train lossD: -0.105847 lossG: -0.163218\n",
      "[33: 920/1795] train lossD: 0.372726 lossG: 0.238947\n",
      "[33: 925/1795] train lossD: 0.030512 lossG: 0.303677\n",
      "[33: 930/1795] train lossD: -0.001469 lossG: 0.316243\n",
      "[33: 935/1795] train lossD: -0.070479 lossG: 0.357656\n",
      "[33: 940/1795] train lossD: 0.027703 lossG: 0.324015\n",
      "[33: 945/1795] train lossD: 0.010647 lossG: 0.153138\n",
      "[33: 950/1795] train lossD: -0.124863 lossG: 0.129714\n",
      "[33: 955/1795] train lossD: -0.217383 lossG: 0.320050\n",
      "[33: 960/1795] train lossD: -0.197087 lossG: -0.089582\n",
      "[33: 965/1795] train lossD: -0.307750 lossG: 0.221336\n",
      "[33: 970/1795] train lossD: -0.152195 lossG: 0.199270\n",
      "[33: 975/1795] train lossD: -0.047887 lossG: -0.053451\n",
      "[33: 980/1795] train lossD: 0.094271 lossG: 0.188345\n",
      "[33: 985/1795] train lossD: 0.050597 lossG: 0.192400\n",
      "[33: 990/1795] train lossD: 0.014253 lossG: 0.190788\n",
      "[33: 995/1795] train lossD: -0.007027 lossG: 0.227385\n",
      "[33: 1000/1795] train lossD: -0.070669 lossG: 0.266774\n",
      "[33: 1005/1795] train lossD: -0.018744 lossG: 0.289617\n",
      "[33: 1010/1795] train lossD: 0.002326 lossG: 0.326683\n",
      "[33: 1015/1795] train lossD: -0.080518 lossG: 0.378801\n",
      "[33: 1020/1795] train lossD: -0.007506 lossG: 0.362042\n",
      "[33: 1025/1795] train lossD: -0.035121 lossG: 0.416731\n",
      "[33: 1030/1795] train lossD: -0.093590 lossG: 0.408852\n",
      "[33: 1035/1795] train lossD: -0.048720 lossG: 0.342175\n",
      "[33: 1040/1795] train lossD: -0.022208 lossG: 0.268774\n",
      "[33: 1045/1795] train lossD: -0.166425 lossG: 0.319691\n",
      "[33: 1050/1795] train lossD: -0.231628 lossG: 0.258207\n",
      "[33: 1055/1795] train lossD: 0.281585 lossG: -0.024104\n",
      "[33: 1060/1795] train lossD: -0.192811 lossG: 0.311867\n",
      "[33: 1065/1795] train lossD: -0.122842 lossG: -0.028729\n",
      "[33: 1070/1795] train lossD: -0.167872 lossG: 0.197080\n",
      "[33: 1075/1795] train lossD: 0.032099 lossG: 0.169980\n",
      "[33: 1080/1795] train lossD: -0.081397 lossG: -0.293704\n",
      "[33: 1085/1795] train lossD: -0.050358 lossG: 0.332237\n",
      "[33: 1090/1795] train lossD: -0.223169 lossG: 0.153386\n",
      "[33: 1095/1795] train lossD: 0.159024 lossG: 0.306467\n",
      "[33: 1100/1795] train lossD: 0.012714 lossG: 0.354397\n",
      "[33: 1105/1795] train lossD: 0.065467 lossG: 0.365226\n",
      "[33: 1110/1795] train lossD: -0.019474 lossG: 0.375185\n",
      "[33: 1115/1795] train lossD: 0.036404 lossG: 0.326046\n",
      "[33: 1120/1795] train lossD: 0.006998 lossG: 0.351059\n",
      "[33: 1125/1795] train lossD: -0.061866 lossG: 0.360829\n",
      "[33: 1130/1795] train lossD: 0.006013 lossG: 0.297755\n",
      "[33: 1135/1795] train lossD: -0.192879 lossG: 0.270841\n",
      "[33: 1140/1795] train lossD: -0.270656 lossG: 0.194029\n",
      "[33: 1145/1795] train lossD: -0.040131 lossG: 0.325066\n",
      "[33: 1150/1795] train lossD: -0.271395 lossG: 0.091719\n",
      "[33: 1155/1795] train lossD: -0.306533 lossG: -0.010136\n",
      "[33: 1160/1795] train lossD: 0.096191 lossG: 0.108603\n",
      "[33: 1165/1795] train lossD: 0.010626 lossG: 0.153738\n",
      "[33: 1170/1795] train lossD: -0.025569 lossG: 0.146084\n",
      "[33: 1175/1795] train lossD: 0.001459 lossG: 0.120171\n",
      "[33: 1180/1795] train lossD: 0.057177 lossG: 0.089972\n",
      "[33: 1185/1795] train lossD: -0.072998 lossG: 0.109083\n",
      "[33: 1190/1795] train lossD: 0.008036 lossG: 0.084547\n",
      "[33: 1195/1795] train lossD: -0.054552 lossG: 0.146262\n",
      "[33: 1200/1795] train lossD: -0.179419 lossG: 0.034986\n",
      "[33: 1205/1795] train lossD: 1.084337 lossG: 0.221017\n",
      "[33: 1210/1795] train lossD: -0.176067 lossG: -0.099249\n",
      "[33: 1215/1795] train lossD: -0.012367 lossG: 0.111522\n",
      "[33: 1220/1795] train lossD: -0.108670 lossG: -0.101063\n",
      "[33: 1225/1795] train lossD: -0.081176 lossG: 0.284183\n",
      "[33: 1230/1795] train lossD: 0.012341 lossG: 0.306489\n",
      "[33: 1235/1795] train lossD: 0.007435 lossG: 0.273904\n",
      "[33: 1240/1795] train lossD: -0.047261 lossG: 0.377332\n",
      "[33: 1245/1795] train lossD: 0.063320 lossG: 0.253181\n",
      "[33: 1250/1795] train lossD: -0.017095 lossG: 0.092541\n",
      "[33: 1255/1795] train lossD: -0.153022 lossG: 0.076499\n",
      "[33: 1260/1795] train lossD: -0.297612 lossG: 0.196495\n",
      "[33: 1265/1795] train lossD: 0.083961 lossG: 0.300292\n",
      "[33: 1270/1795] train lossD: -0.173918 lossG: 0.050633\n",
      "[33: 1275/1795] train lossD: -0.014943 lossG: 0.258403\n",
      "[33: 1280/1795] train lossD: -0.137985 lossG: 0.122860\n",
      "[33: 1285/1795] train lossD: -0.032917 lossG: 0.350898\n",
      "[33: 1290/1795] train lossD: -0.170698 lossG: 0.132490\n",
      "[33: 1295/1795] train lossD: -0.271738 lossG: 0.201352\n",
      "[33: 1300/1795] train lossD: -0.599167 lossG: 0.302213\n",
      "[33: 1305/1795] train lossD: -0.068372 lossG: 0.271040\n",
      "[33: 1310/1795] train lossD: 0.053228 lossG: 0.292281\n",
      "[33: 1315/1795] train lossD: -0.065127 lossG: 0.270229\n",
      "[33: 1320/1795] train lossD: 0.126864 lossG: -0.131643\n",
      "[33: 1325/1795] train lossD: -0.002476 lossG: 0.146192\n",
      "[33: 1330/1795] train lossD: 0.065573 lossG: -0.403502\n",
      "[33: 1335/1795] train lossD: -0.420863 lossG: 0.061454\n",
      "[33: 1340/1795] train lossD: -0.007665 lossG: 0.154416\n",
      "[33: 1345/1795] train lossD: -0.082505 lossG: 0.235891\n",
      "[33: 1350/1795] train lossD: -0.240678 lossG: -0.061090\n",
      "[33: 1355/1795] train lossD: -0.059835 lossG: 0.184063\n",
      "[33: 1360/1795] train lossD: 0.119629 lossG: 0.225264\n",
      "[33: 1365/1795] train lossD: 0.054390 lossG: 0.343639\n",
      "[33: 1370/1795] train lossD: -0.019976 lossG: 0.374038\n",
      "[33: 1375/1795] train lossD: -0.060117 lossG: 0.498474\n",
      "[33: 1380/1795] train lossD: -0.057049 lossG: 0.414838\n",
      "[33: 1385/1795] train lossD: 0.316750 lossG: 0.491047\n",
      "[33: 1390/1795] train lossD: -0.353136 lossG: 0.083430\n",
      "[33: 1395/1795] train lossD: 0.062430 lossG: 0.244661\n",
      "[33: 1400/1795] train lossD: -0.168091 lossG: -0.019179\n",
      "[33: 1405/1795] train lossD: -0.038528 lossG: 0.042493\n",
      "[33: 1410/1795] train lossD: -0.112682 lossG: 0.072627\n",
      "[33: 1415/1795] train lossD: -0.019606 lossG: 0.213485\n",
      "[33: 1420/1795] train lossD: -0.003585 lossG: 0.214416\n",
      "[33: 1425/1795] train lossD: -0.322247 lossG: 0.185303\n",
      "[33: 1430/1795] train lossD: -0.053151 lossG: 0.137350\n",
      "[33: 1435/1795] train lossD: -0.350944 lossG: 0.062018\n",
      "[33: 1440/1795] train lossD: -0.070109 lossG: 0.284150\n",
      "[33: 1445/1795] train lossD: 0.002613 lossG: 0.101203\n",
      "[33: 1450/1795] train lossD: 0.955115 lossG: 0.352418\n",
      "[33: 1455/1795] train lossD: 0.036617 lossG: 0.386000\n",
      "[33: 1460/1795] train lossD: 0.049577 lossG: 0.360515\n",
      "[33: 1465/1795] train lossD: 0.110341 lossG: 0.315379\n",
      "[33: 1470/1795] train lossD: 0.012480 lossG: 0.338916\n",
      "[33: 1475/1795] train lossD: 0.045221 lossG: 0.163895\n",
      "[33: 1480/1795] train lossD: -0.020969 lossG: 0.269303\n",
      "[33: 1485/1795] train lossD: 0.120346 lossG: -0.045794\n",
      "[33: 1490/1795] train lossD: -0.019498 lossG: 0.357395\n",
      "[33: 1495/1795] train lossD: -0.186322 lossG: 0.320546\n",
      "[33: 1500/1795] train lossD: -0.195955 lossG: 0.018497\n",
      "[33: 1505/1795] train lossD: -0.050053 lossG: 0.189391\n",
      "[33: 1510/1795] train lossD: 0.018358 lossG: 0.355167\n",
      "[33: 1515/1795] train lossD: -0.163137 lossG: 0.228060\n",
      "[33: 1520/1795] train lossD: -0.043269 lossG: 0.435126\n",
      "[33: 1525/1795] train lossD: -0.161803 lossG: 0.193923\n",
      "[33: 1530/1795] train lossD: -0.155932 lossG: 0.223079\n",
      "[33: 1535/1795] train lossD: 0.106162 lossG: 0.140084\n",
      "[33: 1540/1795] train lossD: 0.251056 lossG: 0.290873\n",
      "[33: 1545/1795] train lossD: 0.172770 lossG: -0.259520\n",
      "[33: 1550/1795] train lossD: 0.105195 lossG: 0.162749\n",
      "[33: 1555/1795] train lossD: 0.032836 lossG: 0.180345\n",
      "[33: 1560/1795] train lossD: 0.033737 lossG: 0.233705\n",
      "[33: 1565/1795] train lossD: -0.016549 lossG: 0.240314\n",
      "[33: 1570/1795] train lossD: 0.011686 lossG: 0.244697\n",
      "[33: 1575/1795] train lossD: -0.017633 lossG: 0.302149\n",
      "[33: 1580/1795] train lossD: 0.003644 lossG: 0.381303\n",
      "[33: 1585/1795] train lossD: -0.009797 lossG: 0.245696\n",
      "[33: 1590/1795] train lossD: -0.007625 lossG: 0.270169\n",
      "[33: 1595/1795] train lossD: -0.096117 lossG: 0.234894\n",
      "[33: 1600/1795] train lossD: -0.071456 lossG: -0.105405\n",
      "[33: 1605/1795] train lossD: -0.086416 lossG: 0.582866\n",
      "[33: 1610/1795] train lossD: 0.116385 lossG: 0.462327\n",
      "[33: 1615/1795] train lossD: -0.004943 lossG: 0.339717\n",
      "[33: 1620/1795] train lossD: 0.081931 lossG: 0.346919\n",
      "[33: 1625/1795] train lossD: -0.335133 lossG: 0.225129\n",
      "[33: 1630/1795] train lossD: -0.253616 lossG: 0.338578\n",
      "[33: 1635/1795] train lossD: -0.255258 lossG: -0.134640\n",
      "[33: 1640/1795] train lossD: -0.066465 lossG: 0.299718\n",
      "[33: 1645/1795] train lossD: -0.212203 lossG: 0.300094\n",
      "[33: 1650/1795] train lossD: -0.080859 lossG: 0.217986\n",
      "[33: 1655/1795] train lossD: -0.218504 lossG: 0.135322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33: 1660/1795] train lossD: -0.446432 lossG: 0.153428\n",
      "[33: 1665/1795] train lossD: 1.860364 lossG: 0.061546\n",
      "[33: 1670/1795] train lossD: 0.015735 lossG: 0.105149\n",
      "[33: 1675/1795] train lossD: -0.075912 lossG: 0.115959\n",
      "[33: 1680/1795] train lossD: -0.349290 lossG: -0.077328\n",
      "[33: 1685/1795] train lossD: -0.467477 lossG: 0.087741\n",
      "[33: 1690/1795] train lossD: -0.189379 lossG: 0.198766\n",
      "[33: 1695/1795] train lossD: -0.029153 lossG: -0.281501\n",
      "[33: 1700/1795] train lossD: -0.350320 lossG: 0.292581\n",
      "[33: 1705/1795] train lossD: -0.329005 lossG: -0.359933\n",
      "[33: 1710/1795] train lossD: -0.467046 lossG: -0.069315\n",
      "[33: 1715/1795] train lossD: -0.062129 lossG: 0.009048\n",
      "[33: 1720/1795] train lossD: -0.350316 lossG: 0.129986\n",
      "[33: 1725/1795] train lossD: -0.191406 lossG: -0.020604\n",
      "[33: 1730/1795] train lossD: 0.063959 lossG: 0.166769\n",
      "[33: 1735/1795] train lossD: -0.110407 lossG: 0.358172\n",
      "[33: 1740/1795] train lossD: -0.182695 lossG: 0.126293\n",
      "[33: 1745/1795] train lossD: -0.005352 lossG: -0.040145\n",
      "[33: 1750/1795] train lossD: 0.036344 lossG: 0.214919\n",
      "[33: 1755/1795] train lossD: 0.195988 lossG: 0.202713\n",
      "[33: 1760/1795] train lossD: 0.076748 lossG: 0.220388\n",
      "[33: 1765/1795] train lossD: 0.258231 lossG: 0.147106\n",
      "[33: 1770/1795] train lossD: 0.642696 lossG: 0.247715\n",
      "[33: 1775/1795] train lossD: 0.409119 lossG: 0.220415\n",
      "[33: 1780/1795] train lossD: 0.152051 lossG: 0.405743\n",
      "[33: 1785/1795] train lossD: 0.330664 lossG: 0.421184\n",
      "[33: 1790/1795] train lossD: 0.020127 lossG: 0.386353\n",
      "0.043432075530290604\n",
      "[34: 0/1795] train lossD: 0.034030 lossG: 0.309956\n",
      "[34: 5/1795] train lossD: 0.013383 lossG: 0.286842\n",
      "[34: 10/1795] train lossD: -0.014481 lossG: 0.252574\n",
      "[34: 15/1795] train lossD: 0.020035 lossG: 0.155106\n",
      "[34: 20/1795] train lossD: 0.293581 lossG: 0.175293\n",
      "[34: 25/1795] train lossD: -0.021352 lossG: 0.147610\n",
      "[34: 30/1795] train lossD: -0.105713 lossG: 0.003900\n",
      "[34: 35/1795] train lossD: -0.438848 lossG: 0.198477\n",
      "[34: 40/1795] train lossD: -0.179905 lossG: 0.044425\n",
      "[34: 45/1795] train lossD: 1.845575 lossG: 0.200895\n",
      "[34: 50/1795] train lossD: 0.068352 lossG: 0.327263\n",
      "[34: 55/1795] train lossD: -0.024549 lossG: 0.354892\n",
      "[34: 60/1795] train lossD: -0.107905 lossG: 0.352684\n",
      "[34: 65/1795] train lossD: -0.035968 lossG: 0.325262\n",
      "[34: 70/1795] train lossD: -0.029036 lossG: 0.268018\n",
      "[34: 75/1795] train lossD: -0.052062 lossG: 0.254083\n",
      "[34: 80/1795] train lossD: -0.185966 lossG: 0.221759\n",
      "[34: 85/1795] train lossD: 0.142231 lossG: 0.058110\n",
      "[34: 90/1795] train lossD: -0.258768 lossG: -0.095013\n",
      "[34: 95/1795] train lossD: -0.147269 lossG: 0.226184\n",
      "[34: 100/1795] train lossD: -0.169722 lossG: -0.004797\n",
      "[34: 105/1795] train lossD: -0.157798 lossG: 0.087209\n",
      "[34: 110/1795] train lossD: -0.271719 lossG: -0.021204\n",
      "[34: 115/1795] train lossD: -0.410074 lossG: 0.022253\n",
      "[34: 120/1795] train lossD: 0.130553 lossG: 0.301617\n",
      "[34: 125/1795] train lossD: -0.183736 lossG: 0.162746\n",
      "[34: 130/1795] train lossD: -0.267938 lossG: -0.077533\n",
      "[34: 135/1795] train lossD: -0.127148 lossG: 0.220008\n",
      "[34: 140/1795] train lossD: -0.133351 lossG: 0.044183\n",
      "[34: 145/1795] train lossD: -0.024917 lossG: 0.269096\n",
      "[34: 150/1795] train lossD: -0.054389 lossG: 0.283115\n",
      "[34: 155/1795] train lossD: 0.009059 lossG: 0.093705\n",
      "[34: 160/1795] train lossD: -0.131869 lossG: -0.396610\n",
      "[34: 165/1795] train lossD: 0.101518 lossG: -0.514977\n",
      "[34: 170/1795] train lossD: -0.208634 lossG: 0.124823\n",
      "[34: 175/1795] train lossD: -0.141759 lossG: -0.096214\n",
      "[34: 180/1795] train lossD: -0.114932 lossG: -0.001734\n",
      "[34: 185/1795] train lossD: 0.015625 lossG: 0.261417\n",
      "[34: 190/1795] train lossD: 0.017841 lossG: 0.300760\n",
      "[34: 195/1795] train lossD: -0.030780 lossG: 0.317145\n",
      "[34: 200/1795] train lossD: 0.069806 lossG: 0.325523\n",
      "[34: 205/1795] train lossD: -0.010002 lossG: 0.349894\n",
      "[34: 210/1795] train lossD: 0.028729 lossG: 0.321006\n",
      "[34: 215/1795] train lossD: 0.055660 lossG: 0.438199\n",
      "[34: 220/1795] train lossD: 0.000132 lossG: 0.352313\n",
      "[34: 225/1795] train lossD: -0.009474 lossG: 0.285933\n",
      "[34: 230/1795] train lossD: 0.030717 lossG: 0.277904\n",
      "[34: 235/1795] train lossD: -0.006523 lossG: 0.332911\n",
      "[34: 240/1795] train lossD: -0.002760 lossG: 0.294154\n",
      "[34: 245/1795] train lossD: 0.023741 lossG: 0.307022\n",
      "[34: 250/1795] train lossD: -0.036546 lossG: 0.312899\n",
      "[34: 255/1795] train lossD: -0.017525 lossG: 0.111387\n",
      "[34: 260/1795] train lossD: -0.251154 lossG: 0.175734\n",
      "[34: 265/1795] train lossD: -0.074870 lossG: 0.212112\n",
      "[34: 270/1795] train lossD: 0.184133 lossG: 0.359583\n",
      "[34: 275/1795] train lossD: 0.081461 lossG: 0.342799\n",
      "[34: 280/1795] train lossD: -0.095234 lossG: 0.366998\n",
      "[34: 285/1795] train lossD: -0.152787 lossG: 0.482351\n",
      "[34: 290/1795] train lossD: -0.232121 lossG: 0.196221\n",
      "[34: 295/1795] train lossD: -0.202442 lossG: 0.375808\n",
      "[34: 300/1795] train lossD: -0.066305 lossG: 0.043350\n",
      "[34: 305/1795] train lossD: 0.861888 lossG: 0.077272\n",
      "[34: 310/1795] train lossD: 0.004840 lossG: 0.091214\n",
      "[34: 315/1795] train lossD: 0.010934 lossG: 0.095763\n",
      "[34: 320/1795] train lossD: 0.011613 lossG: 0.059786\n",
      "[34: 325/1795] train lossD: -0.087687 lossG: 0.113680\n",
      "[34: 330/1795] train lossD: -0.000664 lossG: 0.093090\n",
      "[34: 335/1795] train lossD: -0.096903 lossG: 0.108155\n",
      "[34: 340/1795] train lossD: 0.180836 lossG: 0.109576\n",
      "[34: 345/1795] train lossD: -0.029042 lossG: 0.123405\n",
      "[34: 350/1795] train lossD: -0.057699 lossG: 0.163432\n",
      "[34: 355/1795] train lossD: -0.015350 lossG: 0.106553\n",
      "[34: 360/1795] train lossD: -0.373420 lossG: 0.044741\n",
      "[34: 365/1795] train lossD: -0.113361 lossG: 0.109276\n",
      "[34: 370/1795] train lossD: -0.501833 lossG: 0.113286\n",
      "[34: 375/1795] train lossD: -0.325617 lossG: 0.106533\n",
      "[34: 380/1795] train lossD: -0.288022 lossG: -0.049081\n",
      "[34: 385/1795] train lossD: -0.055082 lossG: 0.158674\n",
      "[34: 390/1795] train lossD: -0.243407 lossG: -0.136459\n",
      "[34: 395/1795] train lossD: 0.397907 lossG: 0.112189\n",
      "[34: 400/1795] train lossD: 0.012084 lossG: 0.078784\n",
      "[34: 405/1795] train lossD: -0.135905 lossG: 0.063730\n",
      "[34: 410/1795] train lossD: 0.042764 lossG: 0.199419\n",
      "[34: 415/1795] train lossD: -0.007126 lossG: 0.208085\n",
      "[34: 420/1795] train lossD: -0.020222 lossG: 0.229355\n",
      "[34: 425/1795] train lossD: -0.010339 lossG: 0.138599\n",
      "[34: 430/1795] train lossD: -0.045382 lossG: 0.172439\n",
      "[34: 435/1795] train lossD: -0.304089 lossG: -0.094520\n",
      "[34: 440/1795] train lossD: 0.015275 lossG: 0.317223\n",
      "[34: 445/1795] train lossD: -0.235561 lossG: 0.174745\n",
      "[34: 450/1795] train lossD: -0.372992 lossG: 0.013689\n",
      "[34: 455/1795] train lossD: -0.430392 lossG: -0.037796\n",
      "[34: 460/1795] train lossD: 0.049497 lossG: -0.006481\n",
      "[34: 465/1795] train lossD: 0.222889 lossG: 0.080700\n",
      "[34: 470/1795] train lossD: -0.184690 lossG: -0.076351\n",
      "[34: 475/1795] train lossD: -0.369839 lossG: -0.178616\n",
      "[34: 480/1795] train lossD: 0.172092 lossG: 0.357411\n",
      "[34: 485/1795] train lossD: -0.084674 lossG: 0.396151\n",
      "[34: 490/1795] train lossD: 0.015671 lossG: 0.349968\n",
      "[34: 495/1795] train lossD: -0.022079 lossG: 0.466851\n",
      "[34: 500/1795] train lossD: -0.029222 lossG: 0.384546\n",
      "[34: 505/1795] train lossD: -0.019174 lossG: 0.340286\n",
      "[34: 510/1795] train lossD: -0.152622 lossG: 0.422975\n",
      "[34: 515/1795] train lossD: -0.025612 lossG: 0.254539\n",
      "[34: 520/1795] train lossD: -0.252942 lossG: 0.183090\n",
      "[34: 525/1795] train lossD: -0.339116 lossG: 0.217691\n",
      "[34: 530/1795] train lossD: -0.205636 lossG: 0.160208\n",
      "[34: 535/1795] train lossD: -0.315693 lossG: 0.096771\n",
      "[34: 540/1795] train lossD: -0.154539 lossG: 0.229354\n",
      "[34: 545/1795] train lossD: -0.211993 lossG: 0.111516\n",
      "[34: 550/1795] train lossD: 0.149416 lossG: 0.245496\n",
      "[34: 555/1795] train lossD: 0.042811 lossG: 0.233191\n",
      "[34: 560/1795] train lossD: -0.020831 lossG: 0.274045\n",
      "[34: 565/1795] train lossD: 0.019364 lossG: 0.314845\n",
      "[34: 570/1795] train lossD: -0.028115 lossG: 0.221966\n",
      "[34: 575/1795] train lossD: 0.069345 lossG: 0.494697\n",
      "[34: 580/1795] train lossD: 0.029452 lossG: 0.515399\n",
      "[34: 585/1795] train lossD: -0.040578 lossG: 0.596135\n",
      "[34: 590/1795] train lossD: -0.011041 lossG: 0.521596\n",
      "[34: 595/1795] train lossD: 0.020748 lossG: 0.484955\n",
      "[34: 600/1795] train lossD: 0.030788 lossG: 0.512748\n",
      "[34: 605/1795] train lossD: -0.000512 lossG: 0.461227\n",
      "[34: 610/1795] train lossD: -0.025305 lossG: 0.434635\n",
      "[34: 615/1795] train lossD: -0.009893 lossG: 0.479581\n",
      "[34: 620/1795] train lossD: 0.054262 lossG: 0.464661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34: 625/1795] train lossD: -0.032810 lossG: 0.377471\n",
      "[34: 630/1795] train lossD: -0.282150 lossG: 0.060173\n",
      "[34: 635/1795] train lossD: 2.417228 lossG: 0.256981\n",
      "[34: 640/1795] train lossD: 0.014676 lossG: 0.311080\n",
      "[34: 645/1795] train lossD: -0.166882 lossG: 0.428272\n",
      "[34: 650/1795] train lossD: -0.047227 lossG: 0.483267\n",
      "[34: 655/1795] train lossD: 0.051509 lossG: 0.370143\n",
      "[34: 660/1795] train lossD: -0.157476 lossG: 0.380920\n",
      "[34: 665/1795] train lossD: -0.047019 lossG: 0.265208\n",
      "[34: 670/1795] train lossD: -0.413800 lossG: 0.235437\n",
      "[34: 675/1795] train lossD: -0.108873 lossG: 0.126923\n",
      "[34: 680/1795] train lossD: 0.044483 lossG: -0.327591\n",
      "[34: 685/1795] train lossD: 0.260731 lossG: 0.198592\n",
      "[34: 690/1795] train lossD: -0.137735 lossG: 0.249339\n",
      "[34: 695/1795] train lossD: -0.654084 lossG: 0.098191\n",
      "[34: 700/1795] train lossD: -0.131552 lossG: 0.031304\n",
      "[34: 705/1795] train lossD: -0.011964 lossG: 0.348066\n",
      "[34: 710/1795] train lossD: -0.116768 lossG: 0.130474\n",
      "[34: 715/1795] train lossD: -0.042202 lossG: 0.053387\n",
      "[34: 720/1795] train lossD: -0.091064 lossG: 0.233060\n",
      "[34: 725/1795] train lossD: -0.329043 lossG: 0.069657\n",
      "[34: 730/1795] train lossD: -0.143015 lossG: 0.289506\n",
      "[34: 735/1795] train lossD: -0.087845 lossG: 0.289298\n",
      "[34: 740/1795] train lossD: -0.161731 lossG: 0.131682\n",
      "[34: 745/1795] train lossD: 0.117000 lossG: 0.280941\n",
      "[34: 750/1795] train lossD: -0.010940 lossG: 0.369284\n",
      "[34: 755/1795] train lossD: -0.088504 lossG: 0.505536\n",
      "[34: 760/1795] train lossD: -0.220844 lossG: 0.485159\n",
      "[34: 765/1795] train lossD: 0.003521 lossG: 0.443862\n",
      "[34: 770/1795] train lossD: -0.002689 lossG: 0.477971\n",
      "[34: 775/1795] train lossD: 0.006717 lossG: 0.380192\n",
      "[34: 780/1795] train lossD: -0.027359 lossG: 0.344499\n",
      "[34: 785/1795] train lossD: -0.064834 lossG: 0.352207\n",
      "[34: 790/1795] train lossD: -0.440290 lossG: 0.161269\n",
      "[34: 795/1795] train lossD: -0.326983 lossG: 0.070143\n",
      "[34: 800/1795] train lossD: -0.303258 lossG: -0.025326\n",
      "[34: 805/1795] train lossD: -0.233355 lossG: 0.240014\n",
      "[34: 810/1795] train lossD: -0.047133 lossG: -0.460405\n",
      "[34: 815/1795] train lossD: -0.058534 lossG: 0.245026\n",
      "[34: 820/1795] train lossD: 0.007232 lossG: 0.338423\n",
      "[34: 825/1795] train lossD: -0.485238 lossG: 0.128759\n",
      "[34: 830/1795] train lossD: -0.270047 lossG: 0.120441\n",
      "[34: 835/1795] train lossD: -0.132847 lossG: 0.186621\n",
      "[34: 840/1795] train lossD: -0.191819 lossG: 0.305369\n",
      "[34: 845/1795] train lossD: 0.117800 lossG: 0.329295\n",
      "[34: 850/1795] train lossD: -0.271816 lossG: 0.441890\n",
      "[34: 855/1795] train lossD: 0.031836 lossG: 0.390234\n",
      "[34: 860/1795] train lossD: 0.018174 lossG: 0.401954\n",
      "[34: 865/1795] train lossD: 0.083624 lossG: 0.398184\n",
      "[34: 870/1795] train lossD: 0.000868 lossG: 0.323448\n",
      "[34: 875/1795] train lossD: -0.289133 lossG: 0.171569\n",
      "[34: 880/1795] train lossD: -0.094551 lossG: 0.143583\n",
      "[34: 885/1795] train lossD: -0.044713 lossG: 0.545680\n",
      "[34: 890/1795] train lossD: -0.679724 lossG: 0.365583\n",
      "[34: 895/1795] train lossD: -0.415279 lossG: -0.131258\n",
      "[34: 900/1795] train lossD: 0.126720 lossG: 0.325625\n",
      "[34: 905/1795] train lossD: 0.020847 lossG: 0.354264\n",
      "[34: 910/1795] train lossD: -0.098292 lossG: 0.498746\n",
      "[34: 915/1795] train lossD: -0.008904 lossG: 0.414166\n",
      "[34: 920/1795] train lossD: -0.057484 lossG: 0.531636\n",
      "[34: 925/1795] train lossD: 0.013321 lossG: 0.464766\n",
      "[34: 930/1795] train lossD: -0.003424 lossG: 0.464073\n",
      "[34: 935/1795] train lossD: -0.027802 lossG: 0.383575\n",
      "[34: 940/1795] train lossD: -0.029511 lossG: 0.369983\n",
      "[34: 945/1795] train lossD: -0.126704 lossG: 0.374040\n",
      "[34: 950/1795] train lossD: -0.564572 lossG: 0.132559\n",
      "[34: 955/1795] train lossD: -0.307298 lossG: 0.214543\n",
      "[34: 960/1795] train lossD: 0.023339 lossG: -0.390344\n",
      "[34: 965/1795] train lossD: 1.595207 lossG: 0.026498\n",
      "[34: 970/1795] train lossD: -0.027397 lossG: 0.045671\n",
      "[34: 975/1795] train lossD: -0.004173 lossG: 0.145160\n",
      "[34: 980/1795] train lossD: 0.009400 lossG: 0.236045\n",
      "[34: 985/1795] train lossD: -0.018907 lossG: 0.246098\n",
      "[34: 990/1795] train lossD: -0.082454 lossG: 0.353951\n",
      "[34: 995/1795] train lossD: 0.010872 lossG: 0.360318\n",
      "[34: 1000/1795] train lossD: -0.042085 lossG: 0.415420\n",
      "[34: 1005/1795] train lossD: -0.261565 lossG: 0.198900\n",
      "[34: 1010/1795] train lossD: 0.167589 lossG: 0.288521\n",
      "[34: 1015/1795] train lossD: -0.051556 lossG: 0.305996\n",
      "[34: 1020/1795] train lossD: 0.111239 lossG: 0.263709\n",
      "[34: 1025/1795] train lossD: 0.001982 lossG: 0.334797\n",
      "[34: 1030/1795] train lossD: 0.089962 lossG: 0.362740\n",
      "[34: 1035/1795] train lossD: 0.079512 lossG: 0.350629\n",
      "[34: 1040/1795] train lossD: -0.325039 lossG: 0.368625\n",
      "[34: 1045/1795] train lossD: 0.022470 lossG: 0.385110\n",
      "[34: 1050/1795] train lossD: -0.145886 lossG: 0.295022\n",
      "[34: 1055/1795] train lossD: -0.030619 lossG: 0.287112\n",
      "[34: 1060/1795] train lossD: -0.026654 lossG: 0.327133\n",
      "[34: 1065/1795] train lossD: -0.039485 lossG: 0.276981\n",
      "[34: 1070/1795] train lossD: -0.031663 lossG: 0.280538\n",
      "[34: 1075/1795] train lossD: -0.199675 lossG: 0.197286\n",
      "[34: 1080/1795] train lossD: -0.103726 lossG: 0.212207\n",
      "[34: 1085/1795] train lossD: -0.592661 lossG: 0.225065\n",
      "[34: 1090/1795] train lossD: -0.349023 lossG: 0.164110\n",
      "[34: 1095/1795] train lossD: -0.211937 lossG: 0.050434\n",
      "[34: 1100/1795] train lossD: -0.439895 lossG: 0.088591\n",
      "[34: 1105/1795] train lossD: -0.362476 lossG: -0.115292\n",
      "[34: 1110/1795] train lossD: -0.349321 lossG: 0.075314\n",
      "[34: 1115/1795] train lossD: -0.129210 lossG: 0.094778\n",
      "[34: 1120/1795] train lossD: 0.042686 lossG: 0.029045\n",
      "[34: 1125/1795] train lossD: -0.042931 lossG: 0.055246\n",
      "[34: 1130/1795] train lossD: -0.024962 lossG: 0.209068\n",
      "[34: 1135/1795] train lossD: -0.020321 lossG: 0.135597\n",
      "[34: 1140/1795] train lossD: -0.180699 lossG: -0.116504\n",
      "[34: 1145/1795] train lossD: -0.330363 lossG: -0.082739\n",
      "[34: 1150/1795] train lossD: -0.012899 lossG: 0.186074\n",
      "[34: 1155/1795] train lossD: -0.068137 lossG: -0.369899\n",
      "[34: 1160/1795] train lossD: 0.460159 lossG: 0.035894\n",
      "[34: 1165/1795] train lossD: 0.092166 lossG: -0.233474\n",
      "[34: 1170/1795] train lossD: -0.248876 lossG: -0.096206\n",
      "[34: 1175/1795] train lossD: -0.161158 lossG: 0.242685\n",
      "[34: 1180/1795] train lossD: -0.457934 lossG: -0.075698\n",
      "[34: 1185/1795] train lossD: 0.184375 lossG: -0.374489\n",
      "[34: 1190/1795] train lossD: -0.457439 lossG: -0.348848\n",
      "[34: 1195/1795] train lossD: -0.076988 lossG: 0.180149\n",
      "[34: 1200/1795] train lossD: -0.100202 lossG: -0.073488\n",
      "[34: 1205/1795] train lossD: -0.044325 lossG: -0.867371\n",
      "[34: 1210/1795] train lossD: -0.082294 lossG: 0.355484\n",
      "[34: 1215/1795] train lossD: -0.154618 lossG: 0.447781\n",
      "[34: 1220/1795] train lossD: 0.106877 lossG: 0.262263\n",
      "[34: 1225/1795] train lossD: -0.159707 lossG: 0.287697\n",
      "[34: 1230/1795] train lossD: -0.291590 lossG: 0.244331\n",
      "[34: 1235/1795] train lossD: 0.062198 lossG: -0.183886\n",
      "[34: 1240/1795] train lossD: -0.252741 lossG: -0.062019\n",
      "[34: 1245/1795] train lossD: -0.147254 lossG: 0.111444\n",
      "[34: 1250/1795] train lossD: -0.106788 lossG: -0.043835\n",
      "[34: 1255/1795] train lossD: -0.165121 lossG: 0.067654\n",
      "[34: 1260/1795] train lossD: -0.100492 lossG: 0.176470\n",
      "[34: 1265/1795] train lossD: 0.244745 lossG: 0.169141\n",
      "[34: 1270/1795] train lossD: -0.057566 lossG: 0.198135\n",
      "[34: 1275/1795] train lossD: -0.314983 lossG: -0.489164\n",
      "[34: 1280/1795] train lossD: 0.017190 lossG: 0.082122\n",
      "[34: 1285/1795] train lossD: -0.230954 lossG: 0.202848\n",
      "[34: 1290/1795] train lossD: 0.215034 lossG: -0.644464\n",
      "[34: 1295/1795] train lossD: 0.073180 lossG: -0.115737\n",
      "[34: 1300/1795] train lossD: 0.092088 lossG: -0.040082\n",
      "[34: 1305/1795] train lossD: -0.017024 lossG: -0.036688\n",
      "[34: 1310/1795] train lossD: 0.083523 lossG: -0.192267\n",
      "[34: 1315/1795] train lossD: -0.015493 lossG: -0.176932\n",
      "[34: 1320/1795] train lossD: -0.747166 lossG: -0.226563\n",
      "[34: 1325/1795] train lossD: 2.026195 lossG: 0.024254\n",
      "[34: 1330/1795] train lossD: -0.047044 lossG: 0.118799\n",
      "[34: 1335/1795] train lossD: -0.317650 lossG: -0.295343\n",
      "[34: 1340/1795] train lossD: -0.428844 lossG: -0.202571\n",
      "[34: 1345/1795] train lossD: 0.063790 lossG: -0.038981\n",
      "[34: 1350/1795] train lossD: 0.050686 lossG: -0.005568\n",
      "[34: 1355/1795] train lossD: -0.022268 lossG: 0.119443\n",
      "[34: 1360/1795] train lossD: 0.004548 lossG: 0.225508\n",
      "[34: 1365/1795] train lossD: 0.033706 lossG: 0.244869\n",
      "[34: 1370/1795] train lossD: -0.035363 lossG: 0.242757\n",
      "[34: 1375/1795] train lossD: -0.020822 lossG: 0.238044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34: 1380/1795] train lossD: 0.058978 lossG: 0.187645\n",
      "[34: 1385/1795] train lossD: -0.005693 lossG: 0.247081\n",
      "[34: 1390/1795] train lossD: 0.009112 lossG: 0.033403\n",
      "[34: 1395/1795] train lossD: -0.010522 lossG: 0.113836\n",
      "[34: 1400/1795] train lossD: 0.039619 lossG: 0.032745\n",
      "[34: 1405/1795] train lossD: 0.420831 lossG: 0.159925\n",
      "[34: 1410/1795] train lossD: -0.007434 lossG: 0.120608\n",
      "[34: 1415/1795] train lossD: -0.095948 lossG: 0.263969\n",
      "[34: 1420/1795] train lossD: 0.018308 lossG: -0.023604\n",
      "[34: 1425/1795] train lossD: -0.046881 lossG: -0.036803\n",
      "[34: 1430/1795] train lossD: -0.080989 lossG: 0.067891\n",
      "[34: 1435/1795] train lossD: -0.035531 lossG: -0.101260\n",
      "[34: 1440/1795] train lossD: 0.139466 lossG: 0.072095\n",
      "[34: 1445/1795] train lossD: 0.015381 lossG: 0.101683\n",
      "[34: 1450/1795] train lossD: 0.119616 lossG: 0.046576\n",
      "[34: 1455/1795] train lossD: 0.017956 lossG: 0.107137\n",
      "[34: 1460/1795] train lossD: -0.002033 lossG: 0.099701\n",
      "[34: 1465/1795] train lossD: -0.059397 lossG: 0.152396\n",
      "[34: 1470/1795] train lossD: 0.030748 lossG: 0.238915\n",
      "[34: 1475/1795] train lossD: -0.043424 lossG: 0.271743\n",
      "[34: 1480/1795] train lossD: 0.047308 lossG: 0.159745\n",
      "[34: 1485/1795] train lossD: -0.028103 lossG: 0.226636\n",
      "[34: 1490/1795] train lossD: 0.014243 lossG: 0.135474\n",
      "[34: 1495/1795] train lossD: 0.280811 lossG: 0.216139\n",
      "[34: 1500/1795] train lossD: -0.485172 lossG: 0.209467\n",
      "[34: 1505/1795] train lossD: 0.327928 lossG: 0.224131\n",
      "[34: 1510/1795] train lossD: -0.216848 lossG: 0.265212\n",
      "[34: 1515/1795] train lossD: -0.360148 lossG: -0.245217\n",
      "[34: 1520/1795] train lossD: -0.294284 lossG: 0.274938\n",
      "[34: 1525/1795] train lossD: 0.129361 lossG: -0.013760\n",
      "[34: 1530/1795] train lossD: -0.657333 lossG: 0.030960\n",
      "[34: 1535/1795] train lossD: 0.140553 lossG: -0.024158\n",
      "[34: 1540/1795] train lossD: -0.027312 lossG: 0.072601\n",
      "[34: 1545/1795] train lossD: -0.010059 lossG: 0.038550\n",
      "[34: 1550/1795] train lossD: -0.114520 lossG: 0.025869\n",
      "[34: 1555/1795] train lossD: -0.317589 lossG: -0.404586\n",
      "[34: 1560/1795] train lossD: 0.004200 lossG: 0.203843\n",
      "[34: 1565/1795] train lossD: -0.039001 lossG: 0.223048\n",
      "[34: 1570/1795] train lossD: -0.036946 lossG: 0.256008\n",
      "[34: 1575/1795] train lossD: -0.010502 lossG: 0.238892\n",
      "[34: 1580/1795] train lossD: -0.025310 lossG: 0.266415\n",
      "[34: 1585/1795] train lossD: 0.080775 lossG: 0.186252\n",
      "[34: 1590/1795] train lossD: -0.087591 lossG: 0.122254\n",
      "[34: 1595/1795] train lossD: -0.008081 lossG: 0.319094\n",
      "[34: 1600/1795] train lossD: -0.004548 lossG: 0.029610\n",
      "[34: 1605/1795] train lossD: -0.207700 lossG: 0.229639\n",
      "[34: 1610/1795] train lossD: -0.086018 lossG: 0.043622\n",
      "[34: 1615/1795] train lossD: -0.528804 lossG: -0.357185\n",
      "[34: 1620/1795] train lossD: -0.223607 lossG: -0.104851\n",
      "[34: 1625/1795] train lossD: -0.072742 lossG: -0.139234\n",
      "[34: 1630/1795] train lossD: -0.264674 lossG: -0.282071\n",
      "[34: 1635/1795] train lossD: -0.394048 lossG: 0.020717\n",
      "[34: 1640/1795] train lossD: -0.283399 lossG: -0.038597\n",
      "[34: 1645/1795] train lossD: 0.109339 lossG: -0.504320\n",
      "[34: 1650/1795] train lossD: 0.162731 lossG: 0.095947\n",
      "[34: 1655/1795] train lossD: -0.082410 lossG: 0.104978\n",
      "[34: 1660/1795] train lossD: -0.770672 lossG: 0.190238\n",
      "[34: 1665/1795] train lossD: -0.322024 lossG: 0.039336\n",
      "[34: 1670/1795] train lossD: -0.338762 lossG: -0.144976\n",
      "[34: 1675/1795] train lossD: 0.002607 lossG: 0.160748\n",
      "[34: 1680/1795] train lossD: -0.240985 lossG: 0.057998\n",
      "[34: 1685/1795] train lossD: -0.523428 lossG: -0.094813\n",
      "[34: 1690/1795] train lossD: 0.021221 lossG: 0.117932\n",
      "[34: 1695/1795] train lossD: 0.096367 lossG: 0.186204\n",
      "[34: 1700/1795] train lossD: -0.240067 lossG: 0.171098\n",
      "[34: 1705/1795] train lossD: -0.366779 lossG: 0.166948\n",
      "[34: 1710/1795] train lossD: -0.008119 lossG: 0.170418\n",
      "[34: 1715/1795] train lossD: 0.066596 lossG: 0.214196\n",
      "[34: 1720/1795] train lossD: -0.200734 lossG: 0.205636\n",
      "[34: 1725/1795] train lossD: -0.159101 lossG: -0.063787\n",
      "[34: 1730/1795] train lossD: 0.010792 lossG: 0.284753\n",
      "[34: 1735/1795] train lossD: -0.300841 lossG: 0.055316\n",
      "[34: 1740/1795] train lossD: -0.291947 lossG: 0.235418\n",
      "[34: 1745/1795] train lossD: -0.249754 lossG: -0.191110\n",
      "[34: 1750/1795] train lossD: 0.484292 lossG: 0.168120\n",
      "[34: 1755/1795] train lossD: -0.161307 lossG: 0.170890\n",
      "[34: 1760/1795] train lossD: 0.289814 lossG: 0.223670\n",
      "[34: 1765/1795] train lossD: 0.076150 lossG: 0.245597\n",
      "[34: 1770/1795] train lossD: 0.036612 lossG: 0.338606\n",
      "[34: 1775/1795] train lossD: 0.087035 lossG: 0.290639\n",
      "[34: 1780/1795] train lossD: -0.411350 lossG: 0.261014\n",
      "[34: 1785/1795] train lossD: -0.284084 lossG: 0.311559\n",
      "[34: 1790/1795] train lossD: -0.054592 lossG: 0.312186\n",
      "0.04405993968248367\n",
      "[35: 0/1795] train lossD: -0.108116 lossG: 0.270902\n",
      "[35: 5/1795] train lossD: -0.636335 lossG: 0.182379\n",
      "[35: 10/1795] train lossD: -0.319764 lossG: -0.129534\n",
      "[35: 15/1795] train lossD: -0.569596 lossG: -0.099239\n",
      "[35: 20/1795] train lossD: -0.148697 lossG: 0.335814\n",
      "[35: 25/1795] train lossD: -0.052995 lossG: 0.032387\n",
      "[35: 30/1795] train lossD: -0.519052 lossG: 0.051813\n",
      "[35: 35/1795] train lossD: -0.102707 lossG: -0.130431\n",
      "[35: 40/1795] train lossD: 0.169881 lossG: -0.055077\n",
      "[35: 45/1795] train lossD: -0.358193 lossG: 0.132881\n",
      "[35: 50/1795] train lossD: -0.532375 lossG: 0.276160\n",
      "[35: 55/1795] train lossD: -0.265158 lossG: -0.093615\n",
      "[35: 60/1795] train lossD: -0.522257 lossG: 0.156256\n",
      "[35: 65/1795] train lossD: -0.164349 lossG: 0.230771\n",
      "[35: 70/1795] train lossD: 0.177779 lossG: 0.300219\n",
      "[35: 75/1795] train lossD: 2.148191 lossG: 0.132927\n",
      "[35: 80/1795] train lossD: 0.605926 lossG: 0.139951\n",
      "[35: 85/1795] train lossD: 0.385864 lossG: 0.136423\n",
      "[35: 90/1795] train lossD: 0.177841 lossG: 0.178658\n",
      "[35: 95/1795] train lossD: 0.091098 lossG: 0.211639\n",
      "[35: 100/1795] train lossD: 0.281137 lossG: 0.130375\n",
      "[35: 105/1795] train lossD: 0.150916 lossG: 0.138384\n",
      "[35: 110/1795] train lossD: 0.254356 lossG: 0.096644\n",
      "[35: 115/1795] train lossD: 0.076449 lossG: 0.206259\n",
      "[35: 120/1795] train lossD: 0.027249 lossG: 0.253019\n",
      "[35: 125/1795] train lossD: 0.031732 lossG: 0.216808\n",
      "[35: 130/1795] train lossD: 0.002248 lossG: 0.151313\n",
      "[35: 135/1795] train lossD: 0.022326 lossG: 0.137307\n",
      "[35: 140/1795] train lossD: -0.051636 lossG: 0.153570\n",
      "[35: 145/1795] train lossD: -0.033059 lossG: 0.112378\n",
      "[35: 150/1795] train lossD: -0.033334 lossG: -0.215821\n",
      "[35: 155/1795] train lossD: -0.024206 lossG: 0.053403\n",
      "[35: 160/1795] train lossD: 0.030513 lossG: 0.064862\n",
      "[35: 165/1795] train lossD: 0.004117 lossG: 0.026141\n",
      "[35: 170/1795] train lossD: -0.076482 lossG: 0.036274\n",
      "[35: 175/1795] train lossD: -0.007025 lossG: 0.008769\n",
      "[35: 180/1795] train lossD: -0.004476 lossG: -0.016630\n",
      "[35: 185/1795] train lossD: -0.431688 lossG: -0.427674\n",
      "[35: 190/1795] train lossD: -0.025478 lossG: 0.203929\n",
      "[35: 195/1795] train lossD: -0.045716 lossG: 0.146731\n",
      "[35: 200/1795] train lossD: -0.026973 lossG: 0.156445\n",
      "[35: 205/1795] train lossD: 0.099717 lossG: 0.013203\n",
      "[35: 210/1795] train lossD: -0.107315 lossG: -0.142706\n",
      "[35: 215/1795] train lossD: 0.200421 lossG: 0.043114\n",
      "[35: 220/1795] train lossD: -0.051880 lossG: 0.122350\n",
      "[35: 225/1795] train lossD: -0.122819 lossG: 0.180809\n",
      "[35: 230/1795] train lossD: 0.090285 lossG: 0.111239\n",
      "[35: 235/1795] train lossD: 0.381549 lossG: -0.339885\n",
      "[35: 240/1795] train lossD: 0.037570 lossG: 0.300374\n",
      "[35: 245/1795] train lossD: -0.047983 lossG: 0.342985\n",
      "[35: 250/1795] train lossD: -0.042484 lossG: 0.396413\n",
      "[35: 255/1795] train lossD: 0.021418 lossG: 0.261644\n",
      "[35: 260/1795] train lossD: 0.005130 lossG: 0.263825\n",
      "[35: 265/1795] train lossD: 0.039029 lossG: 0.210463\n",
      "[35: 270/1795] train lossD: 0.041868 lossG: 0.344836\n",
      "[35: 275/1795] train lossD: 0.110829 lossG: 0.343154\n",
      "[35: 280/1795] train lossD: -0.071063 lossG: 0.101554\n",
      "[35: 285/1795] train lossD: 0.375158 lossG: -0.214761\n",
      "[35: 290/1795] train lossD: -0.052062 lossG: 0.163414\n",
      "[35: 295/1795] train lossD: -0.266406 lossG: 0.139086\n",
      "[35: 300/1795] train lossD: -0.038840 lossG: 0.131681\n",
      "[35: 305/1795] train lossD: 0.214884 lossG: 0.185692\n",
      "[35: 310/1795] train lossD: -0.232860 lossG: -0.151660\n",
      "[35: 315/1795] train lossD: 0.052004 lossG: 0.205306\n",
      "[35: 320/1795] train lossD: -0.692190 lossG: 0.293661\n",
      "[35: 325/1795] train lossD: -0.468183 lossG: 0.142452\n",
      "[35: 330/1795] train lossD: -0.076513 lossG: -0.041491\n",
      "[35: 335/1795] train lossD: -0.189773 lossG: -0.004625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35: 340/1795] train lossD: -0.278493 lossG: 0.198653\n",
      "[35: 345/1795] train lossD: 0.256416 lossG: 0.030210\n",
      "[35: 350/1795] train lossD: 0.262762 lossG: 0.026786\n",
      "[35: 355/1795] train lossD: 0.061598 lossG: 0.032434\n",
      "[35: 360/1795] train lossD: 0.123603 lossG: 0.051504\n",
      "[35: 365/1795] train lossD: 0.092287 lossG: 0.059472\n",
      "[35: 370/1795] train lossD: 0.876929 lossG: 0.148684\n",
      "[35: 375/1795] train lossD: 0.204816 lossG: 0.194795\n",
      "[35: 380/1795] train lossD: 0.079648 lossG: 0.191849\n",
      "[35: 385/1795] train lossD: 0.072391 lossG: 0.163333\n",
      "[35: 390/1795] train lossD: -0.008163 lossG: 0.198381\n",
      "[35: 395/1795] train lossD: 0.008923 lossG: 0.210488\n",
      "[35: 400/1795] train lossD: -0.005745 lossG: 0.230561\n",
      "[35: 405/1795] train lossD: -0.006193 lossG: 0.169791\n",
      "[35: 410/1795] train lossD: -0.017305 lossG: 0.193750\n",
      "[35: 415/1795] train lossD: -0.017749 lossG: 0.202089\n",
      "[35: 420/1795] train lossD: -0.111720 lossG: 0.037853\n",
      "[35: 425/1795] train lossD: 0.036537 lossG: 0.443150\n",
      "[35: 430/1795] train lossD: 0.103649 lossG: 0.398149\n",
      "[35: 435/1795] train lossD: 0.020127 lossG: 0.383182\n",
      "[35: 440/1795] train lossD: 0.011869 lossG: 0.415684\n",
      "[35: 445/1795] train lossD: -0.067550 lossG: 0.398925\n",
      "[35: 450/1795] train lossD: -0.075207 lossG: 0.395725\n",
      "[35: 455/1795] train lossD: -0.108196 lossG: -0.266810\n",
      "[35: 460/1795] train lossD: -0.118964 lossG: 0.326788\n",
      "[35: 465/1795] train lossD: -0.003792 lossG: 0.099853\n",
      "[35: 470/1795] train lossD: -0.007572 lossG: 0.066697\n",
      "[35: 475/1795] train lossD: 0.014592 lossG: 0.181792\n",
      "[35: 480/1795] train lossD: -0.123666 lossG: -0.082073\n",
      "[35: 485/1795] train lossD: -0.220306 lossG: -0.152774\n",
      "[35: 490/1795] train lossD: 0.438783 lossG: 0.167977\n",
      "[35: 495/1795] train lossD: 0.016466 lossG: 0.135069\n",
      "[35: 500/1795] train lossD: -0.371545 lossG: 0.206168\n",
      "[35: 505/1795] train lossD: -0.109541 lossG: 0.193948\n",
      "[35: 510/1795] train lossD: -0.008357 lossG: 0.164586\n",
      "[35: 515/1795] train lossD: -0.278762 lossG: -0.049477\n",
      "[35: 520/1795] train lossD: -0.455270 lossG: -0.043680\n",
      "[35: 525/1795] train lossD: -0.148846 lossG: 0.080425\n",
      "[35: 530/1795] train lossD: -0.492881 lossG: 0.385222\n",
      "[35: 535/1795] train lossD: -0.248836 lossG: 0.274499\n",
      "[35: 540/1795] train lossD: -0.519375 lossG: 0.117031\n",
      "[35: 545/1795] train lossD: -0.591466 lossG: 0.107155\n",
      "[35: 550/1795] train lossD: 0.227000 lossG: 0.264172\n",
      "[35: 555/1795] train lossD: 0.003508 lossG: 0.296347\n",
      "[35: 560/1795] train lossD: -0.010599 lossG: 0.297827\n",
      "[35: 565/1795] train lossD: 0.105598 lossG: 0.327538\n",
      "[35: 570/1795] train lossD: 0.042289 lossG: 0.264509\n",
      "[35: 575/1795] train lossD: -0.002864 lossG: 0.255614\n",
      "[35: 580/1795] train lossD: -0.014592 lossG: 0.353594\n",
      "[35: 585/1795] train lossD: -0.399505 lossG: 0.067683\n",
      "[35: 590/1795] train lossD: -0.380508 lossG: -0.369757\n",
      "[35: 595/1795] train lossD: 0.054921 lossG: 0.143642\n",
      "[35: 600/1795] train lossD: -0.034494 lossG: 0.151757\n",
      "[35: 605/1795] train lossD: -0.084036 lossG: 0.094036\n",
      "[35: 610/1795] train lossD: 0.450647 lossG: 0.073058\n",
      "[35: 615/1795] train lossD: -0.548742 lossG: -0.175221\n",
      "[35: 620/1795] train lossD: 0.107209 lossG: 0.056477\n",
      "[35: 625/1795] train lossD: -0.034447 lossG: 0.114622\n",
      "[35: 630/1795] train lossD: -0.696078 lossG: -0.162819\n",
      "[35: 635/1795] train lossD: -0.181610 lossG: 0.213216\n",
      "[35: 640/1795] train lossD: 0.141476 lossG: -0.542423\n",
      "[35: 645/1795] train lossD: -0.128731 lossG: 0.127017\n",
      "[35: 650/1795] train lossD: -0.306228 lossG: -0.569785\n",
      "[35: 655/1795] train lossD: -0.186537 lossG: 0.006598\n",
      "[35: 660/1795] train lossD: 0.053255 lossG: 0.078264\n",
      "[35: 665/1795] train lossD: -0.317454 lossG: 0.070785\n",
      "[35: 670/1795] train lossD: -0.315517 lossG: -0.703322\n",
      "[35: 675/1795] train lossD: -0.089483 lossG: 0.200886\n",
      "[35: 680/1795] train lossD: -0.389333 lossG: 0.305549\n",
      "[35: 685/1795] train lossD: -0.456312 lossG: -0.131658\n",
      "[35: 690/1795] train lossD: -0.365247 lossG: -0.465260\n",
      "[35: 695/1795] train lossD: -0.014462 lossG: 0.153073\n",
      "[35: 700/1795] train lossD: -0.243880 lossG: -0.606076\n",
      "[35: 705/1795] train lossD: -0.180873 lossG: 0.396475\n",
      "[35: 710/1795] train lossD: -0.125578 lossG: 0.378347\n",
      "[35: 715/1795] train lossD: 0.023565 lossG: 0.317981\n",
      "[35: 720/1795] train lossD: -0.093467 lossG: 0.321622\n",
      "[35: 725/1795] train lossD: -0.279433 lossG: 0.227444\n",
      "[35: 730/1795] train lossD: 0.372564 lossG: -0.032718\n",
      "[35: 735/1795] train lossD: 0.079378 lossG: -0.024855\n",
      "[35: 740/1795] train lossD: -0.025954 lossG: 0.023572\n",
      "[35: 745/1795] train lossD: 0.058620 lossG: 0.054204\n",
      "[35: 750/1795] train lossD: -0.286276 lossG: 0.311963\n",
      "[35: 755/1795] train lossD: -0.092635 lossG: -0.565963\n",
      "[35: 760/1795] train lossD: 0.029402 lossG: -0.161290\n",
      "[35: 765/1795] train lossD: -0.323062 lossG: 0.072496\n",
      "[35: 770/1795] train lossD: -0.667461 lossG: -0.206859\n",
      "[35: 775/1795] train lossD: -0.269858 lossG: -0.489277\n",
      "[35: 780/1795] train lossD: -0.734315 lossG: 0.123532\n",
      "[35: 785/1795] train lossD: -0.510895 lossG: -0.456656\n",
      "[35: 790/1795] train lossD: -0.107470 lossG: -0.989919\n",
      "[35: 795/1795] train lossD: -0.204034 lossG: 0.333334\n",
      "[35: 800/1795] train lossD: -0.163578 lossG: 0.304385\n",
      "[35: 805/1795] train lossD: -0.092705 lossG: 0.380250\n",
      "[35: 810/1795] train lossD: -0.211549 lossG: 0.205649\n",
      "[35: 815/1795] train lossD: 0.032146 lossG: -0.404047\n",
      "[35: 820/1795] train lossD: -0.271919 lossG: 0.104126\n",
      "[35: 825/1795] train lossD: -0.251859 lossG: 0.041274\n",
      "[35: 830/1795] train lossD: -0.569516 lossG: -0.256858\n",
      "[35: 835/1795] train lossD: 0.100619 lossG: 0.094591\n",
      "[35: 840/1795] train lossD: -0.385873 lossG: -0.117933\n",
      "[35: 845/1795] train lossD: 0.035800 lossG: 0.325176\n",
      "[35: 850/1795] train lossD: -0.012814 lossG: 0.329899\n",
      "[35: 855/1795] train lossD: -0.231352 lossG: 0.349083\n",
      "[35: 860/1795] train lossD: -0.253812 lossG: 0.315059\n",
      "[35: 865/1795] train lossD: -0.611336 lossG: -0.630169\n",
      "[35: 870/1795] train lossD: -0.445515 lossG: -0.528757\n",
      "[35: 875/1795] train lossD: -0.045301 lossG: 0.095345\n",
      "[35: 880/1795] train lossD: -0.078086 lossG: 0.251127\n",
      "[35: 885/1795] train lossD: 0.031068 lossG: 0.229423\n",
      "[35: 890/1795] train lossD: -0.094549 lossG: 0.323194\n",
      "[35: 895/1795] train lossD: -0.053121 lossG: -0.200024\n",
      "[35: 900/1795] train lossD: 0.590148 lossG: -0.271046\n",
      "[35: 905/1795] train lossD: 0.091233 lossG: 0.240521\n",
      "[35: 910/1795] train lossD: -0.088230 lossG: 0.309462\n",
      "[35: 915/1795] train lossD: 0.030810 lossG: 0.254035\n",
      "[35: 920/1795] train lossD: -0.675028 lossG: 0.300050\n",
      "[35: 925/1795] train lossD: -0.135065 lossG: 0.302114\n",
      "[35: 930/1795] train lossD: -0.161739 lossG: 0.232467\n",
      "[35: 935/1795] train lossD: -0.164490 lossG: 0.300029\n",
      "[35: 940/1795] train lossD: -0.073761 lossG: 0.334462\n",
      "[35: 945/1795] train lossD: -0.603844 lossG: 0.341935\n",
      "[35: 950/1795] train lossD: 0.025338 lossG: 0.232836\n",
      "[35: 955/1795] train lossD: -0.144772 lossG: 0.215658\n",
      "[35: 960/1795] train lossD: -1.066385 lossG: 0.190848\n",
      "[35: 965/1795] train lossD: -0.759734 lossG: 0.136337\n",
      "[35: 970/1795] train lossD: -0.811266 lossG: 0.193730\n",
      "[35: 975/1795] train lossD: 0.789035 lossG: -0.836348\n",
      "[35: 980/1795] train lossD: -0.143535 lossG: 0.028768\n",
      "[35: 985/1795] train lossD: -0.098147 lossG: 0.017304\n",
      "[35: 990/1795] train lossD: 0.300770 lossG: 0.398098\n",
      "[35: 995/1795] train lossD: 0.095475 lossG: 0.553802\n",
      "[35: 1000/1795] train lossD: 0.173246 lossG: 0.493175\n",
      "[35: 1005/1795] train lossD: 0.056181 lossG: 0.561375\n",
      "[35: 1010/1795] train lossD: -0.063021 lossG: 0.575611\n",
      "[35: 1015/1795] train lossD: -0.391254 lossG: 0.607183\n",
      "[35: 1020/1795] train lossD: -0.450894 lossG: 0.622167\n",
      "[35: 1025/1795] train lossD: -0.150445 lossG: 0.366729\n",
      "[35: 1030/1795] train lossD: -0.665435 lossG: 0.318639\n",
      "[35: 1035/1795] train lossD: -0.747436 lossG: 0.162505\n",
      "[35: 1040/1795] train lossD: -0.410699 lossG: 0.159102\n",
      "[35: 1045/1795] train lossD: -0.545057 lossG: 0.040358\n",
      "[35: 1050/1795] train lossD: -0.575747 lossG: -0.130290\n",
      "[35: 1055/1795] train lossD: -0.811686 lossG: 0.388391\n",
      "[35: 1060/1795] train lossD: -0.466401 lossG: 0.534983\n",
      "[35: 1065/1795] train lossD: -0.172009 lossG: 0.591020\n",
      "[35: 1070/1795] train lossD: -0.219722 lossG: 0.484509\n",
      "[35: 1075/1795] train lossD: -0.411448 lossG: 0.100490\n",
      "[35: 1080/1795] train lossD: -0.411600 lossG: 0.212755\n",
      "[35: 1085/1795] train lossD: -0.236216 lossG: 0.164941\n",
      "[35: 1090/1795] train lossD: -0.105725 lossG: 0.077003\n",
      "[35: 1095/1795] train lossD: -0.821873 lossG: 0.034887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35: 1100/1795] train lossD: -0.002843 lossG: 0.141315\n",
      "[35: 1105/1795] train lossD: -1.024506 lossG: 0.163467\n",
      "[35: 1110/1795] train lossD: -0.971711 lossG: 0.089246\n",
      "[35: 1115/1795] train lossD: -0.725532 lossG: 0.090727\n",
      "[35: 1120/1795] train lossD: -0.530289 lossG: 0.072159\n",
      "[35: 1125/1795] train lossD: 0.162861 lossG: 0.284447\n",
      "[35: 1130/1795] train lossD: -0.789038 lossG: 0.331341\n",
      "[35: 1135/1795] train lossD: -0.079170 lossG: 0.503167\n",
      "[35: 1140/1795] train lossD: -0.057167 lossG: 0.571812\n",
      "[35: 1145/1795] train lossD: 0.132979 lossG: 0.408222\n",
      "[35: 1150/1795] train lossD: -0.742885 lossG: 0.467473\n",
      "[35: 1155/1795] train lossD: -0.681275 lossG: 0.308848\n",
      "[35: 1160/1795] train lossD: 0.185479 lossG: -0.438141\n",
      "[35: 1165/1795] train lossD: -0.090679 lossG: 0.285103\n",
      "[35: 1170/1795] train lossD: -0.502175 lossG: 0.500662\n",
      "[35: 1175/1795] train lossD: -0.223952 lossG: 0.132002\n",
      "[35: 1180/1795] train lossD: 0.087967 lossG: 0.214856\n",
      "[35: 1185/1795] train lossD: -0.849874 lossG: 0.322690\n",
      "[35: 1190/1795] train lossD: -0.701107 lossG: -0.355328\n",
      "[35: 1195/1795] train lossD: -0.061029 lossG: 0.188056\n",
      "[35: 1200/1795] train lossD: -0.260286 lossG: 0.172660\n",
      "[35: 1205/1795] train lossD: -0.202978 lossG: 0.243855\n",
      "[35: 1210/1795] train lossD: 0.072398 lossG: 0.101372\n",
      "[35: 1215/1795] train lossD: 0.052630 lossG: 0.194684\n",
      "[35: 1220/1795] train lossD: -0.147498 lossG: 0.290707\n",
      "[35: 1225/1795] train lossD: -0.264745 lossG: 0.236073\n",
      "[35: 1230/1795] train lossD: -0.414508 lossG: 0.232170\n",
      "[35: 1235/1795] train lossD: -0.605462 lossG: 0.039689\n",
      "[35: 1240/1795] train lossD: -0.349900 lossG: -0.074750\n",
      "[35: 1245/1795] train lossD: -0.544068 lossG: 0.453391\n",
      "[35: 1250/1795] train lossD: -0.842359 lossG: 0.488105\n",
      "[35: 1255/1795] train lossD: 0.344210 lossG: 0.084435\n",
      "[35: 1260/1795] train lossD: -0.612603 lossG: 0.068050\n",
      "[35: 1265/1795] train lossD: -0.289748 lossG: -0.089969\n",
      "[35: 1270/1795] train lossD: -0.193634 lossG: 0.309822\n",
      "[35: 1275/1795] train lossD: -0.298431 lossG: -0.562619\n",
      "[35: 1280/1795] train lossD: -0.913970 lossG: 0.270507\n",
      "[35: 1285/1795] train lossD: -1.068157 lossG: -0.053120\n",
      "[35: 1290/1795] train lossD: 0.022429 lossG: 0.108029\n",
      "[35: 1295/1795] train lossD: -0.037856 lossG: 0.157922\n",
      "[35: 1300/1795] train lossD: -0.382257 lossG: 0.294939\n",
      "[35: 1305/1795] train lossD: -0.708609 lossG: -0.018228\n",
      "[35: 1310/1795] train lossD: -1.148541 lossG: 0.340967\n",
      "[35: 1315/1795] train lossD: -0.516537 lossG: 0.020495\n",
      "[35: 1320/1795] train lossD: -0.066153 lossG: 0.427130\n",
      "[35: 1325/1795] train lossD: -0.673733 lossG: -0.720878\n",
      "[35: 1330/1795] train lossD: -0.183369 lossG: -0.139891\n",
      "[35: 1335/1795] train lossD: -0.335544 lossG: 0.275005\n",
      "[35: 1340/1795] train lossD: -0.610752 lossG: 0.058475\n",
      "[35: 1345/1795] train lossD: -0.787728 lossG: 0.226728\n",
      "[35: 1350/1795] train lossD: 0.230333 lossG: 0.253110\n",
      "[35: 1355/1795] train lossD: -0.562879 lossG: 0.478983\n",
      "[35: 1360/1795] train lossD: -0.755107 lossG: 0.318528\n",
      "[35: 1365/1795] train lossD: 0.063946 lossG: 0.323779\n",
      "[35: 1370/1795] train lossD: -1.033930 lossG: 0.342755\n",
      "[35: 1375/1795] train lossD: -0.439970 lossG: -0.784101\n",
      "[35: 1380/1795] train lossD: -0.664200 lossG: 0.650911\n",
      "[35: 1385/1795] train lossD: 0.304979 lossG: 0.252214\n",
      "[35: 1390/1795] train lossD: -0.665244 lossG: 0.592447\n",
      "[35: 1395/1795] train lossD: -0.077096 lossG: 0.154992\n",
      "[35: 1400/1795] train lossD: -0.924836 lossG: 0.340855\n",
      "[35: 1405/1795] train lossD: 0.189555 lossG: 0.303871\n",
      "[35: 1410/1795] train lossD: -0.172478 lossG: 0.394224\n",
      "[35: 1415/1795] train lossD: 3.240944 lossG: 0.058455\n",
      "[35: 1420/1795] train lossD: 0.208187 lossG: 0.000600\n",
      "[35: 1425/1795] train lossD: 0.096607 lossG: 0.237848\n",
      "[35: 1430/1795] train lossD: -0.128294 lossG: 0.494192\n",
      "[35: 1435/1795] train lossD: -0.020640 lossG: 0.430904\n",
      "[35: 1440/1795] train lossD: -0.260588 lossG: 0.604917\n",
      "[35: 1445/1795] train lossD: -0.219318 lossG: 0.648314\n",
      "[35: 1450/1795] train lossD: -0.067441 lossG: 0.438833\n",
      "[35: 1455/1795] train lossD: -0.280973 lossG: 0.520510\n",
      "[35: 1460/1795] train lossD: 0.008633 lossG: 0.473126\n",
      "[35: 1465/1795] train lossD: -0.030419 lossG: 0.378419\n",
      "[35: 1470/1795] train lossD: -0.284369 lossG: 0.289312\n",
      "[35: 1475/1795] train lossD: -0.343033 lossG: -0.264438\n",
      "[35: 1480/1795] train lossD: 0.060789 lossG: 0.166984\n",
      "[35: 1485/1795] train lossD: -0.146004 lossG: 0.307888\n",
      "[35: 1490/1795] train lossD: 0.045403 lossG: 0.207376\n",
      "[35: 1495/1795] train lossD: -1.040331 lossG: 0.339616\n",
      "[35: 1500/1795] train lossD: -0.249977 lossG: -0.149154\n",
      "[35: 1505/1795] train lossD: -0.886470 lossG: -0.200189\n",
      "[35: 1510/1795] train lossD: 0.061906 lossG: 0.117578\n",
      "[35: 1515/1795] train lossD: -0.047391 lossG: 0.158071\n",
      "[35: 1520/1795] train lossD: -0.045386 lossG: 0.054218\n",
      "[35: 1525/1795] train lossD: -0.103159 lossG: 0.035998\n",
      "[35: 1530/1795] train lossD: -0.059776 lossG: -0.261806\n",
      "[35: 1535/1795] train lossD: -0.056847 lossG: 0.362485\n",
      "[35: 1540/1795] train lossD: -0.031267 lossG: 0.199917\n",
      "[35: 1545/1795] train lossD: 0.115790 lossG: 0.183841\n",
      "[35: 1550/1795] train lossD: -0.063881 lossG: 0.176520\n",
      "[35: 1555/1795] train lossD: -0.458770 lossG: 0.006194\n",
      "[35: 1560/1795] train lossD: -0.086862 lossG: -0.184641\n",
      "[35: 1565/1795] train lossD: -0.205009 lossG: -0.345741\n",
      "[35: 1570/1795] train lossD: 0.032164 lossG: 0.110799\n",
      "[35: 1575/1795] train lossD: -0.247807 lossG: 0.058467\n",
      "[35: 1580/1795] train lossD: -0.377370 lossG: 0.410430\n",
      "[35: 1585/1795] train lossD: -0.359999 lossG: 0.229318\n",
      "[35: 1590/1795] train lossD: -0.169246 lossG: 0.283419\n",
      "[35: 1595/1795] train lossD: -0.372285 lossG: 0.296689\n",
      "[35: 1600/1795] train lossD: -1.063059 lossG: -0.072911\n",
      "[35: 1605/1795] train lossD: -0.626518 lossG: 0.205742\n",
      "[35: 1610/1795] train lossD: 0.093227 lossG: 0.236977\n",
      "[35: 1615/1795] train lossD: -0.035106 lossG: 0.375809\n",
      "[35: 1620/1795] train lossD: -0.261502 lossG: 0.488606\n",
      "[35: 1625/1795] train lossD: -0.240292 lossG: -0.052499\n",
      "[35: 1630/1795] train lossD: -0.633770 lossG: 0.272717\n",
      "[35: 1635/1795] train lossD: -0.322160 lossG: 0.267439\n",
      "[35: 1640/1795] train lossD: -0.941479 lossG: -0.094780\n",
      "[35: 1645/1795] train lossD: 0.041456 lossG: 0.199476\n",
      "[35: 1650/1795] train lossD: 0.019592 lossG: 0.177930\n",
      "[35: 1655/1795] train lossD: -0.067365 lossG: 0.230849\n",
      "[35: 1660/1795] train lossD: 0.011445 lossG: 0.207223\n",
      "[35: 1665/1795] train lossD: -0.429104 lossG: 0.058715\n",
      "[35: 1670/1795] train lossD: -0.037404 lossG: 0.452362\n",
      "[35: 1675/1795] train lossD: -1.147841 lossG: 0.241663\n",
      "[35: 1680/1795] train lossD: -0.382560 lossG: 0.099580\n",
      "[35: 1685/1795] train lossD: 0.122088 lossG: 0.297473\n",
      "[35: 1690/1795] train lossD: 0.124741 lossG: 0.193839\n",
      "[35: 1695/1795] train lossD: 0.040693 lossG: 0.192355\n",
      "[35: 1700/1795] train lossD: 0.084930 lossG: 0.168336\n",
      "[35: 1705/1795] train lossD: -0.013127 lossG: 0.067400\n",
      "[35: 1710/1795] train lossD: -0.121060 lossG: 0.060380\n",
      "[35: 1715/1795] train lossD: -0.668204 lossG: 0.230603\n",
      "[35: 1720/1795] train lossD: -0.008699 lossG: 0.360318\n",
      "[35: 1725/1795] train lossD: 0.012242 lossG: 0.443098\n",
      "[35: 1730/1795] train lossD: 0.034171 lossG: 0.355570\n",
      "[35: 1735/1795] train lossD: -1.041746 lossG: 0.338516\n",
      "[35: 1740/1795] train lossD: -0.708254 lossG: 0.338727\n",
      "[35: 1745/1795] train lossD: -0.260539 lossG: 0.041243\n",
      "[35: 1750/1795] train lossD: -0.209636 lossG: -0.045948\n",
      "[35: 1755/1795] train lossD: -0.572164 lossG: 0.198637\n",
      "[35: 1760/1795] train lossD: -0.504029 lossG: -0.021372\n",
      "[35: 1765/1795] train lossD: -0.986746 lossG: 0.105100\n",
      "[35: 1770/1795] train lossD: -0.903254 lossG: 0.154980\n",
      "[35: 1775/1795] train lossD: -0.425138 lossG: -0.317684\n",
      "[35: 1780/1795] train lossD: 0.027366 lossG: 0.207375\n",
      "[35: 1785/1795] train lossD: 0.489432 lossG: 0.133512\n",
      "[35: 1790/1795] train lossD: -0.450983 lossG: -0.039942\n",
      "0.033305034041404724\n",
      "[36: 0/1795] train lossD: -0.110609 lossG: -0.793398\n",
      "[36: 5/1795] train lossD: -0.747312 lossG: -0.080929\n",
      "[36: 10/1795] train lossD: -0.201034 lossG: 0.151324\n",
      "[36: 15/1795] train lossD: -0.089188 lossG: 0.408399\n",
      "[36: 20/1795] train lossD: -0.373813 lossG: 0.356766\n",
      "[36: 25/1795] train lossD: 0.152859 lossG: 0.390701\n",
      "[36: 30/1795] train lossD: -0.337823 lossG: 0.292184\n",
      "[36: 35/1795] train lossD: 0.166811 lossG: -0.748956\n",
      "[36: 40/1795] train lossD: -0.770041 lossG: -0.538295\n",
      "[36: 45/1795] train lossD: -1.156842 lossG: -0.269585\n",
      "[36: 50/1795] train lossD: 1.586464 lossG: 0.120087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36: 55/1795] train lossD: 0.011037 lossG: 0.094711\n",
      "[36: 60/1795] train lossD: 0.092865 lossG: 0.069088\n",
      "[36: 65/1795] train lossD: -0.002057 lossG: 0.244925\n",
      "[36: 70/1795] train lossD: -1.319966 lossG: 0.054390\n",
      "[36: 75/1795] train lossD: -0.144562 lossG: 0.506268\n",
      "[36: 80/1795] train lossD: -0.455254 lossG: -0.733165\n",
      "[36: 85/1795] train lossD: -0.165943 lossG: -0.060952\n",
      "[36: 90/1795] train lossD: -0.346985 lossG: 0.030317\n",
      "[36: 95/1795] train lossD: -0.071069 lossG: 0.241970\n",
      "[36: 100/1795] train lossD: -0.744812 lossG: 0.256172\n",
      "[36: 105/1795] train lossD: 0.736403 lossG: 0.246215\n",
      "[36: 110/1795] train lossD: 0.038585 lossG: 0.270112\n",
      "[36: 115/1795] train lossD: -0.195124 lossG: 0.271632\n",
      "[36: 120/1795] train lossD: -1.483785 lossG: 0.254575\n",
      "[36: 125/1795] train lossD: -0.072635 lossG: 0.405744\n",
      "[36: 130/1795] train lossD: -0.575402 lossG: 0.373917\n",
      "[36: 135/1795] train lossD: -0.861628 lossG: -0.314869\n",
      "[36: 140/1795] train lossD: 0.237275 lossG: 0.377087\n",
      "[36: 145/1795] train lossD: -0.203469 lossG: 0.373858\n",
      "[36: 150/1795] train lossD: -0.031658 lossG: 0.594893\n",
      "[36: 155/1795] train lossD: -0.486177 lossG: 0.519917\n",
      "[36: 160/1795] train lossD: -0.903410 lossG: 0.265356\n",
      "[36: 165/1795] train lossD: -1.355241 lossG: 0.354872\n",
      "[36: 170/1795] train lossD: -0.379935 lossG: 0.276933\n",
      "[36: 175/1795] train lossD: -0.935689 lossG: 0.193523\n",
      "[36: 180/1795] train lossD: -0.729223 lossG: 0.401290\n",
      "[36: 185/1795] train lossD: -0.367009 lossG: -0.190687\n",
      "[36: 190/1795] train lossD: -0.979761 lossG: 0.145403\n",
      "[36: 195/1795] train lossD: -0.278422 lossG: 0.233124\n",
      "[36: 200/1795] train lossD: -0.297308 lossG: -0.061968\n",
      "[36: 205/1795] train lossD: -0.772500 lossG: 0.216095\n",
      "[36: 210/1795] train lossD: -0.498330 lossG: 0.326246\n",
      "[36: 215/1795] train lossD: -1.470832 lossG: 0.351060\n",
      "[36: 220/1795] train lossD: 0.081085 lossG: 0.108863\n",
      "[36: 225/1795] train lossD: 0.048625 lossG: 0.173860\n",
      "[36: 230/1795] train lossD: -0.018036 lossG: 0.194038\n",
      "[36: 235/1795] train lossD: -1.086384 lossG: -0.645212\n",
      "[36: 240/1795] train lossD: 0.167294 lossG: 0.310037\n",
      "[36: 245/1795] train lossD: -0.019926 lossG: 0.394035\n",
      "[36: 250/1795] train lossD: 0.097595 lossG: 0.353030\n",
      "[36: 255/1795] train lossD: -0.215967 lossG: 0.429298\n",
      "[36: 260/1795] train lossD: -0.133956 lossG: 0.419825\n",
      "[36: 265/1795] train lossD: -0.153969 lossG: 0.434741\n",
      "[36: 270/1795] train lossD: -0.173608 lossG: 0.493403\n",
      "[36: 275/1795] train lossD: -0.561220 lossG: 0.409259\n",
      "[36: 280/1795] train lossD: -0.129237 lossG: 0.350636\n",
      "[36: 285/1795] train lossD: -0.145428 lossG: 0.400277\n",
      "[36: 290/1795] train lossD: -0.629673 lossG: 0.458911\n",
      "[36: 295/1795] train lossD: -0.376684 lossG: 0.427208\n",
      "[36: 300/1795] train lossD: -0.454938 lossG: 0.493308\n",
      "[36: 305/1795] train lossD: -0.956012 lossG: 0.221963\n",
      "[36: 310/1795] train lossD: -0.244495 lossG: 0.344437\n",
      "[36: 315/1795] train lossD: -0.790233 lossG: 0.084905\n",
      "[36: 320/1795] train lossD: -0.223547 lossG: 0.087548\n",
      "[36: 325/1795] train lossD: -0.335588 lossG: 0.113776\n",
      "[36: 330/1795] train lossD: -0.797101 lossG: 0.096477\n",
      "[36: 335/1795] train lossD: -0.750897 lossG: 0.044373\n",
      "[36: 340/1795] train lossD: -0.824093 lossG: 0.071542\n",
      "[36: 345/1795] train lossD: -0.615297 lossG: 0.157303\n",
      "[36: 350/1795] train lossD: -0.253126 lossG: 0.103564\n",
      "[36: 355/1795] train lossD: -1.748955 lossG: 0.310862\n",
      "[36: 360/1795] train lossD: -0.395143 lossG: -0.269183\n",
      "[36: 365/1795] train lossD: -0.388615 lossG: 0.084956\n",
      "[36: 370/1795] train lossD: 0.431631 lossG: 0.154414\n",
      "[36: 375/1795] train lossD: -0.653695 lossG: 0.095007\n",
      "[36: 380/1795] train lossD: 1.052492 lossG: -0.004855\n",
      "[36: 385/1795] train lossD: 0.149693 lossG: 0.019245\n",
      "[36: 390/1795] train lossD: 0.046042 lossG: 0.075043\n",
      "[36: 395/1795] train lossD: 0.080788 lossG: 0.114057\n",
      "[36: 400/1795] train lossD: 0.000111 lossG: 0.138323\n",
      "[36: 405/1795] train lossD: -0.355760 lossG: -0.055180\n",
      "[36: 410/1795] train lossD: -0.012997 lossG: 0.269560\n",
      "[36: 415/1795] train lossD: 0.015807 lossG: 0.493275\n",
      "[36: 420/1795] train lossD: -0.031112 lossG: 0.555274\n",
      "[36: 425/1795] train lossD: -0.046629 lossG: 0.527372\n",
      "[36: 430/1795] train lossD: 0.012594 lossG: 0.525996\n",
      "[36: 435/1795] train lossD: -0.037825 lossG: 0.409715\n",
      "[36: 440/1795] train lossD: -0.508528 lossG: 0.294401\n",
      "[36: 445/1795] train lossD: -0.208964 lossG: 0.066770\n",
      "[36: 450/1795] train lossD: -0.417033 lossG: 0.006814\n",
      "[36: 455/1795] train lossD: -1.225778 lossG: 0.052523\n",
      "[36: 460/1795] train lossD: -1.446319 lossG: 0.164576\n",
      "[36: 465/1795] train lossD: -0.864863 lossG: -0.037850\n",
      "[36: 470/1795] train lossD: -1.359462 lossG: -0.890526\n",
      "[36: 475/1795] train lossD: 0.138474 lossG: -0.768326\n",
      "[36: 480/1795] train lossD: -0.567829 lossG: -0.057070\n",
      "[36: 485/1795] train lossD: -0.905014 lossG: -0.348267\n",
      "[36: 490/1795] train lossD: -0.063886 lossG: -0.269505\n",
      "[36: 495/1795] train lossD: 0.550832 lossG: -0.407325\n",
      "[36: 500/1795] train lossD: -1.576484 lossG: -0.095000\n",
      "[36: 505/1795] train lossD: -1.182240 lossG: 0.325242\n",
      "[36: 510/1795] train lossD: 0.226584 lossG: 0.221637\n",
      "[36: 515/1795] train lossD: 0.066732 lossG: 0.367809\n",
      "[36: 520/1795] train lossD: 0.034035 lossG: 0.394052\n",
      "[36: 525/1795] train lossD: -0.154778 lossG: 0.395813\n",
      "[36: 530/1795] train lossD: 0.094966 lossG: 0.446316\n",
      "[36: 535/1795] train lossD: -0.962758 lossG: 0.201316\n",
      "[36: 540/1795] train lossD: -0.937210 lossG: 0.073728\n",
      "[36: 545/1795] train lossD: -0.723035 lossG: -0.155763\n",
      "[36: 550/1795] train lossD: -0.180487 lossG: 0.018051\n",
      "[36: 555/1795] train lossD: -0.662957 lossG: -1.489860\n",
      "[36: 560/1795] train lossD: -0.585127 lossG: 0.408088\n",
      "[36: 565/1795] train lossD: -0.005274 lossG: -0.005432\n",
      "[36: 570/1795] train lossD: -0.487582 lossG: -0.344728\n",
      "[36: 575/1795] train lossD: -0.525624 lossG: -1.175490\n",
      "[36: 580/1795] train lossD: -0.655271 lossG: 0.176154\n",
      "[36: 585/1795] train lossD: -0.383156 lossG: -0.401386\n",
      "[36: 590/1795] train lossD: -0.245645 lossG: -0.247187\n",
      "[36: 595/1795] train lossD: -1.028770 lossG: 0.427790\n",
      "[36: 600/1795] train lossD: -0.086332 lossG: 0.356156\n",
      "[36: 605/1795] train lossD: 0.221776 lossG: 0.324243\n",
      "[36: 610/1795] train lossD: 0.147448 lossG: 0.277662\n",
      "[36: 615/1795] train lossD: 0.034704 lossG: 0.261012\n",
      "[36: 620/1795] train lossD: 0.029500 lossG: 0.326540\n",
      "[36: 625/1795] train lossD: 0.003029 lossG: 0.491520\n",
      "[36: 630/1795] train lossD: 0.049468 lossG: 0.438712\n",
      "[36: 635/1795] train lossD: -0.041708 lossG: 0.387513\n",
      "[36: 640/1795] train lossD: -0.018061 lossG: 0.434251\n",
      "[36: 645/1795] train lossD: -0.352739 lossG: 0.143323\n",
      "[36: 650/1795] train lossD: -0.491085 lossG: -0.059603\n",
      "[36: 655/1795] train lossD: -1.224314 lossG: -0.187623\n",
      "[36: 660/1795] train lossD: 0.111570 lossG: 0.130844\n",
      "[36: 665/1795] train lossD: 0.193745 lossG: 0.440169\n",
      "[36: 670/1795] train lossD: -0.094601 lossG: 0.723946\n",
      "[36: 675/1795] train lossD: -0.063742 lossG: 0.690057\n",
      "[36: 680/1795] train lossD: -0.285480 lossG: 0.784523\n",
      "[36: 685/1795] train lossD: -0.143892 lossG: 0.673995\n",
      "[36: 690/1795] train lossD: -0.053935 lossG: 0.620942\n",
      "[36: 695/1795] train lossD: -0.015892 lossG: 0.516582\n",
      "[36: 700/1795] train lossD: -0.350910 lossG: 0.432348\n",
      "[36: 705/1795] train lossD: -1.339934 lossG: 0.367895\n",
      "[36: 710/1795] train lossD: -0.433440 lossG: 0.311163\n",
      "[36: 715/1795] train lossD: 0.244712 lossG: 0.064177\n",
      "[36: 720/1795] train lossD: 0.008155 lossG: 0.208880\n",
      "[36: 725/1795] train lossD: -0.389865 lossG: 0.409786\n",
      "[36: 730/1795] train lossD: 0.673377 lossG: -1.081315\n",
      "[36: 735/1795] train lossD: 0.350347 lossG: -0.843401\n",
      "[36: 740/1795] train lossD: -0.324541 lossG: -0.306272\n",
      "[36: 745/1795] train lossD: -0.593839 lossG: -0.229430\n",
      "[36: 750/1795] train lossD: -0.077579 lossG: 0.221966\n",
      "[36: 755/1795] train lossD: -0.173520 lossG: 0.324006\n",
      "[36: 760/1795] train lossD: -0.546843 lossG: -0.730357\n",
      "[36: 765/1795] train lossD: -0.547744 lossG: 0.133459\n",
      "[36: 770/1795] train lossD: -1.581529 lossG: 0.077500\n",
      "[36: 775/1795] train lossD: -0.595970 lossG: 0.180352\n",
      "[36: 780/1795] train lossD: -0.271258 lossG: 0.339007\n",
      "[36: 785/1795] train lossD: -1.148526 lossG: -0.352882\n",
      "[36: 790/1795] train lossD: -0.079149 lossG: 0.224923\n",
      "[36: 795/1795] train lossD: 0.147822 lossG: 0.137236\n",
      "[36: 800/1795] train lossD: 117.977646 lossG: 0.435888\n",
      "[36: 805/1795] train lossD: -0.298789 lossG: 0.403362\n",
      "[36: 810/1795] train lossD: 0.119326 lossG: 0.438454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36: 815/1795] train lossD: 0.019415 lossG: 0.481123\n",
      "[36: 820/1795] train lossD: 0.036679 lossG: 0.427911\n",
      "[36: 825/1795] train lossD: -0.004231 lossG: 0.438362\n",
      "[36: 830/1795] train lossD: 0.236958 lossG: 0.425853\n",
      "[36: 835/1795] train lossD: -0.099565 lossG: 0.450225\n",
      "[36: 840/1795] train lossD: 0.100126 lossG: 0.477105\n",
      "[36: 845/1795] train lossD: 0.130298 lossG: 0.418010\n",
      "[36: 850/1795] train lossD: -0.132636 lossG: 0.487534\n",
      "[36: 855/1795] train lossD: -0.163764 lossG: 0.352976\n",
      "[36: 860/1795] train lossD: -0.347118 lossG: 0.297075\n",
      "[36: 865/1795] train lossD: -0.111302 lossG: 0.180230\n",
      "[36: 870/1795] train lossD: -0.858246 lossG: -0.331812\n",
      "[36: 875/1795] train lossD: -0.755501 lossG: -0.315019\n",
      "[36: 880/1795] train lossD: -1.256149 lossG: -0.035150\n",
      "[36: 885/1795] train lossD: -0.725892 lossG: -0.058212\n",
      "[36: 890/1795] train lossD: -1.195651 lossG: 0.349802\n",
      "[36: 895/1795] train lossD: -1.700971 lossG: 0.141059\n",
      "[36: 900/1795] train lossD: -0.663023 lossG: -0.017257\n",
      "[36: 905/1795] train lossD: -0.773140 lossG: 0.324438\n",
      "[36: 910/1795] train lossD: -0.174115 lossG: 0.181432\n",
      "[36: 915/1795] train lossD: -1.783010 lossG: -0.109487\n",
      "[36: 920/1795] train lossD: -0.701206 lossG: -0.799667\n",
      "[36: 925/1795] train lossD: -0.043793 lossG: 0.265668\n",
      "[36: 930/1795] train lossD: -0.118384 lossG: 0.246661\n",
      "[36: 935/1795] train lossD: -0.630809 lossG: 0.392642\n",
      "[36: 940/1795] train lossD: -0.367739 lossG: 0.464080\n",
      "[36: 945/1795] train lossD: -0.630142 lossG: 0.412916\n",
      "[36: 950/1795] train lossD: -0.968292 lossG: 0.297560\n",
      "[36: 955/1795] train lossD: -0.714140 lossG: 0.266398\n",
      "[36: 960/1795] train lossD: -0.279683 lossG: 0.426910\n",
      "[36: 965/1795] train lossD: -1.214613 lossG: 0.167930\n",
      "[36: 970/1795] train lossD: 0.213058 lossG: 0.393094\n",
      "[36: 975/1795] train lossD: 2.331180 lossG: -1.304911\n",
      "[36: 980/1795] train lossD: 0.188788 lossG: -0.138610\n",
      "[36: 985/1795] train lossD: -0.012390 lossG: 0.027251\n",
      "[36: 990/1795] train lossD: 0.005533 lossG: 0.219450\n",
      "[36: 995/1795] train lossD: 0.091819 lossG: 0.091987\n",
      "[36: 1000/1795] train lossD: 0.192721 lossG: 0.264867\n",
      "[36: 1005/1795] train lossD: -0.042650 lossG: 0.237604\n",
      "[36: 1010/1795] train lossD: -0.012919 lossG: 0.329906\n",
      "[36: 1015/1795] train lossD: 0.185285 lossG: 0.313105\n",
      "[36: 1020/1795] train lossD: 0.043579 lossG: -0.027103\n",
      "[36: 1025/1795] train lossD: 0.290767 lossG: 0.158602\n",
      "[36: 1030/1795] train lossD: -0.116849 lossG: 0.137451\n",
      "[36: 1035/1795] train lossD: 0.152729 lossG: 0.089639\n",
      "[36: 1040/1795] train lossD: 0.013942 lossG: 0.191002\n",
      "[36: 1045/1795] train lossD: 1.041022 lossG: 0.374336\n",
      "[36: 1050/1795] train lossD: 0.140377 lossG: 0.503791\n",
      "[36: 1055/1795] train lossD: 0.037771 lossG: 0.667734\n",
      "[36: 1060/1795] train lossD: 0.056107 lossG: 0.560048\n",
      "[36: 1065/1795] train lossD: 0.150521 lossG: 0.501686\n",
      "[36: 1070/1795] train lossD: -0.119365 lossG: 0.506380\n",
      "[36: 1075/1795] train lossD: -0.979478 lossG: 0.181763\n",
      "[36: 1080/1795] train lossD: -0.199968 lossG: 0.418871\n",
      "[36: 1085/1795] train lossD: -0.820637 lossG: 0.270550\n",
      "[36: 1090/1795] train lossD: -1.458671 lossG: 0.488936\n",
      "[36: 1095/1795] train lossD: -0.497568 lossG: 0.122386\n",
      "[36: 1100/1795] train lossD: -0.105306 lossG: 0.098580\n",
      "[36: 1105/1795] train lossD: 0.108681 lossG: 0.294512\n",
      "[36: 1110/1795] train lossD: -1.081951 lossG: -0.262508\n",
      "[36: 1115/1795] train lossD: -0.401227 lossG: -0.019261\n",
      "[36: 1120/1795] train lossD: -0.808839 lossG: -0.128051\n",
      "[36: 1125/1795] train lossD: -0.702267 lossG: -0.308870\n",
      "[36: 1130/1795] train lossD: -0.735215 lossG: 0.218922\n",
      "[36: 1135/1795] train lossD: -0.963387 lossG: -0.671489\n",
      "[36: 1140/1795] train lossD: -0.153964 lossG: 0.327283\n",
      "[36: 1145/1795] train lossD: -1.376454 lossG: 0.152926\n",
      "[36: 1150/1795] train lossD: -1.409891 lossG: 0.296284\n",
      "[36: 1155/1795] train lossD: -0.669906 lossG: -0.296257\n",
      "[36: 1160/1795] train lossD: -0.206601 lossG: -0.231340\n",
      "[36: 1165/1795] train lossD: 0.103222 lossG: 0.056674\n",
      "[36: 1170/1795] train lossD: 0.035865 lossG: 0.106202\n",
      "[36: 1175/1795] train lossD: 0.086570 lossG: 0.086760\n",
      "[36: 1180/1795] train lossD: 0.172933 lossG: 0.086373\n",
      "[36: 1185/1795] train lossD: 0.026082 lossG: 0.142612\n",
      "[36: 1190/1795] train lossD: 0.121390 lossG: 0.102779\n",
      "[36: 1195/1795] train lossD: -0.032042 lossG: 0.139889\n",
      "[36: 1200/1795] train lossD: 0.110598 lossG: 0.159929\n",
      "[36: 1205/1795] train lossD: 0.132338 lossG: 0.138603\n",
      "[36: 1210/1795] train lossD: 0.066717 lossG: 0.171529\n",
      "[36: 1215/1795] train lossD: -0.089963 lossG: 0.196764\n",
      "[36: 1220/1795] train lossD: -0.035982 lossG: 0.205947\n",
      "[36: 1225/1795] train lossD: -0.084244 lossG: 0.172950\n",
      "[36: 1230/1795] train lossD: 0.049957 lossG: 0.209916\n",
      "[36: 1235/1795] train lossD: 0.035729 lossG: 0.221666\n",
      "[36: 1240/1795] train lossD: -0.039652 lossG: 0.267687\n",
      "[36: 1245/1795] train lossD: 0.008424 lossG: 0.119256\n",
      "[36: 1250/1795] train lossD: -0.104779 lossG: 0.141647\n",
      "[36: 1255/1795] train lossD: -0.810681 lossG: -0.273304\n",
      "[36: 1260/1795] train lossD: 0.251027 lossG: 0.463201\n",
      "[36: 1265/1795] train lossD: 0.446660 lossG: 0.405097\n",
      "[36: 1270/1795] train lossD: 0.012951 lossG: 0.445581\n",
      "[36: 1275/1795] train lossD: -0.007058 lossG: 0.521988\n",
      "[36: 1280/1795] train lossD: -0.048232 lossG: 0.410351\n",
      "[36: 1285/1795] train lossD: 0.015672 lossG: 0.372914\n",
      "[36: 1290/1795] train lossD: -0.144068 lossG: 0.412356\n",
      "[36: 1295/1795] train lossD: -0.017907 lossG: 0.374630\n",
      "[36: 1300/1795] train lossD: -0.017706 lossG: 0.311286\n",
      "[36: 1305/1795] train lossD: -0.064340 lossG: 0.304392\n",
      "[36: 1310/1795] train lossD: -1.165201 lossG: 0.068042\n",
      "[36: 1315/1795] train lossD: -0.164521 lossG: -0.035349\n",
      "[36: 1320/1795] train lossD: -1.019426 lossG: -0.080217\n",
      "[36: 1325/1795] train lossD: -0.339371 lossG: 0.015272\n",
      "[36: 1330/1795] train lossD: -0.270269 lossG: -0.062774\n",
      "[36: 1335/1795] train lossD: -1.436948 lossG: 0.094011\n",
      "[36: 1340/1795] train lossD: 0.369746 lossG: -0.059019\n",
      "[36: 1345/1795] train lossD: -0.532565 lossG: -0.684424\n",
      "[36: 1350/1795] train lossD: 0.377639 lossG: -1.634660\n",
      "[36: 1355/1795] train lossD: -0.409406 lossG: -0.713692\n",
      "[36: 1360/1795] train lossD: -1.004571 lossG: 0.271067\n",
      "[36: 1365/1795] train lossD: -0.388840 lossG: 0.208670\n",
      "[36: 1370/1795] train lossD: -1.120631 lossG: 0.197919\n",
      "[36: 1375/1795] train lossD: -1.284255 lossG: -0.077051\n",
      "[36: 1380/1795] train lossD: -1.623509 lossG: -0.121287\n",
      "[36: 1385/1795] train lossD: -0.298114 lossG: -0.076628\n",
      "[36: 1390/1795] train lossD: -1.316997 lossG: 0.295567\n",
      "[36: 1395/1795] train lossD: -0.371645 lossG: 0.450654\n",
      "[36: 1400/1795] train lossD: -0.066689 lossG: -1.340955\n",
      "[36: 1405/1795] train lossD: 0.023481 lossG: 0.108912\n",
      "[36: 1410/1795] train lossD: -1.286663 lossG: 0.332957\n",
      "[36: 1415/1795] train lossD: -0.459376 lossG: -0.402992\n",
      "[36: 1420/1795] train lossD: -0.592235 lossG: -1.909966\n",
      "[36: 1425/1795] train lossD: -0.443704 lossG: 0.181546\n",
      "[36: 1430/1795] train lossD: -0.306867 lossG: 0.377174\n",
      "[36: 1435/1795] train lossD: -0.466786 lossG: -0.193346\n",
      "[36: 1440/1795] train lossD: -1.469511 lossG: -0.286883\n",
      "[36: 1445/1795] train lossD: -0.529875 lossG: 0.211040\n",
      "[36: 1450/1795] train lossD: -0.227433 lossG: 0.384895\n",
      "[36: 1455/1795] train lossD: -0.531792 lossG: 0.453316\n",
      "[36: 1460/1795] train lossD: -0.898581 lossG: 0.249191\n",
      "[36: 1465/1795] train lossD: 0.009457 lossG: 0.084249\n",
      "[36: 1470/1795] train lossD: -0.398600 lossG: -0.227018\n",
      "[36: 1475/1795] train lossD: -0.807674 lossG: 0.193078\n",
      "[36: 1480/1795] train lossD: -0.323818 lossG: 0.212769\n",
      "[36: 1485/1795] train lossD: 0.006645 lossG: 0.114635\n",
      "[36: 1490/1795] train lossD: 0.156954 lossG: 0.102023\n",
      "[36: 1495/1795] train lossD: 0.341836 lossG: 0.006452\n",
      "[36: 1500/1795] train lossD: -0.220455 lossG: 0.177709\n",
      "[36: 1505/1795] train lossD: 0.263026 lossG: 0.084793\n",
      "[36: 1510/1795] train lossD: -0.017195 lossG: 0.051764\n",
      "[36: 1515/1795] train lossD: -0.153869 lossG: 0.222904\n",
      "[36: 1520/1795] train lossD: -0.764358 lossG: 0.210653\n",
      "[36: 1525/1795] train lossD: -0.279303 lossG: 0.132526\n",
      "[36: 1530/1795] train lossD: -0.072185 lossG: 0.330194\n",
      "[36: 1535/1795] train lossD: 0.079250 lossG: 0.300032\n",
      "[36: 1540/1795] train lossD: -0.226174 lossG: 0.414962\n",
      "[36: 1545/1795] train lossD: -0.413763 lossG: 0.180528\n",
      "[36: 1550/1795] train lossD: -0.868657 lossG: 0.339002\n",
      "[36: 1555/1795] train lossD: -0.010067 lossG: 0.333243\n",
      "[36: 1560/1795] train lossD: -0.555961 lossG: 0.314419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36: 1565/1795] train lossD: -1.426560 lossG: 0.289778\n",
      "[36: 1570/1795] train lossD: -0.772979 lossG: 0.196000\n",
      "[36: 1575/1795] train lossD: -1.052286 lossG: 0.181589\n",
      "[36: 1580/1795] train lossD: -1.170709 lossG: 0.023878\n",
      "[36: 1585/1795] train lossD: -0.662448 lossG: -0.064635\n",
      "[36: 1590/1795] train lossD: -1.586042 lossG: 0.147968\n",
      "[36: 1595/1795] train lossD: -0.270171 lossG: 0.478258\n",
      "[36: 1600/1795] train lossD: -0.990239 lossG: -0.248379\n",
      "[36: 1605/1795] train lossD: -1.202135 lossG: -0.060171\n",
      "[36: 1610/1795] train lossD: 0.011838 lossG: 0.178984\n",
      "[36: 1615/1795] train lossD: 0.048308 lossG: 0.196977\n",
      "[36: 1620/1795] train lossD: 0.016959 lossG: 0.213944\n",
      "[36: 1625/1795] train lossD: 0.050052 lossG: 0.249934\n",
      "[36: 1630/1795] train lossD: 0.056709 lossG: 0.291504\n",
      "[36: 1635/1795] train lossD: 0.003368 lossG: 0.322268\n",
      "[36: 1640/1795] train lossD: 0.011833 lossG: 0.295306\n",
      "[36: 1645/1795] train lossD: 0.138703 lossG: 0.305401\n",
      "[36: 1650/1795] train lossD: -0.020860 lossG: 0.339298\n",
      "[36: 1655/1795] train lossD: 0.028120 lossG: 0.287547\n",
      "[36: 1660/1795] train lossD: -0.077769 lossG: 0.381748\n",
      "[36: 1665/1795] train lossD: -1.117515 lossG: -0.019227\n",
      "[36: 1670/1795] train lossD: -1.875090 lossG: -0.662633\n",
      "[36: 1675/1795] train lossD: 0.052510 lossG: 0.236049\n",
      "[36: 1680/1795] train lossD: 2.384926 lossG: -1.480443\n",
      "[36: 1685/1795] train lossD: 0.199548 lossG: 0.094084\n",
      "[36: 1690/1795] train lossD: 0.176189 lossG: 0.317081\n",
      "[36: 1695/1795] train lossD: -0.615186 lossG: -0.096534\n",
      "[36: 1700/1795] train lossD: 0.695888 lossG: 0.160370\n",
      "[36: 1705/1795] train lossD: 0.457223 lossG: 0.077502\n",
      "[36: 1710/1795] train lossD: 0.171565 lossG: 0.151910\n",
      "[36: 1715/1795] train lossD: -0.085282 lossG: 0.169374\n",
      "[36: 1720/1795] train lossD: -0.019577 lossG: 0.270790\n",
      "[36: 1725/1795] train lossD: 0.310121 lossG: -0.050515\n",
      "[36: 1730/1795] train lossD: -0.078487 lossG: 0.561495\n",
      "[36: 1735/1795] train lossD: 0.173596 lossG: -0.124883\n",
      "[36: 1740/1795] train lossD: -0.870749 lossG: -1.116526\n",
      "[36: 1745/1795] train lossD: -0.136103 lossG: 0.097545\n",
      "[36: 1750/1795] train lossD: -0.267801 lossG: 0.092068\n",
      "[36: 1755/1795] train lossD: 0.181867 lossG: 0.089775\n",
      "[36: 1760/1795] train lossD: -0.019227 lossG: 0.249281\n",
      "[36: 1765/1795] train lossD: -0.168836 lossG: 0.229700\n",
      "[36: 1770/1795] train lossD: -0.670263 lossG: 0.037807\n",
      "[36: 1775/1795] train lossD: -0.294475 lossG: -0.064159\n",
      "[36: 1780/1795] train lossD: -0.084491 lossG: 0.284879\n",
      "[36: 1785/1795] train lossD: -0.687015 lossG: -0.411635\n",
      "[36: 1790/1795] train lossD: -1.323192 lossG: 0.188919\n",
      "0.04320012032985687\n",
      "[37: 0/1795] train lossD: -1.093953 lossG: 0.062467\n",
      "[37: 5/1795] train lossD: -1.213063 lossG: -1.658785\n",
      "[37: 10/1795] train lossD: -0.609767 lossG: 0.174583\n",
      "[37: 15/1795] train lossD: -0.243588 lossG: 0.086898\n",
      "[37: 20/1795] train lossD: -1.641352 lossG: 0.260931\n",
      "[37: 25/1795] train lossD: -0.266099 lossG: 0.291960\n",
      "[37: 30/1795] train lossD: -0.660776 lossG: -0.695494\n",
      "[37: 35/1795] train lossD: -0.729838 lossG: -1.711787\n",
      "[37: 40/1795] train lossD: -0.976521 lossG: -0.167402\n",
      "[37: 45/1795] train lossD: -0.859600 lossG: -0.779552\n",
      "[37: 50/1795] train lossD: -1.394457 lossG: 0.130720\n",
      "[37: 55/1795] train lossD: 2.132801 lossG: -1.372406\n",
      "[37: 60/1795] train lossD: 0.291838 lossG: 0.175759\n",
      "[37: 65/1795] train lossD: -0.280791 lossG: 0.375232\n",
      "[37: 70/1795] train lossD: -0.257390 lossG: 0.485748\n",
      "[37: 75/1795] train lossD: -1.903024 lossG: 0.478574\n",
      "[37: 80/1795] train lossD: -0.321050 lossG: 0.456773\n",
      "[37: 85/1795] train lossD: -0.902846 lossG: 0.185478\n",
      "[37: 90/1795] train lossD: -0.480994 lossG: -0.239064\n",
      "[37: 95/1795] train lossD: -1.037062 lossG: 0.232881\n",
      "[37: 100/1795] train lossD: -0.617431 lossG: -0.223504\n",
      "[37: 105/1795] train lossD: -1.354988 lossG: 0.165291\n",
      "[37: 110/1795] train lossD: -1.001047 lossG: 0.257392\n",
      "[37: 115/1795] train lossD: -0.691062 lossG: 0.067071\n",
      "[37: 120/1795] train lossD: -0.484360 lossG: 0.128548\n",
      "[37: 125/1795] train lossD: -0.649600 lossG: 0.380872\n",
      "[37: 130/1795] train lossD: 0.011453 lossG: 0.168559\n",
      "[37: 135/1795] train lossD: 5.239701 lossG: -0.040435\n",
      "[37: 140/1795] train lossD: 0.120984 lossG: -0.087194\n",
      "[37: 145/1795] train lossD: -0.033579 lossG: -0.013541\n",
      "[37: 150/1795] train lossD: 0.075123 lossG: 0.045188\n",
      "[37: 155/1795] train lossD: -0.082581 lossG: 0.085747\n",
      "[37: 160/1795] train lossD: 0.044361 lossG: 0.062942\n",
      "[37: 165/1795] train lossD: 0.035361 lossG: -0.038499\n",
      "[37: 170/1795] train lossD: -1.181597 lossG: -1.327226\n",
      "[37: 175/1795] train lossD: -1.453157 lossG: -0.349791\n",
      "[37: 180/1795] train lossD: -1.553386 lossG: 0.232874\n",
      "[37: 185/1795] train lossD: -0.420301 lossG: -0.564429\n",
      "[37: 190/1795] train lossD: -1.734142 lossG: -0.143881\n",
      "[37: 195/1795] train lossD: -0.116865 lossG: -0.067501\n",
      "[37: 200/1795] train lossD: -0.539123 lossG: 0.112679\n",
      "[37: 205/1795] train lossD: -1.602305 lossG: 0.112588\n",
      "[37: 210/1795] train lossD: 0.114678 lossG: 0.075257\n",
      "[37: 215/1795] train lossD: -0.059439 lossG: 0.087065\n",
      "[37: 220/1795] train lossD: 0.005782 lossG: 0.053073\n",
      "[37: 225/1795] train lossD: -0.216742 lossG: 0.156463\n",
      "[37: 230/1795] train lossD: -0.946578 lossG: 0.193620\n",
      "[37: 235/1795] train lossD: -0.496172 lossG: -0.799225\n",
      "[37: 240/1795] train lossD: 0.010105 lossG: 0.188166\n",
      "[37: 245/1795] train lossD: 0.058037 lossG: 0.171929\n",
      "[37: 250/1795] train lossD: 0.184442 lossG: 0.267299\n",
      "[37: 255/1795] train lossD: -0.046428 lossG: 0.319968\n",
      "[37: 260/1795] train lossD: 0.014188 lossG: 0.208940\n",
      "[37: 265/1795] train lossD: -0.046533 lossG: 0.199186\n",
      "[37: 270/1795] train lossD: -0.081822 lossG: 0.280581\n",
      "[37: 275/1795] train lossD: -0.052416 lossG: 0.164824\n",
      "[37: 280/1795] train lossD: -0.185809 lossG: 0.089587\n",
      "[37: 285/1795] train lossD: 1.894988 lossG: -1.971348\n",
      "[37: 290/1795] train lossD: 0.302250 lossG: -0.072817\n",
      "[37: 295/1795] train lossD: -0.071897 lossG: 0.019699\n",
      "[37: 300/1795] train lossD: -0.067818 lossG: 0.094671\n",
      "[37: 305/1795] train lossD: -0.221008 lossG: 0.264881\n",
      "[37: 310/1795] train lossD: -0.189640 lossG: -0.607283\n",
      "[37: 315/1795] train lossD: -0.348917 lossG: 0.289251\n",
      "[37: 320/1795] train lossD: 0.698108 lossG: 0.210460\n",
      "[37: 325/1795] train lossD: -0.477094 lossG: 0.102302\n",
      "[37: 330/1795] train lossD: -0.738106 lossG: -0.174799\n",
      "[37: 335/1795] train lossD: -0.612343 lossG: -0.001069\n",
      "[37: 340/1795] train lossD: -1.319446 lossG: -0.763467\n",
      "[37: 345/1795] train lossD: -0.521888 lossG: -0.088486\n",
      "[37: 350/1795] train lossD: 2.407091 lossG: -0.027386\n",
      "[37: 355/1795] train lossD: -0.737715 lossG: 0.037913\n",
      "[37: 360/1795] train lossD: -1.245058 lossG: 0.093733\n",
      "[37: 365/1795] train lossD: 0.314864 lossG: 0.210168\n",
      "[37: 370/1795] train lossD: 0.093399 lossG: 0.321543\n",
      "[37: 375/1795] train lossD: -0.435496 lossG: -1.197819\n",
      "[37: 380/1795] train lossD: -0.055427 lossG: 0.023156\n",
      "[37: 385/1795] train lossD: -1.101247 lossG: -0.259890\n",
      "[37: 390/1795] train lossD: 0.830723 lossG: -0.955846\n",
      "[37: 395/1795] train lossD: 0.525192 lossG: 0.040435\n",
      "[37: 400/1795] train lossD: -0.026285 lossG: 0.112876\n",
      "[37: 405/1795] train lossD: -1.518653 lossG: -0.665695\n",
      "[37: 410/1795] train lossD: 0.030611 lossG: 0.220529\n",
      "[37: 415/1795] train lossD: -0.574948 lossG: 0.375368\n",
      "[37: 420/1795] train lossD: -0.488297 lossG: 0.436292\n",
      "[37: 425/1795] train lossD: 0.804129 lossG: 0.511736\n",
      "[37: 430/1795] train lossD: -0.073355 lossG: 0.399132\n",
      "[37: 435/1795] train lossD: -0.288795 lossG: 0.561203\n",
      "[37: 440/1795] train lossD: -0.214713 lossG: 0.494293\n",
      "[37: 445/1795] train lossD: -0.437512 lossG: 0.463522\n",
      "[37: 450/1795] train lossD: -0.824225 lossG: 0.141286\n",
      "[37: 455/1795] train lossD: -1.646486 lossG: 0.189608\n",
      "[37: 460/1795] train lossD: -1.335624 lossG: -0.024947\n",
      "[37: 465/1795] train lossD: -1.582247 lossG: 0.273187\n",
      "[37: 470/1795] train lossD: -0.196500 lossG: 0.599244\n",
      "[37: 475/1795] train lossD: -0.680939 lossG: 0.288593\n",
      "[37: 480/1795] train lossD: -1.909507 lossG: 0.338595\n",
      "[37: 485/1795] train lossD: -1.811410 lossG: 0.510632\n",
      "[37: 490/1795] train lossD: -0.908353 lossG: -0.519750\n",
      "[37: 495/1795] train lossD: -0.936310 lossG: -0.199654\n",
      "[37: 500/1795] train lossD: -0.382917 lossG: 0.340579\n",
      "[37: 505/1795] train lossD: -0.703980 lossG: 0.407892\n",
      "[37: 510/1795] train lossD: -1.184928 lossG: -0.017262\n",
      "[37: 515/1795] train lossD: -0.532063 lossG: -0.038766\n",
      "[37: 520/1795] train lossD: -1.507332 lossG: -1.127755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37: 525/1795] train lossD: 0.160657 lossG: 0.029187\n",
      "[37: 530/1795] train lossD: 0.082658 lossG: 0.068741\n",
      "[37: 535/1795] train lossD: 0.048285 lossG: 0.046602\n",
      "[37: 540/1795] train lossD: 0.180121 lossG: 0.069125\n",
      "[37: 545/1795] train lossD: 0.074065 lossG: 0.122209\n",
      "[37: 550/1795] train lossD: 0.009826 lossG: 0.181799\n",
      "[37: 555/1795] train lossD: 0.114444 lossG: 0.088038\n",
      "[37: 560/1795] train lossD: 0.128317 lossG: 0.110529\n",
      "[37: 565/1795] train lossD: 0.074963 lossG: 0.067927\n",
      "[37: 570/1795] train lossD: 0.027336 lossG: 0.071736\n",
      "[37: 575/1795] train lossD: -0.537315 lossG: 0.191590\n",
      "[37: 580/1795] train lossD: -0.322979 lossG: 0.160066\n",
      "[37: 585/1795] train lossD: -0.012171 lossG: 0.161899\n",
      "[37: 590/1795] train lossD: -0.460586 lossG: 0.162541\n",
      "[37: 595/1795] train lossD: -1.187544 lossG: -0.007800\n",
      "[37: 600/1795] train lossD: -1.695260 lossG: 0.040130\n",
      "[37: 605/1795] train lossD: -1.344252 lossG: -0.123384\n",
      "[37: 610/1795] train lossD: -0.532630 lossG: -0.308298\n",
      "[37: 615/1795] train lossD: -1.695668 lossG: 0.323585\n",
      "[37: 620/1795] train lossD: -1.129947 lossG: 0.283424\n",
      "[37: 625/1795] train lossD: 0.349183 lossG: -0.097288\n",
      "[37: 630/1795] train lossD: -1.958024 lossG: 0.206848\n",
      "[37: 635/1795] train lossD: 0.007620 lossG: -0.408350\n",
      "[37: 640/1795] train lossD: -0.843145 lossG: -0.305196\n",
      "[37: 645/1795] train lossD: 1.429972 lossG: 0.030447\n",
      "[37: 650/1795] train lossD: -0.993371 lossG: -0.122842\n",
      "[37: 655/1795] train lossD: 0.039119 lossG: 0.100453\n",
      "[37: 660/1795] train lossD: -0.026133 lossG: 0.101996\n",
      "[37: 665/1795] train lossD: -0.227770 lossG: 0.067851\n",
      "[37: 670/1795] train lossD: -1.489009 lossG: -0.066202\n",
      "[37: 675/1795] train lossD: -0.275818 lossG: -0.181544\n",
      "[37: 680/1795] train lossD: -0.796783 lossG: -0.099571\n",
      "[37: 685/1795] train lossD: 0.942541 lossG: -1.742001\n",
      "[37: 690/1795] train lossD: -1.811693 lossG: -0.328695\n",
      "[37: 695/1795] train lossD: 0.026863 lossG: -0.047462\n",
      "[37: 700/1795] train lossD: 0.130106 lossG: -0.068118\n",
      "[37: 705/1795] train lossD: -0.000042 lossG: 0.040135\n",
      "[37: 710/1795] train lossD: 0.154877 lossG: -0.061655\n",
      "[37: 715/1795] train lossD: -1.126755 lossG: 0.188815\n",
      "[37: 720/1795] train lossD: -1.950884 lossG: -0.535159\n",
      "[37: 725/1795] train lossD: -0.009996 lossG: 0.084831\n",
      "[37: 730/1795] train lossD: 104.858803 lossG: 0.156380\n",
      "[37: 735/1795] train lossD: 0.036563 lossG: 0.102768\n",
      "[37: 740/1795] train lossD: -0.042300 lossG: 0.136645\n",
      "[37: 745/1795] train lossD: -0.053161 lossG: 0.251778\n",
      "[37: 750/1795] train lossD: 0.053961 lossG: 0.203484\n",
      "[37: 755/1795] train lossD: -0.006464 lossG: 0.127227\n",
      "[37: 760/1795] train lossD: -0.083284 lossG: 0.190463\n",
      "[37: 765/1795] train lossD: 0.004484 lossG: 0.138814\n",
      "[37: 770/1795] train lossD: -0.023021 lossG: 0.147131\n",
      "[37: 775/1795] train lossD: -0.339196 lossG: 0.064706\n",
      "[37: 780/1795] train lossD: -0.310861 lossG: 0.126629\n",
      "[37: 785/1795] train lossD: -0.946878 lossG: -0.206600\n",
      "[37: 790/1795] train lossD: -0.667657 lossG: -1.314402\n",
      "[37: 795/1795] train lossD: -1.721843 lossG: -0.301638\n",
      "[37: 800/1795] train lossD: -1.140505 lossG: -0.239003\n",
      "[37: 805/1795] train lossD: -1.530735 lossG: 0.051590\n",
      "[37: 810/1795] train lossD: -0.015605 lossG: -0.107935\n",
      "[37: 815/1795] train lossD: -2.034176 lossG: 0.043617\n",
      "[37: 820/1795] train lossD: -1.598032 lossG: -0.241835\n",
      "[37: 825/1795] train lossD: -1.649997 lossG: -0.586285\n",
      "[37: 830/1795] train lossD: -0.060251 lossG: 0.099264\n",
      "[37: 835/1795] train lossD: 0.061776 lossG: 0.102171\n",
      "[37: 840/1795] train lossD: -0.970606 lossG: -1.126485\n",
      "[37: 845/1795] train lossD: -1.479040 lossG: 0.046350\n",
      "[37: 850/1795] train lossD: -1.569431 lossG: -1.208844\n",
      "[37: 855/1795] train lossD: -0.010639 lossG: 0.042274\n",
      "[37: 860/1795] train lossD: 0.008228 lossG: -0.127656\n",
      "[37: 865/1795] train lossD: -1.041137 lossG: -0.270689\n",
      "[37: 870/1795] train lossD: 0.508986 lossG: 0.033642\n",
      "[37: 875/1795] train lossD: -0.875573 lossG: -0.347750\n",
      "[37: 880/1795] train lossD: 0.162559 lossG: -0.075709\n",
      "[37: 885/1795] train lossD: -0.693719 lossG: -0.140863\n",
      "[37: 890/1795] train lossD: -0.477916 lossG: -0.473138\n",
      "[37: 895/1795] train lossD: -1.254175 lossG: 0.069011\n",
      "[37: 900/1795] train lossD: -0.029430 lossG: 0.045984\n",
      "[37: 905/1795] train lossD: -0.927334 lossG: -0.325348\n",
      "[37: 910/1795] train lossD: -0.667407 lossG: 0.425242\n",
      "[37: 915/1795] train lossD: -1.329530 lossG: -1.084065\n",
      "[37: 920/1795] train lossD: -0.540948 lossG: -0.068028\n",
      "[37: 925/1795] train lossD: 0.047042 lossG: 0.457582\n",
      "[37: 930/1795] train lossD: -1.325911 lossG: 0.338103\n",
      "[37: 935/1795] train lossD: -0.801822 lossG: 0.361243\n",
      "[37: 940/1795] train lossD: -0.981036 lossG: 0.131522\n",
      "[37: 945/1795] train lossD: -0.068517 lossG: 0.364910\n",
      "[37: 950/1795] train lossD: -0.515436 lossG: 0.378064\n",
      "[37: 955/1795] train lossD: -1.696011 lossG: 0.426843\n",
      "[37: 960/1795] train lossD: -1.440305 lossG: 0.185643\n",
      "[37: 965/1795] train lossD: -0.681542 lossG: 0.139018\n",
      "[37: 970/1795] train lossD: 0.153406 lossG: -0.200087\n",
      "[37: 975/1795] train lossD: 0.216771 lossG: -0.072664\n",
      "[37: 980/1795] train lossD: 0.189068 lossG: 0.000463\n",
      "[37: 985/1795] train lossD: 0.182939 lossG: -0.043478\n",
      "[37: 990/1795] train lossD: 0.064546 lossG: 0.004512\n",
      "[37: 995/1795] train lossD: -0.874800 lossG: 0.084984\n",
      "[37: 1000/1795] train lossD: -0.878798 lossG: -0.078933\n",
      "[37: 1005/1795] train lossD: -1.248521 lossG: 0.128736\n",
      "[37: 1010/1795] train lossD: -2.027617 lossG: -0.004905\n",
      "[37: 1015/1795] train lossD: -1.472368 lossG: -0.135116\n",
      "[37: 1020/1795] train lossD: -0.131364 lossG: 0.053986\n",
      "[37: 1025/1795] train lossD: -2.361012 lossG: -0.963858\n",
      "[37: 1030/1795] train lossD: -0.736446 lossG: -0.875798\n",
      "[37: 1035/1795] train lossD: -0.381670 lossG: -0.765000\n",
      "[37: 1040/1795] train lossD: -1.950782 lossG: -0.119236\n",
      "[37: 1045/1795] train lossD: -1.094724 lossG: 0.053985\n",
      "[37: 1050/1795] train lossD: 0.354098 lossG: -0.067191\n",
      "[37: 1055/1795] train lossD: 0.215053 lossG: -0.021844\n",
      "[37: 1060/1795] train lossD: 0.127812 lossG: -0.004214\n",
      "[37: 1065/1795] train lossD: 0.113686 lossG: 0.036657\n",
      "[37: 1070/1795] train lossD: 0.009439 lossG: 0.088207\n",
      "[37: 1075/1795] train lossD: 0.110427 lossG: 0.078449\n",
      "[37: 1080/1795] train lossD: 0.033029 lossG: 0.129990\n",
      "[37: 1085/1795] train lossD: 0.005150 lossG: 0.117183\n",
      "[37: 1090/1795] train lossD: 0.000400 lossG: 0.218059\n",
      "[37: 1095/1795] train lossD: -0.015151 lossG: 0.221730\n",
      "[37: 1100/1795] train lossD: 0.042354 lossG: 0.160680\n",
      "[37: 1105/1795] train lossD: -0.012254 lossG: 0.149302\n",
      "[37: 1110/1795] train lossD: 0.010603 lossG: 0.044599\n",
      "[37: 1115/1795] train lossD: -0.605073 lossG: -1.489964\n",
      "[37: 1120/1795] train lossD: -0.616717 lossG: 0.117860\n",
      "[37: 1125/1795] train lossD: 0.273840 lossG: -0.046952\n",
      "[37: 1130/1795] train lossD: 0.096396 lossG: -0.053631\n",
      "[37: 1135/1795] train lossD: 0.283638 lossG: 0.252215\n",
      "[37: 1140/1795] train lossD: 0.039854 lossG: 0.230314\n",
      "[37: 1145/1795] train lossD: -0.027688 lossG: 0.148746\n",
      "[37: 1150/1795] train lossD: 0.302342 lossG: 0.175114\n",
      "[37: 1155/1795] train lossD: -0.198236 lossG: 0.191259\n",
      "[37: 1160/1795] train lossD: 0.037700 lossG: 0.489266\n",
      "[37: 1165/1795] train lossD: -0.223680 lossG: 0.539735\n",
      "[37: 1170/1795] train lossD: -0.024308 lossG: 0.523721\n",
      "[37: 1175/1795] train lossD: -0.099214 lossG: 0.478694\n",
      "[37: 1180/1795] train lossD: -0.946022 lossG: 0.489266\n",
      "[37: 1185/1795] train lossD: -0.648795 lossG: 0.192131\n",
      "[37: 1190/1795] train lossD: -1.508121 lossG: 0.279916\n",
      "[37: 1195/1795] train lossD: -1.186080 lossG: 0.111209\n",
      "[37: 1200/1795] train lossD: -1.338571 lossG: 0.255358\n",
      "[37: 1205/1795] train lossD: 7.843431 lossG: -0.227548\n",
      "[37: 1210/1795] train lossD: -0.052904 lossG: -0.196007\n",
      "[37: 1215/1795] train lossD: -0.060694 lossG: -0.032096\n",
      "[37: 1220/1795] train lossD: -0.351359 lossG: -0.544799\n",
      "[37: 1225/1795] train lossD: 0.485103 lossG: 0.374635\n",
      "[37: 1230/1795] train lossD: -1.945185 lossG: -0.115472\n",
      "[37: 1235/1795] train lossD: -0.498936 lossG: -0.388202\n",
      "[37: 1240/1795] train lossD: -1.044031 lossG: -0.297727\n",
      "[37: 1245/1795] train lossD: -0.385902 lossG: -1.096539\n",
      "[37: 1250/1795] train lossD: 0.544987 lossG: 0.034485\n",
      "[37: 1255/1795] train lossD: -0.624575 lossG: 0.066536\n",
      "[37: 1260/1795] train lossD: -1.154529 lossG: -1.395790\n",
      "[37: 1265/1795] train lossD: -1.269320 lossG: 0.091487\n",
      "[37: 1270/1795] train lossD: -0.717920 lossG: -1.950893\n",
      "[37: 1275/1795] train lossD: -0.020189 lossG: 0.095570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37: 1280/1795] train lossD: -0.400057 lossG: -0.399147\n",
      "[37: 1285/1795] train lossD: 0.083018 lossG: -0.222535\n",
      "[37: 1290/1795] train lossD: -1.663473 lossG: 0.030819\n",
      "[37: 1295/1795] train lossD: -1.619113 lossG: 0.103589\n",
      "[37: 1300/1795] train lossD: -0.753400 lossG: -0.798283\n",
      "[37: 1305/1795] train lossD: -1.160715 lossG: -0.698509\n",
      "[37: 1310/1795] train lossD: -0.642346 lossG: -0.364858\n",
      "[37: 1315/1795] train lossD: -0.330427 lossG: 0.069739\n",
      "[37: 1320/1795] train lossD: -0.827378 lossG: 0.058700\n",
      "[37: 1325/1795] train lossD: -0.789504 lossG: -0.918243\n",
      "[37: 1330/1795] train lossD: -2.548352 lossG: -0.058829\n",
      "[37: 1335/1795] train lossD: -0.091296 lossG: -0.114406\n",
      "[37: 1340/1795] train lossD: -2.154801 lossG: 0.039891\n",
      "[37: 1345/1795] train lossD: -1.337048 lossG: -0.459461\n",
      "[37: 1350/1795] train lossD: -1.313703 lossG: -0.977729\n",
      "[37: 1355/1795] train lossD: -1.860893 lossG: -0.401662\n",
      "[37: 1360/1795] train lossD: -0.315357 lossG: -1.291215\n",
      "[37: 1365/1795] train lossD: -0.145749 lossG: 0.013276\n",
      "[37: 1370/1795] train lossD: -0.566013 lossG: -1.664086\n",
      "[37: 1375/1795] train lossD: -1.605348 lossG: 0.046808\n",
      "[37: 1380/1795] train lossD: 0.713629 lossG: 0.166210\n",
      "[37: 1385/1795] train lossD: -0.265726 lossG: -0.030365\n",
      "[37: 1390/1795] train lossD: -0.603098 lossG: -0.285825\n",
      "[37: 1395/1795] train lossD: -2.056675 lossG: -0.282085\n",
      "[37: 1400/1795] train lossD: -0.982578 lossG: -0.403738\n",
      "[37: 1405/1795] train lossD: -2.607685 lossG: -0.274461\n",
      "[37: 1410/1795] train lossD: -1.296304 lossG: -0.287866\n",
      "[37: 1415/1795] train lossD: -0.130815 lossG: -0.007892\n",
      "[37: 1420/1795] train lossD: 0.604039 lossG: -0.479650\n",
      "[37: 1425/1795] train lossD: -1.187295 lossG: 0.110814\n",
      "[37: 1430/1795] train lossD: -0.828951 lossG: 0.061512\n",
      "[37: 1435/1795] train lossD: 15.675116 lossG: 0.058565\n",
      "[37: 1440/1795] train lossD: 0.143710 lossG: 0.103858\n",
      "[37: 1445/1795] train lossD: -0.035159 lossG: 0.178070\n",
      "[37: 1450/1795] train lossD: -0.206204 lossG: 0.379929\n",
      "[37: 1455/1795] train lossD: -0.697109 lossG: 0.235381\n",
      "[37: 1460/1795] train lossD: -1.530051 lossG: 0.148364\n",
      "[37: 1465/1795] train lossD: -1.065825 lossG: -0.957112\n",
      "[37: 1470/1795] train lossD: -0.298379 lossG: -0.420282\n",
      "[37: 1475/1795] train lossD: -1.472421 lossG: -0.201558\n",
      "[37: 1480/1795] train lossD: -0.365144 lossG: -0.478544\n",
      "[37: 1485/1795] train lossD: -1.205181 lossG: -2.908062\n",
      "[37: 1490/1795] train lossD: -0.550931 lossG: 0.208648\n",
      "[37: 1495/1795] train lossD: -2.618714 lossG: -0.316393\n",
      "[37: 1500/1795] train lossD: -0.533906 lossG: -1.815214\n",
      "[37: 1505/1795] train lossD: -1.542219 lossG: -1.251213\n",
      "[37: 1510/1795] train lossD: -0.311382 lossG: 0.074697\n",
      "[37: 1515/1795] train lossD: -0.089413 lossG: 0.275769\n",
      "[37: 1520/1795] train lossD: -1.638374 lossG: 0.084605\n",
      "[37: 1525/1795] train lossD: 0.765576 lossG: -0.455226\n",
      "[37: 1530/1795] train lossD: -1.943670 lossG: 0.072240\n",
      "[37: 1535/1795] train lossD: 0.244404 lossG: -0.212933\n",
      "[37: 1540/1795] train lossD: 0.225663 lossG: -0.135084\n",
      "[37: 1545/1795] train lossD: 0.079653 lossG: -0.139420\n",
      "[37: 1550/1795] train lossD: 0.153683 lossG: -0.103109\n",
      "[37: 1555/1795] train lossD: 0.092605 lossG: -0.068435\n",
      "[37: 1560/1795] train lossD: -0.010426 lossG: -0.008565\n",
      "[37: 1565/1795] train lossD: 0.158995 lossG: -0.382450\n",
      "[37: 1570/1795] train lossD: -0.026412 lossG: 0.090036\n",
      "[37: 1575/1795] train lossD: 0.075415 lossG: 0.154699\n",
      "[37: 1580/1795] train lossD: -0.284575 lossG: 0.116258\n",
      "[37: 1585/1795] train lossD: -0.960280 lossG: -0.313502\n",
      "[37: 1590/1795] train lossD: -0.651867 lossG: 0.227145\n",
      "[37: 1595/1795] train lossD: -1.111952 lossG: -0.230784\n",
      "[37: 1600/1795] train lossD: -2.455717 lossG: -0.305984\n",
      "[37: 1605/1795] train lossD: -1.325781 lossG: -0.248206\n",
      "[37: 1610/1795] train lossD: -1.453667 lossG: -0.130531\n",
      "[37: 1615/1795] train lossD: 0.028878 lossG: -0.016159\n",
      "[37: 1620/1795] train lossD: -1.667138 lossG: 0.027174\n",
      "[37: 1625/1795] train lossD: -3.076289 lossG: 0.125879\n",
      "[37: 1630/1795] train lossD: -2.357395 lossG: -0.075228\n",
      "[37: 1635/1795] train lossD: 0.155898 lossG: -0.258431\n",
      "[37: 1640/1795] train lossD: -2.458364 lossG: -0.266351\n",
      "[37: 1645/1795] train lossD: -0.837921 lossG: -0.061404\n",
      "[37: 1650/1795] train lossD: -2.709931 lossG: -0.610975\n",
      "[37: 1655/1795] train lossD: -3.359802 lossG: 0.209678\n",
      "[37: 1660/1795] train lossD: 0.005692 lossG: -0.019542\n",
      "[37: 1665/1795] train lossD: -2.157634 lossG: 0.029585\n",
      "[37: 1670/1795] train lossD: 0.383310 lossG: -0.264788\n",
      "[37: 1675/1795] train lossD: 0.105083 lossG: -0.520110\n",
      "[37: 1680/1795] train lossD: -0.798283 lossG: 0.064051\n",
      "[37: 1685/1795] train lossD: 0.054023 lossG: -0.092906\n",
      "[37: 1690/1795] train lossD: -0.285311 lossG: 0.088851\n",
      "[37: 1695/1795] train lossD: -1.591466 lossG: 0.092292\n",
      "[37: 1700/1795] train lossD: 0.461639 lossG: -0.108826\n",
      "[37: 1705/1795] train lossD: -0.166084 lossG: 0.131993\n",
      "[37: 1710/1795] train lossD: -0.010914 lossG: 0.103085\n",
      "[37: 1715/1795] train lossD: -1.291295 lossG: -0.073207\n",
      "[37: 1720/1795] train lossD: -0.258642 lossG: 0.122269\n",
      "[37: 1725/1795] train lossD: -1.136976 lossG: 0.118982\n",
      "[37: 1730/1795] train lossD: -0.978652 lossG: -0.082621\n",
      "[37: 1735/1795] train lossD: -1.292786 lossG: -0.080531\n",
      "[37: 1740/1795] train lossD: -1.540085 lossG: 0.070088\n",
      "[37: 1745/1795] train lossD: -0.935781 lossG: -0.001104\n",
      "[37: 1750/1795] train lossD: -0.466619 lossG: 0.020364\n",
      "[37: 1755/1795] train lossD: -1.889706 lossG: -0.098602\n",
      "[37: 1760/1795] train lossD: -2.303683 lossG: -0.131271\n",
      "[37: 1765/1795] train lossD: -1.784520 lossG: -0.068263\n",
      "[37: 1770/1795] train lossD: -0.848997 lossG: -0.244346\n",
      "[37: 1775/1795] train lossD: 0.471452 lossG: -1.356598\n",
      "[37: 1780/1795] train lossD: -2.153773 lossG: 0.278610\n",
      "[37: 1785/1795] train lossD: -0.899594 lossG: -0.248602\n",
      "[37: 1790/1795] train lossD: -0.146774 lossG: -0.052923\n",
      "0.05068539083003998\n",
      "[38: 0/1795] train lossD: -0.138503 lossG: -0.233046\n",
      "[38: 5/1795] train lossD: -2.597149 lossG: 0.048230\n",
      "[38: 10/1795] train lossD: -1.956761 lossG: -1.398306\n",
      "[38: 15/1795] train lossD: -1.129243 lossG: -0.792791\n",
      "[38: 20/1795] train lossD: 0.064692 lossG: -0.552595\n",
      "[38: 25/1795] train lossD: -1.975209 lossG: -0.820085\n",
      "[38: 30/1795] train lossD: -1.419571 lossG: -1.958114\n",
      "[38: 35/1795] train lossD: -1.175271 lossG: 0.302569\n",
      "[38: 40/1795] train lossD: -1.131409 lossG: 0.217851\n",
      "[38: 45/1795] train lossD: -2.068930 lossG: 0.062081\n",
      "[38: 50/1795] train lossD: -0.096680 lossG: -0.895167\n",
      "[38: 55/1795] train lossD: -0.263733 lossG: -0.159159\n",
      "[38: 60/1795] train lossD: -0.777615 lossG: -0.565423\n",
      "[38: 65/1795] train lossD: -1.949479 lossG: -0.610065\n",
      "[38: 70/1795] train lossD: -0.686480 lossG: -0.218604\n",
      "[38: 75/1795] train lossD: -2.861562 lossG: -0.063161\n",
      "[38: 80/1795] train lossD: -1.398638 lossG: -0.933254\n",
      "[38: 85/1795] train lossD: -2.104970 lossG: -1.837020\n",
      "[38: 90/1795] train lossD: -0.090011 lossG: 0.192467\n",
      "[38: 95/1795] train lossD: 0.273421 lossG: 0.166135\n",
      "[38: 100/1795] train lossD: -1.278418 lossG: 0.233639\n",
      "[38: 105/1795] train lossD: -0.555667 lossG: 0.305973\n",
      "[38: 110/1795] train lossD: -0.542702 lossG: 0.109535\n",
      "[38: 115/1795] train lossD: -1.607724 lossG: 0.266230\n",
      "[38: 120/1795] train lossD: -2.640510 lossG: 0.245639\n",
      "[38: 125/1795] train lossD: -1.442827 lossG: 0.220380\n",
      "[38: 130/1795] train lossD: -1.935780 lossG: -0.451632\n",
      "[38: 135/1795] train lossD: -1.358155 lossG: 0.079580\n",
      "[38: 140/1795] train lossD: -2.147821 lossG: -0.300530\n",
      "[38: 145/1795] train lossD: -1.391359 lossG: -0.609260\n",
      "[38: 150/1795] train lossD: -1.095433 lossG: -0.294323\n",
      "[38: 155/1795] train lossD: -1.903263 lossG: -0.892697\n",
      "[38: 160/1795] train lossD: -2.829818 lossG: 0.082210\n",
      "[38: 165/1795] train lossD: -0.559579 lossG: -0.250141\n",
      "[38: 170/1795] train lossD: -1.060712 lossG: -0.818224\n",
      "[38: 175/1795] train lossD: -3.207630 lossG: 0.029756\n",
      "[38: 180/1795] train lossD: -1.560752 lossG: -0.534107\n",
      "[38: 185/1795] train lossD: -0.033723 lossG: -0.564564\n",
      "[38: 190/1795] train lossD: -1.342725 lossG: 0.267650\n",
      "[38: 195/1795] train lossD: -0.884016 lossG: 0.122086\n",
      "[38: 200/1795] train lossD: -1.789740 lossG: -0.473375\n",
      "[38: 205/1795] train lossD: 0.119080 lossG: -0.075585\n",
      "[38: 210/1795] train lossD: 0.155976 lossG: -0.097164\n",
      "[38: 215/1795] train lossD: -1.245476 lossG: -1.592313\n",
      "[38: 220/1795] train lossD: -1.225380 lossG: -0.128499\n",
      "[38: 225/1795] train lossD: 0.144018 lossG: -0.088639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38: 230/1795] train lossD: -0.037890 lossG: -0.089643\n",
      "[38: 235/1795] train lossD: -0.011309 lossG: 0.007671\n",
      "[38: 240/1795] train lossD: 0.087120 lossG: 0.013606\n",
      "[38: 245/1795] train lossD: 0.007396 lossG: 0.043023\n",
      "[38: 250/1795] train lossD: 0.063871 lossG: 0.064247\n",
      "[38: 255/1795] train lossD: -0.156423 lossG: 0.240442\n",
      "[38: 260/1795] train lossD: -1.405535 lossG: -1.106499\n",
      "[38: 265/1795] train lossD: 0.368732 lossG: 0.044418\n",
      "[38: 270/1795] train lossD: 0.239095 lossG: -2.075015\n",
      "[38: 275/1795] train lossD: 0.204358 lossG: -0.504946\n",
      "[38: 280/1795] train lossD: 0.193471 lossG: -0.596026\n",
      "[38: 285/1795] train lossD: 0.052891 lossG: -0.505955\n",
      "[38: 290/1795] train lossD: -1.354221 lossG: -0.690121\n",
      "[38: 295/1795] train lossD: -1.908196 lossG: -1.265279\n",
      "[38: 300/1795] train lossD: 0.874999 lossG: 0.082350\n",
      "[38: 305/1795] train lossD: -1.511365 lossG: -0.229059\n",
      "[38: 310/1795] train lossD: -0.199047 lossG: -0.156301\n",
      "[38: 315/1795] train lossD: -0.006885 lossG: -0.065165\n",
      "[38: 320/1795] train lossD: -0.559737 lossG: -0.149768\n",
      "[38: 325/1795] train lossD: -2.521675 lossG: -0.407046\n",
      "[38: 330/1795] train lossD: -1.553031 lossG: 0.236734\n",
      "[38: 335/1795] train lossD: -0.876244 lossG: 0.302508\n",
      "[38: 340/1795] train lossD: -1.978029 lossG: 0.292883\n",
      "[38: 345/1795] train lossD: -2.732709 lossG: 0.040631\n",
      "[38: 350/1795] train lossD: -1.599664 lossG: -1.804574\n",
      "[38: 355/1795] train lossD: -0.553079 lossG: 0.461802\n",
      "[38: 360/1795] train lossD: -2.467358 lossG: -1.519246\n",
      "[38: 365/1795] train lossD: -1.952031 lossG: -0.118087\n",
      "[38: 370/1795] train lossD: -2.330064 lossG: -0.256095\n",
      "[38: 375/1795] train lossD: -3.017623 lossG: -0.248047\n",
      "[38: 380/1795] train lossD: -1.243041 lossG: -0.152277\n",
      "[38: 385/1795] train lossD: -0.750687 lossG: -0.427048\n",
      "[38: 390/1795] train lossD: -1.042533 lossG: 0.056804\n",
      "[38: 395/1795] train lossD: -0.694210 lossG: 0.080389\n",
      "[38: 400/1795] train lossD: -0.908229 lossG: -0.534706\n",
      "[38: 405/1795] train lossD: -2.877985 lossG: 0.089946\n",
      "[38: 410/1795] train lossD: -2.903850 lossG: -0.020432\n",
      "[38: 415/1795] train lossD: -0.720205 lossG: -0.463474\n",
      "[38: 420/1795] train lossD: -1.407740 lossG: 0.221596\n",
      "[38: 425/1795] train lossD: -1.986972 lossG: -0.028025\n",
      "[38: 430/1795] train lossD: -0.488918 lossG: -2.757612\n",
      "[38: 435/1795] train lossD: -0.366811 lossG: 0.471284\n",
      "[38: 440/1795] train lossD: -2.465403 lossG: 0.549469\n",
      "[38: 445/1795] train lossD: -1.432024 lossG: 0.459803\n",
      "[38: 450/1795] train lossD: -1.316584 lossG: 0.351247\n",
      "[38: 455/1795] train lossD: -3.184766 lossG: 0.145440\n",
      "[38: 460/1795] train lossD: -3.455777 lossG: 0.171163\n",
      "[38: 465/1795] train lossD: -2.965788 lossG: 0.078526\n",
      "[38: 470/1795] train lossD: 0.291350 lossG: -0.105309\n",
      "[38: 475/1795] train lossD: 0.177099 lossG: -0.036019\n",
      "[38: 480/1795] train lossD: 0.106729 lossG: -0.074729\n",
      "[38: 485/1795] train lossD: 0.043766 lossG: -0.045294\n",
      "[38: 490/1795] train lossD: -0.181969 lossG: -0.080991\n",
      "[38: 495/1795] train lossD: -1.110485 lossG: -0.095435\n",
      "[38: 500/1795] train lossD: -2.386475 lossG: 0.255308\n",
      "[38: 505/1795] train lossD: -0.455407 lossG: 0.081522\n",
      "[38: 510/1795] train lossD: -0.660225 lossG: 0.051426\n",
      "[38: 515/1795] train lossD: -1.342369 lossG: -0.678525\n",
      "[38: 520/1795] train lossD: 6.674466 lossG: -0.232391\n",
      "[38: 525/1795] train lossD: -0.116811 lossG: -0.153247\n",
      "[38: 530/1795] train lossD: 0.085976 lossG: -0.094817\n",
      "[38: 535/1795] train lossD: 0.213526 lossG: 0.050421\n",
      "[38: 540/1795] train lossD: -0.124788 lossG: 0.137138\n",
      "[38: 545/1795] train lossD: -0.474403 lossG: 0.427239\n",
      "[38: 550/1795] train lossD: -3.154840 lossG: 0.034993\n",
      "[38: 555/1795] train lossD: -2.507941 lossG: 0.056061\n",
      "[38: 560/1795] train lossD: -3.388345 lossG: -0.104451\n",
      "[38: 565/1795] train lossD: -2.286138 lossG: 0.230758\n",
      "[38: 570/1795] train lossD: -1.575982 lossG: -0.543750\n",
      "[38: 575/1795] train lossD: -2.533389 lossG: 0.003194\n",
      "[38: 580/1795] train lossD: 0.376308 lossG: -0.165372\n",
      "[38: 585/1795] train lossD: -2.597876 lossG: -0.608547\n",
      "[38: 590/1795] train lossD: -1.062452 lossG: 0.177450\n",
      "[38: 595/1795] train lossD: -0.739700 lossG: -0.378511\n",
      "[38: 600/1795] train lossD: -0.667808 lossG: 0.040867\n",
      "[38: 605/1795] train lossD: 0.516106 lossG: -3.089249\n",
      "[38: 610/1795] train lossD: 0.108592 lossG: 0.122186\n",
      "[38: 615/1795] train lossD: -0.015320 lossG: 0.228896\n",
      "[38: 620/1795] train lossD: 0.070673 lossG: 0.299180\n",
      "[38: 625/1795] train lossD: -0.023337 lossG: 0.375728\n",
      "[38: 630/1795] train lossD: -0.068992 lossG: 0.312999\n",
      "[38: 635/1795] train lossD: 0.064556 lossG: 0.093707\n",
      "[38: 640/1795] train lossD: -0.049492 lossG: -0.018310\n",
      "[38: 645/1795] train lossD: 0.150801 lossG: 0.194705\n",
      "[38: 650/1795] train lossD: 0.002471 lossG: 0.168133\n",
      "[38: 655/1795] train lossD: -0.227890 lossG: 0.196827\n",
      "[38: 660/1795] train lossD: -0.888317 lossG: 0.130711\n",
      "[38: 665/1795] train lossD: -2.041872 lossG: 0.178569\n",
      "[38: 670/1795] train lossD: 5.232450 lossG: -0.444318\n",
      "[38: 675/1795] train lossD: 0.344048 lossG: -0.332176\n",
      "[38: 680/1795] train lossD: 0.210417 lossG: -0.284871\n",
      "[38: 685/1795] train lossD: 0.023031 lossG: -0.255224\n",
      "[38: 690/1795] train lossD: -0.262656 lossG: -0.182926\n",
      "[38: 695/1795] train lossD: -0.008317 lossG: -0.227274\n",
      "[38: 700/1795] train lossD: -0.043878 lossG: -0.304477\n",
      "[38: 705/1795] train lossD: 0.820689 lossG: -0.619689\n",
      "[38: 710/1795] train lossD: -2.026659 lossG: -0.127613\n",
      "[38: 715/1795] train lossD: 0.014840 lossG: 0.097459\n",
      "[38: 720/1795] train lossD: -0.096980 lossG: 0.195779\n",
      "[38: 725/1795] train lossD: 0.059375 lossG: 0.208928\n",
      "[38: 730/1795] train lossD: -0.001418 lossG: 0.202869\n",
      "[38: 735/1795] train lossD: -1.442457 lossG: -0.123103\n",
      "[38: 740/1795] train lossD: -0.990756 lossG: -1.444647\n",
      "[38: 745/1795] train lossD: 0.065591 lossG: -0.221023\n",
      "[38: 750/1795] train lossD: -0.012935 lossG: -0.081241\n",
      "[38: 755/1795] train lossD: 0.103569 lossG: -0.194691\n",
      "[38: 760/1795] train lossD: -0.987837 lossG: -1.228326\n",
      "[38: 765/1795] train lossD: -4.052381 lossG: -0.067133\n",
      "[38: 770/1795] train lossD: -1.857061 lossG: -0.539009\n",
      "[38: 775/1795] train lossD: 0.129983 lossG: -0.136340\n",
      "[38: 780/1795] train lossD: -0.196450 lossG: -0.065119\n",
      "[38: 785/1795] train lossD: -0.204030 lossG: -0.141544\n",
      "[38: 790/1795] train lossD: -1.865739 lossG: -2.372087\n",
      "[38: 795/1795] train lossD: -0.322333 lossG: 0.164250\n",
      "[38: 800/1795] train lossD: 1.891728 lossG: -2.534637\n",
      "[38: 805/1795] train lossD: -2.331253 lossG: -0.068195\n",
      "[38: 810/1795] train lossD: 0.120466 lossG: -0.201327\n",
      "[38: 815/1795] train lossD: -0.926024 lossG: -0.006473\n",
      "[38: 820/1795] train lossD: -1.793039 lossG: 0.101629\n",
      "[38: 825/1795] train lossD: -1.258226 lossG: -0.036100\n",
      "[38: 830/1795] train lossD: -0.896599 lossG: -1.148114\n",
      "[38: 835/1795] train lossD: -2.512588 lossG: -0.018516\n",
      "[38: 840/1795] train lossD: -2.500523 lossG: -0.688165\n",
      "[38: 845/1795] train lossD: -1.266951 lossG: -0.423652\n",
      "[38: 850/1795] train lossD: -1.183256 lossG: -1.060091\n",
      "[38: 855/1795] train lossD: -2.360976 lossG: -2.062420\n",
      "[38: 860/1795] train lossD: 0.081047 lossG: -0.499281\n",
      "[38: 865/1795] train lossD: 0.226107 lossG: -0.413990\n",
      "[38: 870/1795] train lossD: 0.068120 lossG: -0.331589\n",
      "[38: 875/1795] train lossD: -0.709969 lossG: -0.353766\n",
      "[38: 880/1795] train lossD: -1.089286 lossG: -2.068242\n",
      "[38: 885/1795] train lossD: -1.750396 lossG: -0.152775\n",
      "[38: 890/1795] train lossD: -1.578427 lossG: -0.106816\n",
      "[38: 895/1795] train lossD: -0.273272 lossG: -2.445923\n",
      "[38: 900/1795] train lossD: -0.796585 lossG: 0.391146\n",
      "[38: 905/1795] train lossD: -1.787314 lossG: -0.954744\n",
      "[38: 910/1795] train lossD: -2.801817 lossG: -1.083422\n",
      "[38: 915/1795] train lossD: 0.917209 lossG: -0.114220\n",
      "[38: 920/1795] train lossD: -0.042235 lossG: -0.088767\n",
      "[38: 925/1795] train lossD: -2.276561 lossG: -0.633657\n",
      "[38: 930/1795] train lossD: -0.518603 lossG: -0.383723\n",
      "[38: 935/1795] train lossD: -2.888814 lossG: -0.246480\n",
      "[38: 940/1795] train lossD: -2.774019 lossG: -0.910921\n",
      "[38: 945/1795] train lossD: -1.701421 lossG: -1.300419\n",
      "[38: 950/1795] train lossD: -0.271873 lossG: -0.293148\n",
      "[38: 955/1795] train lossD: -2.008936 lossG: -0.907457\n",
      "[38: 960/1795] train lossD: -1.310570 lossG: -1.013969\n",
      "[38: 965/1795] train lossD: -2.553100 lossG: -0.129466\n",
      "[38: 970/1795] train lossD: -0.129314 lossG: -0.439975\n",
      "[38: 975/1795] train lossD: -2.299313 lossG: -0.586568\n",
      "[38: 980/1795] train lossD: -0.332112 lossG: -1.150491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38: 985/1795] train lossD: -4.171470 lossG: -0.384867\n",
      "[38: 990/1795] train lossD: -3.156004 lossG: -1.189877\n",
      "[38: 995/1795] train lossD: 0.201452 lossG: -0.314785\n",
      "[38: 1000/1795] train lossD: 0.131517 lossG: -0.289923\n",
      "[38: 1005/1795] train lossD: 0.271116 lossG: -0.230807\n",
      "[38: 1010/1795] train lossD: 0.085539 lossG: -0.143189\n",
      "[38: 1015/1795] train lossD: 0.034521 lossG: -0.122034\n",
      "[38: 1020/1795] train lossD: 0.011073 lossG: -0.064953\n",
      "[38: 1025/1795] train lossD: 0.227806 lossG: -0.130983\n",
      "[38: 1030/1795] train lossD: 0.204385 lossG: -0.114892\n",
      "[38: 1035/1795] train lossD: 0.097206 lossG: -0.122048\n",
      "[38: 1040/1795] train lossD: -0.194720 lossG: -0.105571\n",
      "[38: 1045/1795] train lossD: -0.041736 lossG: -0.158900\n",
      "[38: 1050/1795] train lossD: -0.179628 lossG: -0.226566\n",
      "[38: 1055/1795] train lossD: 69.062233 lossG: -0.130676\n",
      "[38: 1060/1795] train lossD: -0.167190 lossG: -0.112366\n",
      "[38: 1065/1795] train lossD: -1.243884 lossG: -0.211814\n",
      "[38: 1070/1795] train lossD: -1.345820 lossG: -0.185051\n",
      "[38: 1075/1795] train lossD: 0.057426 lossG: 0.024480\n",
      "[38: 1080/1795] train lossD: -2.864790 lossG: -0.057755\n",
      "[38: 1085/1795] train lossD: -2.947887 lossG: 0.285139\n",
      "[38: 1090/1795] train lossD: -2.699320 lossG: -0.023842\n",
      "[38: 1095/1795] train lossD: -2.434011 lossG: -0.019714\n",
      "[38: 1100/1795] train lossD: -0.899478 lossG: 0.157189\n",
      "[38: 1105/1795] train lossD: -0.402109 lossG: -0.375036\n",
      "[38: 1110/1795] train lossD: -0.368235 lossG: -0.206538\n",
      "[38: 1115/1795] train lossD: -1.677423 lossG: -0.064781\n",
      "[38: 1120/1795] train lossD: 0.704921 lossG: -0.001725\n",
      "[38: 1125/1795] train lossD: -2.738199 lossG: -0.204574\n",
      "[38: 1130/1795] train lossD: -2.523326 lossG: -0.598032\n",
      "[38: 1135/1795] train lossD: -0.974263 lossG: -2.440526\n",
      "[38: 1140/1795] train lossD: -1.687376 lossG: -0.223971\n",
      "[38: 1145/1795] train lossD: -1.599037 lossG: -0.013262\n",
      "[38: 1150/1795] train lossD: -2.283235 lossG: -0.007391\n",
      "[38: 1155/1795] train lossD: -1.596838 lossG: 0.211942\n",
      "[38: 1160/1795] train lossD: -1.807121 lossG: -2.171610\n",
      "[38: 1165/1795] train lossD: -2.403347 lossG: 0.088493\n",
      "[38: 1170/1795] train lossD: -0.027444 lossG: -0.022350\n",
      "[38: 1175/1795] train lossD: -1.133076 lossG: 0.108930\n",
      "[38: 1180/1795] train lossD: -2.238224 lossG: -0.549097\n",
      "[38: 1185/1795] train lossD: -0.616245 lossG: -0.272954\n",
      "[38: 1190/1795] train lossD: 0.183866 lossG: -0.208089\n",
      "[38: 1195/1795] train lossD: 0.020860 lossG: -0.257103\n",
      "[38: 1200/1795] train lossD: -0.093624 lossG: -0.217059\n",
      "[38: 1205/1795] train lossD: -3.546381 lossG: -0.551418\n",
      "[38: 1210/1795] train lossD: -2.089391 lossG: -2.011822\n",
      "[38: 1215/1795] train lossD: -3.440074 lossG: -0.337411\n",
      "[38: 1220/1795] train lossD: -2.472661 lossG: -0.085938\n",
      "[38: 1225/1795] train lossD: -2.777026 lossG: 0.035673\n",
      "[38: 1230/1795] train lossD: 0.269078 lossG: -0.308984\n",
      "[38: 1235/1795] train lossD: 0.181888 lossG: -0.241809\n",
      "[38: 1240/1795] train lossD: 0.341753 lossG: -0.210513\n",
      "[38: 1245/1795] train lossD: -0.570227 lossG: -0.936018\n",
      "[38: 1250/1795] train lossD: 0.042698 lossG: -0.643949\n",
      "[38: 1255/1795] train lossD: -0.076550 lossG: -0.575102\n",
      "[38: 1260/1795] train lossD: -0.988997 lossG: -0.455268\n",
      "[38: 1265/1795] train lossD: 0.438278 lossG: -1.835027\n",
      "[38: 1270/1795] train lossD: 1.102680 lossG: -3.226284\n",
      "[38: 1275/1795] train lossD: -0.227548 lossG: -3.180016\n",
      "[38: 1280/1795] train lossD: -2.170767 lossG: -0.713612\n",
      "[38: 1285/1795] train lossD: -2.376672 lossG: -0.611003\n",
      "[38: 1290/1795] train lossD: -4.580327 lossG: -0.226630\n",
      "[38: 1295/1795] train lossD: -0.704090 lossG: -0.286550\n",
      "[38: 1300/1795] train lossD: 0.022780 lossG: -0.598580\n",
      "[38: 1305/1795] train lossD: -2.595890 lossG: 0.117730\n",
      "[38: 1310/1795] train lossD: 0.189871 lossG: -0.154957\n",
      "[38: 1315/1795] train lossD: 0.168988 lossG: -0.138846\n",
      "[38: 1320/1795] train lossD: 0.098007 lossG: -0.129153\n",
      "[38: 1325/1795] train lossD: 0.152295 lossG: -0.070402\n",
      "[38: 1330/1795] train lossD: -0.224177 lossG: -0.025027\n",
      "[38: 1335/1795] train lossD: 0.140934 lossG: 0.060864\n",
      "[38: 1340/1795] train lossD: 0.100047 lossG: 0.003708\n",
      "[38: 1345/1795] train lossD: 0.084035 lossG: 0.105423\n",
      "[38: 1350/1795] train lossD: 0.007201 lossG: 0.167707\n",
      "[38: 1355/1795] train lossD: 0.282411 lossG: 0.081050\n",
      "[38: 1360/1795] train lossD: 0.038217 lossG: 0.094225\n",
      "[38: 1365/1795] train lossD: -0.139421 lossG: 0.032850\n",
      "[38: 1370/1795] train lossD: 0.024625 lossG: 0.049221\n",
      "[38: 1375/1795] train lossD: -0.032816 lossG: 0.140314\n",
      "[38: 1380/1795] train lossD: -0.042970 lossG: -0.019173\n",
      "[38: 1385/1795] train lossD: -0.698470 lossG: -0.300908\n",
      "[38: 1390/1795] train lossD: -0.174318 lossG: -1.112667\n",
      "[38: 1395/1795] train lossD: 5.092721 lossG: 0.075403\n",
      "[38: 1400/1795] train lossD: 0.142018 lossG: 0.371251\n",
      "[38: 1405/1795] train lossD: -2.035341 lossG: 0.507286\n",
      "[38: 1410/1795] train lossD: -1.746212 lossG: 0.308311\n",
      "[38: 1415/1795] train lossD: -1.970276 lossG: 0.275943\n",
      "[38: 1420/1795] train lossD: -0.100937 lossG: 0.054248\n",
      "[38: 1425/1795] train lossD: -0.334579 lossG: 0.105977\n",
      "[38: 1430/1795] train lossD: 0.357132 lossG: -0.102337\n",
      "[38: 1435/1795] train lossD: -3.586504 lossG: 0.090047\n",
      "[38: 1440/1795] train lossD: -0.985685 lossG: -0.235051\n",
      "[38: 1445/1795] train lossD: -0.815226 lossG: 0.116983\n",
      "[38: 1450/1795] train lossD: -2.613875 lossG: -0.150843\n",
      "[38: 1455/1795] train lossD: -2.991397 lossG: -1.760741\n",
      "[38: 1460/1795] train lossD: -0.609661 lossG: 0.122595\n",
      "[38: 1465/1795] train lossD: 0.049742 lossG: -0.378097\n",
      "[38: 1470/1795] train lossD: -0.057211 lossG: -0.288863\n",
      "[38: 1475/1795] train lossD: 0.480733 lossG: -0.226164\n",
      "[38: 1480/1795] train lossD: -0.244633 lossG: 0.052320\n",
      "[38: 1485/1795] train lossD: -3.294343 lossG: -0.220617\n",
      "[38: 1490/1795] train lossD: 16.026581 lossG: -0.129108\n",
      "[38: 1495/1795] train lossD: -0.268077 lossG: -0.088162\n",
      "[38: 1500/1795] train lossD: -0.011274 lossG: -0.101726\n",
      "[38: 1505/1795] train lossD: 0.083727 lossG: -0.058758\n",
      "[38: 1510/1795] train lossD: 0.004913 lossG: 0.021920\n",
      "[38: 1515/1795] train lossD: -2.023791 lossG: 0.156334\n",
      "[38: 1520/1795] train lossD: -1.396341 lossG: -1.393484\n",
      "[38: 1525/1795] train lossD: -1.603483 lossG: -0.863161\n",
      "[38: 1530/1795] train lossD: -1.988289 lossG: 0.009762\n",
      "[38: 1535/1795] train lossD: -3.936286 lossG: -0.268656\n",
      "[38: 1540/1795] train lossD: -3.565856 lossG: -0.859630\n",
      "[38: 1545/1795] train lossD: -3.013802 lossG: -0.177885\n",
      "[38: 1550/1795] train lossD: 0.930866 lossG: -0.336912\n",
      "[38: 1555/1795] train lossD: -0.023799 lossG: -0.265924\n",
      "[38: 1560/1795] train lossD: -1.093472 lossG: -0.237229\n",
      "[38: 1565/1795] train lossD: -3.185920 lossG: -0.744976\n",
      "[38: 1570/1795] train lossD: -3.885246 lossG: -0.163799\n",
      "[38: 1575/1795] train lossD: -1.934958 lossG: -0.094349\n",
      "[38: 1580/1795] train lossD: -3.536195 lossG: -0.112049\n",
      "[38: 1585/1795] train lossD: -0.523323 lossG: -0.059012\n",
      "[38: 1590/1795] train lossD: -2.246200 lossG: -0.341201\n",
      "[38: 1595/1795] train lossD: -0.552679 lossG: -0.073414\n",
      "[38: 1600/1795] train lossD: -1.132421 lossG: -0.243406\n",
      "[38: 1605/1795] train lossD: -1.391137 lossG: -0.368654\n",
      "[38: 1610/1795] train lossD: -3.363832 lossG: -0.183502\n",
      "[38: 1615/1795] train lossD: -1.180409 lossG: -1.335969\n",
      "[38: 1620/1795] train lossD: -0.042425 lossG: -0.276036\n",
      "[38: 1625/1795] train lossD: -3.172443 lossG: -1.029559\n",
      "[38: 1630/1795] train lossD: -1.540272 lossG: -0.767534\n",
      "[38: 1635/1795] train lossD: -2.716233 lossG: -0.326634\n",
      "[38: 1640/1795] train lossD: -3.198856 lossG: -1.923352\n",
      "[38: 1645/1795] train lossD: 0.049794 lossG: -0.255032\n",
      "[38: 1650/1795] train lossD: 0.026743 lossG: -0.162997\n",
      "[38: 1655/1795] train lossD: -0.084060 lossG: -0.181728\n",
      "[38: 1660/1795] train lossD: -2.758111 lossG: -0.116502\n",
      "[38: 1665/1795] train lossD: -2.332899 lossG: -0.519773\n",
      "[38: 1670/1795] train lossD: -1.736954 lossG: -0.045747\n",
      "[38: 1675/1795] train lossD: -4.523696 lossG: -0.218466\n",
      "[38: 1680/1795] train lossD: -3.226486 lossG: -0.519175\n",
      "[38: 1685/1795] train lossD: -3.211789 lossG: -1.672090\n",
      "[38: 1690/1795] train lossD: -2.925496 lossG: -0.375479\n",
      "[38: 1695/1795] train lossD: 12.700118 lossG: -0.532629\n",
      "[38: 1700/1795] train lossD: -2.663072 lossG: -1.277777\n",
      "[38: 1705/1795] train lossD: -3.376313 lossG: -0.811650\n",
      "[38: 1710/1795] train lossD: -3.959845 lossG: -1.012521\n",
      "[38: 1715/1795] train lossD: -0.689023 lossG: -1.688803\n",
      "[38: 1720/1795] train lossD: -2.732463 lossG: -1.048656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38: 1725/1795] train lossD: -2.806200 lossG: -1.018286\n",
      "[38: 1730/1795] train lossD: -2.537774 lossG: -0.157397\n",
      "[38: 1735/1795] train lossD: 1662.068481 lossG: -0.220517\n",
      "[38: 1740/1795] train lossD: 0.056082 lossG: -0.298367\n",
      "[38: 1745/1795] train lossD: 0.017895 lossG: -0.267275\n",
      "[38: 1750/1795] train lossD: 0.177554 lossG: -0.262192\n",
      "[38: 1755/1795] train lossD: -0.453121 lossG: -0.246056\n",
      "[38: 1760/1795] train lossD: -0.373889 lossG: -0.249420\n",
      "[38: 1765/1795] train lossD: 0.295679 lossG: -0.220449\n",
      "[38: 1770/1795] train lossD: 0.129634 lossG: -0.234887\n",
      "[38: 1775/1795] train lossD: 0.035619 lossG: -0.236790\n",
      "[38: 1780/1795] train lossD: 0.012978 lossG: -0.227303\n",
      "[38: 1785/1795] train lossD: 0.392684 lossG: -0.265077\n",
      "[38: 1790/1795] train lossD: 0.118506 lossG: -0.220596\n",
      "0.036171235144138336\n",
      "[39: 0/1795] train lossD: 0.179193 lossG: -0.213773\n",
      "[39: 5/1795] train lossD: 0.291939 lossG: -0.306243\n",
      "[39: 10/1795] train lossD: 0.032552 lossG: -0.222349\n",
      "[39: 15/1795] train lossD: 0.064712 lossG: -0.080222\n",
      "[39: 20/1795] train lossD: 0.065745 lossG: -0.090490\n",
      "[39: 25/1795] train lossD: 0.167882 lossG: -0.197245\n",
      "[39: 30/1795] train lossD: -0.413659 lossG: -0.145660\n",
      "[39: 35/1795] train lossD: -2.553641 lossG: -0.472924\n",
      "[39: 40/1795] train lossD: -2.886600 lossG: -0.041520\n",
      "[39: 45/1795] train lossD: -3.401583 lossG: -0.267749\n",
      "[39: 50/1795] train lossD: -4.382215 lossG: -0.301359\n",
      "[39: 55/1795] train lossD: -3.320001 lossG: -2.138342\n",
      "[39: 60/1795] train lossD: 0.397332 lossG: -0.458792\n",
      "[39: 65/1795] train lossD: 0.046880 lossG: -0.408142\n",
      "[39: 70/1795] train lossD: -0.296248 lossG: -0.350445\n",
      "[39: 75/1795] train lossD: -0.098192 lossG: -0.231840\n",
      "[39: 80/1795] train lossD: -0.178789 lossG: -0.136513\n",
      "[39: 85/1795] train lossD: -3.375566 lossG: -0.151671\n",
      "[39: 90/1795] train lossD: -3.973794 lossG: -0.263037\n",
      "[39: 95/1795] train lossD: -1.778253 lossG: -1.038729\n",
      "[39: 100/1795] train lossD: -2.373543 lossG: -3.973314\n",
      "[39: 105/1795] train lossD: 15.133123 lossG: -0.094927\n",
      "[39: 110/1795] train lossD: -0.122140 lossG: 0.027508\n",
      "[39: 115/1795] train lossD: -0.201960 lossG: -0.519302\n",
      "[39: 120/1795] train lossD: -4.316777 lossG: -0.214068\n",
      "[39: 125/1795] train lossD: -2.401623 lossG: -0.786012\n",
      "[39: 130/1795] train lossD: -2.818755 lossG: -0.074852\n",
      "[39: 135/1795] train lossD: -3.950234 lossG: -2.021181\n",
      "[39: 140/1795] train lossD: -2.168840 lossG: -1.158568\n",
      "[39: 145/1795] train lossD: -1.991459 lossG: 0.077401\n",
      "[39: 150/1795] train lossD: -1.367242 lossG: -0.260707\n",
      "[39: 155/1795] train lossD: -4.061237 lossG: -0.819987\n",
      "[39: 160/1795] train lossD: -3.726968 lossG: -0.050747\n",
      "[39: 165/1795] train lossD: -0.531907 lossG: -0.080089\n",
      "[39: 170/1795] train lossD: -3.550267 lossG: -0.284768\n",
      "[39: 175/1795] train lossD: -3.341963 lossG: -0.918697\n",
      "[39: 180/1795] train lossD: -1.840982 lossG: -0.622312\n",
      "[39: 185/1795] train lossD: -3.412662 lossG: -2.739933\n",
      "[39: 190/1795] train lossD: -2.629485 lossG: 0.117230\n",
      "[39: 195/1795] train lossD: -3.863132 lossG: -0.006778\n",
      "[39: 200/1795] train lossD: -4.027115 lossG: -0.340694\n",
      "[39: 205/1795] train lossD: -1.038558 lossG: -0.166738\n",
      "[39: 210/1795] train lossD: -3.077693 lossG: -0.301289\n",
      "[39: 215/1795] train lossD: -3.604213 lossG: -0.113018\n",
      "[39: 220/1795] train lossD: -3.424373 lossG: -1.829110\n",
      "[39: 225/1795] train lossD: -2.808493 lossG: -0.091060\n",
      "[39: 230/1795] train lossD: -4.141948 lossG: -0.625241\n",
      "[39: 235/1795] train lossD: 0.186119 lossG: -0.621165\n",
      "[39: 240/1795] train lossD: 0.141045 lossG: -0.589952\n",
      "[39: 245/1795] train lossD: 0.060017 lossG: -0.568276\n",
      "[39: 250/1795] train lossD: 0.222480 lossG: -0.538887\n",
      "[39: 255/1795] train lossD: 0.051354 lossG: -0.395127\n",
      "[39: 260/1795] train lossD: 0.090403 lossG: -0.265157\n",
      "[39: 265/1795] train lossD: 0.008004 lossG: -0.357938\n",
      "[39: 270/1795] train lossD: -0.271748 lossG: -0.026413\n",
      "[39: 275/1795] train lossD: -0.970080 lossG: -5.635014\n",
      "[39: 280/1795] train lossD: -4.572748 lossG: -0.266437\n",
      "[39: 285/1795] train lossD: -2.729022 lossG: -0.801976\n",
      "[39: 290/1795] train lossD: -4.451221 lossG: -0.770018\n",
      "[39: 295/1795] train lossD: -5.204987 lossG: -0.762102\n",
      "[39: 300/1795] train lossD: -5.079715 lossG: -0.245256\n",
      "[39: 305/1795] train lossD: -3.624185 lossG: -1.742422\n",
      "[39: 310/1795] train lossD: -0.806649 lossG: -0.159915\n",
      "[39: 315/1795] train lossD: 1.327306 lossG: -0.074469\n",
      "[39: 320/1795] train lossD: -4.155053 lossG: -0.110732\n",
      "[39: 325/1795] train lossD: -3.094921 lossG: -0.548098\n",
      "[39: 330/1795] train lossD: -1.723190 lossG: -0.961661\n",
      "[39: 335/1795] train lossD: 1.419541 lossG: -0.208887\n",
      "[39: 340/1795] train lossD: -3.736627 lossG: 0.018387\n",
      "[39: 345/1795] train lossD: 0.101674 lossG: -0.233469\n",
      "[39: 350/1795] train lossD: 0.119839 lossG: -0.235606\n",
      "[39: 355/1795] train lossD: 0.089390 lossG: -0.272546\n",
      "[39: 360/1795] train lossD: 0.071218 lossG: -0.270363\n",
      "[39: 365/1795] train lossD: 0.124537 lossG: -0.323232\n",
      "[39: 370/1795] train lossD: -0.076890 lossG: -0.329631\n",
      "[39: 375/1795] train lossD: -0.660159 lossG: -1.071010\n",
      "[39: 380/1795] train lossD: -4.336387 lossG: -0.538746\n",
      "[39: 385/1795] train lossD: -1.816596 lossG: -0.903075\n",
      "[39: 390/1795] train lossD: -3.981544 lossG: -2.308350\n",
      "[39: 395/1795] train lossD: -0.189830 lossG: -0.067901\n",
      "[39: 400/1795] train lossD: -2.694985 lossG: -0.477861\n",
      "[39: 405/1795] train lossD: -4.669168 lossG: -0.316077\n",
      "[39: 410/1795] train lossD: -1.803572 lossG: -1.672725\n",
      "[39: 415/1795] train lossD: -3.044736 lossG: 0.131095\n",
      "[39: 420/1795] train lossD: 0.018938 lossG: 0.041653\n",
      "[39: 425/1795] train lossD: -3.134754 lossG: -0.187432\n",
      "[39: 430/1795] train lossD: 0.240537 lossG: -0.281531\n",
      "[39: 435/1795] train lossD: 0.026828 lossG: -0.084510\n",
      "[39: 440/1795] train lossD: -1.165724 lossG: -0.411910\n",
      "[39: 445/1795] train lossD: -3.398092 lossG: -0.595389\n",
      "[39: 450/1795] train lossD: -2.902837 lossG: -0.333201\n",
      "[39: 455/1795] train lossD: -0.747248 lossG: -0.862722\n",
      "[39: 460/1795] train lossD: -2.148299 lossG: -1.302529\n",
      "[39: 465/1795] train lossD: -5.868030 lossG: 0.004235\n",
      "[39: 470/1795] train lossD: -3.975992 lossG: -0.209195\n",
      "[39: 475/1795] train lossD: 0.081227 lossG: 0.081200\n",
      "[39: 480/1795] train lossD: -0.852911 lossG: 0.026895\n",
      "[39: 485/1795] train lossD: -2.820316 lossG: 0.112401\n",
      "[39: 490/1795] train lossD: -2.573437 lossG: 0.072670\n",
      "[39: 495/1795] train lossD: -3.181074 lossG: -0.005264\n",
      "[39: 500/1795] train lossD: 0.074762 lossG: -0.696094\n",
      "[39: 505/1795] train lossD: 0.062611 lossG: -0.514674\n",
      "[39: 510/1795] train lossD: 0.130668 lossG: -0.566638\n",
      "[39: 515/1795] train lossD: 0.035592 lossG: -0.404987\n",
      "[39: 520/1795] train lossD: 0.181863 lossG: -0.685489\n",
      "[39: 525/1795] train lossD: -4.194689 lossG: -0.367563\n",
      "[39: 530/1795] train lossD: -2.170210 lossG: -0.301795\n",
      "[39: 535/1795] train lossD: 0.222250 lossG: -1.134458\n",
      "[39: 540/1795] train lossD: -4.894412 lossG: -0.171860\n",
      "[39: 545/1795] train lossD: 0.242603 lossG: -0.352597\n",
      "[39: 550/1795] train lossD: -4.243992 lossG: -0.231950\n",
      "[39: 555/1795] train lossD: -4.544658 lossG: -0.425805\n",
      "[39: 560/1795] train lossD: 0.376380 lossG: -4.090597\n",
      "[39: 565/1795] train lossD: -2.596848 lossG: -0.098006\n",
      "[39: 570/1795] train lossD: -4.142144 lossG: -0.245685\n",
      "[39: 575/1795] train lossD: -4.744555 lossG: -3.287112\n",
      "[39: 580/1795] train lossD: -0.444398 lossG: -0.085710\n",
      "[39: 585/1795] train lossD: -4.603877 lossG: -0.212186\n",
      "[39: 590/1795] train lossD: -1.588928 lossG: -1.385494\n",
      "[39: 595/1795] train lossD: -3.772381 lossG: -0.261549\n",
      "[39: 600/1795] train lossD: -3.876377 lossG: -0.041628\n",
      "[39: 605/1795] train lossD: -4.143467 lossG: 0.103755\n",
      "[39: 610/1795] train lossD: 0.125889 lossG: -0.022204\n",
      "[39: 615/1795] train lossD: -0.510309 lossG: 0.036789\n",
      "[39: 620/1795] train lossD: -1.322575 lossG: -0.772525\n",
      "[39: 625/1795] train lossD: -1.136975 lossG: -0.278626\n",
      "[39: 630/1795] train lossD: -3.707804 lossG: -0.460837\n",
      "[39: 635/1795] train lossD: -1.123346 lossG: -0.853055\n",
      "[39: 640/1795] train lossD: -4.971545 lossG: -0.012849\n",
      "[39: 645/1795] train lossD: -1.826048 lossG: 0.067652\n",
      "[39: 650/1795] train lossD: -3.694413 lossG: -0.812008\n",
      "[39: 655/1795] train lossD: -5.468312 lossG: -0.336232\n",
      "[39: 660/1795] train lossD: -5.502741 lossG: -1.560090\n",
      "[39: 665/1795] train lossD: -3.444594 lossG: -0.387378\n",
      "[39: 670/1795] train lossD: 0.826728 lossG: -0.246212\n",
      "[39: 675/1795] train lossD: -5.560188 lossG: -0.346785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39: 680/1795] train lossD: -4.108419 lossG: -1.003076\n",
      "[39: 685/1795] train lossD: -6.377517 lossG: 0.028495\n",
      "[39: 690/1795] train lossD: 0.149702 lossG: -0.446987\n",
      "[39: 695/1795] train lossD: 0.162025 lossG: -0.282551\n",
      "[39: 700/1795] train lossD: -0.069486 lossG: -0.285462\n",
      "[39: 705/1795] train lossD: -0.899304 lossG: -0.246603\n",
      "[39: 710/1795] train lossD: -3.143528 lossG: -0.708503\n",
      "[39: 715/1795] train lossD: -2.685865 lossG: -2.223185\n",
      "[39: 720/1795] train lossD: -4.906788 lossG: -0.116703\n",
      "[39: 725/1795] train lossD: -0.471645 lossG: -0.332836\n",
      "[39: 730/1795] train lossD: -3.705525 lossG: -0.297792\n",
      "[39: 735/1795] train lossD: -1.738905 lossG: -0.969556\n",
      "[39: 740/1795] train lossD: -5.900486 lossG: -0.542652\n",
      "[39: 745/1795] train lossD: -5.773779 lossG: -0.708774\n",
      "[39: 750/1795] train lossD: -2.640245 lossG: -0.196195\n",
      "[39: 755/1795] train lossD: -3.864635 lossG: -1.077354\n",
      "[39: 760/1795] train lossD: -4.692628 lossG: -0.097824\n",
      "[39: 765/1795] train lossD: -2.068612 lossG: -1.341447\n",
      "[39: 770/1795] train lossD: -4.208149 lossG: -0.270819\n",
      "[39: 775/1795] train lossD: -6.553349 lossG: -0.288835\n",
      "[39: 780/1795] train lossD: -4.537233 lossG: -0.139477\n",
      "[39: 785/1795] train lossD: 3.782249 lossG: -0.497147\n",
      "[39: 790/1795] train lossD: -0.342430 lossG: -0.402000\n",
      "[39: 795/1795] train lossD: -2.730983 lossG: -1.478836\n",
      "[39: 800/1795] train lossD: 0.942157 lossG: -0.351809\n",
      "[39: 805/1795] train lossD: 0.402198 lossG: -0.471439\n",
      "[39: 810/1795] train lossD: -0.301657 lossG: -0.377620\n",
      "[39: 815/1795] train lossD: -0.124340 lossG: -0.400002\n",
      "[39: 820/1795] train lossD: -0.082142 lossG: -0.427126\n",
      "[39: 825/1795] train lossD: -1.551845 lossG: -0.530113\n",
      "[39: 830/1795] train lossD: 0.329293 lossG: -0.452247\n",
      "[39: 835/1795] train lossD: -2.738832 lossG: -0.466870\n",
      "[39: 840/1795] train lossD: -3.385593 lossG: -0.491002\n",
      "[39: 845/1795] train lossD: -4.225493 lossG: -0.389966\n",
      "[39: 850/1795] train lossD: -1.159119 lossG: -0.548290\n",
      "[39: 855/1795] train lossD: -4.527046 lossG: -0.570352\n",
      "[39: 860/1795] train lossD: -0.347912 lossG: -0.589749\n",
      "[39: 865/1795] train lossD: -2.714412 lossG: -0.756792\n",
      "[39: 870/1795] train lossD: -3.605486 lossG: -0.634297\n",
      "[39: 875/1795] train lossD: -5.139748 lossG: -0.514033\n",
      "[39: 880/1795] train lossD: -5.367949 lossG: -0.300098\n",
      "[39: 885/1795] train lossD: -1.986652 lossG: -0.273052\n",
      "[39: 890/1795] train lossD: -4.644899 lossG: -0.400923\n",
      "[39: 895/1795] train lossD: -2.754620 lossG: -0.244817\n",
      "[39: 900/1795] train lossD: -3.931480 lossG: -0.265349\n",
      "[39: 905/1795] train lossD: -6.734734 lossG: -0.389755\n",
      "[39: 910/1795] train lossD: -5.136816 lossG: -0.185640\n",
      "[39: 915/1795] train lossD: -3.584741 lossG: -2.086342\n",
      "[39: 920/1795] train lossD: -3.757330 lossG: -0.086704\n",
      "[39: 925/1795] train lossD: -1.720369 lossG: -0.513394\n",
      "[39: 930/1795] train lossD: -1.478083 lossG: -1.287024\n",
      "[39: 935/1795] train lossD: -2.337744 lossG: -0.507714\n",
      "[39: 940/1795] train lossD: -6.051218 lossG: 0.030390\n",
      "[39: 945/1795] train lossD: -3.881132 lossG: -0.218547\n",
      "[39: 950/1795] train lossD: -0.645566 lossG: -0.758474\n",
      "[39: 955/1795] train lossD: -3.606324 lossG: -1.302148\n",
      "[39: 960/1795] train lossD: -2.487942 lossG: -0.233319\n",
      "[39: 965/1795] train lossD: -0.111508 lossG: 0.020988\n",
      "[39: 970/1795] train lossD: -0.305186 lossG: -0.061997\n",
      "[39: 975/1795] train lossD: -0.042587 lossG: 0.063070\n",
      "[39: 980/1795] train lossD: -0.479517 lossG: 0.019061\n",
      "[39: 985/1795] train lossD: -0.716516 lossG: 0.027057\n",
      "[39: 990/1795] train lossD: -0.958099 lossG: -0.000928\n",
      "[39: 995/1795] train lossD: 0.068139 lossG: 0.029050\n",
      "[39: 1000/1795] train lossD: 0.129891 lossG: -0.013502\n",
      "[39: 1005/1795] train lossD: -0.189762 lossG: -0.116789\n",
      "[39: 1010/1795] train lossD: -1.936440 lossG: -0.022907\n",
      "[39: 1015/1795] train lossD: -2.159933 lossG: -0.017781\n",
      "[39: 1020/1795] train lossD: -1.467432 lossG: -0.124641\n",
      "[39: 1025/1795] train lossD: -1.165291 lossG: -0.339770\n",
      "[39: 1030/1795] train lossD: -5.982215 lossG: -0.116841\n",
      "[39: 1035/1795] train lossD: -5.888526 lossG: -0.460350\n",
      "[39: 1040/1795] train lossD: -7.482388 lossG: -0.315590\n",
      "[39: 1045/1795] train lossD: -2.130391 lossG: -1.455431\n",
      "[39: 1050/1795] train lossD: -5.097380 lossG: -1.964170\n",
      "[39: 1055/1795] train lossD: -4.343959 lossG: -0.400973\n",
      "[39: 1060/1795] train lossD: -4.816331 lossG: -0.037629\n",
      "[39: 1065/1795] train lossD: 1.217443 lossG: -0.253041\n",
      "[39: 1070/1795] train lossD: -3.017314 lossG: -0.071072\n",
      "[39: 1075/1795] train lossD: -6.003852 lossG: -0.174001\n",
      "[39: 1080/1795] train lossD: -0.603936 lossG: -0.261557\n",
      "[39: 1085/1795] train lossD: -2.763358 lossG: -5.134375\n",
      "[39: 1090/1795] train lossD: -0.038171 lossG: -0.548516\n",
      "[39: 1095/1795] train lossD: 0.072406 lossG: -0.504303\n",
      "[39: 1100/1795] train lossD: -1.082189 lossG: -1.220459\n",
      "[39: 1105/1795] train lossD: -2.438795 lossG: -1.823106\n",
      "[39: 1110/1795] train lossD: -1.120075 lossG: -0.589044\n",
      "[39: 1115/1795] train lossD: -5.565170 lossG: -0.205898\n",
      "[39: 1120/1795] train lossD: -2.788318 lossG: -0.453114\n",
      "[39: 1125/1795] train lossD: -4.669738 lossG: -0.345834\n",
      "[39: 1130/1795] train lossD: -5.785915 lossG: -0.211273\n",
      "[39: 1135/1795] train lossD: -2.760990 lossG: -0.306076\n",
      "[39: 1140/1795] train lossD: -2.898281 lossG: -0.589221\n",
      "[39: 1145/1795] train lossD: -5.666343 lossG: -1.849063\n",
      "[39: 1150/1795] train lossD: -3.748556 lossG: -2.510656\n",
      "[39: 1155/1795] train lossD: 0.058096 lossG: -0.755790\n",
      "[39: 1160/1795] train lossD: -1.869958 lossG: -0.658335\n",
      "[39: 1165/1795] train lossD: -0.522973 lossG: -0.623927\n",
      "[39: 1170/1795] train lossD: -3.437200 lossG: -0.775743\n",
      "[39: 1175/1795] train lossD: -1.530547 lossG: -0.757377\n",
      "[39: 1180/1795] train lossD: -5.043003 lossG: -1.903082\n",
      "[39: 1185/1795] train lossD: -5.308777 lossG: -0.993345\n",
      "[39: 1190/1795] train lossD: -4.152738 lossG: -2.012046\n",
      "[39: 1195/1795] train lossD: -6.926968 lossG: -0.191722\n",
      "[39: 1200/1795] train lossD: -6.214021 lossG: -0.364517\n",
      "[39: 1205/1795] train lossD: -6.518029 lossG: -1.467747\n",
      "[39: 1210/1795] train lossD: -5.899336 lossG: -1.124099\n",
      "[39: 1215/1795] train lossD: -0.835799 lossG: -0.702323\n",
      "[39: 1220/1795] train lossD: -2.447718 lossG: -0.408174\n",
      "[39: 1225/1795] train lossD: -6.942465 lossG: -0.376239\n",
      "[39: 1230/1795] train lossD: -3.190365 lossG: -0.339821\n",
      "[39: 1235/1795] train lossD: -5.038584 lossG: -0.610546\n",
      "[39: 1240/1795] train lossD: -3.808332 lossG: -5.105108\n",
      "[39: 1245/1795] train lossD: -2.831921 lossG: -0.871845\n",
      "[39: 1250/1795] train lossD: -4.871526 lossG: -2.212796\n",
      "[39: 1255/1795] train lossD: -1.191605 lossG: -0.119276\n",
      "[39: 1260/1795] train lossD: -5.315383 lossG: -0.412213\n",
      "[39: 1265/1795] train lossD: -7.160644 lossG: -0.589283\n",
      "[39: 1270/1795] train lossD: -5.260317 lossG: -3.388953\n",
      "[39: 1275/1795] train lossD: -8.828599 lossG: -0.756653\n",
      "[39: 1280/1795] train lossD: -4.237881 lossG: -2.706877\n",
      "[39: 1285/1795] train lossD: -6.949828 lossG: -1.200422\n",
      "[39: 1290/1795] train lossD: -0.418478 lossG: -0.329924\n",
      "[39: 1295/1795] train lossD: 26.666874 lossG: -0.058194\n",
      "[39: 1300/1795] train lossD: -3.147112 lossG: 0.232744\n",
      "[39: 1305/1795] train lossD: -8.035006 lossG: -0.025028\n",
      "[39: 1310/1795] train lossD: -8.288507 lossG: -0.925817\n",
      "[39: 1315/1795] train lossD: -6.499364 lossG: -0.427885\n",
      "[39: 1320/1795] train lossD: -5.202260 lossG: -6.335284\n",
      "[39: 1325/1795] train lossD: -3.600051 lossG: -1.238261\n",
      "[39: 1330/1795] train lossD: 0.340534 lossG: -0.575451\n",
      "[39: 1335/1795] train lossD: 0.441015 lossG: -0.514404\n",
      "[39: 1340/1795] train lossD: 1.140849 lossG: -0.255929\n",
      "[39: 1345/1795] train lossD: -1.389065 lossG: -0.811638\n",
      "[39: 1350/1795] train lossD: -3.404906 lossG: -1.169825\n",
      "[39: 1355/1795] train lossD: -0.458475 lossG: -0.357953\n",
      "[39: 1360/1795] train lossD: -3.404193 lossG: -0.425460\n",
      "[39: 1365/1795] train lossD: 0.440777 lossG: -0.644752\n",
      "[39: 1370/1795] train lossD: -7.230100 lossG: -0.536597\n",
      "[39: 1375/1795] train lossD: 1.218143 lossG: -1.561058\n",
      "[39: 1380/1795] train lossD: -5.442505 lossG: -0.576659\n",
      "[39: 1385/1795] train lossD: -4.171184 lossG: -0.109907\n",
      "[39: 1390/1795] train lossD: -6.122930 lossG: -1.005208\n",
      "[39: 1395/1795] train lossD: -2.525413 lossG: -0.649450\n",
      "[39: 1400/1795] train lossD: -4.723500 lossG: -0.199449\n",
      "[39: 1405/1795] train lossD: -5.177711 lossG: -4.700173\n",
      "[39: 1410/1795] train lossD: -4.786536 lossG: -1.421273\n",
      "[39: 1415/1795] train lossD: -0.318448 lossG: -0.193880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39: 1420/1795] train lossD: -3.964623 lossG: -0.130455\n",
      "[39: 1425/1795] train lossD: 0.117460 lossG: -0.212944\n",
      "[39: 1430/1795] train lossD: 0.002792 lossG: -0.161222\n",
      "[39: 1435/1795] train lossD: -0.084504 lossG: -0.134999\n",
      "[39: 1440/1795] train lossD: 0.073458 lossG: -0.142915\n",
      "[39: 1445/1795] train lossD: -0.018950 lossG: -0.142787\n",
      "[39: 1450/1795] train lossD: -0.261965 lossG: -0.147242\n",
      "[39: 1455/1795] train lossD: -0.185123 lossG: -0.203382\n",
      "[39: 1460/1795] train lossD: 0.239345 lossG: -0.348871\n",
      "[39: 1465/1795] train lossD: 1.229861 lossG: -0.519055\n",
      "[39: 1470/1795] train lossD: 1.032183 lossG: -0.674683\n",
      "[39: 1475/1795] train lossD: -0.294048 lossG: -0.590278\n",
      "[39: 1480/1795] train lossD: 0.224363 lossG: -0.535990\n",
      "[39: 1485/1795] train lossD: 0.025119 lossG: -0.360621\n",
      "[39: 1490/1795] train lossD: -0.971395 lossG: -0.078631\n",
      "[39: 1495/1795] train lossD: -6.523236 lossG: -0.407102\n",
      "[39: 1500/1795] train lossD: -5.217040 lossG: -0.170955\n",
      "[39: 1505/1795] train lossD: -3.642585 lossG: -3.086711\n",
      "[39: 1510/1795] train lossD: -8.632356 lossG: -0.604961\n",
      "[39: 1515/1795] train lossD: -3.091038 lossG: -4.334658\n",
      "[39: 1520/1795] train lossD: -0.339723 lossG: -0.869020\n",
      "[39: 1525/1795] train lossD: -6.791159 lossG: -0.199759\n",
      "[39: 1530/1795] train lossD: -3.811962 lossG: -0.566894\n",
      "[39: 1535/1795] train lossD: -3.962586 lossG: -3.311255\n",
      "[39: 1540/1795] train lossD: -0.584918 lossG: -0.356030\n",
      "[39: 1545/1795] train lossD: -5.516580 lossG: -1.072527\n",
      "[39: 1550/1795] train lossD: -4.646879 lossG: -0.524778\n",
      "[39: 1555/1795] train lossD: -6.936292 lossG: -0.334994\n",
      "[39: 1560/1795] train lossD: -7.169600 lossG: -0.463078\n",
      "[39: 1565/1795] train lossD: 0.643349 lossG: -0.395695\n",
      "[39: 1570/1795] train lossD: 0.105701 lossG: -0.307842\n",
      "[39: 1575/1795] train lossD: 0.096742 lossG: -0.277481\n",
      "[39: 1580/1795] train lossD: 0.183100 lossG: -0.203200\n",
      "[39: 1585/1795] train lossD: 0.223652 lossG: -0.176607\n",
      "[39: 1590/1795] train lossD: 0.331387 lossG: -0.299040\n",
      "[39: 1595/1795] train lossD: 0.763199 lossG: -0.847435\n",
      "[39: 1600/1795] train lossD: 1.614240 lossG: -0.794329\n",
      "[39: 1605/1795] train lossD: 0.978632 lossG: -0.733425\n",
      "[39: 1610/1795] train lossD: 0.790532 lossG: -0.661621\n",
      "[39: 1615/1795] train lossD: 0.699074 lossG: -0.667830\n",
      "[39: 1620/1795] train lossD: 0.666742 lossG: -0.641817\n",
      "[39: 1625/1795] train lossD: 0.418017 lossG: -0.691331\n",
      "[39: 1630/1795] train lossD: 0.189206 lossG: -0.579533\n",
      "[39: 1635/1795] train lossD: 0.024404 lossG: -0.293379\n",
      "[39: 1640/1795] train lossD: 0.155310 lossG: -0.473297\n",
      "[39: 1645/1795] train lossD: 0.118720 lossG: -0.231114\n",
      "[39: 1650/1795] train lossD: 0.029922 lossG: -0.040198\n",
      "[39: 1655/1795] train lossD: -0.011863 lossG: -0.635146\n",
      "[39: 1660/1795] train lossD: 0.065987 lossG: -0.424944\n",
      "[39: 1665/1795] train lossD: -1.779898 lossG: -0.124964\n",
      "[39: 1670/1795] train lossD: 0.022141 lossG: -0.858362\n",
      "[39: 1675/1795] train lossD: -2.077507 lossG: -0.153195\n",
      "[39: 1680/1795] train lossD: -0.538826 lossG: -0.371539\n",
      "[39: 1685/1795] train lossD: -3.955183 lossG: -2.627894\n",
      "[39: 1690/1795] train lossD: -0.848271 lossG: -0.406270\n",
      "[39: 1695/1795] train lossD: -0.726849 lossG: -2.303108\n",
      "[39: 1700/1795] train lossD: -5.192559 lossG: -4.086478\n",
      "[39: 1705/1795] train lossD: 0.156860 lossG: -0.013562\n",
      "[39: 1710/1795] train lossD: -0.738046 lossG: -0.028017\n",
      "[39: 1715/1795] train lossD: 0.192268 lossG: 0.100182\n",
      "[39: 1720/1795] train lossD: -2.545112 lossG: 0.081509\n",
      "[39: 1725/1795] train lossD: -5.609199 lossG: -0.272857\n",
      "[39: 1730/1795] train lossD: -7.634880 lossG: 0.021824\n",
      "[39: 1735/1795] train lossD: -3.574065 lossG: -0.171974\n",
      "[39: 1740/1795] train lossD: -5.541105 lossG: -0.381061\n",
      "[39: 1745/1795] train lossD: -7.082355 lossG: 0.026621\n",
      "[39: 1750/1795] train lossD: -7.948613 lossG: -0.217834\n",
      "[39: 1755/1795] train lossD: -3.909798 lossG: -0.289696\n",
      "[39: 1760/1795] train lossD: -0.878549 lossG: -0.529607\n",
      "[39: 1765/1795] train lossD: -1.539264 lossG: -0.513762\n",
      "[39: 1770/1795] train lossD: -7.318263 lossG: -0.417876\n",
      "[39: 1775/1795] train lossD: 0.567405 lossG: -0.324723\n",
      "[39: 1780/1795] train lossD: 0.208693 lossG: -0.287447\n",
      "[39: 1785/1795] train lossD: 0.054026 lossG: -0.223098\n",
      "[39: 1790/1795] train lossD: 0.075855 lossG: -0.170917\n",
      "0.030209101736545563\n"
     ]
    }
   ],
   "source": [
    "#another 20 epochs \n",
    "for epoch in tqdm(range(20)):\n",
    "    loss_epoch = []\n",
    "    for i, (imgs) in enumerate(train_loader):\n",
    "\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "        optimizer_D.zero_grad()\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (32, 128))))\n",
    "        fake_imgs = generator(z)\n",
    "        real_validity = discriminator(real_imgs)\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "       # print()\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "\n",
    "        if i % n_critic == 0:\n",
    "\n",
    "            fake_imgs = generator(z)\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake_imgs)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            loss_epoch.append(g_loss.item())\n",
    "            print('[%d: %d/%d] train lossD: %f lossG: %f' %(20 + epoch, i, num_batch, d_loss.item(), g_loss.item()))\n",
    "    \n",
    "    loss_metric.append(np.mean(loss_epoch))\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D.step()\n",
    "  \n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs) in enumerate(train_loader):\n",
    "            real_imgs = Variable(imgs.type(Tensor))\n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (32, 128))))\n",
    "            fake_imgs = generator(z)\n",
    "            metric = evaluate_chamfer(real_imgs, fake_imgs)\n",
    "            print(metric.item())\n",
    "            break\n",
    "        evaluate.append(metric.item())\n",
    "        generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82a9e93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4323050262287134,\n",
       " 0.9222088059343003,\n",
       " 0.7767139810207494,\n",
       " 0.7275533637960642,\n",
       " 0.6970954487582767,\n",
       " 0.6279972803293828,\n",
       " 0.506528032440329,\n",
       " 0.45121871902085947,\n",
       " 0.45607200335493325,\n",
       " 0.44971108478091887,\n",
       " 0.4427383228264811,\n",
       " 0.4037037217019328,\n",
       " 0.37972715563428766,\n",
       " 0.37237212041128315,\n",
       " 0.3517938849819736,\n",
       " 0.37264720304845766,\n",
       " 0.37103379194035835,\n",
       " 0.3482412675546072,\n",
       " 0.26491313311984777,\n",
       " 0.18868337146040248,\n",
       " 0.028184454581988223,\n",
       " -0.07199223144472808,\n",
       " 0.16016489515874877,\n",
       " 0.6743973408900927,\n",
       " 0.6254090029217074,\n",
       " 0.6307525320969585,\n",
       " 0.632965053190428,\n",
       " 0.5895270662055374,\n",
       " 0.5368644741252272,\n",
       " 0.4228716310020277,\n",
       " 0.3332138168197488,\n",
       " 0.21974149769467813,\n",
       " 0.23078663912822278,\n",
       " 0.2236530573384883,\n",
       " 0.1598041756260196,\n",
       " 0.13880675474394497,\n",
       " 0.1210674116566964,\n",
       " -0.09312290773522057,\n",
       " -0.335221137138068,\n",
       " -0.6389943713472747]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de255399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04706810414791107,\n",
       " 0.04150030016899109,\n",
       " 0.050314679741859436,\n",
       " 0.04303291440010071,\n",
       " 0.03097650408744812,\n",
       " 0.037385858595371246,\n",
       " 0.04351937025785446,\n",
       " 0.038115449249744415,\n",
       " 0.03754439949989319,\n",
       " 0.03710556402802467,\n",
       " 0.05840221047401428,\n",
       " 0.04416750371456146,\n",
       " 0.04391780495643616,\n",
       " 0.04444083571434021,\n",
       " 0.035055823624134064,\n",
       " 0.05547195300459862,\n",
       " 0.05058055743575096,\n",
       " 0.044261276721954346,\n",
       " 0.04403220862150192,\n",
       " 0.04144319146871567,\n",
       " 0.038034774363040924,\n",
       " 0.03929232805967331,\n",
       " 0.04248970001935959,\n",
       " 0.04734976589679718,\n",
       " 0.047086551785469055,\n",
       " 0.044641152024269104,\n",
       " 0.05280192196369171,\n",
       " 0.042118966579437256,\n",
       " 0.03937861695885658,\n",
       " 0.039278384298086166,\n",
       " 0.050072867423295975,\n",
       " 0.03799403831362724,\n",
       " 0.05065019801259041,\n",
       " 0.043432075530290604,\n",
       " 0.04405993968248367,\n",
       " 0.033305034041404724,\n",
       " 0.04320012032985687,\n",
       " 0.05068539083003998,\n",
       " 0.036171235144138336,\n",
       " 0.030209101736545563]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11aaef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    z = Variable(Tensor(np.random.normal(0, 1, (32, 128))))\n",
    "    generated_pcd = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "277aa798",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = generated_pcd[31]\n",
    "points = pcd.permute(1,0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4cff589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "points = o3d.utility.Vector3dVector(points) \n",
    "pcd.points = points\n",
    "o3d.visualization.draw_geometries([pcd]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b89f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
